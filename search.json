[{"path":[]},{"path":"https://easystats.github.io/parameters/CODE_OF_CONDUCT.html","id":"our-pledge","dir":"","previous_headings":"","what":"Our Pledge","title":"Contributor Covenant Code of Conduct","text":"members, contributors, leaders pledge make participation community harassment-free experience everyone, regardless age, body size, visible invisible disability, ethnicity, sex characteristics, gender identity expression, level experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, sexual identity orientation. pledge act interact ways contribute open, welcoming, diverse, inclusive, healthy community.","code":""},{"path":"https://easystats.github.io/parameters/CODE_OF_CONDUCT.html","id":"our-standards","dir":"","previous_headings":"","what":"Our Standards","title":"Contributor Covenant Code of Conduct","text":"Examples behavior contributes positive environment community include: Demonstrating empathy kindness toward people respectful differing opinions, viewpoints, experiences Giving gracefully accepting constructive feedback Accepting responsibility apologizing affected mistakes, learning experience Focusing best just us individuals, overall community Examples unacceptable behavior include: use sexualized language imagery, sexual attention advances kind Trolling, insulting derogatory comments, personal political attacks Public private harassment Publishing others’ private information, physical email address, without explicit permission conduct reasonably considered inappropriate professional setting","code":""},{"path":"https://easystats.github.io/parameters/CODE_OF_CONDUCT.html","id":"enforcement-responsibilities","dir":"","previous_headings":"","what":"Enforcement Responsibilities","title":"Contributor Covenant Code of Conduct","text":"Community leaders responsible clarifying enforcing standards acceptable behavior take appropriate fair corrective action response behavior deem inappropriate, threatening, offensive, harmful. Community leaders right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct, communicate reasons moderation decisions appropriate.","code":""},{"path":"https://easystats.github.io/parameters/CODE_OF_CONDUCT.html","id":"scope","dir":"","previous_headings":"","what":"Scope","title":"Contributor Covenant Code of Conduct","text":"Code Conduct applies within community spaces, also applies individual officially representing community public spaces. Examples representing community include using official e-mail address, posting via official social media account, acting appointed representative online offline event.","code":""},{"path":"https://easystats.github.io/parameters/CODE_OF_CONDUCT.html","id":"enforcement","dir":"","previous_headings":"","what":"Enforcement","title":"Contributor Covenant Code of Conduct","text":"Instances abusive, harassing, otherwise unacceptable behavior may reported community leaders responsible enforcement d.luedecke@uke.de. complaints reviewed investigated promptly fairly. community leaders obligated respect privacy security reporter incident.","code":""},{"path":"https://easystats.github.io/parameters/CODE_OF_CONDUCT.html","id":"enforcement-guidelines","dir":"","previous_headings":"","what":"Enforcement Guidelines","title":"Contributor Covenant Code of Conduct","text":"Community leaders follow Community Impact Guidelines determining consequences action deem violation Code Conduct:","code":""},{"path":"https://easystats.github.io/parameters/CODE_OF_CONDUCT.html","id":"id_1-correction","dir":"","previous_headings":"Enforcement Guidelines","what":"1. Correction","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Use inappropriate language behavior deemed unprofessional unwelcome community. Consequence: private, written warning community leaders, providing clarity around nature violation explanation behavior inappropriate. public apology may requested.","code":""},{"path":"https://easystats.github.io/parameters/CODE_OF_CONDUCT.html","id":"id_2-warning","dir":"","previous_headings":"Enforcement Guidelines","what":"2. Warning","title":"Contributor Covenant Code of Conduct","text":"Community Impact: violation single incident series actions. Consequence: warning consequences continued behavior. interaction people involved, including unsolicited interaction enforcing Code Conduct, specified period time. includes avoiding interactions community spaces well external channels like social media. Violating terms may lead temporary permanent ban.","code":""},{"path":"https://easystats.github.io/parameters/CODE_OF_CONDUCT.html","id":"id_3-temporary-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"3. Temporary Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: serious violation community standards, including sustained inappropriate behavior. Consequence: temporary ban sort interaction public communication community specified period time. public private interaction people involved, including unsolicited interaction enforcing Code Conduct, allowed period. Violating terms may lead permanent ban.","code":""},{"path":"https://easystats.github.io/parameters/CODE_OF_CONDUCT.html","id":"id_4-permanent-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"4. Permanent Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Demonstrating pattern violation community standards, including sustained inappropriate behavior, harassment individual, aggression toward disparagement classes individuals. Consequence: permanent ban sort public interaction within community.","code":""},{"path":"https://easystats.github.io/parameters/CODE_OF_CONDUCT.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Contributor Covenant Code of Conduct","text":"Code Conduct adapted Contributor Covenant, version 2.1, available https://www.contributor-covenant.org/version/2/1/code_of_conduct.html. Community Impact Guidelines inspired [Mozilla’s code conduct enforcement ladder][https://github.com/mozilla/inclusion]. answers common questions code conduct, see FAQ https://www.contributor-covenant.org/faq. Translations available https://www.contributor-covenant.org/translations.","code":""},{"path":"https://easystats.github.io/parameters/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contributing to parameters","title":"Contributing to parameters","text":"outlines propose change parameters.","code":""},{"path":"https://easystats.github.io/parameters/CONTRIBUTING.html","id":"fixing-typos","dir":"","previous_headings":"","what":"Fixing typos","title":"Contributing to parameters","text":"Small typos grammatical errors documentation may edited directly using GitHub web interface, long changes made source file. want fix typos documentation, please edit related .R file R/ folder. edit .Rd file man/.","code":""},{"path":"https://easystats.github.io/parameters/CONTRIBUTING.html","id":"filing-an-issue","dir":"","previous_headings":"","what":"Filing an issue","title":"Contributing to parameters","text":"easiest way propose change new feature file issue. ’ve found bug, may also create associated issue. possible, try illustrate proposal bug minimal reproducible example.","code":""},{"path":"https://easystats.github.io/parameters/CONTRIBUTING.html","id":"pull-requests","dir":"","previous_headings":"","what":"Pull requests","title":"Contributing to parameters","text":"Please create Git branch pull request (PR). contributed code roughly follow R style guide, particular easystats convention code-style. parameters uses roxygen2, Markdown syntax, documentation. parameters uses testthat. Adding tests PR makes easier merge PR code base. PR user-visible change, may add bullet top NEWS.md describing changes made. may optionally add GitHub username, links relevant issue(s)/PR(s).","code":""},{"path":"https://easystats.github.io/parameters/CONTRIBUTING.html","id":"code-of-conduct","dir":"","previous_headings":"","what":"Code of Conduct","title":"Contributing to parameters","text":"Please note project released Contributor Code Conduct. participating project agree abide terms.","code":""},{"path":"https://easystats.github.io/parameters/articles/clustering.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Clustering with easystats","text":"Clustering traditionally refers identification groups observations (.e., data rows). differs methods like PCA Factor Analysis, usually applied variables (.e., columns). said, possible transpose data (columns become rows) apply clustering variables. many clustering algorithms (see overview), can grouped two categories: supervised unsupervised techniques. supervised techniques, explicitly specify many clusters want extract. Unsupervised techniques, hand, estimate number part algorithm. Note inherently superior inferior clustering methods, come sets limitations benefits. example tutorial , use iris dataset, know 3 “real” clusters (3 Species flowers). Let’s first start visualizing 3 “real” clusters 2D space variables created PCA.  setosa species stands quite clearly PCA space, separation two species appear less clear cut. Let’s see data-driven clustering performs, manage retrieve 3 clusters.","code":"library(ggplot2) library(parameters) library(see)  set.seed(33) # Set random seed  # Select the first 4 numeric columns (drop the Species fator) data <- iris[1:4] head(data) # Print the 6 first rows #>   Sepal.Length Sepal.Width Petal.Length Petal.Width #> 1          5.1         3.5          1.4         0.2 #> 2          4.9         3.0          1.4         0.2 #> 3          4.7         3.2          1.3         0.2 #> 4          4.6         3.1          1.5         0.2 #> 5          5.0         3.6          1.4         0.2 #> 6          5.4         3.9          1.7         0.4  # Run PCA pca <- principal_components(data, n = 2) pca_scores <- predict(pca, names = c(\"PCA_1\", \"PCA_2\")) pca_scores$True_Clusters <- iris$Species # Add real clusters  # Visualize ggplot(pca_scores, aes(x = PCA_1, y = PCA_2, color = True_Clusters)) +   geom_point() +   theme_modern()"},{"path":[]},{"path":"https://easystats.github.io/parameters/articles/clustering.html","id":"how-many-clusters-to-extract","dir":"Articles","previous_headings":"Supervised Clustering Methods","what":"How Many Clusters to Extract?","title":"Clustering with easystats","text":"easy answer important question. best way strong expectations hypotheses. don’t, well, researchers came data-driven solutions estimate optimal number clusters. problem now lot numerical methods, don’t always agree… clearly better method, implemented easystats consensus-based algorithm runs many methods, returns number clusters agreed upon.  can see, methods suggest existence 2 clusters, followed 3-clusters solution. seems like data clearly discriminate 3 species flowers. discrepancy , can recover real-world data, fundamental issue data science.","code":"n <- n_clusters(data, package = c(\"easystats\", \"NbClust\", \"mclust\")) n #> # Method Agreement Procedure: #>  #> The choice of 2 clusters is supported by 15 (51.72%) methods out of 29 (Elbow, Silhouette, Gap_Maechler2012, Gap_Dudoit2002, Ch, DB, Duda, Pseudot2, Beale, Ratkowsky, PtBiserial, Mcclain, Dunn, SDindex, Mixture (VVV)). plot(n)"},{"path":"https://easystats.github.io/parameters/articles/clustering.html","id":"k-means","dir":"Articles","previous_headings":"Supervised Clustering Methods","what":"K-Means","title":"Clustering with easystats","text":"won’t go much details mathematics intuition behind clustering methods, good resources available internet. Instead, ’ll focus apply . K-means one basic clustering algorithm, available base R kmeans() function. However, provide easystats unified function run different clustering algorithms: cluster_analysis(). (Note k-means non-deterministic algorithm; running multiple times result different results!) Now know many clusters want extract (let’s say strong hypothesis 3, partially supported consensus method estimating optimal number clusters). Note can also visualize centers (.e., “average” variable cluster):  One can extract cluster assignments use new variable using predict().","code":"rez_kmeans <- cluster_analysis(data, n = 3, method = \"kmeans\")  rez_kmeans # Show results #> # Clustering Solution #>  #> The 3 clusters accounted for 76.70% of the total variance of the original data. #>  #> Cluster | n_Obs | Sum_Squares | Sepal.Length | Sepal.Width | Petal.Length | Petal.Width #> --------------------------------------------------------------------------------------- #> 1       |    53 |       44.09 |        -0.05 |       -0.88 |         0.35 |        0.28 #> 2       |    47 |       47.45 |         1.13 |        0.09 |         0.99 |        1.01 #> 3       |    50 |       47.35 |        -1.01 |        0.85 |        -1.30 |       -1.25 #>  #> # Indices of model performance #>  #> Sum_Squares_Total | Sum_Squares_Between | Sum_Squares_Within |    R2 #> -------------------------------------------------------------------- #> 596.000           |             457.112 |            138.888 | 0.767 #>  #> # You can access the predicted clusters via 'predict()'. plot(summary(rez_kmeans)) # Visualize cluster centers predict(rez_kmeans) # Get clusters #>   [1] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 #>  [38] 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 1 1 1 2 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 #>  [75] 1 2 2 2 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 2 2 2 1 2 2 2 2 #> [112] 2 2 1 1 2 2 2 2 1 2 1 2 1 2 2 1 2 2 2 2 2 2 1 1 2 2 2 1 2 2 2 1 2 2 2 1 2 #> [149] 2 1"},{"path":"https://easystats.github.io/parameters/articles/clustering.html","id":"hierarchical-clustering","dir":"Articles","previous_headings":"Supervised Clustering Methods","what":"Hierarchical Clustering","title":"Clustering with easystats","text":"Hierarchical clustering also common clustering algorithm, available base R hclust() function. method bit different sense straight return clusters. Instead, creates hierarchical structure (dendrogram), tree can cut branches get given number clusters. Note “tree” cutting can done unsupervised fashion using bootstrapping (apply next section).","code":"rez_hclust <- cluster_analysis(data, n = 3, method = \"hclust\")  rez_hclust # Show results #> # Clustering Solution #>  #> The 3 clusters accounted for 74.35% of the total variance of the original data. #>  #> Cluster | n_Obs | Sum_Squares | Sepal.Length | Sepal.Width | Petal.Length | Petal.Width #> --------------------------------------------------------------------------------------- #> 1       |    49 |       40.12 |        -1.00 |        0.90 |        -1.30 |       -1.25 #> 2       |    24 |       18.65 |        -0.40 |       -1.36 |         0.06 |       -0.04 #> 3       |    77 |       94.08 |         0.76 |       -0.15 |         0.81 |        0.81 #>  #> # Indices of model performance #>  #> Sum_Squares_Total | Sum_Squares_Between | Sum_Squares_Within |    R2 #> -------------------------------------------------------------------- #> 596.000           |             443.143 |            152.857 | 0.744 #>  #> # You can access the predicted clusters via 'predict()'.  # Visualize plot(rez_hclust) + theme_modern() # Visualize"},{"path":"https://easystats.github.io/parameters/articles/clustering.html","id":"hierarchical-k-means","dir":"Articles","previous_headings":"Supervised Clustering Methods","what":"Hierarchical K-Means","title":"Clustering with easystats","text":"Hierarchical K-Means, name suggest, essentially combination K-Means hierarchical clustering aims improving stability robustness results.","code":"rez_hkmeans <- cluster_analysis(data, n = 3, method = \"hkmeans\")  rez_hkmeans # Show results #> # Clustering Solution #>  #> The 3 clusters accounted for 76.70% of the total variance of the original data. #>  #> Cluster | n_Obs | Sum_Squares | Sepal.Length | Sepal.Width | Petal.Length | Petal.Width #> --------------------------------------------------------------------------------------- #> 1       |    50 |       47.35 |        -1.01 |        0.85 |        -1.30 |       -1.25 #> 2       |    53 |       44.09 |        -0.05 |       -0.88 |         0.35 |        0.28 #> 3       |    47 |       47.45 |         1.13 |        0.09 |         0.99 |        1.01 #>  #> # Indices of model performance #>  #> Sum_Squares_Total | Sum_Squares_Between | Sum_Squares_Within |    R2 #> -------------------------------------------------------------------- #> 596.000           |             457.112 |            138.888 | 0.767 #>  #> # You can access the predicted clusters via 'predict()'.  # Visualize plot(rez_hkmeans) + theme_modern() # Visualize"},{"path":"https://easystats.github.io/parameters/articles/clustering.html","id":"k-medoids-pam","dir":"Articles","previous_headings":"Supervised Clustering Methods","what":"K-Medoids (PAM)","title":"Clustering with easystats","text":"Clustering around “medoids”, instead “centroid”, considered robust version K-means. See cluster::pam() information.","code":"rez_pam <- cluster_analysis(data, n = 3, method = \"pam\")  rez_pam # Show results #> # Clustering Solution #>  #> The 3 clusters accounted for 76.46% of the total variance of the original data. #>  #> Cluster | n_Obs | Sum_Squares | Sepal.Length | Sepal.Width | Petal.Length | Petal.Width #> --------------------------------------------------------------------------------------- #> 1       |    50 |       47.35 |        -1.01 |        0.85 |        -1.30 |       -1.25 #> 2       |    45 |       45.26 |         1.17 |        0.06 |         1.02 |        1.05 #> 3       |    55 |       47.67 |        -0.04 |       -0.82 |         0.35 |        0.28 #>  #> # Indices of model performance #>  #> Sum_Squares_Total | Sum_Squares_Between | Sum_Squares_Within |    R2 #> -------------------------------------------------------------------- #> 596.000           |             455.714 |            140.286 | 0.765 #>  #> # You can access the predicted clusters via 'predict()'.  # Visualize plot(rez_pam) + theme_modern() # Visualize"},{"path":"https://easystats.github.io/parameters/articles/clustering.html","id":"unsupervised-clustering-methods","dir":"Articles","previous_headings":"","what":"Unsupervised Clustering Methods","title":"Clustering with easystats","text":"Unsupervised clustering methods estimate optimal number clusters (hence, n = NULL don’t pre-specify given number clusters). Note unsupervised methods can sometimes identify observations fit clusters (.e., “outliers”). classified belonging cluster “0” (real cluster, rather groups outliers).","code":""},{"path":"https://easystats.github.io/parameters/articles/clustering.html","id":"bootstrapped-hierarchical-clustering","dir":"Articles","previous_headings":"Unsupervised Clustering Methods","what":"Bootstrapped Hierarchical Clustering","title":"Clustering with easystats","text":"method computes p-values cluster hierarchical cluster structure, returns significant clusters. method can return larger number smaller clusters , ’s based bootstrapping, quite slow.","code":"rez_hclust2 <- cluster_analysis(data,   n = NULL,   method = \"hclust\",   iterations = 500,   ci = 0.90 )  rez_hclust2 # Show results #> # Clustering Solution #>  #> The 25 clusters accounted for 48.37% of the total variance of the original data. #>  #> Cluster | n_Obs | Sum_Squares | Sepal.Length | Sepal.Width | Petal.Length | Petal.Width #> --------------------------------------------------------------------------------------- #> 0       |    89 |      304.31 |         0.11 |       -0.19 |         0.12 |        0.12 #> 1       |     2 |    7.29e-03 |        -0.96 |        0.79 |        -1.28 |       -1.31 #> 10      |     2 |        0.02 |        -0.23 |       -0.13 |         0.22 |        0.07 #> 11      |     2 |        0.02 |         0.49 |        0.79 |         0.99 |        1.51 #> 12      |     2 |        0.03 |        -0.41 |       -0.13 |         0.42 |        0.39 #> 13      |     2 |        0.03 |        -1.02 |        0.44 |        -1.39 |       -1.31 #> 14      |     2 |        0.03 |        -1.08 |       -1.62 |        -0.26 |       -0.26 #> 15      |     3 |        0.07 |        -1.78 |       -0.21 |        -1.41 |       -1.35 #> 16      |     3 |        0.09 |        -0.13 |       -0.74 |         0.72 |        0.96 #> 17      |     3 |        0.12 |        -0.50 |        0.86 |        -1.28 |       -1.22 #> 18      |     3 |        0.09 |        -1.34 |        0.79 |        -1.20 |       -1.27 #> 19      |     2 |        0.08 |         2.18 |       -0.13 |         1.47 |        1.31 #> 2       |     2 |    7.29e-03 |        -0.60 |        1.47 |        -1.28 |       -1.31 #> 20      |     2 |        0.10 |        -0.60 |        2.51 |        -1.31 |       -1.38 #> 21      |     2 |        0.15 |         1.64 |        0.10 |         1.21 |        0.66 #> 22      |     3 |        0.22 |         0.39 |       -1.89 |         0.50 |        0.31 #> 23      |     7 |        1.42 |         0.29 |        0.23 |         0.57 |        0.66 #> 24      |     3 |        0.80 |         2.12 |        1.55 |         1.50 |        1.36 #> 3       |     2 |    8.61e-03 |         0.67 |       -0.59 |         1.04 |        1.25 #> 4       |     2 |        0.01 |        -0.41 |       -1.51 |    -4.53e-03 |       -0.20 #> 5       |     2 |        0.01 |        -0.90 |        1.70 |        -1.25 |       -1.25 #> 6       |     2 |        0.01 |         1.22 |        0.33 |         1.16 |        1.44 #> 7       |     2 |        0.02 |        -1.08 |        1.25 |        -1.34 |       -1.38 #> 8       |     3 |        0.02 |        -0.94 |        1.02 |        -1.35 |       -1.22 #> 9       |     3 |        0.02 |        -1.18 |        0.10 |        -1.26 |       -1.35 #>  #> # Indices of model performance #>  #> Sum_Squares_Total | Sum_Squares_Between | Sum_Squares_Within |    R2 #> -------------------------------------------------------------------- #> 596.000           |             288.295 |              3.390 | 0.484 #>  #> # You can access the predicted clusters via 'predict()'. plot(rez_hclust2) + theme_modern() # Visualize"},{"path":"https://easystats.github.io/parameters/articles/clustering.html","id":"dbscan","dir":"Articles","previous_headings":"Unsupervised Clustering Methods","what":"DBSCAN","title":"Clustering with easystats","text":"Although DBSCAN method quite powerful identify clusters, highly dependent parameters, namely, eps min_size. Regarding latter, minimum size cluster set default 0.1 (.e., 10% rows), appropriate avoid small clusters. “optimal” eps value can estimated using n_clusters_dbscan() function:  seems like numeric method find elbow curve doesn’t work well, returns value high. Based visual assessment, elbow seems located around eps = 1.45.","code":"eps <- n_clusters_dbscan(data, min_size = 0.1) eps #> The DBSCAN method, based on the total clusters sum of squares, suggests that the optimal eps = 2.11193281281293 (with min. cluster size set to 15), which corresponds to 1 clusters. plot(eps) rez_dbscan <- cluster_analysis(data, method = \"dbscan\", dbscan_eps = 1.45)  rez_dbscan # Show results #> # Clustering Solution #>  #> The 3 clusters accounted for 61.14% of the total variance of the original data. #>  #> Cluster | n_Obs | Sum_Squares | Sepal.Length | Sepal.Width | Petal.Length | Petal.Width #> --------------------------------------------------------------------------------------- #> 0       |     5 |       47.84 |         1.03 |        0.74 |         0.45 |        0.32 #> 1       |    48 |       34.54 |        -1.02 |        0.86 |        -1.30 |       -1.26 #> 2       |    97 |      149.21 |         0.45 |       -0.46 |         0.62 |        0.61 #>  #> # Indices of model performance #>  #> Sum_Squares_Total | Sum_Squares_Between | Sum_Squares_Within |    R2 #> -------------------------------------------------------------------- #> 596.000           |             364.406 |            183.751 | 0.611 #>  #> # You can access the predicted clusters via 'predict()'. plot(rez_dbscan) + theme_modern() # Visualize"},{"path":"https://easystats.github.io/parameters/articles/clustering.html","id":"hierarchical-k-means-1","dir":"Articles","previous_headings":"Unsupervised Clustering Methods","what":"Hierarchical K-Means","title":"Clustering with easystats","text":"Hierarchical DBSCAN variant require critical EPS argument. computes hierarchy DBSCAN solutions, finds optimal cuts hierarchy using stability-based extraction method.","code":"rez_hdbscan <- cluster_analysis(data, method = \"hdbscan\")  rez_hdbscan # Show results #> # Clustering Solution #>  #> The 3 clusters accounted for 66.08% of the total variance of the original data. #>  #> Cluster | n_Obs | Sum_Squares | Sepal.Length | Sepal.Width | Petal.Length | Petal.Width #> --------------------------------------------------------------------------------------- #> 0       |     2 |        0.08 |         2.36 |        1.70 |         1.58 |        1.18 #> 1       |    98 |      154.76 |         0.47 |       -0.47 |         0.63 |        0.61 #> 2       |    50 |       47.35 |        -1.01 |        0.85 |        -1.30 |       -1.25 #>  #> # Indices of model performance #>  #> Sum_Squares_Total | Sum_Squares_Between | Sum_Squares_Within |    R2 #> -------------------------------------------------------------------- #> 596.000           |             393.813 |            202.108 | 0.661 #>  #> # You can access the predicted clusters via 'predict()'.  # Visualize plot(rez_hdbscan) + theme_modern() # Visualize"},{"path":"https://easystats.github.io/parameters/articles/clustering.html","id":"k-medoids-with-estimation-of-number-of-clusters-pamk","dir":"Articles","previous_headings":"Unsupervised Clustering Methods","what":"K-Medoids with estimation of number of clusters (pamk)","title":"Clustering with easystats","text":"K-Medoids integrated estimation number clusters. See fpc::pamk details.","code":"rez_pamk <- cluster_analysis(data, method = \"pamk\")  rez_pamk # Show results #> # Clustering Solution #>  #> The 2 clusters accounted for 62.94% of the total variance of the original data. #>  #> Cluster | n_Obs | Sum_Squares | Sepal.Length | Sepal.Width | Petal.Length | Petal.Width #> --------------------------------------------------------------------------------------- #> 1       |    50 |       47.35 |        -1.01 |        0.85 |        -1.30 |       -1.25 #> 2       |   100 |      173.53 |         0.51 |       -0.43 |         0.65 |        0.63 #>  #> # Indices of model performance #>  #> Sum_Squares_Total | Sum_Squares_Between | Sum_Squares_Within |    R2 #> -------------------------------------------------------------------- #> 596.000           |             375.121 |            220.879 | 0.629 #>  #> # You can access the predicted clusters via 'predict()'.  # Visualize plot(rez_pamk) + theme_modern() # Visualize"},{"path":"https://easystats.github.io/parameters/articles/clustering.html","id":"mixture","dir":"Articles","previous_headings":"Unsupervised Clustering Methods","what":"Mixture","title":"Clustering with easystats","text":"Model-based clustering based finite Gaussian mixture models. Models estimated EM algorithm initialized hierarchical model-based agglomerative clustering. optimal model selected according BIC.","code":"library(mclust)  rez_mixture <- cluster_analysis(data, method = \"mixture\")  rez_mixture # Show results #> # Clustering Solution #>  #> The 2 clusters accounted for 62.94% of the total variance of the original data. #>  #> Cluster | n_Obs | Sum_Squares | Sepal.Length | Sepal.Width | Petal.Length | Petal.Width #> --------------------------------------------------------------------------------------- #> 1       |    50 |       47.35 |        -1.01 |        0.85 |        -1.30 |       -1.25 #> 2       |   100 |      173.53 |         0.51 |       -0.43 |         0.65 |        0.63 #>  #> # Indices of model performance #>  #> Sum_Squares_Total | Sum_Squares_Between | Sum_Squares_Within |    R2 #> -------------------------------------------------------------------- #> 596.000           |             375.121 |            220.879 | 0.629 #>  #> # You can access the predicted clusters via 'predict()'.  # Visualize plot(rez_mixture) + theme_modern() # Visualize"},{"path":"https://easystats.github.io/parameters/articles/clustering.html","id":"metaclustering","dir":"Articles","previous_headings":"","what":"Metaclustering","title":"Clustering with easystats","text":"One core “issue” statistical clustering , many cases, different methods give different results. metaclustering approach proposed easystats (finds echoes consensus clustering; see Monti et al., 2003) consists treating unique clustering solutions ensemble, can derive probability matrix. matrix contains, pair observations, probability cluster. instance, 6th 9th row dataframe assigned similar cluster 5 10 clustering methods, probability grouped together 0.5. Metaclustering based hypothesis , clustering algorithm embodies different prism sees data, running infinite amount algorithms result emergence “true” clusters. number algorithms parameters finite, probabilistic perspective useful proxy. method interesting obvious reasons prefer one another clustering method, well investigate robust clusters different algorithms.  dendrogram (hierarchical clustering clustering solution, hence name metaclustering), well heatmap (darker squares represent higher probability belonging cluster) shows one metacluster consisting 1-50 first rows (bottom left), rest observations closer one another. However, two subclusters still visible, corresponding “true” species. metaclustering approach confirms initial hypothesis, setosa species stands quite clearly, separation two species less clear cut.","code":"list_of_results <- list(   rez_kmeans, rez_hclust, rez_hkmeans, rez_pam,   rez_hclust2, rez_dbscan, rez_hdbscan, rez_mixture )  probability_matrix <- cluster_meta(list_of_results)  # Plot the matrix as a reordered heatmap heatmap(probability_matrix,   scale = \"none\",   col = grDevices::hcl.colors(256, palette = \"inferno\") )"},{"path":"https://easystats.github.io/parameters/articles/clustering.html","id":"resources","dir":"Articles","previous_headings":"","what":"Resources","title":"Clustering with easystats","text":"Clustering algorithms overview Density-based Clustering","code":""},{"path":"https://easystats.github.io/parameters/articles/demean.html","id":"sample-data-used-in-this-vignette","dir":"Articles","previous_headings":"","what":"Sample data used in this vignette","title":"Analysing Longitudinal or Panel Data","text":"Variables: QoL : Response (quality life patient) phq4 : Patient Health Questionnaire, time-varying variable hospital : Location treatment, time-invariant variable, co-variate education: Educational level, time-invariant variable, co-variate ID : patient ID time : time-point measurement","code":"library(parameters) data(\"qol_cancer\")"},{"path":"https://easystats.github.io/parameters/articles/demean.html","id":"heterogeneity-bias","dir":"Articles","previous_headings":"","what":"Heterogeneity bias","title":"Analysing Longitudinal or Panel Data","text":"Heterogeneity bias occurs group-level predictors vary within across groups, hence fixed effects may correlate group (random) effects. typical situation analyzing longitudinal panel data: Due repeated measurements persons, “person” (subject-ID) now level-2 variable. Predictors level-1 (“fixed effects”), e.g. self-rated health income, now effect level-1 (“within”-effect) higher-level units (level-2, subject-level, “”-effect) (see also posting). inevitably leads correlating fixed effects error terms - , turn, results biased estimates, within- -effect captured one estimate. can check model may suffer heterogeneity bias using check_heterogeneity_bias() function:","code":"library(performance) check_heterogeneity_bias(qol_cancer, select = c(\"phq4\", \"education\"), group = \"ID\") #> Possible heterogeneity bias due to following predictors: phq4"},{"path":"https://easystats.github.io/parameters/articles/demean.html","id":"adressing-heterogeneity-bias-the-fixed-effects-regression-fe-approach","dir":"Articles","previous_headings":"","what":"Adressing heterogeneity bias: the Fixed Effects Regression (FE) approach","title":"Analysing Longitudinal or Panel Data","text":"Fixed effects regression models (FE) popular approach panel data analysis particular econometrics considered gold standard. avoid problem heterogeneity bias, FE higher-level variance (thus, -effects), “controlled using higher-level entities , included model dummy variables” (Bell Jones 2015). consequence, FE models able estimate within-effects. remove -effects model within-effects, data needs preparation: de-meaning. De-meaning, person-mean centering, centering within clusters, takes away higher-level mean regression equation, , FE avoids estimating parameter higher-level unit.","code":""},{"path":"https://easystats.github.io/parameters/articles/demean.html","id":"computing-the-de-meaned-and-group-meaned-variables","dir":"Articles","previous_headings":"Adressing heterogeneity bias: the Fixed Effects Regression (FE) approach","what":"Computing the de-meaned and group-meaned variables","title":"Analysing Longitudinal or Panel Data","text":"Now : phq4_between: time-varying variable mean phq4 across time-points, patient (ID). phq4_within: de-meaned time-varying variable phq4. FE model classical linear model, Intercept removed time-invariant predictors allowed included group-level factor included predictor time-varying predictors de-meaned (“person-mean centered”, indicating “within-subject” effect) can see, within-effect PHQ-4 -3.66, hence mean change average individual case sample (, “net” effect), -3.66. -effect? people higher PHQ-4 score differ people lower PHQ-4 score? educational inequalities? higher educated people higher PHQ-4 score lower educated people? question answered FE regression. : “Can one fit multilevel model varying intercepts (coefficients) units predictors correlate? answer yes. solution simple.” (Bafumi Gelman 2006)","code":"qol_cancer <- cbind(   qol_cancer,   datawizard::demean(qol_cancer, select = c(\"phq4\", \"QoL\"), group = \"ID\") ) fe_model1 <- lm(   QoL ~ 0 + time + phq4_within + ID,   data = qol_cancer ) # we use only the first two rows, because the remaining rows are # the estimates for \"ID\", which is not of interest here... model_parameters(fe_model1)[1:2, ] #> Parameter   | Coefficient |   SE |         95% CI | t(374) |      p #> ------------------------------------------------------------------- #> time        |        1.09 | 0.64 | [-0.17,  2.34] |   1.70 | 0.089  #> phq4 within |       -3.66 | 0.41 | [-4.46, -2.86] |  -8.95 | < .001   # instead of removing the intercept, we could also use the # de-meaned response... fe_model2 <- lm(   QoL_within ~ time + phq4_within + ID,   data = qol_cancer ) model_parameters(fe_model2)[2:3, ] #> Parameter   | Coefficient |   SE |         95% CI | t(374) |      p #> ------------------------------------------------------------------- #> time        |        1.09 | 0.64 | [-0.17,  2.34] |   1.70 | 0.089  #> phq4 within |       -3.66 | 0.41 | [-4.46, -2.86] |  -8.95 | < .001  # we compare the results with those from the \"lfe\"-package for panel data library(lfe) fe_model3 <- felm(   QoL ~ time + phq4 | ID,   data = qol_cancer ) model_parameters(fe_model3) #> # Fixed Effects #>  #> Parameter | Coefficient |   SE |         95% CI | t(374) |      p #> ----------------------------------------------------------------- #> time      |        1.09 | 0.64 | [-0.17,  2.34] |   1.70 | 0.089  #> phq4      |       -3.66 | 0.41 | [-4.46, -2.86] |  -8.95 | < .001"},{"path":"https://easystats.github.io/parameters/articles/demean.html","id":"adressing-heterogeneity-bias-the-mixed-model-approach","dir":"Articles","previous_headings":"","what":"Adressing heterogeneity bias: the Mixed Model approach","title":"Analysing Longitudinal or Panel Data","text":"Mixed models include different levels sources variability (.e. error terms level). Predictors used level-1 varying across higher-level units thus residual errors level-1 higher-level units. “covariates contain two parts: one specific higher-level entity vary occasions, one represents difference occasions, within higher-level entities” (Bell Jones 2015). Hence, error terms correlated covariate, violates one assumptions mixed models (iid, independent identically distributed error terms) - also known described heterogeneity bias. can issue addressed outside FE framework? several ways address using mixed models approach: Correlated group factors predictors problem anyway, partial pooling allows estimates units o borrow strength whole sample shrink toward common mean (Shor et al. (2007)). predictor group factors correlate, one can remove correlation group-meaning (“mean within clusters,” Bafumi Gelman 2006; Gelman Hill 2007, chap. 12.6.). time-varying predictors “decomposed” time-varying time-invariant components (demeaning), mixed models can model within- -subject effects (Bell, Fairbrother, Jones 2019) - approach essentially development long-known recommendation Mundlak (Mundlak 1978). now, follow last recommendation use within- -version phq4. can see, estimates standard errors identical. argument use mixed models, .e. using mixed models panel data yield biased estimates standard errors, based incorrect model specification (Mundlak 1978). , (mixed) model properly specified, estimator mixed model identical ‘within’ (.e. FE) estimator. consequence, use specified mixed model panel data, can even specify complex models including within-effects, -effects random effects variation. mixed models approach can model causes endogeneity explicitly including (separated) within- -effects time-varying fixed effects including time-constant fixed effects. complex models, within-effects naturally change slightly longer identical simpler FE models. “bias”, rather result building complex models: FE models lack information variation group-effects -subject effects. Furthermore, FE models include random slopes, means fixed effects regressions neglecting “cross-cluster differences effects lower-level controls () reduces precision estimated context effects, resulting (…) low statistical power” (Heisig, Schaeffer, Giesecke 2017).","code":"library(lme4) mixed_1 <- lmer(   QoL ~ time + phq4_within + phq4_between + (1 | ID),   data = qol_cancer ) model_parameters(mixed_1) #> # Fixed Effects #>  #> Parameter    | Coefficient |   SE |         95% CI | t(558) |      p #> -------------------------------------------------------------------- #> (Intercept)  |       71.53 | 1.56 | [68.48, 74.59] |  45.98 | < .001 #> time         |        1.09 | 0.64 | [-0.17,  2.34] |   1.70 | 0.089  #> phq4 within  |       -3.66 | 0.41 | [-4.46, -2.86] |  -8.95 | < .001 #> phq4 between |       -6.28 | 0.50 | [-7.27, -5.30] | -12.53 | < .001 #>  #> # Random Effects #>  #> Parameter          | Coefficient |   SE |         95% CI #> -------------------------------------------------------- #> SD (Intercept: ID) |        9.88 | 0.80 | [ 8.43, 11.58] #> SD (Residual)      |       12.37 | 0.45 | [11.51, 13.28]  # compare to FE-model model_parameters(fe_model1)[1:2, ] #> Parameter   | Coefficient |   SE |         95% CI | t(374) |      p #> ------------------------------------------------------------------- #> time        |        1.09 | 0.64 | [-0.17,  2.34] |   1.70 | 0.089  #> phq4 within |       -3.66 | 0.41 | [-4.46, -2.86] |  -8.95 | < .001 mixed_2 <- lmer(   QoL ~ time + phq4_within + phq4_between + education + (1 + time | ID),   data = qol_cancer ) # effects = \"fixed\" will not display random effects, but split the # fixed effects into its between- and within-effects components. model_parameters(mixed_2, effects = \"fixed\") #> Parameter        | Coefficient |   SE |         95% CI | t(554) |      p #> ------------------------------------------------------------------------ #> (Intercept)      |       67.36 | 2.48 | [62.48, 72.23] |  27.15 | < .001 #> time             |        1.09 | 0.66 | [-0.21,  2.39] |   1.65 | 0.099  #> education [mid]  |        5.01 | 2.35 | [ 0.40,  9.62] |   2.14 | 0.033  #> education [high] |        5.52 | 2.75 | [ 0.11, 10.93] |   2.00 | 0.046  #>  #> # Within-Effects #>  #> Parameter   | Coefficient |   SE |         95% CI | t(554) |      p #> ------------------------------------------------------------------- #> phq4 within |       -3.72 | 0.41 | [-4.52, -2.92] |  -9.10 | < .001 #>  #> # Between-Effects #>  #> Parameter    | Coefficient |   SE |         95% CI | t(554) |      p #> -------------------------------------------------------------------- #> phq4 between |       -6.13 | 0.52 | [-7.14, -5.11] | -11.84 | < .001"},{"path":"https://easystats.github.io/parameters/articles/demean.html","id":"conclusion-complex-random-effects-within-between-models","dir":"Articles","previous_headings":"","what":"Conclusion: Complex Random Effects Within-Between Models","title":"Analysing Longitudinal or Panel Data","text":"Depending structure data, best approach analyzing panel data called “complex random effects within-” model (Bell, Fairbrother, Jones 2019): yit = β0 + β1W (xit - ͞xi) + β2B ͞xi + β3 zi + υi0 + υi1 (xit - ͞xi) + εit xit - ͞xi de-meaned predictor, phq4_within ͞xi group-meaned predictor, phq4_between β1W coefficient phq4_within (within-subject) β2B coefficient phq4_between (bewteen-subject) β3 coefficient time-constant predictors, hospital education (bewteen-subject) R-code, model written like : time-constant predictors? demeaning time-varying predictors, “higher level, mean term longer constrained Level 1 effects, free account higher-level variance associated variable” (Bell Jones 2015). Thus, time-constant categorical predictors, -effect, can simply included fixed effects predictor (since ’re constrained level-1 effects). Time-constant continuous group-level predictors (instance, GDP countries) group-meaned, proper “”-effect (Gelman Hill 2007, chap. 12.6.). benefit kind model information within-, - time-constant (.e. ) effects group-level predictors… … can also model variation (group) effects across time (probably space), can even include higher-level units (e.g. nested design cross-classified design two levels): imbalanced groups, .e. large differences N per group? See little example visual example…","code":"rewb <- lmer(   QoL ~ time + phq4_within + phq4_between + education +     (1 + time | ID) + (1 + phq4_within | ID),   data = qol_cancer ) model_parameters(rewb, effects = \"fixed\") #> Parameter        | Coefficient |   SE |         95% CI | t(551) |      p #> ------------------------------------------------------------------------ #> (Intercept)      |       67.18 | 2.39 | [62.49, 71.87] |  28.13 | < .001 #> time             |        1.18 | 0.60 | [-0.01,  2.37] |   1.95 | 0.051  #> education [mid]  |        4.95 | 2.35 | [ 0.34,  9.56] |   2.11 | 0.035  #> education [high] |        5.62 | 2.76 | [ 0.20, 11.04] |   2.04 | 0.042  #>  #> # Within-Effects #>  #> Parameter   | Coefficient |   SE |         95% CI | t(551) |      p #> ------------------------------------------------------------------- #> phq4 within |       -4.50 | 0.58 | [-5.64, -3.36] |  -7.78 | < .001 #>  #> # Between-Effects #>  #> Parameter    | Coefficient |   SE |         95% CI | t(551) |      p #> -------------------------------------------------------------------- #> phq4 between |       -6.11 | 0.52 | [-7.13, -5.10] | -11.81 | < .001 random_parameters(rewb) #> # Random Effects #>  #> Within-Group Variance              119.47 (10.93) #> Between-Group Variance #>   Random Intercept (ID)             107.5 (10.37) #>   Random Intercept (ID.1)           25.76  (5.08) #>   Random Slope (ID.time)             0.49   (0.7) #>   Random Slope (ID.1.phq4_within)   14.37  (3.79) #> Correlations #>   ID.time                           -0.99 #>   ID.phq4_within                     0.44 #> N (groups per factor) #>   ID                                  188 #> Observations                          564"},{"path":"https://easystats.github.io/parameters/articles/demean.html","id":"a-visual-example","dir":"Articles","previous_headings":"","what":"A visual example","title":"Analysing Longitudinal or Panel Data","text":"First, generate fake data implies linear relationship outcome independent variable. objective amount typing errors depends fast (typing speed) can type, however, typing experience , faster can type. Thus, outcome measure “amount typing errors”, predictor “typing speed”. Furthermore, repeated measurements people different “typing experience levels”. results show two sources variation: Overall, experienced typists make less mistakes (group-level pattern). typing faster, typists make mistakes (individual-level pattern). Let’s look raw data…","code":"library(ggplot2) library(poorman) library(see)  set.seed(123) n <- 5 b <- seq(1, 1.5, length.out = 5) x <- seq(2, 2 * n, 2)  d <- do.call(rbind, lapply(1:n, function(i) {   data.frame(     x = seq(1, n, by = .2),     y = 2 * x[i] + b[i] * seq(1, n, by = .2) + rnorm(21),     grp = as.factor(2 * i)   ) }))  d <- d %>%   group_by(grp) %>%   mutate(x = rev(15 - (x + 1.5 * as.numeric(grp)))) %>%   ungroup()  labs <- c(\"very slow\", \"slow\", \"average\", \"fast\", \"very fast\") levels(d$grp) <- rev(labs)  d <- cbind(d, datawizard::demean(d, c(\"x\", \"y\"), group = \"grp\"))"},{"path":"https://easystats.github.io/parameters/articles/demean.html","id":"model-1-linear-relationship-between-typing-errors-and-typing-speed","dir":"Articles","previous_headings":"A visual example","what":"Model 1: Linear relationship between typing errors and typing speed","title":"Analysing Longitudinal or Panel Data","text":"can now assume (linear) relationship typing errors typing speed.  Looking coefficients, following model coefficient -1.92. However, ignored clustered structure data, example due repeated measurements.","code":"m1 <- lm(y ~ x, data = d) model_parameters(m1) #> Parameter   | Coefficient |   SE |         95% CI | t(103) |      p #> ------------------------------------------------------------------- #> (Intercept) |       30.20 | 1.42 | [27.39, 33.00] |  21.34 | < .001 #> x           |       -1.92 | 0.18 | [-2.27, -1.56] | -10.69 | < .001"},{"path":"https://easystats.github.io/parameters/articles/demean.html","id":"model-2-within-subject-effect-of-typing-speed","dir":"Articles","previous_headings":"A visual example","what":"Model 2: Within-subject effect of typing speed","title":"Analysing Longitudinal or Panel Data","text":"fixed effects regression (FE-regression) now remove -effects include within-effects well group-level indicator.  returns coefficient “within”-effect, 1.2, standard error 0.07. Note FE-model take variation subjects account, thus resulting (possibly) biased estimates, biased standard errors.","code":"m2 <- lm(y ~ 0 + x_within + grp, data = d) model_parameters(m2)[1, ] #> Parameter | Coefficient |   SE |       95% CI | t(99) |      p #> -------------------------------------------------------------- #> x within  |        1.20 | 0.07 | [1.06, 1.35] | 16.08 | < .001"},{"path":"https://easystats.github.io/parameters/articles/demean.html","id":"model-3-between-subject-effect-of-typing-speed","dir":"Articles","previous_headings":"A visual example","what":"Model 3: Between-subject effect of typing speed","title":"Analysing Longitudinal or Panel Data","text":"understand, model 1 (m1) returns biased estimate, “weighted average” within- -effects, let us look -effect now.  can see, -effect -2.93, different -1.92 estimated model m1.","code":"m3 <- lm(y ~ x_between, data = d) model_parameters(m3) #> Parameter   | Coefficient |   SE |         95% CI | t(103) |      p #> ------------------------------------------------------------------- #> (Intercept) |       37.83 | 0.62 | [36.59, 39.06] |  60.79 | < .001 #> x between   |       -2.93 | 0.08 | [-3.09, -2.78] | -36.76 | < .001"},{"path":"https://easystats.github.io/parameters/articles/demean.html","id":"model-4-mixed-model-with-within--and-between-subjects","dir":"Articles","previous_headings":"A visual example","what":"Model 4: Mixed model with within- and between-subjects","title":"Analysing Longitudinal or Panel Data","text":"Since FE-models can model within-effects, now use mixed model within- -effects.  see, estimate within-effects biased. Furthermore, get correct -effect well (standard errors differ, variance grouping structure accurately taken account).","code":"m4 <- lmer(y ~ x_between + x_within + (1 | grp), data = d) model_parameters(m4) #> # Fixed Effects #>  #> Parameter   | Coefficient |   SE |         95% CI | t(100) |      p #> ------------------------------------------------------------------- #> (Intercept) |       37.83 | 0.33 | [37.17, 38.48] | 114.46 | < .001 #> x between   |       -2.93 | 0.04 | [-3.02, -2.85] | -69.22 | < .001 #> x within    |        1.20 | 0.07 | [ 1.06,  1.35] |  16.22 | < .001 #>  #> # Random Effects #>  #> Parameter           | Coefficient #> --------------------------------- #> SD (Intercept: grp) |        0.00 #> SD (Residual)       |        0.92"},{"path":"https://easystats.github.io/parameters/articles/demean.html","id":"model-5-complex-random-effects-within-between-model","dir":"Articles","previous_headings":"A visual example","what":"Model 5: Complex Random-Effects Within-Between Model","title":"Analysing Longitudinal or Panel Data","text":"Finally, can also take variation subjects account adding random slope. model can called complex “REWB” (random-effects within-) model. Due variation subjects, get larger standard errors within-effect.","code":"m5 <- lmer(y ~ x_between + x_within + (1 + x_within | grp), data = d) model_parameters(m5) #> # Fixed Effects #>  #> Parameter   | Coefficient |   SE |         95% CI |  t(98) |      p #> ------------------------------------------------------------------- #> (Intercept) |       37.95 | 0.34 | [37.28, 38.63] | 111.15 | < .001 #> x between   |       -2.95 | 0.04 | [-3.04, -2.87] | -67.57 | < .001 #> x within    |        1.20 | 0.10 | [ 1.01,  1.40] |  12.16 | < .001 #>  #> # Random Effects #>  #> Parameter                     | Coefficient |   SE |         95% CI #> ------------------------------------------------------------------- #> SD (Intercept: grp)           |        0.09 | 0.22 | [ 0.00, 14.20] #> SD (x_within: grp)            |        0.15 | 0.12 | [ 0.03,  0.69] #> Cor (Intercept~x_within: grp) |       -1.00 | 2.18 | [-1.00,      ] #> SD (Residual)                 |        0.90 | 0.07 | [ 0.78,  1.04]"},{"path":"https://easystats.github.io/parameters/articles/demean.html","id":"balanced-versus-imbalanced-groups","dir":"Articles","previous_headings":"","what":"Balanced versus imbalanced groups","title":"Analysing Longitudinal or Panel Data","text":"“simple” linear slope -effect (also within-effect) (almost) identical “classical” linear regression compared linear mixed models groups balanced, .e. number observation per group similar . Whenever group size imbalanced, “simple” linear slope adjusted. leads different estimates -effects classical mixed models regressions due shrinkage - .e. larger variation group sizes find stronger regularization estimates. Hence, mixed models larger differences number observation per random effects group, -effect differ -effect calculated “classical” regression models. However, shrinkage desired property mixed models usually improves estimates.","code":"set.seed(123) n <- 5 b <- seq(1, 1.5, length.out = 5) x <- seq(2, 2 * n, 2)  d <- do.call(rbind, lapply(1:n, function(i) {   data.frame(     x = seq(1, n, by = .2),     y = 2 * x[i] + b[i] * seq(1, n, by = .2) + rnorm(21),     grp = as.factor(2 * i)   ) }))  # create imbalanced groups d$grp[sample(which(d$grp == 8), 10)] <- 6 d$grp[sample(which(d$grp == 4), 8)] <- 2 d$grp[sample(which(d$grp == 10), 9)] <- 6  d <- d %>%   group_by(grp) %>%   mutate(x = rev(15 - (x + 1.5 * as.numeric(grp)))) %>%   ungroup()  labs <- c(\"very slow\", \"slow\", \"average\", \"fast\", \"very fast\") levels(d$grp) <- rev(labs)  d <- cbind(d, datawizard::demean(d, c(\"x\", \"y\"), group = \"grp\"))  # Between-subject effect of typing speed m1 <- lm(y ~ x_between, data = d) model_parameters(m1) #> Parameter   | Coefficient |   SE |         95% CI | t(103) |      p #> ------------------------------------------------------------------- #> (Intercept) |       38.32 | 1.33 | [35.69, 40.95] |  28.87 | < .001 #> x between   |       -2.81 | 0.16 | [-3.13, -2.49] | -17.47 | < .001  # Between-subject effect of typing speed, accounting for group structure m2 <- lmer(y ~ x_between + (1 | grp), data = d) model_parameters(m2) #> # Fixed Effects #>  #> Parameter   | Coefficient |   SE |         95% CI | t(101) |      p #> ------------------------------------------------------------------- #> (Intercept) |       37.02 | 2.73 | [31.59, 42.44] |  13.54 | < .001 #> x between   |       -2.71 | 0.35 | [-3.40, -2.02] |  -7.81 | < .001 #>  #> # Random Effects #>  #> Parameter           | Coefficient |   SE |       95% CI #> ------------------------------------------------------- #> SD (Intercept: grp) |        1.54 | 0.77 | [0.58, 4.09] #> SD (Residual)       |        2.98 | 0.21 | [2.60, 3.42]"},{"path":[]},{"path":"https://easystats.github.io/parameters/articles/efa_cfa.html","id":"how-to-perform-a-factor-analysis-fa","dir":"Articles","previous_headings":"","what":"How to perform a Factor Analysis (FA)","title":"Structural Models (EFA, CFA, SEM, ...)","text":"difference PCA EFA can quite hard intuitively grasp output familiar. idea PCA aims extracting variance possible variables dataset, whereas EFA aims creating consistent factors dataset without desperately trying represent variables. PCA popular feature reduction, try best represent variance contained original data, minimizing loss information. hand, EFA usually context exploring latent dimensions might hidden observed variables, without necessarily striving represent whole dataset. illustrate EFA, let us use International Personality Item Pool data available psych package. includes 25 personality self report items. authors built items following big 5 personality structure.","code":""},{"path":"https://easystats.github.io/parameters/articles/efa_cfa.html","id":"factor-structure-sphericity-and-kmo","dir":"Articles","previous_headings":"How to perform a Factor Analysis (FA)","what":"Factor Structure (Sphericity and KMO)","title":"Structural Models (EFA, CFA, SEM, ...)","text":"first step test dataset suitable carrying factor analysis. two Bartlett’s Test Sphericity: tests whether matrix (correlations) significantly different identity matrix. test provides probability correlation matrix significant correlations among least variables dataset, prerequisite factor analysis work. words, starting factor analysis, one needs check whether Bartlett’s test sphericity significant. Kaiser, Meyer, Olkin (KMO) Measure Sampling Adequacy (MSA): test introduced Kaiser (1970) Measure Sampling Adequacy (MSA), later modified Kaiser Rice (1974). Kaiser-Meyer-Olkin (KMO) statistic, can vary 0 1, indicates degree variable set predicted without error variables. value 0 indicates sum partial correlations large relative sum correlations, indicating factor analysis likely inappropriate. KMO value close 1 indicates sum partial correlations large relative sum correlations factor analysis yield distinct reliable factors. tests can performed using check_factorstructure() function.","code":"library(parameters) library(psych)  # Load the data data <- psych::bfi[, 1:25] # Select only the 25 first columns corresponding to the items data <- na.omit(data) # remove missing values  # Check factor structure check_factorstructure(data) #> # Is the data suitable for Factor Analysis? #>  #>   - KMO: The Kaiser, Meyer, Olkin (KMO) measure of sampling adequacy suggests that data seems appropriate for factor analysis (KMO = 0.85). #>   - Sphericity: Bartlett's test of sphericity suggests that there is sufficient significant correlation in the data for factor analysis (Chisq(300) = 18146.07, p < .001)."},{"path":"https://easystats.github.io/parameters/articles/efa_cfa.html","id":"exploratory-factor-analysis-efa","dir":"Articles","previous_headings":"How to perform a Factor Analysis (FA)","what":"Exploratory Factor Analysis (EFA)","title":"Structural Models (EFA, CFA, SEM, ...)","text":"Now confident dataset appropriate, explore factor structure made 5 latent variables, corresponding items’ authors theory personality. can see, 25 items nicely spread 5 latent factors, famous big 5. Based model, can now predict back scores individual new variables:","code":"# Fit an EFA efa <- psych::fa(data, nfactors = 5) %>%   model_parameters(sort = TRUE, threshold = \"max\")  efa #> # Rotated loadings from Factor Analysis (oblimin-rotation) #>  #> Variable | MR2  |  MR1  |  MR3  |  MR5  |  MR4  | Complexity | Uniqueness #> ------------------------------------------------------------------------- #> N1       | 0.83 |       |       |       |       |    1.07    |    0.32    #> N2       | 0.78 |       |       |       |       |    1.03    |    0.39    #> N3       | 0.70 |       |       |       |       |    1.08    |    0.46    #> N5       | 0.48 |       |       |       |       |    2.00    |    0.65    #> N4       | 0.47 |       |       |       |       |    2.33    |    0.49    #> E2       |      | 0.67  |       |       |       |    1.08    |    0.45    #> E4       |      | -0.59 |       |       |       |    1.52    |    0.46    #> E1       |      | 0.55  |       |       |       |    1.22    |    0.65    #> E5       |      | -0.42 |       |       |       |    2.68    |    0.59    #> E3       |      | -0.41 |       |       |       |    2.65    |    0.56    #> C2       |      |       | 0.67  |       |       |    1.18    |    0.55    #> C4       |      |       | -0.64 |       |       |    1.13    |    0.52    #> C3       |      |       | 0.57  |       |       |    1.10    |    0.68    #> C5       |      |       | -0.56 |       |       |    1.41    |    0.56    #> C1       |      |       | 0.55  |       |       |    1.20    |    0.65    #> A3       |      |       |       | 0.68  |       |    1.06    |    0.46    #> A2       |      |       |       | 0.66  |       |    1.03    |    0.54    #> A5       |      |       |       | 0.54  |       |    1.48    |    0.53    #> A4       |      |       |       | 0.45  |       |    1.74    |    0.70    #> A1       |      |       |       | -0.44 |       |    1.88    |    0.80    #> O3       |      |       |       |       | 0.62  |    1.16    |    0.53    #> O5       |      |       |       |       | -0.54 |    1.21    |    0.70    #> O1       |      |       |       |       | 0.52  |    1.10    |    0.68    #> O2       |      |       |       |       | -0.47 |    1.68    |    0.73    #> O4       |      |       |       |       | 0.36  |    2.65    |    0.75    #>  #> The 5 latent factors (oblimin rotation) accounted for 42.36% of the total variance of the original data (MR2 = 10.31%, MR1 = 8.83%, MR3 = 8.39%, MR5 = 8.29%, MR4 = 6.55%). # let's look only at the first five individuals head(predict(efa, names = c(\"Neuroticism\", \"Conscientiousness\", \"Extraversion\", \"Agreeableness\", \"Opennness\")), 5) #>   Neuroticism Conscientiousness Extraversion Agreeableness Opennness #> 1       -0.22            -0.128       -1.327        -0.855     -1.61 #> 2        0.16            -0.466       -0.572        -0.072     -0.17 #> 3        0.62            -0.141       -0.043        -0.552      0.23 #> 4       -0.12            -0.058       -1.063        -0.091     -1.06 #> 5       -0.17            -0.460       -0.099        -0.712     -0.66"},{"path":"https://easystats.github.io/parameters/articles/efa_cfa.html","id":"how-many-factors-to-retain-in-factor-analysis-fa","dir":"Articles","previous_headings":"How to perform a Factor Analysis (FA)","what":"How many factors to retain in Factor Analysis (FA)","title":"Structural Models (EFA, CFA, SEM, ...)","text":"running factor analysis (FA), one often needs specify many components (latent variables) retain extract. decision often motivated supported statistical indices procedures aiming finding optimal number factors. huge number methods exist statistically address issue, can sometimes give different results. Unfortunately, consensus method use, best.","code":""},{"path":"https://easystats.github.io/parameters/articles/efa_cfa.html","id":"the-method-agreement-procedure","dir":"Articles","previous_headings":"How to perform a Factor Analysis (FA) > How many factors to retain in Factor Analysis (FA)","what":"The Method Agreement procedure","title":"Structural Models (EFA, CFA, SEM, ...)","text":"Method Agreement procedure, first implemented psycho package (Makowski 2018), proposes rely consensus methods, rather one method particular. procedure can easily used via n_factors() function, re-implemented improved parameters package. One can provide dataframe, function run large number routines return optimal number factors based higher consensus. Interestingly, smallest nubmer factors methods suggest 6, consistent newer models personality (e.g., HEXACO). details, well summary table can obtained follows: plot can also obtained (see package must loaded):","code":"n <- n_factors(data) n #> # Method Agreement Procedure: #>  #> The choice of 6 dimensions is supported by 3 (15.79%) methods out of 19 (Optimal coordinates, Parallel analysis, Kaiser criterion). as.data.frame(n) #>    n_Factors              Method              Family #> 1          1 Acceleration factor               Scree #> 2          3                 CNG                 CNG #> 3          4                beta Multiple_regression #> 4          4    VSS complexity 1                 VSS #> 5          5    VSS complexity 2                 VSS #> 6          5       Velicer's MAP        Velicers_MAP #> 7          6 Optimal coordinates               Scree #> 8          6   Parallel analysis               Scree #> 9          6    Kaiser criterion               Scree #> 10         7                   t Multiple_regression #> 11         7                   p Multiple_regression #> 12         7          Scree (R2)            Scree_SE #> 13         8          Scree (SE)            Scree_SE #> 14         8                 BIC                 BIC #> 15        11      BIC (adjusted)                 BIC #> 16        22             Bentler             Bentler #> 17        24            Bartlett             Barlett #> 18        24            Anderson             Barlett #> 19        24              Lawley             Barlett summary(n) #>    n_Factors n_Methods #> 1          1         1 #> 2          3         1 #> 3          4         2 #> 4          5         2 #> 5          6         3 #> 6          7         3 #> 7          8         2 #> 8         11         1 #> 9         22         1 #> 10        24         3 library(see)  plot(n) + theme_modern()"},{"path":"https://easystats.github.io/parameters/articles/efa_cfa.html","id":"confirmatory-factor-analysis-cfa","dir":"Articles","previous_headings":"How to perform a Factor Analysis (FA)","what":"Confirmatory Factor Analysis (CFA)","title":"Structural Models (EFA, CFA, SEM, ...)","text":"’ve seen EFA 5 latent variables works great dataset, structure 6 latent factors might fact appropriate. can statistically test actually case? can done using Confirmatory Factor Analysis (CFA) (opposed Exploratory FA), bridges factor analysis Structural Equation Modeling (SEM). However, order cleanly, EFA independent CFA: factor structure explored “training” set, tested (“confirmed”) “testing” set. words, dataset used exploration confirmation , standard widely adopted field machine learning.","code":""},{"path":"https://easystats.github.io/parameters/articles/efa_cfa.html","id":"partition-the-data","dir":"Articles","previous_headings":"How to perform a Factor Analysis (FA) > Confirmatory Factor Analysis (CFA)","what":"Partition the data","title":"Structural Models (EFA, CFA, SEM, ...)","text":"data can easily split two sets data_partition() function, use 70% sample training rest test.","code":"# to have reproducible result, we will also set seed here so that similar # portions of the data are used each time we run the following code partitions <- datawizard::data_partition(data, training_proportion = 0.7, seed = 111) training <- partitions$p_0.7 test <- partitions$test"},{"path":"https://easystats.github.io/parameters/articles/efa_cfa.html","id":"create-cfa-structures-out-of-efa-models","dir":"Articles","previous_headings":"How to perform a Factor Analysis (FA) > Confirmatory Factor Analysis (CFA)","what":"Create CFA structures out of EFA models","title":"Structural Models (EFA, CFA, SEM, ...)","text":"next step, run two EFA models training set, specifying 5 6 latent factors respectively, transform CFA structures. can see, structure just string encoding manifest variables (observed variables) integrated latent variables.","code":"structure_big5 <- psych::fa(training, nfactors = 5) %>%   efa_to_cfa() structure_big6 <- psych::fa(training, nfactors = 6) %>%   efa_to_cfa()  # Investigate how the models look structure_big5 #> # Latent variables #> MR2 =~ N1 + N2 + N3 + N4 + N5 + .row_id #> MR1 =~ E1 + E2 + E3 + E4 + E5 #> MR3 =~ C1 + C2 + C3 + C4 + C5 #> MR5 =~ A1 + A2 + A3 + A4 + A5 #> MR4 =~ O1 + O2 + O3 + O4 + O5  structure_big6 #> # Latent variables #> MR2 =~ N1 + N2 + N3 + N5 + .row_id #> MR3 =~ C1 + C2 + C3 + C4 + C5 #> MR1 =~ E1 + E2 + E4 + E5 + N4 + O4 #> MR5 =~ A1 + A2 + A3 + A4 + A5 #> MR4 =~ E3 + O1 + O2 + O3 #> MR6 =~ O5"},{"path":"https://easystats.github.io/parameters/articles/efa_cfa.html","id":"fit-and-compare-models","dir":"Articles","previous_headings":"How to perform a Factor Analysis (FA) > Confirmatory Factor Analysis (CFA)","what":"Fit and Compare models","title":"Structural Models (EFA, CFA, SEM, ...)","text":"can finally apply structure testing dataset using lavaan package, compare models : , seems Big-5 structure remains quite reliable.","code":"library(lavaan) library(performance)  big5 <- lavaan::cfa(structure_big5, data = test) big6 <- lavaan::cfa(structure_big6, data = test)  performance::compare_performance(big5, big6) #> # Comparison of Model Performance Indices #>  #> Name |  Model |     Chi2 | Chi2_df | p (Chi2) | Baseline(325) | p (Baseline) |   GFI |  AGFI |   NFI |  NNFI |   CFI | RMSEA |    RMSEA  CI | p (RMSEA) |    RMR |  SRMR |   RFI |  PNFI |   IFI |   RNI | Loglikelihood |     AIC (weights) |     BIC (weights) | BIC_adjusted #> ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- #> big5 | lavaan | 1366.793 | 289.000 |   < .001 |      5413.276 |       < .001 | 0.861 | 0.831 | 0.748 | 0.762 | 0.788 | 0.071 | [0.07, 0.08] |    < .001 | 12.332 | 0.076 | 0.716 | 0.665 | 0.790 | 0.788 |    -35860.601 | 71845.202 (>.999) | 72130.055 (>.999) |    71933.186 #> big6 | lavaan | 1504.653 | 285.000 |   < .001 |      5413.276 |       < .001 | 0.854 | 0.820 | 0.722 | 0.727 | 0.760 | 0.077 | [0.07, 0.08] |    < .001 | 12.595 | 0.083 | 0.683 | 0.633 | 0.762 | 0.760 |    -35929.531 | 71991.062 (<.001) | 72294.293 (<.001) |    72084.722"},{"path":"https://easystats.github.io/parameters/articles/efa_cfa.html","id":"structural-equation-modeling","dir":"Articles","previous_headings":"","what":"Structural Equation Modeling","title":"Structural Models (EFA, CFA, SEM, ...)","text":"previous example shows one enormous amount modeling possibilities structural equation models, particular example mediation analysis, .e. model estimates indirect effects partial mediation structures.","code":"set.seed(1234) X <- rnorm(100) M <- 0.5 * X + rnorm(100) Y <- 0.7 * M + rnorm(100) df <- data.frame(X = X, Y = Y, M = M)  model <- \" # direct effect              Y ~ c*X            # mediator              M ~ a*X              Y ~ b*M            # indirect effect (a*b)              ab := a*b            # total effect              total := c + (a*b)          \" fit <- lavaan::sem(model, data = df, test = \"Satorra-Bentler\") model_parameters(fit) #> # Regression #>  #> Link      | Coefficient |   SE |        95% CI |    z |      p #> -------------------------------------------------------------- #> Y ~ X (c) |        0.04 | 0.10 | [-0.17, 0.24] | 0.35 | 0.728  #> M ~ X (a) |        0.47 | 0.10 | [ 0.27, 0.68] | 4.61 | < .001 #> Y ~ M (b) |        0.79 | 0.09 | [ 0.61, 0.97] | 8.54 | < .001 #>  #> # Defined #>  #> To      | Coefficient |   SE |       95% CI |    z |      p #> ----------------------------------------------------------- #> (ab)    |        0.37 | 0.09 | [0.19, 0.55] | 4.06 | < .001 #> (total) |        0.41 | 0.12 | [0.17, 0.65] | 3.29 | 0.001"},{"path":[]},{"path":[]},{"path":"https://easystats.github.io/parameters/articles/model_parameters.html","id":"frequentist","dir":"Articles","previous_headings":"Correlations and t-tests","what":"Frequentist","title":"Summary of Model Parameters","text":"","code":"cor.test(iris$Sepal.Length, iris$Sepal.Width) %>%   parameters() #> Pearson's product-moment correlation #>  #> Parameter1        |       Parameter2 |     r |        95% CI | t(148) |     p #> ----------------------------------------------------------------------------- #> iris$Sepal.Length | iris$Sepal.Width | -0.12 | [-0.27, 0.04] |  -1.44 | 0.152 #>  #> Alternative hypothesis: true correlation is not equal to 0 t.test(mpg ~ vs, data = mtcars) %>%   parameters() #> Welch Two Sample t-test #>  #> Parameter | Group | vs = 0 | vs = 1 | Difference |          95% CI | t(22.72) |      p #> -------------------------------------------------------------------------------------- #> mpg       |    vs |  16.62 |  24.56 |      -7.94 | [-11.46, -4.42] |    -4.67 | < .001 #>  #> Alternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0"},{"path":"https://easystats.github.io/parameters/articles/model_parameters.html","id":"bayesian","dir":"Articles","previous_headings":"Correlations and t-tests","what":"Bayesian","title":"Summary of Model Parameters","text":"","code":"library(BayesFactor)  BayesFactor::correlationBF(iris$Sepal.Length, iris$Sepal.Width) %>%   parameters() #> Bayesian correlation analysis #>  #> Parameter | Median |        95% CI |     pd | % in ROPE |         Prior |    BF #> ------------------------------------------------------------------------------- #> rho       |  -0.11 | [-0.27, 0.04] | 92.25% |    19.82% | Beta (3 +- 3) | 0.509 BayesFactor::ttestBF(formula = mpg ~ vs, data = mtcars) %>%   parameters() #> Bayesian t-test #>  #> Parameter  | Median |          95% CI |     pd | % in ROPE |              Prior |     BF #> ---------------------------------------------------------------------------------------- #> Difference |  -7.31 | [-10.81, -3.79] | 99.98% |        0% | Cauchy (0 +- 0.71) | 529.27"},{"path":"https://easystats.github.io/parameters/articles/model_parameters.html","id":"anovas","dir":"Articles","previous_headings":"","what":"ANOVAs","title":"Summary of Model Parameters","text":"Indices effect size ANOVAs, partial non-partial versions eta_squared(), epsilon_sqared() omega_squared() powered effectsize-package. However, parameters uses function compute indices parameters summaries, including confidence intervals","code":""},{"path":"https://easystats.github.io/parameters/articles/model_parameters.html","id":"simple","dir":"Articles","previous_headings":"ANOVAs","what":"Simple","title":"Summary of Model Parameters","text":"Let’s complicate things interaction term:","code":"aov(Sepal.Length ~ Species, data = iris) %>%   parameters(     omega_squared = \"partial\",     eta_squared = \"partial\",     epsilon_squared = \"partial\"   ) #> Parameter | Sum_Squares |  df | Mean_Square |      F |      p | Omega2 | Eta2 | Epsilon2 #> ---------------------------------------------------------------------------------------- #> Species   |       63.21 |   2 |       31.61 | 119.26 | < .001 |   0.61 | 0.62 |     0.61 #> Residuals |       38.96 | 147 |        0.27 |        |        |        |      |          #>  #> Anova Table (Type 1 tests) aov(Sepal.Length ~ Species * Sepal.Width, data = iris) %>%   parameters(     omega_squared = \"partial\",     eta_squared = \"partial\",     ci = .8   ) #> Parameter           | Sum_Squares |  df | Mean_Square |      F |      p | Omega2 (partial) | Omega2 80% CI | Eta2 (partial) |  Eta2 80% CI #> ------------------------------------------------------------------------------------------------------------------------------------------ #> Species             |       63.21 |   2 |       31.61 | 163.44 | < .001 |             0.68 |  [0.65, 1.00] |           0.69 | [0.66, 1.00] #> Sepal.Width         |       10.95 |   1 |       10.95 |  56.64 | < .001 |             0.27 |  [0.22, 1.00] |           0.28 | [0.23, 1.00] #> Species:Sepal.Width |        0.16 |   2 |        0.08 |   0.41 | 0.667  |        -7.98e-03 |  [0.00, 1.00] |       5.61e-03 | [0.00, 1.00] #> Residuals           |       27.85 | 144 |        0.19 |        |        |                  |               |                |              #>  #> Anova Table (Type 1 tests)"},{"path":"https://easystats.github.io/parameters/articles/model_parameters.html","id":"repeated-measures","dir":"Articles","previous_headings":"ANOVAs","what":"Repeated measures","title":"Summary of Model Parameters","text":"parameters() (resp. alias model_parameters()) also works repeated measures ANOVAs, whether computed aov() mixed model.","code":"aov(mpg ~ am + Error(gear), data = mtcars) %>%   parameters() #> # gear #>  #> Parameter | Sum_Squares | df | Mean_Square #> ------------------------------------------ #> am        |      259.75 |  1 |      259.75 #>  #> # Within #>  #> Parameter | Sum_Squares | df | Mean_Square |    F |     p #> --------------------------------------------------------- #> am        |      145.45 |  1 |      145.45 | 5.85 | 0.022 #> Residuals |      720.85 | 29 |       24.86 |      |       #>  #> Anova Table (Type 1 tests)"},{"path":"https://easystats.github.io/parameters/articles/model_parameters.html","id":"regressions-glms-mixed-models-gams","dir":"Articles","previous_headings":"","what":"Regressions (GLMs, Mixed Models, GAMs, …)","title":"Summary of Model Parameters","text":"parameters() (resp. alias model_parameters()) mainly built regression models mind. works many types models packages, including mixed models Bayesian models.","code":""},{"path":"https://easystats.github.io/parameters/articles/model_parameters.html","id":"glms","dir":"Articles","previous_headings":"Regressions (GLMs, Mixed Models, GAMs, …)","what":"GLMs","title":"Summary of Model Parameters","text":"","code":"glm(vs ~ poly(mpg, 2) + cyl, data = mtcars, family = binomial()) %>%   parameters() #> Parameter        | Log-Odds |   SE |          95% CI |     z |     p #> -------------------------------------------------------------------- #> (Intercept)      |    13.51 | 7.20 | [  2.56, 33.42] |  1.88 | 0.060 #> mpg [1st degree] |    -6.64 | 8.99 | [-27.81, 11.13] | -0.74 | 0.461 #> mpg [2nd degree] |     1.16 | 3.59 | [ -7.91,  8.56] |  0.32 | 0.746 #> cyl              |    -2.28 | 1.18 | [ -5.58, -0.51] | -1.92 | 0.055 # show Odds Ratios and Wald-method for degrees of freedom glm(vs ~ poly(mpg, 2) + cyl, data = mtcars, family = binomial()) %>%   parameters(exponentiate = TRUE, ci_method = \"wald\") #> Parameter        | Odds Ratio |       SE |           95% CI |     z |     p #> --------------------------------------------------------------------------- #> (Intercept)      |   7.38e+05 | 5.31e+06 | [0.55, 9.87e+11] |  1.88 | 0.060 #> mpg [1st degree] |   1.31e-03 |     0.01 | [0.00, 59497.56] | -0.74 | 0.461 #> mpg [2nd degree] |       3.20 |    11.49 | [0.00,  3637.30] |  0.32 | 0.746 #> cyl              |       0.10 |     0.12 | [0.01,     1.05] | -1.92 | 0.055 # show Odds Ratios and include model summary glm(vs ~ poly(mpg, 2) + cyl, data = mtcars, family = binomial()) %>%   parameters(exponentiate = TRUE, summary = TRUE) #> Parameter        | Odds Ratio |       SE |            95% CI |     z |     p #> ---------------------------------------------------------------------------- #> (Intercept)      |   7.38e+05 | 5.31e+06 | [12.95, 3.26e+14] |  1.88 | 0.060 #> mpg [1st degree] |   1.31e-03 |     0.01 | [ 0.00, 68459.83] | -0.74 | 0.461 #> mpg [2nd degree] |       3.20 |    11.49 | [ 0.00,  5212.21] |  0.32 | 0.746 #> cyl              |       0.10 |     0.12 | [ 0.00,     0.60] | -1.92 | 0.055 #>  #> Model: vs ~ poly(mpg, 2) + cyl (32 Observations) #> Residual standard deviation: 0.788 (df = 28) #> Tjur's R2: 0.670"},{"path":"https://easystats.github.io/parameters/articles/model_parameters.html","id":"mixed-models","dir":"Articles","previous_headings":"Regressions (GLMs, Mixed Models, GAMs, …)","what":"Mixed Models","title":"Summary of Model Parameters","text":"","code":"library(lme4)  lmer(Sepal.Width ~ Petal.Length + (1 | Species), data = iris) %>%   parameters() #> # Fixed Effects #>  #> Parameter    | Coefficient |   SE |       95% CI | t(146) |      p #> ------------------------------------------------------------------ #> (Intercept)  |        2.00 | 0.56 | [0.89, 3.11] |   3.56 | < .001 #> Petal Length |        0.28 | 0.06 | [0.16, 0.40] |   4.75 | < .001 #>  #> # Random Effects #>  #> Parameter               | Coefficient |   SE |       95% CI #> ----------------------------------------------------------- #> SD (Intercept: Species) |        0.89 | 0.46 | [0.33, 2.43] #> SD (Residual)           |        0.32 | 0.02 | [0.28, 0.35]"},{"path":"https://easystats.github.io/parameters/articles/model_parameters.html","id":"mixed-models-without-random-effects-variances","dir":"Articles","previous_headings":"Regressions (GLMs, Mixed Models, GAMs, …)","what":"Mixed Models, without Random Effects Variances","title":"Summary of Model Parameters","text":"","code":"lmer(Sepal.Width ~ Petal.Length + (1 | Species), data = iris) %>%   parameters(effects = \"fixed\") #> # Fixed Effects #>  #> Parameter    | Coefficient |   SE |       95% CI | t(146) |      p #> ------------------------------------------------------------------ #> (Intercept)  |        2.00 | 0.56 | [0.89, 3.11] |   3.56 | < .001 #> Petal Length |        0.28 | 0.06 | [0.16, 0.40] |   4.75 | < .001"},{"path":"https://easystats.github.io/parameters/articles/model_parameters.html","id":"mixed-model-with-zero-inflation-model","dir":"Articles","previous_headings":"Regressions (GLMs, Mixed Models, GAMs, …)","what":"Mixed Model with Zero-Inflation Model","title":"Summary of Model Parameters","text":"","code":"library(GLMMadaptive) library(glmmTMB) data(\"Salamanders\") model <- mixed_model(   count ~ spp + mined,   random = ~ 1 | site,   zi_fixed = ~ spp + mined,   family = zi.negative.binomial(),   data = Salamanders ) parameters(model) #> # Fixed Effects (Count Model) #>  #> Parameter   | Log-Mean |   SE |        95% CI |     z |      p #> -------------------------------------------------------------- #> (Intercept) |    -0.63 | 0.40 | [-1.42, 0.16] | -1.56 | 0.118  #> spp [PR]    |    -0.99 | 0.70 | [-2.35, 0.38] | -1.41 | 0.157  #> spp [DM]    |     0.17 | 0.24 | [-0.29, 0.63] |  0.72 | 0.469  #> spp [EC-A]  |    -0.39 | 0.35 | [-1.07, 0.29] | -1.13 | 0.258  #> spp [EC-L]  |     0.49 | 0.24 | [ 0.02, 0.96] |  2.03 | 0.043  #> spp [DES-L] |     0.59 | 0.23 | [ 0.14, 1.04] |  2.57 | 0.010  #> spp [DF]    |    -0.11 | 0.24 | [-0.59, 0.37] | -0.46 | 0.642  #> mined [no]  |     1.45 | 0.37 | [ 0.73, 2.17] |  3.95 | < .001 #>  #> # Fixed Effects (Zero-Inflated Model) #>  #> Parameter   | Log-Odds |   SE |         95% CI |     z |      p #> --------------------------------------------------------------- #> (Intercept) |     0.90 | 0.64 | [-0.35,  2.15] |  1.41 | 0.159  #> spp [PR]    |     1.12 | 1.50 | [-1.82,  4.06] |  0.74 | 0.456  #> spp [DM]    |    -0.95 | 0.82 | [-2.56,  0.65] | -1.17 | 0.244  #> spp [EC-A]  |     1.04 | 0.72 | [-0.38,  2.46] |  1.44 | 0.150  #> spp [EC-L]  |    -0.58 | 0.74 | [-2.03,  0.88] | -0.77 | 0.439  #> spp [DES-L] |    -0.91 | 0.78 | [-2.43,  0.61] | -1.18 | 0.239  #> spp [DF]    |    -2.63 | 2.37 | [-7.27,  2.02] | -1.11 | 0.268  #> mined [no]  |    -2.56 | 0.63 | [-3.80, -1.32] | -4.06 | < .001 #>  #> # Random Effects Variances #>  #> Parameter            | Coefficient #> ---------------------------------- #> SD (Intercept: site) |        0.39 #> SD (Residual)        |        1.61"},{"path":"https://easystats.github.io/parameters/articles/model_parameters.html","id":"mixed-models-with-dispersion-model","dir":"Articles","previous_headings":"Regressions (GLMs, Mixed Models, GAMs, …)","what":"Mixed Models with Dispersion Model","title":"Summary of Model Parameters","text":"","code":"library(glmmTMB)  sim1 <- function(nfac = 40, nt = 100, facsd = 0.1, tsd = 0.15, mu = 0, residsd = 1) {   dat <- expand.grid(fac = factor(letters[1:nfac]), t = 1:nt)   n <- nrow(dat)   dat$REfac <- rnorm(nfac, sd = facsd)[dat$fac]   dat$REt <- rnorm(nt, sd = tsd)[dat$t]   dat$x <- rnorm(n, mean = mu, sd = residsd) + dat$REfac + dat$REt   dat }  set.seed(101) d1 <- sim1(mu = 100, residsd = 10) d2 <- sim1(mu = 200, residsd = 5) d1$sd <- \"ten\" d2$sd <- \"five\" dat <- rbind(d1, d2) model <- glmmTMB(x ~ sd + (1 | t), dispformula = ~sd, data = dat)  parameters(model) #> # Fixed Effects #>  #> Parameter   | Coefficient |   SE |            95% CI |       z |      p #> ----------------------------------------------------------------------- #> (Intercept) |      200.03 | 0.10 | [ 199.84, 200.22] | 2056.35 | < .001 #> sd [ten]    |      -99.71 | 0.22 | [-100.14, -99.29] | -458.39 | < .001 #>  #> # Dispersion #>  #> Parameter   | Coefficient |   SE |       95% CI |      z |      p #> ----------------------------------------------------------------- #> (Intercept) |        3.20 | 0.03 | [3.15, 3.26] | 115.48 | < .001 #> sd [ten]    |        1.39 | 0.04 | [1.31, 1.46] |  35.35 | < .001 #>  #> # Random Effects Variances #>  #> Parameter         | Coefficient #> ------------------------------- #> SD (Intercept: t) |    5.56e-04 #> SD (Residual)     |"},{"path":"https://easystats.github.io/parameters/articles/model_parameters.html","id":"bayesian-models","dir":"Articles","previous_headings":"Regressions (GLMs, Mixed Models, GAMs, …)","what":"Bayesian Models","title":"Summary of Model Parameters","text":"model_parameters() also works Bayesian models rstanarm package: Additionally, also works models brms package. complex models, specific model components can printed using arguments effects component arguments. include information random effect parameters (group levels), set group_level = TRUE:","code":"library(rstanarm)  # if you are unfamiliar with the `refresh` argument here, it just avoids # printing few messages to the console stan_glm(mpg ~ wt * cyl, data = mtcars, refresh = 0) %>%   parameters() #> Parameter   | Median |          95% CI |     pd | % in ROPE |  Rhat |     ESS |                   Prior #> ------------------------------------------------------------------------------------------------------- #> (Intercept) |  52.78 | [ 40.58, 64.63] |   100% |        0% | 1.001 | 1147.00 | Normal (20.09 +- 15.07) #> wt          |  -8.06 | [-12.58, -3.54] | 99.98% |        0% | 1.001 | 1228.00 |  Normal (0.00 +- 15.40) #> cyl         |  -3.58 | [ -5.57, -1.56] | 99.98% |        0% | 1.001 | 1275.00 |   Normal (0.00 +- 8.44) #> wt:cyl      |   0.72 | [  0.09,  1.35] | 98.55% |    33.37% | 1.001 | 1148.00 |   Normal (0.00 +- 1.36) library(brms) data(fish) set.seed(123)  # fitting a model using `brms` model <- brm(   bf(     count ~ persons + child + camper + (1 | persons),     zi ~ child + camper + (1 | persons)   ),   data = fish,   family = zero_inflated_poisson(),   refresh = 0 )  parameters(model, component = \"conditional\") #> Parameter   | Median |         95% CI |     pd | % in ROPE |  Rhat |     ESS #> ---------------------------------------------------------------------------- #> (Intercept) |  -0.87 | [-1.63, -0.25] | 99.28% |        0% | 1.007 |  449.00 #> persons     |   0.84 | [ 0.64,  1.12] |   100% |        0% | 1.012 |  324.00 #> child       |  -1.15 | [-1.34, -0.98] |   100% |        0% | 1.005 |  677.00 #> camper1     |   0.74 | [ 0.55,  0.92] |   100% |        0% | 1.000 | 2687.00  parameters(model, effects = \"all\", component = \"all\") #> # Fixed effects (conditional) #>  #> Parameter   | Median |         95% CI |     pd | % in ROPE |  Rhat |     ESS #> ---------------------------------------------------------------------------- #> (Intercept) |  -0.87 | [-1.63, -0.25] | 99.28% |        0% | 1.007 |  449.00 #> persons     |   0.84 | [ 0.64,  1.12] |   100% |        0% | 1.012 |  324.00 #> child       |  -1.15 | [-1.34, -0.98] |   100% |        0% | 1.005 |  677.00 #> camper1     |   0.74 | [ 0.55,  0.92] |   100% |        0% | 1.000 | 2687.00 #>  #> # Fixed effects (zero-inflated) #>  #> Parameter   | Median |         95% CI |     pd | % in ROPE |  Rhat |     ESS #> ---------------------------------------------------------------------------- #> (Intercept) |  -0.67 | [-2.16,  0.79] | 83.85% |     6.95% | 1.003 | 1479.00 #> child       |   1.86 | [ 1.25,  2.53] |   100% |        0% | 0.999 | 2670.00 #> camper1     |  -0.81 | [-1.51, -0.11] | 98.67% |        0% | 1.004 | 1576.00 #>  #> # Random effects (conditional) SD/Cor: persons #>  #> Parameter   | Median |       95% CI |   pd | % in ROPE |  Rhat |    ESS #> ----------------------------------------------------------------------- #> (Intercept) |   0.11 | [0.00, 0.71] | 100% |    45.00% | 1.015 | 209.00 #>  #> # Random effects (zero-inflated) SD/Cor: persons #>  #> Parameter   | Median |       95% CI |   pd | % in ROPE |  Rhat |     ESS #> ------------------------------------------------------------------------ #> (Intercept) |   1.30 | [0.52, 3.47] | 100% |        0% | 1.003 | 1145.00 parameters(model, effects = \"all\", component = \"conditional\", group_level = TRUE) #> # Fixed effects #>  #> Parameter   | Median |         95% CI |     pd | % in ROPE |  Rhat |     ESS #> ---------------------------------------------------------------------------- #> (Intercept) |  -0.87 | [-1.63, -0.25] | 99.28% |        0% | 1.007 |  449.00 #> persons     |   0.84 | [ 0.64,  1.12] |   100% |        0% | 1.012 |  324.00 #> child       |  -1.15 | [-1.34, -0.98] |   100% |        0% | 1.005 |  677.00 #> camper1     |   0.74 | [ 0.55,  0.92] |   100% |        0% | 1.000 | 2687.00 #>  #> # Random effects Intercept: persons #>  #> Parameter |    Median |        95% CI |     pd | % in ROPE |  Rhat |    ESS #> --------------------------------------------------------------------------- #> persons.1 | -3.90e-03 | [-0.40, 0.41] | 54.05% |    68.87% | 1.007 | 592.00 #> persons.2 |      0.02 | [-0.20, 0.43] | 65.30% |    70.11% | 1.005 | 557.00 #> persons.3 | -9.44e-03 | [-0.38, 0.25] | 58.55% |    73.53% | 1.017 | 228.00 #> persons.4 |  1.97e-03 | [-0.46, 0.43] | 52.20% |    65.92% | 1.018 | 188.00 #>  #> # Random effects SD/Cor: persons #>  #> Parameter   | Median |       95% CI |   pd | % in ROPE |  Rhat |    ESS #> ----------------------------------------------------------------------- #> (Intercept) |   0.11 | [0.00, 0.71] | 100% |    45.00% | 1.015 | 209.00"},{"path":"https://easystats.github.io/parameters/articles/model_parameters.html","id":"structural-models-pca-efa-cfa-sem","dir":"Articles","previous_headings":"","what":"Structural Models (PCA, EFA, CFA, SEM…)","title":"Summary of Model Parameters","text":"parameters package extends support structural models.","code":""},{"path":"https://easystats.github.io/parameters/articles/model_parameters.html","id":"principal-component-analysis-pca-and-exploratory-factor-analysis-efa","dir":"Articles","previous_headings":"Structural Models (PCA, EFA, CFA, SEM…)","what":"Principal Component Analysis (PCA) and Exploratory Factor Analysis (EFA)","title":"Summary of Model Parameters","text":"avoid displaying graph carrying factor analysis:","code":"library(psych)  psych::pca(mtcars, nfactors = 3) %>%   parameters() #> # Rotated loadings from Principal Component Analysis (varimax-rotation) #>  #> Variable |  RC2  |  RC3  |  RC1  | Complexity | Uniqueness #> ---------------------------------------------------------- #> mpg      | 0.66  | -0.41 | -0.54 |    2.63    |    0.10    #> cyl      | -0.62 | 0.67  | 0.34  |    2.49    |    0.05    #> disp     | -0.72 | 0.52  | 0.35  |    2.33    |    0.10    #> hp       | -0.30 | 0.64  | 0.63  |    2.40    |    0.10    #> drat     | 0.85  | -0.26 | -0.05 |    1.19    |    0.21    #> wt       | -0.78 | 0.21  | 0.51  |    1.90    |    0.08    #> qsec     | -0.18 | -0.91 | -0.28 |    1.28    |    0.06    #> vs       | 0.28  | -0.86 | -0.23 |    1.36    |    0.12    #> am       | 0.92  | 0.14  | -0.11 |    1.08    |    0.12    #> gear     | 0.91  | -0.02 | 0.26  |    1.16    |    0.10    #> carb     | 0.11  | 0.44  | 0.85  |    1.53    |    0.07    #>  #> The 3 principal components (varimax rotation) accounted for 89.87% of the total variance of the original data (RC2 = 41.43%, RC3 = 29.06%, RC1 = 19.39%). library(FactoMineR)  FactoMineR::FAMD(iris, ncp = 3, graph = FALSE) %>%   parameters() #> # Loadings from Factor Analysis (no rotation) #>  #> Variable     | Dim.1 |  Dim.2   |  Dim.3   | Complexity #> ------------------------------------------------------- #> Sepal.Length | 0.75  |   0.07   |   0.10   |    1.05    #> Sepal.Width  | 0.23  |   0.51   |   0.23   |    1.86    #> Petal.Length | 0.98  | 1.32e-03 | 1.99e-03 |    1.00    #> Petal.Width  | 0.94  |   0.01   | 2.82e-05 |    1.00    #> Species      | 0.96  |   0.75   |   0.26   |    2.05    #>  #> The 3 latent factors accounted for 96.73% of the total variance of the original data (Dim.1 = 64.50%, Dim.2 = 22.37%, Dim.3 = 9.86%)."},{"path":[]},{"path":"https://easystats.github.io/parameters/articles/model_parameters.html","id":"frequentist-1","dir":"Articles","previous_headings":"Structural Models (PCA, EFA, CFA, SEM…) > Confirmatory Factor Analysis (CFA) and Structural Equation Models (SEM)","what":"Frequentist","title":"Summary of Model Parameters","text":"","code":"library(lavaan)  model <- lavaan::cfa(\" visual  =~ x1 + x2 + x3                        textual =~ x4 + x5 + x6                        speed   =~ x7 + x8 + x9 \",   data = HolzingerSwineford1939 )  model_parameters(model) #> # Loading #>  #> Link          | Coefficient |   SE |       95% CI |     z |      p #> ------------------------------------------------------------------ #> visual =~ x1  |        1.00 | 0.00 | [1.00, 1.00] |       | < .001 #> visual =~ x2  |        0.55 | 0.10 | [0.36, 0.75] |  5.55 | < .001 #> visual =~ x3  |        0.73 | 0.11 | [0.52, 0.94] |  6.68 | < .001 #> textual =~ x4 |        1.00 | 0.00 | [1.00, 1.00] |       | < .001 #> textual =~ x5 |        1.11 | 0.07 | [0.98, 1.24] | 17.01 | < .001 #> textual =~ x6 |        0.93 | 0.06 | [0.82, 1.03] | 16.70 | < .001 #> speed =~ x7   |        1.00 | 0.00 | [1.00, 1.00] |       | < .001 #> speed =~ x8   |        1.18 | 0.16 | [0.86, 1.50] |  7.15 | < .001 #> speed =~ x9   |        1.08 | 0.15 | [0.79, 1.38] |  7.15 | < .001 #>  #> # Correlation #>  #> Link              | Coefficient |   SE |       95% CI |    z |      p #> --------------------------------------------------------------------- #> visual ~~ textual |        0.41 | 0.07 | [0.26, 0.55] | 5.55 | < .001 #> visual ~~ speed   |        0.26 | 0.06 | [0.15, 0.37] | 4.66 | < .001 #> textual ~~ speed  |        0.17 | 0.05 | [0.08, 0.27] | 3.52 | < .001"},{"path":"https://easystats.github.io/parameters/articles/model_parameters.html","id":"bayesian-1","dir":"Articles","previous_headings":"Structural Models (PCA, EFA, CFA, SEM…) > Confirmatory Factor Analysis (CFA) and Structural Equation Models (SEM)","what":"Bayesian","title":"Summary of Model Parameters","text":"blavaan done.","code":""},{"path":"https://easystats.github.io/parameters/articles/model_parameters.html","id":"meta-analysis","dir":"Articles","previous_headings":"","what":"Meta-Analysis","title":"Summary of Model Parameters","text":"parameters() also works rma-objects metafor package.","code":"library(metafor)  mydat <- data.frame(   effectsize = c(-0.393, 0.675, 0.282, -1.398),   standarderror = c(0.317, 0.317, 0.13, 0.36) )  rma(yi = effectsize, sei = standarderror, method = \"REML\", data = mydat) %>%   model_parameters() #> Meta-analysis using 'metafor' #>  #> Parameter | Coefficient |   SE |         95% CI |     z |      p | Weight #> ------------------------------------------------------------------------- #> Study 1   |       -0.39 | 0.32 | [-1.01,  0.23] | -1.24 | 0.215  |   9.95 #> Study 2   |        0.68 | 0.32 | [ 0.05,  1.30] |  2.13 | 0.033  |   9.95 #> Study 3   |        0.28 | 0.13 | [ 0.03,  0.54] |  2.17 | 0.030  |  59.17 #> Study 4   |       -1.40 | 0.36 | [-2.10, -0.69] | -3.88 | < .001 |   7.72 #> Overall   |       -0.18 | 0.44 | [-1.05,  0.68] | -0.42 | 0.676  |"},{"path":"https://easystats.github.io/parameters/articles/model_parameters.html","id":"plotting-model-parameters","dir":"Articles","previous_headings":"","what":"Plotting Model Parameters","title":"Summary of Model Parameters","text":"plot()-method implemented see-package. Several examples shown vignette.","code":""},{"path":"https://easystats.github.io/parameters/articles/model_parameters_formatting.html","id":"an-example-model","dir":"Articles","previous_headings":"","what":"An Example Model","title":"Formatting Model Parameters","text":"start model make much sense, useful demonstrating formatting functions.","code":"data(iris) iris$Petlen <- cut(iris$Petal.Length, breaks = c(0, 3, 7)) model <- lm(Sepal.Width ~ poly(Sepal.Length, 2) + Species + Petlen, data = iris)  summary(model) #>  #> Call: #> lm(formula = Sepal.Width ~ poly(Sepal.Length, 2) + Species +  #>     Petlen, data = iris) #>  #> Residuals: #>     Min      1Q  Median      3Q     Max  #> -0.7742 -0.1490 -0.0056  0.1666  0.6973  #>  #> Coefficients: #>                        Estimate Std. Error t value Pr(>|t|)     #> (Intercept)              3.8127     0.0582   65.50  < 2e-16 *** #> poly(Sepal.Length, 2)1   4.0602     0.4668    8.70    7e-15 *** #> poly(Sepal.Length, 2)2  -1.3024     0.3149   -4.14    6e-05 *** #> Speciesversicolor       -1.0056     0.2781   -3.62  0.00041 *** #> Speciesvirginica        -0.9913     0.2851   -3.48  0.00067 *** #> Petlen(3,7]             -0.1360     0.2818   -0.48  0.63019     #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: 0.28 on 144 degrees of freedom #> Multiple R-squared:  0.615,  Adjusted R-squared:  0.602  #> F-statistic:   46 on 5 and 144 DF,  p-value: <2e-16"},{"path":"https://easystats.github.io/parameters/articles/model_parameters_formatting.html","id":"formatting-parameter-names","dir":"Articles","previous_headings":"","what":"Formatting Parameter Names","title":"Formatting Model Parameters","text":"can see, cases, standard R output looks bit cryptic, although necessary important information included summary. formatting coefficients polynomial transformation difficult read, factors grouped cut() always require short time thinking find bound (case, Petlen(3,7], 3 7) included range, names factor levels directly concatenated name factor variable. Thus, first step format parameter names, can done format_parameters() parameters package: format_parameters() returns (named) character vector original coefficients names character element, formatted names coefficients values character vector. Let’s look results : Now variable names factor levels, also polynomial terms even factors grouped cut() much readable. Factor levels separated variable name, inside brackets. coefficients different polynomial degrees. exact range cut()-factors also clearer now.","code":"library(parameters) format_parameters(model) #>                 (Intercept)      poly(Sepal.Length, 2)1  #>               \"(Intercept)\" \"Sepal Length [1st degree]\"  #>      poly(Sepal.Length, 2)2           Speciesversicolor  #> \"Sepal Length [2nd degree]\"      \"Species [versicolor]\"  #>            Speciesvirginica                 Petlen(3,7]  #>       \"Species [virginica]\"              \"Petlen [4-7]\" cat(format_parameters(model), sep = \"\\n\") #> (Intercept) #> Sepal Length [1st degree] #> Sepal Length [2nd degree] #> Species [versicolor] #> Species [virginica] #> Petlen [4-7]"},{"path":"https://easystats.github.io/parameters/articles/model_parameters_formatting.html","id":"standardizing-column-names-of-parameter-tables","dir":"Articles","previous_headings":"","what":"Standardizing Column Names of Parameter Tables","title":"Formatting Model Parameters","text":"seen , summary() returns columns named Estimate, t value Pr(>|t|). Estimate specific certain models, t value . logistic regression models, get z value. packages alter names, get just t t-value etc. model_parameters() also uses context-specific column names, applicable: Bayesian models, Coefficient usually named Median etc. makes sense user perspective, instantly know type statistic coefficient , becomes difficult need generic naming scheme access model parameters input model unknown. typical approach broom package, get “standardized” column names: deal situations, insight package provides standardize_names() function, exactly : standardizing column names input. following example, see statistic-column longer named t, statistic. df_error df_residuals renamed df. Furthermore, can request “broom”-style column names:","code":"colnames(model_parameters(model)) #> [1] \"Parameter\"   \"Coefficient\" \"SE\"          \"CI\"          \"CI_low\"      #> [6] \"CI_high\"     \"t\"           \"df_error\"    \"p\" library(broom) colnames(tidy(model)) #> [1] \"term\"      \"estimate\"  \"std.error\" \"statistic\" \"p.value\" library(insight) library(magrittr) model %>%   model_parameters() %>%   standardize_names() %>%   colnames() #> [1] \"Parameter\"   \"Coefficient\" \"SE\"          \"CI\"          \"CI_low\"      #> [6] \"CI_high\"     \"Statistic\"   \"df\"          \"p\" model %>%   model_parameters() %>%   standardize_names(style = \"broom\") %>%   colnames() #> [1] \"term\"       \"estimate\"   \"std.error\"  \"conf.level\" \"conf.low\"   #> [6] \"conf.high\"  \"statistic\"  \"df.error\"   \"p.value\""},{"path":"https://easystats.github.io/parameters/articles/model_parameters_formatting.html","id":"formatting-column-names-and-columns","dir":"Articles","previous_headings":"","what":"Formatting Column Names and Columns","title":"Formatting Model Parameters","text":"Beside formatting parameter names (coefficient names) using format_parameters(), can even make output readable. Let’s look example includes confidence intervals. can get similar tabular output using broom. improvements according readability collapsing formatting confidence intervals, maybe p-values. require effort, instance, format values lower upper confidence intervals collapsing one column. However, format_table() function convenient function work . format_table() requires data frame model parameters input, however, requirements make format_table() work. particular, column names must follow certain pattern recognized, pattern may either naming convention broom easystats packages. parameters table also includes degrees freedom, degrees freedom parameter, information included statistic-column. usually default model_parameters():","code":"cbind(summary(model)$coefficients, confint(model)) #>                        Estimate Std. Error t value Pr(>|t|) 2.5 % 97.5 % #> (Intercept)                3.81      0.058   65.50 4.6e-109  3.70   3.93 #> poly(Sepal.Length, 2)1     4.06      0.467    8.70  7.0e-15  3.14   4.98 #> poly(Sepal.Length, 2)2    -1.30      0.315   -4.14  6.0e-05 -1.92  -0.68 #> Speciesversicolor         -1.01      0.278   -3.62  4.1e-04 -1.56  -0.46 #> Speciesvirginica          -0.99      0.285   -3.48  6.7e-04 -1.55  -0.43 #> Petlen(3,7]               -0.14      0.282   -0.48  6.3e-01 -0.69   0.42 tidy(model, conf.int = TRUE) #> # A tibble: 6 × 7 #>   term                   estimate std.error statistic   p.value conf.low conf.…¹ #>   <chr>                     <dbl>     <dbl>     <dbl>     <dbl>    <dbl>   <dbl> #> 1 (Intercept)               3.81     0.0582    65.5   4.61e-109    3.70    3.93  #> 2 poly(Sepal.Length, 2)1    4.06     0.467      8.70  7.00e- 15    3.14    4.98  #> 3 poly(Sepal.Length, 2)2   -1.30     0.315     -4.14  5.98e-  5   -1.92   -0.680 #> 4 Speciesversicolor        -1.01     0.278     -3.62  4.12e-  4   -1.56   -0.456 #> 5 Speciesvirginica         -0.991    0.285     -3.48  6.72e-  4   -1.55   -0.428 #> 6 Petlen(3,7]              -0.136    0.282     -0.482 6.30e-  1   -0.693   0.421 #> # … with abbreviated variable name ¹​conf.high model %>%   tidy(conf.int = TRUE) %>%   format_table() #>                     term estimate std.error statistic p.value       conf.int #> 1            (Intercept)     3.81      0.06     65.50  < .001 [ 3.70,  3.93] #> 2 poly(Sepal.Length, 2)1     4.06      0.47      8.70  < .001 [ 3.14,  4.98] #> 3 poly(Sepal.Length, 2)2    -1.30      0.31     -4.14  < .001 [-1.92, -0.68] #> 4      Speciesversicolor    -1.01      0.28     -3.62  < .001 [-1.56, -0.46] #> 5       Speciesvirginica    -0.99      0.29     -3.48  < .001 [-1.55, -0.43] #> 6            Petlen(3,7]    -0.14      0.28     -0.48  0.630  [-0.69,  0.42] model %>%   model_parameters() %>%   format_table() #>                   Parameter Coefficient   SE         95% CI t(144)      p #> 1               (Intercept)        3.81 0.06 [ 3.70,  3.93]  65.50 < .001 #> 2 Sepal Length [1st degree]        4.06 0.47 [ 3.14,  4.98]   8.70 < .001 #> 3 Sepal Length [2nd degree]       -1.30 0.31 [-1.92, -0.68]  -4.14 < .001 #> 4      Species [versicolor]       -1.01 0.28 [-1.56, -0.46]  -3.62 < .001 #> 5       Species [virginica]       -0.99 0.29 [-1.55, -0.43]  -3.48 < .001 #> 6              Petlen [4-7]       -0.14 0.28 [-0.69,  0.42]  -0.48 0.630"},{"path":"https://easystats.github.io/parameters/articles/model_parameters_formatting.html","id":"exporting-the-parameters-table","dir":"Articles","previous_headings":"","what":"Exporting the Parameters Table","title":"Formatting Model Parameters","text":"Finally, export_table() insight formats data frame returns character vector can printed console inside rmarkdown documents. data frame looks “table-like”. Putting together allows us create nice tabular outputs parameters tables. can done using broom: , simpler way much options (like standardizing, robust standard errors, bootstrapping, …) using model_parameters(), print()-method steps automatically:","code":"data(mtcars) export_table(mtcars[1:8, 1:5]) #>   mpg | cyl |   disp |  hp | drat #> --------------------------------- #> 21.00 |   6 | 160.00 | 110 | 3.90 #> 21.00 |   6 | 160.00 | 110 | 3.90 #> 22.80 |   4 | 108.00 |  93 | 3.85 #> 21.40 |   6 | 258.00 | 110 | 3.08 #> 18.70 |   8 | 360.00 | 175 | 3.15 #> 18.10 |   6 | 225.00 | 105 | 2.76 #> 14.30 |   8 | 360.00 | 245 | 3.21 #> 24.40 |   4 | 146.70 |  62 | 3.69 model %>%   tidy(conf.int = TRUE) %>%   format_table() %>%   export_table() #> term                   | estimate | std.error | statistic | p.value |       conf.int #> ------------------------------------------------------------------------------------ #> (Intercept)            |     3.81 |      0.06 |     65.50 |  < .001 | [ 3.70,  3.93] #> poly(Sepal.Length, 2)1 |     4.06 |      0.47 |      8.70 |  < .001 | [ 3.14,  4.98] #> poly(Sepal.Length, 2)2 |    -1.30 |      0.31 |     -4.14 |  < .001 | [-1.92, -0.68] #> Speciesversicolor      |    -1.01 |      0.28 |     -3.62 |  < .001 | [-1.56, -0.46] #> Speciesvirginica       |    -0.99 |      0.29 |     -3.48 |  < .001 | [-1.55, -0.43] #> Petlen(3,7]            |    -0.14 |      0.28 |     -0.48 |  0.630  | [-0.69,  0.42] model_parameters(model) #> Parameter                 | Coefficient |   SE |         95% CI | t(144) |      p #> --------------------------------------------------------------------------------- #> (Intercept)               |        3.81 | 0.06 | [ 3.70,  3.93] |  65.50 | < .001 #> Sepal Length [1st degree] |        4.06 | 0.47 | [ 3.14,  4.98] |   8.70 | < .001 #> Sepal Length [2nd degree] |       -1.30 | 0.31 | [-1.92, -0.68] |  -4.14 | < .001 #> Species [versicolor]      |       -1.01 | 0.28 | [-1.56, -0.46] |  -3.62 | < .001 #> Species [virginica]       |       -0.99 | 0.29 | [-1.55, -0.43] |  -3.48 | < .001 #> Petlen [4-7]              |       -0.14 | 0.28 | [-0.69,  0.42] |  -0.48 | 0.630"},{"path":"https://easystats.github.io/parameters/articles/model_parameters_formatting.html","id":"formatting-the-parameters-table-in-markdown","dir":"Articles","previous_headings":"","what":"Formatting the Parameters Table in Markdown","title":"Formatting Model Parameters","text":"export_table() provides options generate tables markdown-format. allows easily render nice-looking tables inside markdown-documents. First , use format = \"markdown\" activate markdown-formatting. caption can used add table caption. Furthermore, align allows choose alignment table columns, specify alignment column individually. following table six columns. Using align = \"lcccrr\" left-align first column, center columns two four, right-align last two columns. Table print_md() convenient wrapper around format_table() export_table(format = \"markdown\"), allows directly format output functions like model_parameters(), simulate_parameters() parameters functions markdown-format. tables also nicely formatted knitting markdown-documents Word PDF. print_md() applies default settings proven work well markdown, PDF Word tables. similar option print_html(), convenient wrapper format_table() export_table(format = \"html\"). Using HTML markdown advantage properly rendered exporting PDF. print_md() print_html() considered main functions users want generate nicely rendered tables inside markdown-documents. wrapper around display(), either calls print_md() print_html().","code":"model %>%   tidy(conf.int = TRUE) %>%   # parenthesis look better in markdown-tables, so we use \"brackets\" here   format_table(ci_brackets = c(\"(\", \")\")) %>%   export_table(format = \"markdown\", caption = \"My Table\", align = \"lcccrr\") model_parameters(model) %>% print_md() model_parameters(model) %>% print_html() model_parameters(model) %>% display(format = \"html\")"},{"path":"https://easystats.github.io/parameters/articles/model_parameters_mice.html","id":"model-parameters-from-mira-objects","dir":"Articles","previous_headings":"","what":"Model Parameters from mira objects","title":"Model Parameters for Multiply Imputed Repeated Analyses","text":"model_parameters() can used combination mice package deal missing data, particular summaries regression models used multiple imputed datasets. computes pooled summaries multiple imputed repeated regression analyses, .e. objects class mira. Thus, model_parameters() mira-objects comparable pool()-function mice, focuses final summary parameters include diagnostic statistic per estimate. packages work .mids() package mice. Thus, modeling packages, ’s possible perform multiply imputed repeated analyses, .e. work imputed data models. give example GLMMadaptive package . First, generate dataset missing values. take data cbpp lme4 randomly assign missing values one predictors. impute data, using mice() package mice. Using compute multiple regression analyses imputed dataset fails. However, can use workaround using pool_parameters(), works list model objects. whenever model-object yet supported mice::(), can instead fit multiple models imputed datasets pool parameters pool_parameters(): steps : Calculate regression models imputed dataset manually (either using complete() package mice get imputed datasets, accessing datasets directly mids object) Save model objects list. Pass list pool_parameters(). comparison show results mice:pool() pool_parameters() identical, take example also works mice package:","code":"library(mice) library(parameters)  data(\"nhanes2\") imp <- mice(nhanes2, printFlag = FALSE) fit <- with(data = imp, exp = lm(bmi ~ age + hyp + chl))  model_parameters(fit) #> # Fixed Effects #>  #> Parameter   | Coefficient |   SE |          95% CI | Statistic |    df |      p #> ------------------------------------------------------------------------------- #> (Intercept) |       18.93 | 2.89 | [ 12.82, 25.03] |      6.54 | 16.91 | < .001 #> age40-59    |       -6.16 | 1.65 | [ -9.74, -2.58] |     -3.73 | 12.59 | 0.003  #> age60-99    |       -7.87 | 2.17 | [-12.99, -2.76] |     -3.63 |  7.05 | 0.008  #> hypyes      |        2.23 | 1.68 | [ -1.40,  5.86] |      1.33 | 12.84 | 0.208  #> chl         |        0.06 | 0.02 | [  0.02,  0.09] |      3.51 | 17.27 | 0.003 library(lme4) library(GLMMadaptive)  data(cbpp) cbpp$period[sample(1:nrow(cbpp), size = 10)] <- NA  imputed_data <- mice(cbpp, printFlag = FALSE) fit <- with(data = imputed_data, expr = GLMMadaptive::mixed_model(   cbind(incidence, size - incidence) ~ period,   random = ~ 1 | herd,   family = binomial )) # > Error in as.data.frame(data) : # >   argument \"data\" is missing, with no default models <- lapply(1:imputed_data$m, function(i) {   mixed_model(     cbind(incidence, size - incidence) ~ period,     random = ~ 1 | herd,     data = complete(imputed_data, action = i),     family = binomial   ) }) pool_parameters(models) #> Warning in checkDepPackageVersion(dep_pkg = \"TMB\"): Package version inconsistency detected. #> glmmTMB was built with TMB version 1.9.0 #> Current TMB version is 1.9.1 #> Please re-install glmmTMB from source or restore original 'TMB' package (see '?reinstalling' for more information) #> # Fixed Effects #>  #> Parameter   | Log-Odds |   SE |         95% CI | Statistic |      p #> ------------------------------------------------------------------- #> (Intercept) |    -1.27 | 0.22 | [-1.71, -0.83] |     -5.68 | < .001 #> period [2]  |    -1.12 | 0.35 | [-1.80, -0.43] |     -3.19 | 0.001  #> period [3]  |    -1.91 | 0.43 | [-2.74, -1.07] |     -4.48 | < .001 #> period [4]  |    -1.36 | 0.52 | [-2.38, -0.34] |     -2.62 | 0.009 library(mice) library(parameters)  data(\"nhanes2\") imp <- mice(nhanes2, printFlag = FALSE)  # approach when model is supported by \"mice\" fit <- with(data = imp, exp = lm(bmi ~ age + hyp + chl)) summary(pool(fit)) #>          term estimate std.error statistic   df p.value #> 1 (Intercept)    17.81      3.60      4.95 12.3 0.00031 #> 2    age40-59    -4.66      1.77     -2.63 15.0 0.01880 #> 3    age60-99    -7.46      2.37     -3.14  9.9 0.01064 #> 4      hypyes     1.83      2.39      0.76  7.9 0.46686 #> 5         chl     0.06      0.02      2.99 12.0 0.01126 # approach when model is *not* supported by \"mice\" models <- lapply(1:5, function(i) {   lm(bmi ~ age + hyp + chl, data = complete(imp, action = i)) }) pool_parameters(models) #> # Fixed Effects #>  #> Parameter   | Coefficient |   SE |          95% CI | Statistic |    df |      p #> ------------------------------------------------------------------------------- #> (Intercept) |       17.81 | 3.60 | [  9.99, 25.63] |      4.95 | 12.25 | < .001 #> age [40-59] |       -4.66 | 1.77 | [ -8.43, -0.89] |     -2.63 | 15.00 | 0.019  #> age [60-99] |       -7.46 | 2.37 | [-12.76, -2.16] |     -3.14 |  9.90 | 0.011  #> hyp [yes]   |        1.83 | 2.39 | [ -3.70,  7.36] |      0.76 |  7.88 | 0.467  #> chl         |        0.06 | 0.02 | [  0.02,  0.10] |      2.99 | 11.99 | 0.011"},{"path":"https://easystats.github.io/parameters/articles/model_parameters_mice.html","id":"model-parameters-from-mipo-objects","dir":"Articles","previous_headings":"","what":"Model Parameters from mipo objects","title":"Model Parameters for Multiply Imputed Repeated Analyses","text":"also possible compute summaries pooled objects class mipo.","code":"data(\"nhanes2\") imp <- mice(nhanes2, printFlag = FALSE) fit <- with(data = imp, exp = lm(bmi ~ age + hyp + chl)) pooled <- pool(fit)  model_parameters(pooled) #> # Fixed Effects #>  #> Parameter   | Coefficient |   SE |          95% CI |     t |    df |      p #> --------------------------------------------------------------------------- #> (Intercept) |       17.81 | 3.60 | [  9.99, 25.63] |  4.95 | 12.25 | < .001 #> age [40-59] |       -4.66 | 1.77 | [ -8.43, -0.89] | -2.63 | 15.00 | 0.019  #> age [60-99] |       -7.46 | 2.37 | [-12.76, -2.16] | -3.14 |  9.90 | 0.011  #> hyp [yes]   |        1.83 | 2.39 | [ -3.70,  7.36] |  0.76 |  7.88 | 0.467  #> chl         |        0.06 | 0.02 | [  0.02,  0.10] |  2.99 | 11.99 | 0.011"},{"path":"https://easystats.github.io/parameters/articles/model_parameters_print.html","id":"summaries-for-a-single-model","dir":"Articles","previous_headings":"","what":"Summaries for a single model","title":"Printing Model Parameters","text":"following examples model_parameters(), returns tabular output single models, shown.","code":""},{"path":"https://easystats.github.io/parameters/articles/model_parameters_print.html","id":"pretty-parameter-names-formatting","dir":"Articles","previous_headings":"Summaries for a single model","what":"Pretty parameter names formatting","title":"Printing Model Parameters","text":"default, argument pretty_names TRUE, meaning parameter names formatted make “human readable”, .e. factor levels separated variable names, interactions denoted * etc.","code":"library(parameters) data(iris) model <- lm(Sepal.Length ~ Species * Petal.Length, data = iris) model_parameters(model) #> Parameter                           | Coefficient |   SE |         95% CI | t(144) |      p #> ------------------------------------------------------------------------------------------- #> (Intercept)                         |        4.21 | 0.41 | [ 3.41,  5.02] |  10.34 | < .001 #> Species [versicolor]                |       -1.81 | 0.60 | [-2.99, -0.62] |  -3.02 | 0.003  #> Species [virginica]                 |       -3.15 | 0.63 | [-4.41, -1.90] |  -4.97 | < .001 #> Petal Length                        |        0.54 | 0.28 | [ 0.00,  1.09] |   1.96 | 0.052  #> Species [versicolor] * Petal Length |        0.29 | 0.30 | [-0.30,  0.87] |   0.97 | 0.334  #> Species [virginica] * Petal Length  |        0.45 | 0.29 | [-0.12,  1.03] |   1.56 | 0.120  mp <- model_parameters(model) print(mp, pretty_names = FALSE) #> Parameter                      | Coefficient |   SE |         95% CI | t(144) |      p #> -------------------------------------------------------------------------------------- #> (Intercept)                    |        4.21 | 0.41 | [ 3.41,  5.02] |  10.34 | < .001 #> Speciesversicolor              |       -1.81 | 0.60 | [-2.99, -0.62] |  -3.02 | 0.003  #> Speciesvirginica               |       -3.15 | 0.63 | [-4.41, -1.90] |  -4.97 | < .001 #> Petal.Length                   |        0.54 | 0.28 | [ 0.00,  1.09] |   1.96 | 0.052  #> Speciesversicolor:Petal.Length |        0.29 | 0.30 | [-0.30,  0.87] |   0.97 | 0.334  #> Speciesvirginica:Petal.Length  |        0.45 | 0.29 | [-0.12,  1.03] |   1.56 | 0.120"},{"path":"https://easystats.github.io/parameters/articles/model_parameters_print.html","id":"splitting-model-components","dir":"Articles","previous_headings":"Summaries for a single model","what":"Splitting model components","title":"Printing Model Parameters","text":"default, argument split_components TRUE, means models multiple components like fixed random effects, count zero-inflated part etc. split separate tables output. Redundant columns removed. related model component shown table header. However, can also return single table:","code":"library(glmmTMB) data(\"Salamanders\") model <- glmmTMB(count ~ spp + mined + (1 | site),   ziformula = ~ spp + mined,   family = nbinom2(),   data = Salamanders ) model_parameters(model) #> # Fixed Effects (Count Model) #>  #> Parameter   | Log-Mean |   SE |        95% CI |     z |      p #> -------------------------------------------------------------- #> (Intercept) |    -0.61 | 0.41 | [-1.40, 0.18] | -1.51 | 0.132  #> spp [PR]    |    -0.96 | 0.64 | [-2.23, 0.30] | -1.50 | 0.134  #> spp [DM]    |     0.17 | 0.24 | [-0.29, 0.63] |  0.73 | 0.468  #> spp [EC-A]  |    -0.39 | 0.34 | [-1.06, 0.28] | -1.13 | 0.258  #> spp [EC-L]  |     0.49 | 0.24 | [ 0.02, 0.96] |  2.05 | 0.041  #> spp [DES-L] |     0.59 | 0.23 | [ 0.14, 1.04] |  2.59 | 0.010  #> spp [DF]    |    -0.11 | 0.24 | [-0.59, 0.36] | -0.46 | 0.642  #> mined [no]  |     1.43 | 0.37 | [ 0.71, 2.15] |  3.90 | < .001 #>  #> # Fixed Effects (Zero-Inflated Model) #>  #> Parameter   | Log-Odds |   SE |         95% CI |     z |      p #> --------------------------------------------------------------- #> (Intercept) |     0.91 | 0.63 | [-0.32,  2.14] |  1.45 | 0.147  #> spp [PR]    |     1.16 | 1.33 | [-1.45,  3.78] |  0.87 | 0.384  #> spp [DM]    |    -0.94 | 0.80 | [-2.51,  0.63] | -1.17 | 0.241  #> spp [EC-A]  |     1.04 | 0.71 | [-0.36,  2.44] |  1.46 | 0.144  #> spp [EC-L]  |    -0.56 | 0.73 | [-1.99,  0.86] | -0.77 | 0.439  #> spp [DES-L] |    -0.89 | 0.75 | [-2.37,  0.58] | -1.19 | 0.236  #> spp [DF]    |    -2.54 | 2.18 | [-6.82,  1.74] | -1.16 | 0.244  #> mined [no]  |    -2.56 | 0.60 | [-3.75, -1.38] | -4.24 | < .001 #>  #> # Dispersion #>  #> Parameter   | Coefficient |       95% CI #> ---------------------------------------- #> (Intercept) |        1.51 | [0.93, 2.46] #>  #> # Random Effects Variances #>  #> Parameter            | Coefficient |       95% CI #> ------------------------------------------------- #> SD (Intercept: site) |        0.38 | [0.17, 0.87] mp <- model_parameters(model) print(mp, split_component = FALSE) #> # Fixed Effects #>  #> Parameter            | Coefficient |   SE |         95% CI |     z |      p | Effects |     Component #> ----------------------------------------------------------------------------------------------------- #> (Intercept)          |       -0.61 | 0.41 | [-1.40,  0.18] | -1.51 | 0.132  |   fixed |   conditional #> spp [PR]             |       -0.96 | 0.64 | [-2.23,  0.30] | -1.50 | 0.134  |   fixed |   conditional #> spp [DM]             |        0.17 | 0.24 | [-0.29,  0.63] |  0.73 | 0.468  |   fixed |   conditional #> spp [EC-A]           |       -0.39 | 0.34 | [-1.06,  0.28] | -1.13 | 0.258  |   fixed |   conditional #> spp [EC-L]           |        0.49 | 0.24 | [ 0.02,  0.96] |  2.05 | 0.041  |   fixed |   conditional #> spp [DES-L]          |        0.59 | 0.23 | [ 0.14,  1.04] |  2.59 | 0.010  |   fixed |   conditional #> spp [DF]             |       -0.11 | 0.24 | [-0.59,  0.36] | -0.46 | 0.642  |   fixed |   conditional #> mined [no]           |        1.43 | 0.37 | [ 0.71,  2.15] |  3.90 | < .001 |   fixed |   conditional #> (Intercept)          |        0.91 | 0.63 | [-0.32,  2.14] |  1.45 | 0.147  |   fixed | zero_inflated #> sppPR                |        1.16 | 1.33 | [-1.45,  3.78] |  0.87 | 0.384  |   fixed | zero_inflated #> sppDM                |       -0.94 | 0.80 | [-2.51,  0.63] | -1.17 | 0.241  |   fixed | zero_inflated #> sppEC-A              |        1.04 | 0.71 | [-0.36,  2.44] |  1.46 | 0.144  |   fixed | zero_inflated #> sppEC-L              |       -0.56 | 0.73 | [-1.99,  0.86] | -0.77 | 0.439  |   fixed | zero_inflated #> sppDES-L             |       -0.89 | 0.75 | [-2.37,  0.58] | -1.19 | 0.236  |   fixed | zero_inflated #> sppDF                |       -2.54 | 2.18 | [-6.82,  1.74] | -1.16 | 0.244  |   fixed | zero_inflated #> minedno              |       -2.56 | 0.60 | [-3.75, -1.38] | -4.24 | < .001 |   fixed | zero_inflated #> (Intercept)          |        1.51 |      | [ 0.93,  2.46] |       |        |   fixed |    dispersion #> SD (Intercept: site) |        0.38 |      | [ 0.17,  0.87] |       |        |  random |   conditional"},{"path":"https://easystats.github.io/parameters/articles/model_parameters_print.html","id":"adding-model-summaries","dir":"Articles","previous_headings":"Summaries for a single model","what":"Adding model summaries","title":"Printing Model Parameters","text":"model summary can added table summary = TRUE call model_parameters():","code":"model <- lm(Sepal.Length ~ Species * Petal.Length, data = iris) model_parameters(model, summary = TRUE) #> Parameter                           | Coefficient |   SE |         95% CI | t(144) |      p #> ------------------------------------------------------------------------------------------- #> (Intercept)                         |        4.21 | 0.41 | [ 3.41,  5.02] |  10.34 | < .001 #> Species [versicolor]                |       -1.81 | 0.60 | [-2.99, -0.62] |  -3.02 | 0.003  #> Species [virginica]                 |       -3.15 | 0.63 | [-4.41, -1.90] |  -4.97 | < .001 #> Petal Length                        |        0.54 | 0.28 | [ 0.00,  1.09] |   1.96 | 0.052  #> Species [versicolor] * Petal Length |        0.29 | 0.30 | [-0.30,  0.87] |   0.97 | 0.334  #> Species [virginica] * Petal Length  |        0.45 | 0.29 | [-0.12,  1.03] |   1.56 | 0.120  #>  #> Model: Sepal.Length ~ Species * Petal.Length (150 Observations) #> Residual standard deviation: 0.336 (df = 144) #> R2: 0.840; adjusted R2: 0.835"},{"path":"https://easystats.github.io/parameters/articles/model_parameters_print.html","id":"changing-number-of-digits","dir":"Articles","previous_headings":"Summaries for a single model","what":"Changing number of digits","title":"Printing Model Parameters","text":"digits changes digits coefficients, standard errors statistics. ci_digits p_digits especially confidence intervals p-values. p-values can displayed exact, scientific notation required.","code":"model <- lm(Sepal.Length ~ Species, data = iris) model_parameters(model, digits = 4) #> Parameter            | Coefficient |     SE |       95% CI |  t(147) |      p #> ----------------------------------------------------------------------------- #> (Intercept)          |      5.0060 | 0.0728 | [4.86, 5.15] | 68.7616 | < .001 #> Species [versicolor] |      0.9300 | 0.1030 | [0.73, 1.13] |  9.0328 | < .001 #> Species [virginica]  |      1.5820 | 0.1030 | [1.38, 1.79] | 15.3655 | < .001 model_parameters(model, p_digits = \"scientific\") #> Parameter            | Coefficient |   SE |       95% CI | t(147) |            p #> -------------------------------------------------------------------------------- #> (Intercept)          |        5.01 | 0.07 | [4.86, 5.15] |  68.76 | 1.13429e-113 #> Species [versicolor] |        0.93 | 0.10 | [0.73, 1.13] |   9.03 | 8.77019e-16  #> Species [virginica]  |        1.58 | 0.10 | [1.38, 1.79] |  15.37 | 2.21482e-32"},{"path":"https://easystats.github.io/parameters/articles/model_parameters_print.html","id":"fixing-column-widths","dir":"Articles","previous_headings":"Summaries for a single model","what":"Fixing column widths","title":"Printing Model Parameters","text":"default, width table columns set minimum required width. works well models produce just one table. However, models multiple components, component shown separate table, columns possibly longer aligned across tables. See following example zero-inflated mixed model three components (fixed count, fixed zero-inflated, random effects): column_width argument can used either define width specific columns, fix column widths columns across tables width. latter case, use column_width = \"fixed\" print() method. column_width named vector, names matched column names, columns gain specified minimum width.","code":"data(\"Salamanders\") # we create very long parameter names for this predictor here levels(Salamanders$spp) <- paste(\"long\", levels(Salamanders$spp))  model <- glmmTMB(   count ~ spp + mined + (1 | site),   ziformula = ~mined,   family = poisson(),   data = Salamanders )  # default printing model_parameters(model) #> # Fixed Effects (Count Model) #>  #> Parameter        | Log-Mean |   SE |         95% CI |     z |      p #> -------------------------------------------------------------------- #> (Intercept)      |    -0.36 | 0.28 | [-0.90,  0.18] | -1.30 | 0.194  #> spp [long PR]    |    -1.27 | 0.24 | [-1.74, -0.80] | -5.27 | < .001 #> spp [long DM]    |     0.27 | 0.14 | [ 0.00,  0.54] |  1.95 | 0.051  #> spp [long EC-A]  |    -0.57 | 0.21 | [-0.97, -0.16] | -2.75 | 0.006  #> spp [long EC-L]  |     0.67 | 0.13 | [ 0.41,  0.92] |  5.20 | < .001 #> spp [long DES-L] |     0.63 | 0.13 | [ 0.38,  0.87] |  4.96 | < .001 #> spp [long DF]    |     0.12 | 0.15 | [-0.17,  0.40] |  0.78 | 0.435  #> mined [no]       |     1.27 | 0.27 | [ 0.74,  1.80] |  4.72 | < .001 #>  #> # Fixed Effects (Zero-Inflated Model) #>  #> Parameter   | Log-Odds |   SE |         95% CI |     z |      p #> --------------------------------------------------------------- #> (Intercept) |     0.79 | 0.27 | [ 0.26,  1.32] |  2.90 | 0.004  #> mined [no]  |    -1.84 | 0.31 | [-2.46, -1.23] | -5.87 | < .001 #>  #> # Random Effects Variances #>  #> Parameter            | Coefficient |       95% CI #> ------------------------------------------------- #> SD (Intercept: site) |        0.33 | [0.18, 0.63] mp <- model_parameters(model) print(mp, column_width = \"fixed\") #> # Fixed Effects (Count Model) #>  #> Parameter            | Log-Mean |   SE |         95% CI |     z |      p #> ------------------------------------------------------------------------ #> (Intercept)          |    -0.36 | 0.28 | [-0.90,  0.18] | -1.30 | 0.194  #> spp [long PR]        |    -1.27 | 0.24 | [-1.74, -0.80] | -5.27 | < .001 #> spp [long DM]        |     0.27 | 0.14 | [ 0.00,  0.54] |  1.95 | 0.051  #> spp [long EC-A]      |    -0.57 | 0.21 | [-0.97, -0.16] | -2.75 | 0.006  #> spp [long EC-L]      |     0.67 | 0.13 | [ 0.41,  0.92] |  5.20 | < .001 #> spp [long DES-L]     |     0.63 | 0.13 | [ 0.38,  0.87] |  4.96 | < .001 #> spp [long DF]        |     0.12 | 0.15 | [-0.17,  0.40] |  0.78 | 0.435  #> mined [no]           |     1.27 | 0.27 | [ 0.74,  1.80] |  4.72 | < .001 #>  #> # Fixed Effects (Zero-Inflated Model) #>  #> Parameter            | Log-Odds |   SE |         95% CI |     z |      p #> ------------------------------------------------------------------------ #> (Intercept)          |     0.79 | 0.27 | [ 0.26,  1.32] |  2.90 | 0.004  #> mined [no]           |    -1.84 | 0.31 | [-2.46, -1.23] | -5.87 | < .001 #>  #> # Random Effects Variances #>  #> Parameter            | Coefficient |         95% CI #> --------------------------------------------------- #> SD (Intercept: site) |        0.33 |   [0.18, 0.63] print(mp, column_width = c(SE = 8, `95% CI` = 12, p = 7)) #> # Fixed Effects (Count Model) #>  #> Parameter        | Log-Mean |       SE |         95% CI |     z |       p #> ------------------------------------------------------------------------- #> (Intercept)      |    -0.36 |     0.28 | [-0.90,  0.18] | -1.30 |   0.194 #> spp [long PR]    |    -1.27 |     0.24 | [-1.74, -0.80] | -5.27 |  < .001 #> spp [long DM]    |     0.27 |     0.14 | [ 0.00,  0.54] |  1.95 |   0.051 #> spp [long EC-A]  |    -0.57 |     0.21 | [-0.97, -0.16] | -2.75 |   0.006 #> spp [long EC-L]  |     0.67 |     0.13 | [ 0.41,  0.92] |  5.20 |  < .001 #> spp [long DES-L] |     0.63 |     0.13 | [ 0.38,  0.87] |  4.96 |  < .001 #> spp [long DF]    |     0.12 |     0.15 | [-0.17,  0.40] |  0.78 |   0.435 #> mined [no]       |     1.27 |     0.27 | [ 0.74,  1.80] |  4.72 |  < .001 #>  #> # Fixed Effects (Zero-Inflated Model) #>  #> Parameter   | Log-Odds |       SE |         95% CI |     z |       p #> -------------------------------------------------------------------- #> (Intercept) |     0.79 |     0.27 | [ 0.26,  1.32] |  2.90 |   0.004 #> mined [no]  |    -1.84 |     0.31 | [-2.46, -1.23] | -5.87 |  < .001 #>  #> # Random Effects Variances #>  #> Parameter            | Coefficient |       95% CI #> ------------------------------------------------- #> SD (Intercept: site) |        0.33 | [0.18, 0.63]"},{"path":"https://easystats.github.io/parameters/articles/model_parameters_print.html","id":"group-parameters","dir":"Articles","previous_headings":"Summaries for a single model","what":"Group parameters","title":"Printing Model Parameters","text":"groups argument can used group parameters table. groups must named list, names list elements equal header group, values list elements equal parameter names, position parameters table (data frame). following example, see names parameters Parameter column, rownumbers indicate position. Now create group named \"Engine\", encompasses parameters \"cyl6\", \"cyl8\", \"vs\" \"hp\". \"Interactions\" group includes \"gear4:vs\" \"gear5:vs\". group \"controls\" parameters rows 2, 3 7. Note parameters table summary re-ordered according order specified groups. prefer tables without vertical borders, use sep argument define string used border-separator. argument passed insight::export_table().","code":"data(mtcars) mtcars$cyl <- as.factor(mtcars$cyl) mtcars$gear <- as.factor(mtcars$gear) model <- lm(mpg ~ hp + gear * vs + cyl + drat, data = mtcars)  # don't select \"Intercept\" parameter mp <- model_parameters(model, drop = \"^\\\\(Intercept\")  # inspect data frame as.data.frame(mp) #>   Parameter Coefficient    SE   CI CI_low CI_high     t df_error      p #> 1        hp      -0.062 0.021 0.95  -0.11  -0.018 -2.91       22 0.0081 #> 2     gear4       3.100 4.339 0.95  -5.90  12.098  0.71       22 0.4825 #> 3     gear5       4.798 3.478 0.95  -2.42  12.011  1.38       22 0.1816 #> 4        vs       3.183 3.790 0.95  -4.68  11.042  0.84       22 0.4100 #> 5      cyl6      -2.466 2.210 0.95  -7.05   2.116 -1.12       22 0.2764 #> 6      cyl8       1.975 5.111 0.95  -8.63  12.575  0.39       22 0.7029 #> 7      drat       2.697 2.033 0.95  -1.52   6.913  1.33       22 0.1983 #> 8  gear4:vs      -2.897 4.665 0.95 -12.57   6.778 -0.62       22 0.5410 #> 9  gear5:vs       2.588 4.537 0.95  -6.82  11.998  0.57       22 0.5741 # group parameters, either by parameter name or position print(mp, groups = list(   \"Engine\" = c(\"cyl6\", \"cyl8\", \"vs\", \"hp\"),   \"Interactions\" = c(\"gear4:vs\", \"gear5:vs\"),   \"Controls\" = c(2, 3, 7) )) # gear 4 and 5, drat #> Parameter        | Coefficient |   SE |          95% CI | t(22) |     p #> ----------------------------------------------------------------------- #> Engine           |             |      |                 |       |       #>   cyl [6]        |       -2.47 | 2.21 | [ -7.05,  2.12] | -1.12 | 0.276 #>   cyl [8]        |        1.97 | 5.11 | [ -8.63, 12.58] |  0.39 | 0.703 #>   vs             |        3.18 | 3.79 | [ -4.68, 11.04] |  0.84 | 0.410 #>   hp             |       -0.06 | 0.02 | [ -0.11, -0.02] | -2.91 | 0.008 #> Interactions     |             |      |                 |       |       #>   gear [4] * vs  |       -2.90 | 4.67 | [-12.57,  6.78] | -0.62 | 0.541 #>   gear [5] * vs  |        2.59 | 4.54 | [ -6.82, 12.00] |  0.57 | 0.574 #> Controls         |             |      |                 |       |       #>   gear [4]       |        3.10 | 4.34 | [ -5.90, 12.10] |  0.71 | 0.482 #>   gear [5]       |        4.80 | 3.48 | [ -2.42, 12.01] |  1.38 | 0.182 #>   drat           |        2.70 | 2.03 | [ -1.52,  6.91] |  1.33 | 0.198 # group parameters, either by parameter name or position print(mp,   sep = \"  \",   groups = list(     \"Engine\" = c(\"cyl6\", \"cyl8\", \"vs\", \"hp\"),     \"Interactions\" = c(\"gear4:vs\", \"gear5:vs\"),     \"Controls\" = c(2, 3, 7)   ) ) #> Parameter         Coefficient    SE           95% CI  t(22)      p #> ------------------------------------------------------------------ #> Engine                                                             #>   cyl [6]               -2.47  2.21  [ -7.05,  2.12]  -1.12  0.276 #>   cyl [8]                1.97  5.11  [ -8.63, 12.58]   0.39  0.703 #>   vs                     3.18  3.79  [ -4.68, 11.04]   0.84  0.410 #>   hp                    -0.06  0.02  [ -0.11, -0.02]  -2.91  0.008 #> Interactions                                                       #>   gear [4] * vs         -2.90  4.67  [-12.57,  6.78]  -0.62  0.541 #>   gear [5] * vs          2.59  4.54  [ -6.82, 12.00]   0.57  0.574 #> Controls                                                           #>   gear [4]               3.10  4.34  [ -5.90, 12.10]   0.71  0.482 #>   gear [5]               4.80  3.48  [ -2.42, 12.01]   1.38  0.182 #>   drat                   2.70  2.03  [ -1.52,  6.91]   1.33  0.198"},{"path":"https://easystats.github.io/parameters/articles/model_parameters_print.html","id":"summaries-for-multiple-models","dir":"Articles","previous_headings":"","what":"Summaries for multiple models","title":"Printing Model Parameters","text":"compare_parameters() (alias compare_models()) allows create tables multiple models, aligned side side. default, estimates confidence intervals shown.","code":"data(iris) lm1 <- lm(Sepal.Length ~ Species, data = iris) lm2 <- lm(Sepal.Length ~ Species + Petal.Length, data = iris) lm3 <- lm(Sepal.Length ~ Species * Petal.Length, data = iris) compare_parameters(lm1, lm2, lm3) #> Parameter                           |               lm1 |                  lm2 |                  lm3 #> ----------------------------------------------------------------------------------------------------- #> (Intercept)                         | 5.01 (4.86, 5.15) |  3.68 ( 3.47,  3.89) |  4.21 ( 3.41,  5.02) #> Species (versicolor)                | 0.93 (0.73, 1.13) | -1.60 (-1.98, -1.22) | -1.81 (-2.99, -0.62) #> Species (virginica)                 | 1.58 (1.38, 1.79) | -2.12 (-2.66, -1.58) | -3.15 (-4.41, -1.90) #> Petal Length                        |                   |  0.90 ( 0.78,  1.03) |  0.54 ( 0.00,  1.09) #> Species (versicolor) * Petal Length |                   |                      |  0.29 (-0.30,  0.87) #> Species (virginica) * Petal Length  |                   |                      |  0.45 (-0.12,  1.03) #> ----------------------------------------------------------------------------------------------------- #> Observations                        |               150 |                  150 |                  150"},{"path":"https://easystats.github.io/parameters/articles/model_parameters_print.html","id":"changing-style-of-column-output","dir":"Articles","previous_headings":"Summaries for multiple models","what":"Changing style of column output","title":"Printing Model Parameters","text":"default, estimates confidence intervals shown. Using style allows us create different output, e.g. standard errors instead confidence intervals, including p-values.","code":"compare_parameters(lm1, lm2, lm3, style = \"se_p\") #> Parameter                           |            lm1 |             lm2 |             lm3 #> ---------------------------------------------------------------------------------------- #> (Intercept)                         | 5.01*** (0.07) |  3.68*** (0.11) |  4.21*** (0.41) #> Species (versicolor)                | 0.93*** (0.10) | -1.60*** (0.19) |  -1.81** (0.60) #> Species (virginica)                 | 1.58*** (0.10) | -2.12*** (0.27) | -3.15*** (0.63) #> Petal Length                        |                |  0.90*** (0.06) |     0.54 (0.28) #> Species (versicolor) * Petal Length |                |                 |     0.29 (0.30) #> Species (virginica) * Petal Length  |                |                 |     0.45 (0.29) #> ---------------------------------------------------------------------------------------- #> Observations                        |            150 |             150 |             150"},{"path":"https://easystats.github.io/parameters/articles/model_parameters_print.html","id":"defining-column-names","dir":"Articles","previous_headings":"Summaries for multiple models","what":"Defining column names","title":"Printing Model Parameters","text":"column names models default objects’ names. can define names using column_names argument.","code":"compare_parameters(   lm1, lm2, lm3,   column_names = c(\"First Model\", \"Second Model\", \"Third Model\") ) #> Parameter                           |       First Model |         Second Model |          Third Model #> ----------------------------------------------------------------------------------------------------- #> (Intercept)                         | 5.01 (4.86, 5.15) |  3.68 ( 3.47,  3.89) |  4.21 ( 3.41,  5.02) #> Species (versicolor)                | 0.93 (0.73, 1.13) | -1.60 (-1.98, -1.22) | -1.81 (-2.99, -0.62) #> Species (virginica)                 | 1.58 (1.38, 1.79) | -2.12 (-2.66, -1.58) | -3.15 (-4.41, -1.90) #> Petal Length                        |                   |  0.90 ( 0.78,  1.03) |  0.54 ( 0.00,  1.09) #> Species (versicolor) * Petal Length |                   |                      |  0.29 (-0.30,  0.87) #> Species (virginica) * Petal Length  |                   |                      |  0.45 (-0.12,  1.03) #> ----------------------------------------------------------------------------------------------------- #> Observations                        |               150 |                  150 |                  150"},{"path":"https://easystats.github.io/parameters/articles/model_parameters_print.html","id":"group-parameters-of-multiple-model-tables","dir":"Articles","previous_headings":"Summaries for multiple models","what":"Group parameters of multiple model tables","title":"Printing Model Parameters","text":"Grouping parameters works compare_models() way shown model_parameters().","code":"lm1 <- lm(Sepal.Length ~ Species + Petal.Length, data = iris) lm2 <- lm(Sepal.Width ~ Species * Petal.Length, data = iris)  # remove intercept cp <- compare_parameters(lm1, lm2, drop = \"^\\\\(Intercept\")  # look at parameters names, to know their names for \"groups\" argument as.data.frame(cp)$Parameter #> [1] \"Species (versicolor)\"                \"Species (virginica)\"                 #> [3] \"Petal Length\"                        \"Species (versicolor) * Petal Length\" #> [5] \"Species (virginica) * Petal Length\"  # create groups. Interactions only present in 2nd model print(cp, groups = list(   Species = c(     \"Species (versicolor)\",     \"Species (virginica)\"   ),   Interactions = c(     \"Species (versicolor) * Petal Length\",     \"Species (virginica) * Petal Length\"   ),   Controls = \"Petal Length\" )) #> Parameter                             |                  lm1 |                  lm2 #> ----------------------------------------------------------------------------------- #> Species                               |                      |                      #>   Species (versicolor)                | -1.60 (-1.98, -1.22) | -1.69 (-2.80, -0.57) #>   Species (virginica)                 | -2.12 (-2.66, -1.58) | -1.19 (-2.37, -0.01) #> Interactions                          |                      |                      #>   Species (versicolor) * Petal Length |                      | -0.01 (-0.56,  0.53) #>   Species (virginica) * Petal Length  |                      | -0.15 (-0.69,  0.39) #> Controls                              |                      |                      #>   Petal Length                        |  0.90 ( 0.78,  1.03) |  0.39 (-0.13,  0.90) #> ----------------------------------------------------------------------------------- #>   Observations                        |                  150 |                  150"},{"path":"https://easystats.github.io/parameters/articles/model_parameters_print.html","id":"splitting-wide-tables-into-multiple-table-parts","dir":"Articles","previous_headings":"","what":"Splitting wide tables into multiple table parts","title":"Printing Model Parameters","text":"wide tables displayed properly, can use table_width argument print() method split tables multiple parts. table_width can numeric value, \"auto\", indicating width complete table. table_width = \"auto\" table wider current available width (.e. line length) console (source textual output, like markdown files), table split multiple parts. Else, table_width numeric table rows wider table_width, table split multiple parts.","code":"data(iris) lm1 <- lm(Sepal.Length ~ Species, data = iris) lm2 <- lm(Sepal.Length ~ Species + Petal.Length, data = iris) lm3 <- lm(Sepal.Length ~ Species * Petal.Length, data = iris) lm4 <- lm(Sepal.Length ~ Species * Petal.Length + Petal.Width, data = iris)  # very wide table compare_parameters(lm1, lm2, lm3, lm4) #> Parameter                           |               lm1 |                  lm2 |                  lm3 |                  lm4 #> ---------------------------------------------------------------------------------------------------------------------------- #> (Intercept)                         | 5.01 (4.86, 5.15) |  3.68 ( 3.47,  3.89) |  4.21 ( 3.41,  5.02) |  4.21 ( 3.41,  5.02) #> Species (versicolor)                | 0.93 (0.73, 1.13) | -1.60 (-1.98, -1.22) | -1.81 (-2.99, -0.62) | -1.80 (-2.99, -0.62) #> Species (virginica)                 | 1.58 (1.38, 1.79) | -2.12 (-2.66, -1.58) | -3.15 (-4.41, -1.90) | -3.19 (-4.50, -1.88) #> Petal Length                        |                   |  0.90 ( 0.78,  1.03) |  0.54 ( 0.00,  1.09) |  0.54 (-0.02,  1.09) #> Species (versicolor) * Petal Length |                   |                      |  0.29 (-0.30,  0.87) |  0.28 (-0.30,  0.87) #> Species (virginica) * Petal Length  |                   |                      |  0.45 (-0.12,  1.03) |  0.45 (-0.12,  1.03) #> Petal Width                         |                   |                      |                      |  0.03 (-0.28,  0.34) #> ---------------------------------------------------------------------------------------------------------------------------- #> Observations                        |               150 |                  150 |                  150 |                  150  # table split into two parts tab <- compare_parameters(lm1, lm2, lm3, lm4) print(tab, table_width = 80) #> Parameter                           |               lm1 |                  lm2 #> ------------------------------------------------------------------------------ #> (Intercept)                         | 5.01 (4.86, 5.15) |  3.68 ( 3.47,  3.89) #> Species (versicolor)                | 0.93 (0.73, 1.13) | -1.60 (-1.98, -1.22) #> Species (virginica)                 | 1.58 (1.38, 1.79) | -2.12 (-2.66, -1.58) #> Petal Length                        |                   |  0.90 ( 0.78,  1.03) #> Species (versicolor) * Petal Length |                   |                      #> Species (virginica) * Petal Length  |                   |                      #> Petal Width                         |                   |                      #> ------------------------------------------------------------------------------ #> Observations                        |               150 |                  150 #>  #> Parameter                           |                  lm3 |                  lm4 #> --------------------------------------------------------------------------------- #> (Intercept)                         |  4.21 ( 3.41,  5.02) |  4.21 ( 3.41,  5.02) #> Species (versicolor)                | -1.81 (-2.99, -0.62) | -1.80 (-2.99, -0.62) #> Species (virginica)                 | -3.15 (-4.41, -1.90) | -3.19 (-4.50, -1.88) #> Petal Length                        |  0.54 ( 0.00,  1.09) |  0.54 (-0.02,  1.09) #> Species (versicolor) * Petal Length |  0.29 (-0.30,  0.87) |  0.28 (-0.30,  0.87) #> Species (virginica) * Petal Length  |  0.45 (-0.12,  1.03) |  0.45 (-0.12,  1.03) #> Petal Width                         |                      |  0.03 (-0.28,  0.34) #> --------------------------------------------------------------------------------- #> Observations                        |                  150 |                  150"},{"path":"https://easystats.github.io/parameters/articles/model_parameters_print.html","id":"more-advances-tables-and-markdown-html-formatting","dir":"Articles","previous_headings":"","what":"More advances tables and markdown / HTML formatting","title":"Printing Model Parameters","text":"print_md() well print_html() functions can used create markdown (knitting PDF Word) HTML tables. Meanwhile, lot additional packages allow users even flexibility regarding table layouts. One package can recommend modelsummary package.","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/articles/model_parameters_robust.html","id":"robust-covariance-matrix-estimation-from-model-parameters","dir":"Articles","previous_headings":"Linear Regression Models","what":"Robust Covariance Matrix Estimation from Model Parameters","title":"Robust Estimation of Standard Errors, Confidence Intervals, and p-values","text":"two arguments (see ?standard_error details) allow choosing different methods options robust estimation: - vcov - vcov_args Let us start simple example, uses heteroskedasticity-consistent covariance matrix estimation estimation-type “HC3” (.e. sandwich::vcovHC(type = \"HC3\")). First let’s create simple linear regression model, know violates homoscedasticity assumption, thus robust estimation methods considered. extract model parameters without robust estimation highlight difference makes standard errors, confidence intervals, t-statistic, p-values. Also, note coefficient estimate remains unchanged.","code":"data(cars) model <- lm(dist ~ speed, data = cars)  library(performance) check_heteroscedasticity(model) #> Warning: Heteroscedasticity (non-constant error variance) detected (p = 0.031). # model parameters, where SE, CI, and p-values are *not* based on robust estimation model_parameters(model) #> Parameter   | Coefficient |   SE |          95% CI | t(48) |      p #> ------------------------------------------------------------------- #> (Intercept) |      -17.58 | 6.76 | [-31.17, -3.99] | -2.60 | 0.012  #> speed       |        3.93 | 0.42 | [  3.10,  4.77] |  9.46 | < .001  # model parameters, where SE, CI, and p-values are based on robust estimation mp <- model_parameters(model, vcov = \"HC3\") mp #> Parameter   | Coefficient |   SE |          95% CI | t(48) |      p #> ------------------------------------------------------------------- #> (Intercept) |      -17.58 | 5.93 | [-29.51, -5.65] | -2.96 | 0.005  #> speed       |        3.93 | 0.43 | [  3.07,  4.79] |  9.20 | < .001  # compare standard errors to result from sandwich-package mp$SE #> [1] 5.93 0.43 unname(sqrt(diag(sandwich::vcovHC(model)))) #> [1] 5.93 0.43"},{"path":"https://easystats.github.io/parameters/articles/model_parameters_robust.html","id":"cluster-robust-covariance-matrix-estimation-sandwich","dir":"Articles","previous_headings":"Linear Regression Models","what":"Cluster-Robust Covariance Matrix Estimation (sandwich)","title":"Robust Estimation of Standard Errors, Confidence Intervals, and p-values","text":"different type covariance matrix estimation required, use vcov-argument. argument accepts name function sandwich clubSandwich packages string, \"vcovCL\" (just suffix \"CL\"). parameters call corresponding function content vcov_args arguments. specific estimation type can controlled passing type argument via vcov_args. See ?sandwich::vcovCL information different types covariance matrices function can produce (HC0 HC3). next example, use clustered covariance matrix estimation HC1-estimation type. Usually, clustered covariance matrix estimation used cluster-structure data. variable indicating cluster-structure can defined sandwich::vcovCL() cluster-argument. model_parameters(), additional arguments passed functions sandwich package can specified vcov_args:","code":"# let's create a more complicated model data(iris) model <- lm(Petal.Length ~ Sepal.Length * Species + Sepal.Width, data = iris)  # change estimation-type mp <- model_parameters(   model,   vcov = \"CL\", # type of covariance matrix   vcov_args = list(type = \"HC1\") # type of robust estimation )  mp #> Parameter                           | Coefficient |   SE |        95% CI | t(143) |      p #> ------------------------------------------------------------------------------------------ #> (Intercept)                         |        0.87 | 0.42 | [ 0.03, 1.70] |   2.05 | 0.042  #> Sepal Length                        |        0.04 | 0.11 | [-0.18, 0.26] |   0.40 | 0.692  #> Species [versicolor]                |       -0.78 | 0.65 | [-2.07, 0.51] |  -1.19 | 0.237  #> Species [virginica]                 |       -0.41 | 0.59 | [-1.57, 0.75] |  -0.70 | 0.483  #> Sepal Width                         |        0.11 | 0.08 | [-0.05, 0.27] |   1.38 | 0.170  #> Sepal Length * Species [versicolor] |        0.61 | 0.12 | [ 0.37, 0.85] |   4.96 | < .001 #> Sepal Length * Species [virginica]  |        0.68 | 0.11 | [ 0.46, 0.90] |   6.15 | < .001  # compare standard errors to result from sandwich-package mp$SE #> [1] 0.422 0.111 0.653 0.587 0.079 0.123 0.111 unname(sqrt(diag(sandwich::vcovCL(model)))) #> [1] 0.422 0.111 0.653 0.587 0.079 0.123 0.111 iris$cluster <- factor(rep(LETTERS[1:8], length.out = nrow(iris)))  # change estimation-type, defining additional arguments mp <- model_parameters(   model,   vcov = \"vcovCL\",   vcov_args = list(type = \"HC1\", cluster = iris$cluster) )  mp #> Parameter                           | Coefficient |   SE |        95% CI | t(143) |      p #> ------------------------------------------------------------------------------------------ #> (Intercept)                         |        0.87 | 0.34 | [ 0.20, 1.53] |   2.57 | 0.011  #> Sepal Length                        |        0.04 | 0.07 | [-0.10, 0.19] |   0.61 | 0.540  #> Species [versicolor]                |       -0.78 | 0.52 | [-1.80, 0.25] |  -1.49 | 0.137  #> Species [virginica]                 |       -0.41 | 0.26 | [-0.94, 0.11] |  -1.56 | 0.120  #> Sepal Width                         |        0.11 | 0.07 | [-0.03, 0.25] |   1.52 | 0.131  #> Sepal Length * Species [versicolor] |        0.61 | 0.10 | [ 0.42, 0.80] |   6.29 | < .001 #> Sepal Length * Species [virginica]  |        0.68 | 0.05 | [ 0.58, 0.78] |  13.28 | < .001  # compare standard errors to result from sandwich-package mp$SE #> [1] 0.337 0.072 0.519 0.264 0.072 0.097 0.051 unname(sqrt(diag(sandwich::vcovCL(model, cluster = iris$cluster)))) #> [1] 0.337 0.072 0.519 0.264 0.072 0.097 0.051"},{"path":"https://easystats.github.io/parameters/articles/model_parameters_robust.html","id":"cluster-robust-covariance-matrix-estimation-clubsandwich","dir":"Articles","previous_headings":"Linear Regression Models","what":"Cluster-Robust Covariance Matrix Estimation (clubSandwich)","title":"Robust Estimation of Standard Errors, Confidence Intervals, and p-values","text":"using clubSandwich::vcovCR(). Thus, vcov = \"CR\", related function clubSandwich package called. Note function requires specification cluster-argument.","code":"# create fake-cluster-variable, to demonstrate cluster robust standard errors iris$cluster <- factor(rep(LETTERS[1:8], length.out = nrow(iris)))  # cluster-robust estimation mp <- model_parameters(   model,   vcov = \"vcovCR\",   vcov_args = list(type = \"CR1\", cluster = iris$cluster) ) mp #> Parameter                           | Coefficient |   SE |        95% CI | t(143) |      p #> ------------------------------------------------------------------------------------------ #> (Intercept)                         |        0.87 | 0.33 | [ 0.21, 1.52] |   2.62 | 0.010  #> Sepal Length                        |        0.04 | 0.07 | [-0.10, 0.18] |   0.63 | 0.531  #> Species [versicolor]                |       -0.78 | 0.51 | [-1.78, 0.23] |  -1.53 | 0.129  #> Species [virginica]                 |       -0.41 | 0.26 | [-0.92, 0.10] |  -1.60 | 0.112  #> Sepal Width                         |        0.11 | 0.07 | [-0.03, 0.25] |   1.55 | 0.123  #> Sepal Length * Species [versicolor] |        0.61 | 0.09 | [ 0.42, 0.79] |   6.42 | < .001 #> Sepal Length * Species [virginica]  |        0.68 | 0.05 | [ 0.58, 0.78] |  13.56 | < .001  # compare standard errors to result from clubSsandwich-package mp$SE #> [1] 0.330 0.070 0.508 0.259 0.071 0.095 0.050  unname(sqrt(diag(clubSandwich::vcovCR(model, type = \"CR1\", cluster = iris$cluster)))) #> [1] 0.330 0.070 0.508 0.259 0.071 0.095 0.050"},{"path":"https://easystats.github.io/parameters/articles/model_parameters_robust.html","id":"robust-covariance-matrix-estimation-on-standardized-model-parameters","dir":"Articles","previous_headings":"Linear Regression Models","what":"Robust Covariance Matrix Estimation on Standardized Model Parameters","title":"Robust Estimation of Standard Errors, Confidence Intervals, and p-values","text":"Finally, robust estimation can combined standardization. However, robust covariance matrix estimation works standardize = \"refit\".","code":"# model parameters, robust estimation on standardized model model_parameters(model, standardize = \"refit\", vcov = \"HC3\") #> Parameter                           | Coefficient |   SE |         95% CI | t(143) |      p #> ------------------------------------------------------------------------------------------- #> (Intercept)                         |       -1.30 | 0.07 | [-1.44, -1.16] | -18.70 | < .001 #> Sepal Length                        |        0.02 | 0.06 | [-0.09,  0.13] |   0.37 | 0.711  #> Species [versicolor]                |        1.57 | 0.09 | [ 1.40,  1.74] |  17.84 | < .001 #> Species [virginica]                 |        2.02 | 0.09 | [ 1.84,  2.20] |  22.49 | < .001 #> Sepal Width                         |        0.03 | 0.02 | [-0.01,  0.07] |   1.32 | 0.190  #> Sepal Length * Species [versicolor] |        0.28 | 0.06 | [ 0.16,  0.41] |   4.65 | < .001 #> Sepal Length * Species [virginica]  |        0.32 | 0.06 | [ 0.21,  0.43] |   5.75 | < .001"},{"path":[]},{"path":"https://easystats.github.io/parameters/articles/model_parameters_robust.html","id":"robust-covariance-matrix-estimation-for-mixed-models","dir":"Articles","previous_headings":"Linear Mixed-Effects Regression Models","what":"Robust Covariance Matrix Estimation for Mixed Models","title":"Robust Estimation of Standard Errors, Confidence Intervals, and p-values","text":"linear mixed-effects models, definition clustered (hierarchical multilevel) structure data, also possible estimate cluster-robust covariance matrix. possible due clubSandwich package, thus need define arguments example. Notice robust estimation returns different standard errors, confidence intervals, test statistic p-values compared standard estimation. Also, note coefficient estimate remains unchanged.","code":"library(lme4) data(iris) set.seed(1234) iris$grp <- as.factor(sample(1:3, nrow(iris), replace = TRUE))  # fit example model model <- lme4::lmer(   Sepal.Length ~ Species * Sepal.Width + Petal.Length + (1 | grp),   data = iris )  # model parameters without robust estimation model_parameters(model) #> # Fixed Effects #>  #> Parameter                          | Coefficient |   SE |         95% CI | t(141) |      p #> ------------------------------------------------------------------------------------------ #> (Intercept)                        |        1.55 | 0.40 | [ 0.76,  2.35] |   3.87 | < .001 #> Species [versicolor]               |        0.41 | 0.55 | [-0.67,  1.50] |   0.75 | 0.454  #> Species [virginica]                |       -0.41 | 0.58 | [-1.56,  0.74] |  -0.70 | 0.483  #> Sepal Width                        |        0.66 | 0.11 | [ 0.44,  0.89] |   5.83 | < .001 #> Petal Length                       |        0.82 | 0.07 | [ 0.69,  0.95] |  12.52 | < .001 #> Species [versicolor] * Sepal Width |       -0.48 | 0.19 | [-0.85, -0.12] |  -2.60 | 0.010  #> Species [virginica] * Sepal Width  |       -0.36 | 0.18 | [-0.71,  0.00] |  -1.99 | 0.048  #>  #> # Random Effects #>  #> Parameter           | Coefficient |   SE |       95% CI #> ------------------------------------------------------- #> SD (Intercept: grp) |        0.08 | 0.05 | [0.02, 0.29] #> SD (Residual)       |        0.30 | 0.02 | [0.27, 0.33]  # model parameters with cluster robust estimation model_parameters(   model,   vcov = \"vcovCR\",   vcov_args = list(type = \"CR1\", cluster = iris$grp) ) #> # Fixed Effects #>  #> Parameter                          | Coefficient |   SE |         95% CI | t(141) |      p #> ------------------------------------------------------------------------------------------ #> (Intercept)                        |        1.55 | 0.40 | [ 0.76,  2.35] |   3.87 | < .001 #> Species [versicolor]               |        0.41 | 0.80 | [-1.17,  1.99] |   0.51 | 0.608  #> Species [virginica]                |       -0.41 | 0.19 | [-0.78, -0.03] |  -2.15 | 0.033  #> Sepal Width                        |        0.66 | 0.10 | [ 0.46,  0.86] |   6.64 | < .001 #> Petal Length                       |        0.82 | 0.05 | [ 0.72,  0.91] |  17.27 | < .001 #> Species [versicolor] * Sepal Width |       -0.48 | 0.35 | [-1.18,  0.21] |  -1.37 | 0.172  #> Species [virginica] * Sepal Width  |       -0.36 | 0.11 | [-0.57, -0.15] |  -3.39 | < .001 #>  #> # Random Effects #>  #> Parameter           | Coefficient |   SE |       95% CI #> ------------------------------------------------------- #> SD (Intercept: grp) |        0.08 | 0.05 | [0.02, 0.29] #> SD (Residual)       |        0.30 | 0.02 | [0.27, 0.33]"},{"path":"https://easystats.github.io/parameters/articles/model_parameters_robust.html","id":"robust-covariance-matrix-estimation-on-standardized-mixed-model-parameters","dir":"Articles","previous_headings":"Linear Mixed-Effects Regression Models","what":"Robust Covariance Matrix Estimation on Standardized Mixed Model Parameters","title":"Robust Estimation of Standard Errors, Confidence Intervals, and p-values","text":", robust estimation can combined standardization linear mixed-effects models well works standardize = \"refit\". Notice drastically p-values change robust-unstandardized model robust-standardized model.","code":"# model parameters, cluster robust estimation of standardized mixed model model_parameters(   model,   standardize = \"refit\",   vcov = \"vcovCR\",   vcov_args = list(type = \"CR1\", cluster = iris$grp) ) #> # Fixed Effects #>  #> Parameter                          | Coefficient |   SE |         95% CI | t(141) |      p #> ------------------------------------------------------------------------------------------ #> (Intercept)                        |        0.97 | 0.08 | [ 0.82,  1.12] |  12.55 | < .001 #> Species [versicolor]               |       -1.29 | 0.33 | [-1.95, -0.63] |  -3.85 | < .001 #> Species [virginica]                |       -1.81 | 0.23 | [-2.26, -1.37] |  -8.01 | < .001 #> Sepal Width                        |        0.35 | 0.05 | [ 0.24,  0.45] |   6.64 | < .001 #> Petal Length                       |        1.74 | 0.10 | [ 1.54,  1.94] |  17.27 | < .001 #> Species [versicolor] * Sepal Width |       -0.25 | 0.19 | [-0.62,  0.11] |  -1.37 | 0.172  #> Species [virginica] * Sepal Width  |       -0.19 | 0.06 | [-0.30, -0.08] |  -3.39 | < .001 #>  #> # Random Effects #>  #> Parameter           | Coefficient |   SE |       95% CI #> ------------------------------------------------------- #> SD (Intercept: grp) |        0.10 | 0.06 | [0.03, 0.35] #> SD (Residual)       |        0.36 | 0.02 | [0.32, 0.40]"},{"path":"https://easystats.github.io/parameters/articles/model_parameters_standardized.html","id":"standardization-by-re-fitting-the-model","dir":"Articles","previous_headings":"","what":"Standardization by re-fitting the model","title":"Standardized Model Parameters","text":"standardize = \"refit\" based complete model re-fit standardized version data. Hence, method equal standardizing variables fitting model. accurate (Neter et al., 1989), also computationally costly long (especially heavy models , instance, Bayesian models). method particularly recommended complex models include interactions transformations (e.g., polynomial spline terms). standardize = \"refit\", model_parameters() internally calls effectsize::standardize() standardize data used fit model updates model standardized data. Note effectsize::standardize() tries detect variables standardized . instance, log(x) model formula exclude x standardized, x might get negative values, thus log(x) longer defined. Factors dates also standardized. Response variables standardized, appropriate. second output identical following:","code":"library(lme4) data(iris) set.seed(1234) iris$grp <- as.factor(sample(1:3, nrow(iris), replace = TRUE))  # fit example model model <- lme4::lmer(   Sepal.Length ~ Species * Sepal.Width + Petal.Length + (1 | grp),   data = iris )  # classic model parameters model_parameters(model) #> # Fixed Effects #>  #> Parameter                          | Coefficient |   SE |         95% CI | t(141) |      p #> ------------------------------------------------------------------------------------------ #> (Intercept)                        |        1.55 | 0.40 | [ 0.76,  2.35] |   3.87 | < .001 #> Species [versicolor]               |        0.41 | 0.55 | [-0.67,  1.50] |   0.75 | 0.454  #> Species [virginica]                |       -0.41 | 0.58 | [-1.56,  0.74] |  -0.70 | 0.483  #> Sepal Width                        |        0.66 | 0.11 | [ 0.44,  0.89] |   5.83 | < .001 #> Petal Length                       |        0.82 | 0.07 | [ 0.69,  0.95] |  12.52 | < .001 #> Species [versicolor] * Sepal Width |       -0.48 | 0.19 | [-0.85, -0.12] |  -2.60 | 0.010  #> Species [virginica] * Sepal Width  |       -0.36 | 0.18 | [-0.71,  0.00] |  -1.99 | 0.048  #>  #> # Random Effects #>  #> Parameter           | Coefficient |   SE |       95% CI #> ------------------------------------------------------- #> SD (Intercept: grp) |        0.08 | 0.05 | [0.02, 0.29] #> SD (Residual)       |        0.30 | 0.02 | [0.27, 0.33]  # standardized model parameters model_parameters(model, standardize = \"refit\") #> # Fixed Effects #>  #> Parameter                          | Coefficient |   SE |         95% CI | t(141) |      p #> ------------------------------------------------------------------------------------------ #> (Intercept)                        |        0.97 | 0.20 | [ 0.57,  1.37] |   4.74 | < .001 #> Species [versicolor]               |       -1.29 | 0.26 | [-1.80, -0.77] |  -4.91 | < .001 #> Species [virginica]                |       -1.81 | 0.34 | [-2.49, -1.14] |  -5.33 | < .001 #> Sepal Width                        |        0.35 | 0.06 | [ 0.23,  0.47] |   5.83 | < .001 #> Petal Length                       |        1.74 | 0.14 | [ 1.47,  2.02] |  12.52 | < .001 #> Species [versicolor] * Sepal Width |       -0.25 | 0.10 | [-0.45, -0.06] |  -2.60 | 0.010  #> Species [virginica] * Sepal Width  |       -0.19 | 0.09 | [-0.38,  0.00] |  -1.99 | 0.048  #>  #> # Random Effects #>  #> Parameter           | Coefficient |   SE |       95% CI #> ------------------------------------------------------- #> SD (Intercept: grp) |        0.10 | 0.06 | [0.03, 0.35] #> SD (Residual)       |        0.36 | 0.02 | [0.32, 0.40] # standardize continuous variables manually model2 <- lme4::lmer(   scale(Sepal.Length) ~ Species * scale(Sepal.Width) + scale(Petal.Length) + (1 | grp),   data = iris )  model_parameters(model2) #> # Fixed Effects #>  #> Parameter                          | Coefficient |   SE |         95% CI | t(141) |      p #> ------------------------------------------------------------------------------------------ #> (Intercept)                        |        0.97 | 0.20 | [ 0.57,  1.37] |   4.74 | < .001 #> Species [versicolor]               |       -1.29 | 0.26 | [-1.80, -0.77] |  -4.91 | < .001 #> Species [virginica]                |       -1.81 | 0.34 | [-2.49, -1.14] |  -5.33 | < .001 #> Sepal Width                        |        0.35 | 0.06 | [ 0.23,  0.47] |   5.83 | < .001 #> Petal Length                       |        1.74 | 0.14 | [ 1.47,  2.02] |  12.52 | < .001 #> Species [versicolor] * Sepal Width |       -0.25 | 0.10 | [-0.45, -0.06] |  -2.60 | 0.010  #> Species [virginica] * Sepal Width  |       -0.19 | 0.09 | [-0.38,  0.00] |  -1.99 | 0.048  #>  #> # Random Effects #>  #> Parameter           | Coefficient |   SE |       95% CI #> ------------------------------------------------------- #> SD (Intercept: grp) |        0.10 | 0.06 | [0.03, 0.35] #> SD (Residual)       |        0.36 | 0.02 | [0.32, 0.40]"},{"path":"https://easystats.github.io/parameters/articles/model_parameters_standardized.html","id":"post-hoc-standardization","dir":"Articles","previous_headings":"","what":"Post-hoc standardization","title":"Standardized Model Parameters","text":"standardize = \"posthoc\" aims emulating results obtained \"refit\" without refitting model. coefficients divided standard deviation outcome (becomes expression unit). , coefficients related numeric variables additionally multiplied standard deviation related terms, correspond changes 1 SD predictor (e.g., “change 1 SD x related change 0.24 SD y”). apply binary variables factors, coefficients still related changes levels. method accurate tends give aberrant results interactions specified. However, method standardization “classic” result obtained many statistical packages standardized coefficients requested. standardize = \"posthoc\", model_parameters() internally calls effectsize::standardize_parameters(method = \"posthoc\"). Test statistic p-values affected, .e. standardization applied. standardize = \"basic\" also applies post-hoc standardization, however, factors converted numeric, means also scales coefficient standard deviation model’s matrix’ parameter factor levels (transformed integers) binary predictors. Compare two outputs notice coefficient estimates, standard errors, confidence intervals, p-values change main effect interaction effect terms containing Species variable, factor variable model. method one implemented default software packages, lm.beta::lm.beta():","code":"model_parameters(model, standardize = \"posthoc\") #> # Fixed Effects #>  #> Parameter                          | Std. Coef. |   SE |         95% CI | t(141) |      p #> ----------------------------------------------------------------------------------------- #> (Intercept)                        |       0.00 | 0.00 | [ 0.00,  0.00] |   3.87 | < .001 #> Species [versicolor]               |       0.50 | 0.66 | [-0.81,  1.81] |   0.75 | 0.454  #> Species [virginica]                |      -0.49 | 0.70 | [-1.88,  0.89] |  -0.70 | 0.483  #> Sepal Width                        |       0.35 | 0.06 | [ 0.23,  0.47] |   5.83 | < .001 #> Petal Length                       |       1.74 | 0.14 | [ 1.47,  2.02] |  12.52 | < .001 #> Species [versicolor] * Sepal Width |      -0.25 | 0.10 | [-0.45, -0.06] |  -2.60 | 0.010  #> Species [virginica] * Sepal Width  |      -0.19 | 0.09 | [-0.38,  0.00] |  -1.99 | 0.048 model_parameters(model, standardize = \"basic\") #> # Fixed Effects #>  #> Parameter                          | Std. Coef. |   SE |         95% CI | t(141) |      p #> ----------------------------------------------------------------------------------------- #> (Intercept)                        |       0.00 | 0.00 | [ 0.00,  0.00] |   3.87 | < .001 #> Species [versicolor]               |       0.23 | 0.31 | [-0.38,  0.85] |   0.75 | 0.454  #> Species [virginica]                |      -0.23 | 0.33 | [-0.89,  0.42] |  -0.70 | 0.483  #> Sepal Width                        |       0.35 | 0.06 | [ 0.23,  0.47] |   5.83 | < .001 #> Petal Length                       |       1.74 | 0.14 | [ 1.47,  2.02] |  12.52 | < .001 #> Species [versicolor] * Sepal Width |      -0.77 | 0.30 | [-1.36, -0.19] |  -2.60 | 0.010  #> Species [virginica] * Sepal Width  |      -0.61 | 0.31 | [-1.22,  0.00] |  -1.99 | 0.048 library(lm.beta) data(iris) model3 <- lm(Sepal.Length ~ Species * Sepal.Width + Petal.Length, data = iris) mp <- model_parameters(model3, standardize = \"basic\") out <- lm.beta(model3)  data.frame(model_parameters = mp$Std_Coefficient, lm.beta = coef(out)) #>                               model_parameters lm.beta #> (Intercept)                               0.00      NA #> Speciesversicolor                         0.16    0.16 #> Speciesvirginica                         -0.37   -0.37 #> Sepal.Width                               0.33    0.33 #> Petal.Length                              1.75    1.75 #> Speciesversicolor:Sepal.Width            -0.72   -0.72 #> Speciesvirginica:Sepal.Width             -0.49   -0.49"},{"path":"https://easystats.github.io/parameters/articles/model_parameters_standardized.html","id":"smart-standardization","dir":"Articles","previous_headings":"","what":"Smart standardization","title":"Standardized Model Parameters","text":"standardize = \"smart\" similar standardize = \"posthoc\" involve model re-fitting. difference SD response computed relevant section data. instance, factor 3 levels (intercept), B C entered predictor, effect corresponding B versus scaled variance response intercept . results, coefficients effects factors similar Glass’ delta.","code":"model_parameters(model, standardize = \"smart\") #> # Fixed Effects #>  #> Parameter                          | Std. Coef. |   SE |         95% CI | t(141) |      p #> ----------------------------------------------------------------------------------------- #> (Intercept)                        |       0.00 | 0.00 | [ 0.00,  0.00] |   3.87 | < .001 #> Species [versicolor]               |       1.17 | 1.56 | [-1.91,  4.24] |   0.75 | 0.454  #> Species [virginica]                |      -1.16 | 1.65 | [-4.42,  2.10] |  -0.70 | 0.483  #> Sepal Width                        |       0.35 | 0.06 | [ 0.23,  0.47] |   5.83 | < .001 #> Petal Length                       |       1.74 | 0.14 | [ 1.47,  2.02] |  12.52 | < .001 #> Species [versicolor] * Sepal Width |      -1.13 | 0.43 | [-1.98, -0.27] |  -2.60 | 0.010  #> Species [virginica] * Sepal Width  |      -0.83 | 0.42 | [-1.66, -0.01] |  -1.99 | 0.048"},{"path":"https://easystats.github.io/parameters/articles/overview_of_vignettes.html","id":"function-overview","dir":"Articles","previous_headings":"","what":"Function Overview","title":"Overview of Vignettes","text":"Function Reference","code":""},{"path":"https://easystats.github.io/parameters/articles/overview_of_vignettes.html","id":"description-of-parameters","dir":"Articles","previous_headings":"","what":"Description of Parameters","title":"Overview of Vignettes","text":"Summary Model Parameters Standardized Model Parameters Robust Estimation Standard Errors, Confidence Intervals, p-values Model Parameters Multiply Imputed Repeated Analyses Analysing Longitudinal Panel Data","code":""},{"path":"https://easystats.github.io/parameters/articles/overview_of_vignettes.html","id":"formatting-and-printing","dir":"Articles","previous_headings":"","what":"Formatting and Printing","title":"Overview of Vignettes","text":"Formatting Model Parameters Printing Model Parameters","code":""},{"path":"https://easystats.github.io/parameters/articles/overview_of_vignettes.html","id":"dimension-reduction-and-clustering","dir":"Articles","previous_headings":"","what":"Dimension Reduction and Clustering","title":"Overview of Vignettes","text":"Feature Reduction (PCA, cMDS, ICA, …) Structural Models (EFA, CFA, SEM, …) Selection Model Parameters Clustering easystats","code":""},{"path":"https://easystats.github.io/parameters/articles/parameters_reduction.html","id":"quick-and-exploratory-method","dir":"Articles","previous_headings":"","what":"Quick and Exploratory Method","title":"Feature Reduction (PCA, cMDS, ICA, ...)","text":"Let’s start fitting multiple linear regression model attitude dataset, available base R, predict overall rating employees organization remaining variables (handling employee complaints, special privileges, opportunity learning, raises, feedback considered critical opportunity advancement). can explore reduction number parameters reduce_parameters() function. output hints fact model represented via two “latent” dimensions, one correlated positive things company offer, one related amount negative critiques received employees. two dimensions positive negative relationship company rating, respectively. reduce_parameters() exactly ? function performs reduction parameter space (number variables). starts creating new set variables, based chosen method (default method “PCA”, available via method argument, “cMDS”, “DRR” “ICA”). , names new dimensions using original variables correlate . instance, example variable named raises_0.88/learning_0.82/complaints_0.78/privileges_0.70/advance_0.68 means respective variables (raises, learning, complaints, privileges, advance) correlate maximally (coefficients .88, .82, .78, .70, .68, respectively) dimension. different method (Classical Multidimensional Scaling - cMDS) suggests negative critiques significant impact rating, lack opportunities career advancement separate dimension importance . Although reduce_parameters() function can useful exploratory data analysis, ’s best perform dimension reduction step separate dedicated stage, important process data analysis workflow.","code":"data(\"attitude\") model <- lm(rating ~ ., data = attitude) parameters(model) #> Parameter   | Coefficient |    SE |          95% CI | t(23) |      p #> -------------------------------------------------------------------- #> (Intercept) |       10.79 | 11.59 | [-13.19, 34.76] |  0.93 | 0.362  #> complaints  |        0.61 |  0.16 | [  0.28,  0.95] |  3.81 | < .001 #> privileges  |       -0.07 |  0.14 | [ -0.35,  0.21] | -0.54 | 0.596  #> learning    |        0.32 |  0.17 | [ -0.03,  0.67] |  1.90 | 0.070  #> raises      |        0.08 |  0.22 | [ -0.38,  0.54] |  0.37 | 0.715  #> critical    |        0.04 |  0.15 | [ -0.27,  0.34] |  0.26 | 0.796  #> advance     |       -0.22 |  0.18 | [ -0.59,  0.15] | -1.22 | 0.236 newmodel <- reduce_parameters(model) parameters(newmodel) #> Parameter                                                              | Coefficient |   SE |         95% CI | t(27) |      p #> ----------------------------------------------------------------------------------------------------------------------------- #> (Intercept)                                                            |       64.63 | 1.57 | [61.41, 67.85] | 41.19 | < .001 #> raises 0 88/learning 0 82/complaints 0 78/privileges 0 70/advance 0 68 |        4.62 | 0.90 | [ 2.78,  6.46] |  5.16 | < .001 #> critical 0 80                                                          |       -3.41 | 1.59 | [-6.67, -0.14] | -2.14 | 0.041 reduce_parameters(model, method = \"cMDS\") %>%   parameters() #> Parameter                                                 | Coefficient |   SE |         95% CI | t(26) |      p #> ---------------------------------------------------------------------------------------------------------------- #> (Intercept)                                               |       64.63 | 1.41 | [61.73, 67.53] | 45.80 | < .001 #> raises 0 85/complaints 0 84/learning 0 83/privileges 0 74 |        0.43 | 0.07 | [ 0.28,  0.57] |  6.14 | < .001 #> advance -0 60                                             |        0.32 | 0.13 | [ 0.04,  0.59] |  2.36 | 0.026  #> critical -0 65                                            |       -0.24 | 0.15 | [-0.56,  0.07] | -1.61 | 0.120"},{"path":"https://easystats.github.io/parameters/articles/parameters_reduction.html","id":"principal-component-analysis-pca","dir":"Articles","previous_headings":"","what":"Principal Component Analysis (PCA)","title":"Feature Reduction (PCA, cMDS, ICA, ...)","text":"PCA widely used procedure lies -dimension reduction structural modeling. Indeed, one ways reducing number predictors extract new set uncorrelated variables represent variance initial dataset. original variables relate can also question . can apply principal_components() function predictors model: principal_components() function automatically selected one component (number components specified, function uses n_factors() estimate optimal number keep) returned loadings, .e., relationship original variables. can see , seems new component captured essence (half total variance present original dataset) variables together. can extract values component observation using predict() method add response variable initial dataset. can know update model new component:","code":"pca <- principal_components(insight::get_predictors(model), n = \"auto\") pca #> # Loadings from Principal Component Analysis (no rotation) #>  #> Variable   | PC1  | Complexity #> ------------------------------ #> complaints | 0.78 |    1.00    #> privileges | 0.70 |    1.00    #> learning   | 0.82 |    1.00    #> raises     | 0.88 |    1.00    #> critical   | 0.40 |    1.00    #> advance    | 0.68 |    1.00    #>  #> The unique principal component accounted for 52.82% of the total variance of the original data. newdata <- predict(pca) newdata$rating <- attitude$rating update(model, rating ~ Component_1, data = newdata) %>%   parameters() #> Parameter   | Coefficient |   SE |         95% CI | t(28) |      p #> ------------------------------------------------------------------ #> (Intercept) |       64.63 | 1.67 | [61.22, 68.05] | 38.78 | < .001 #> Component 1 |        4.62 | 0.95 | [ 2.67,  6.57] |  4.86 | < .001"},{"path":"https://easystats.github.io/parameters/articles/parameters_reduction.html","id":"using-the-psych-package-for-pca","dir":"Articles","previous_headings":"Principal Component Analysis (PCA)","what":"Using the psych package for PCA","title":"Feature Reduction (PCA, cMDS, ICA, ...)","text":"can also use different packages models, psych (Revelle 2018) FactoMineR PCA Exploratory Factor Analysis (EFA), allows flexibility control running procedures. functions package fully supported parameters model_parameters() function. instance, can redo analysis using psych package follows: Note: default, psych::principal() uses varimax rotation extract rotated components, possibly leading discrepancies results. Finally, refit model:","code":"library(psych)  # Fit the PCA pca <- model_parameters(psych::principal(attitude, nfactors = 1)) pca #> # Rotated loadings from Principal Component Analysis (varimax-rotation) #>  #> Variable   | PC1  | Complexity | Uniqueness #> ------------------------------------------- #> rating     | 0.80 |    1.00    |    0.37    #> complaints | 0.85 |    1.00    |    0.28    #> privileges | 0.68 |    1.00    |    0.53    #> learning   | 0.83 |    1.00    |    0.32    #> raises     | 0.86 |    1.00    |    0.26    #> critical   | 0.36 |    1.00    |    0.87    #> advance    | 0.58 |    1.00    |    0.66    #>  #> The unique principal component (varimax rotation) accounted for 53.09% of the total variance of the original data. df <- cbind(attitude, predict(pca))  update(model, rating ~ PC1, data = df) %>%   model_parameters()"},{"path":[]},{"path":[]},{"path":"https://easystats.github.io/parameters/articles/parameters_selection.html","id":"fit-a-powerful-model","dir":"Articles","previous_headings":"Simple linear regression","what":"Fit a powerful model","title":"Selection of Model Parameters","text":"familiar R formula interface, know possibility including dot (.) formula, signifying “remaining variables”. Curiously, aware possibility additionally easily adding “interaction terms”. can achieved using .*. notation. Let’s try linear regression predicting Sepal.Length iris dataset, included default R. Wow, ’s lot parameters! almost none significant! weird, considering gorgeous \\(R^2\\) 0.882! wish research!","code":"model <- lm(Sepal.Length ~ . * ., data = iris) summary(model) #>  #> Call: #> lm(formula = Sepal.Length ~ . * ., data = iris) #>  #> Residuals: #>    Min     1Q Median     3Q    Max  #> -0.726 -0.210  0.014  0.213  0.713  #>  #> Coefficients: #>                                Estimate Std. Error t value Pr(>|t|)    #> (Intercept)                      1.6998     1.0576    1.61   0.1103    #> Sepal.Width                      0.8301     0.3047    2.72   0.0073 ** #> Petal.Length                     0.3178     0.7852    0.40   0.6863    #> Petal.Width                      2.5827     1.5874    1.63   0.1061    #> Speciesversicolor               -2.7193     1.6201   -1.68   0.0956 .  #> Speciesvirginica                -6.1704     3.2045   -1.93   0.0563 .  #> Sepal.Width:Petal.Length        -0.0149     0.2185   -0.07   0.9458    #> Sepal.Width:Petal.Width         -0.6112     0.4536   -1.35   0.1801    #> Sepal.Width:Speciesversicolor    0.4300     0.6666    0.65   0.5200    #> Sepal.Width:Speciesvirginica     0.8288     1.0031    0.83   0.4101    #> Petal.Length:Petal.Width        -0.1195     0.3300   -0.36   0.7178    #> Petal.Length:Speciesversicolor   0.7398     0.5166    1.43   0.1544    #> Petal.Length:Speciesvirginica    0.9034     0.6938    1.30   0.1951    #> Petal.Width:Speciesversicolor   -1.0070     1.2454   -0.81   0.4202    #> Petal.Width:Speciesvirginica    -0.2864     1.5065   -0.19   0.8495    #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: 0.3 on 135 degrees of freedom #> Multiple R-squared:  0.882,  Adjusted R-squared:  0.87  #> F-statistic: 72.1 on 14 and 135 DF,  p-value: <2e-16"},{"path":"https://easystats.github.io/parameters/articles/parameters_selection.html","id":"too-many-parameters","dir":"Articles","previous_headings":"Simple linear regression","what":"Too many parameters?","title":"Selection of Model Parameters","text":"might know, model performant always good thing. instance, can marker overfitting: model corresponds closely particular set data, may therefore fail predict future observations reliably. multiple regressions, can also fall Freedman’s paradox: predictors actually relation dependent variable predicted spuriously found statistically significant. Let’s run checks using performance package: main issue model seems high multicollinearity. suggests model might able give valid results individual predictor, tell predictors redundant respect others.","code":"library(performance)  check_normality(model) #> OK: residuals appear as normally distributed (p = 0.612). check_heteroscedasticity(model) #> OK: Error variance appears to be homoscedastic (p = 0.118). check_autocorrelation(model) #> OK: Residuals appear to be independent and not autocorrelated (p = 0.574). check_collinearity(model) #> # Check for Multicollinearity #>  #> High Correlation #>  #>                      Term      VIF           VIF 95% CI Increased SE Tolerance #>               Sepal.Width    29.42 [   22.31,    38.91]         5.42      0.03 #>              Petal.Length  3204.78 [ 2414.74,  4253.41]        56.61  3.12e-04 #>               Petal.Width  2442.10 [ 1840.11,  3241.14]        49.42  4.09e-04 #>                   Species 3.98e+05 [3.00e+05, 5.28e+05]       630.97  2.51e-06 #>  Sepal.Width:Petal.Length  2183.98 [ 1645.63,  2898.55]        46.73  4.58e-04 #>   Sepal.Width:Petal.Width  1866.48 [ 1406.42,  2477.15]        43.20  5.36e-04 #>       Sepal.Width:Species 3.49e+05 [2.63e+05, 4.64e+05]       591.13  2.86e-06 #>  Petal.Length:Petal.Width  4032.80 [ 3038.60,  5352.41]        63.50  2.48e-04 #>      Petal.Length:Species 1.23e+06 [9.27e+05, 1.63e+06]      1109.09  8.13e-07 #>       Petal.Width:Species 3.77e+05 [2.84e+05, 5.01e+05]       614.38  2.65e-06 #>  Tolerance 95% CI #>      [0.03, 0.04] #>      [0.00, 0.00] #>      [0.00, 0.00] #>      [0.00, 0.00] #>      [0.00, 0.00] #>      [0.00, 0.00] #>      [0.00, 0.00] #>      [0.00, 0.00] #>      [0.00, 0.00] #>      [0.00, 0.00]"},{"path":"https://easystats.github.io/parameters/articles/parameters_selection.html","id":"parameters-selection","dir":"Articles","previous_headings":"Simple linear regression","what":"Parameters selection","title":"Selection of Model Parameters","text":"Time variables selection! can easily done using select_parameters() function parameters. automatically select best variables update model accordingly. One way using tidy pipeline (using %>%), using output update new model. ’s still lot parameters, can see, almost now significant, \\(R^2\\) change much. Although appealing, please note automated selection methods quite criticized, used place theoretical hypothetical reasons (.e., priori hypotheses parameters model want focus ).","code":"lm(Sepal.Length ~ . * ., data = iris) %>%   select_parameters() %>%   summary() #>  #> Call: #> lm(formula = Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width +  #>     Species + Sepal.Width:Petal.Width + Petal.Length:Species +  #>     Petal.Width:Species, data = iris) #>  #> Residuals: #>     Min      1Q  Median      3Q     Max  #> -0.7261 -0.2165  0.0021  0.2191  0.7439  #>  #> Coefficients: #>                                Estimate Std. Error t value Pr(>|t|)     #> (Intercept)                       2.090      0.528    3.95  0.00012 *** #> Sepal.Width                       0.734      0.130    5.66  8.3e-08 *** #> Petal.Length                      0.232      0.260    0.89  0.37310     #> Petal.Width                       1.051      0.532    1.98  0.04993 *   #> Speciesversicolor                -1.047      0.547   -1.92  0.05754 .   #> Speciesvirginica                 -2.682      0.638   -4.21  4.6e-05 *** #> Sepal.Width:Petal.Width          -0.232      0.103   -2.24  0.02667 *   #> Petal.Length:Speciesversicolor    0.660      0.298    2.22  0.02837 *   #> Petal.Length:Speciesvirginica     0.720      0.273    2.63  0.00941 **  #> Petal.Width:Speciesversicolor    -1.112      0.550   -2.02  0.04528 *   #> Petal.Width:Speciesvirginica     -0.499      0.460   -1.09  0.27934     #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: 0.3 on 139 degrees of freedom #> Multiple R-squared:  0.88,   Adjusted R-squared:  0.872  #> F-statistic:  102 on 10 and 139 DF,  p-value: <2e-16"},{"path":"https://easystats.github.io/parameters/articles/parameters_selection.html","id":"mixed-models","dir":"Articles","previous_headings":"","what":"Mixed models","title":"Selection of Model Parameters","text":"simple linear regressions , selection made using step() function (available base R). performs stepwise selection. However, procedures available types models, mixed models.","code":""},{"path":"https://easystats.github.io/parameters/articles/parameters_selection.html","id":"mixed-models-1","dir":"Articles","previous_headings":"Mixed models","what":"Mixed models","title":"Selection of Model Parameters","text":"mixed models (class merMod), stepwise selection based cAIC4::stepcAIC(). step function searches “best” model based random effects structure, .e. select_parameters() adds excludes random effects cAIC can’t improved . initial model looks like. model selected select_parameters(). Please notice differences random effects structure initial selected models:","code":"library(lme4) data(\"qol_cancer\")  # initial model lmer(   QoL ~ time + phq4 + age + (1 + time | hospital / ID),   data = qol_cancer ) %>%   summary() #> Linear mixed model fit by REML ['lmerMod'] #> Formula: QoL ~ time + phq4 + age + (1 + time | hospital/ID) #>    Data: qol_cancer #>  #> REML criterion at convergence: 4647 #>  #> Scaled residuals:  #>    Min     1Q Median     3Q    Max  #> -3.581 -0.393  0.082  0.507  2.505  #>  #> Random effects: #>  Groups      Name        Variance Std.Dev. Corr  #>  ID:hospital (Intercept) 202.48   14.23          #>              time         12.54    3.54    -0.72 #>  hospital    (Intercept)   8.54    2.92          #>              time          1.28    1.13    -1.00 #>  Residual                143.11   11.96          #> Number of obs: 564, groups:  ID:hospital, 188; hospital, 2 #>  #> Fixed effects: #>             Estimate Std. Error t value #> (Intercept)  70.6456     3.1363   22.52 #> time          1.4920     1.2230    1.22 #> phq4         -4.7687     0.3235  -14.74 #> age          -0.0173     0.1889   -0.09 #>  #> Correlation of Fixed Effects: #>      (Intr) time   phq4   #> time -0.954               #> phq4  0.014 -0.010        #> age  -0.017  0.004  0.107 #> optimizer (nloptwrap) convergence code: 0 (OK) #> boundary (singular) fit: see help('isSingular') ## TODO: this is currently broken due to an issue in package cAIC4  # multiple models are checked, however, initial models # already seems to be the best one... lmer(   QoL ~ time + phq4 + age + (1 + time | hospital / ID),   data = qol_cancer ) %>%   select_parameters() %>%   summary()"},{"path":"https://easystats.github.io/parameters/articles/standardize_parameters_effsize.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Parameter and Model Standardization","text":"Standardizing parameters (.e., coefficients) can allow comparison within models, variables studies. Moreover, returns coefficients expressed terms change variance (instance, coefficients expressed terms SD response variable), can allow usage effect size interpretation guidelines, Cohen’s (1988) famous rules thumb. However, standardizing model’s parameters automatically mindlessly done: research fields, particular variables types studies (e.g., replications), sometimes makes sense keep, use interpret original parameters, especially well known easily understood. Critically, parameters standardization trivial process. Different techniques exist, can lead drastically different results. Thus, critical standardization method explicitly documented detailed.","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/articles/standardize_parameters_effsize.html","id":"standardized-associations","dir":"Articles","previous_headings":"Introduction > Standardizing Parameters of Simple Models","what":"Standardized Associations","title":"Parameter and Model Standardization","text":"Standardizing coefficient simple linear regression gives value 0.87, know simple regression actually correlation? Thus, can eventually apply ()famous interpretation guidelines (e.g., Cohen’s rules thumb).","code":"library(parameters) library(effectsize) m <- lm(rating ~ complaints, data = attitude)  standardize_parameters(m) correlation::correlation(attitude, select = c(\"rating\", \"complaints\"))"},{"path":"https://easystats.github.io/parameters/articles/standardize_parameters_effsize.html","id":"standardized-differences","dir":"Articles","previous_headings":"Introduction > Standardizing Parameters of Simple Models","what":"Standardized Differences","title":"Parameter and Model Standardization","text":"work case differences, factors entered differences given level reference level? might heard similar Cohen’s d. Well, let’s see. linear model suggests standardized difference Manual (reference level - model’s intercept) Automatic 1.20 standard deviation mpg (response variable standardized, right?). Let’s compute Cohen’s d two levels: larger! ? ? differences expressed units SD! SDs? Different SDs! looking difference groups slope, standardized parameter difference means \\(SD_{mpg}\\). , slope Manual Automatic change 1.20 \\(SD_{mpg}\\)s. However, looking difference distance two populations, Cohen’s d distance means units pooled SDs. , distance Manual Automatic 1.48 SDs groups (assumed equal). simple model, pooled SD residual SD, can also estimate Cohen’s d : can also get approximation Cohen’s d converting \\(t\\)-statistic regression model via t_to_d(): also interesting note using smart method (explained detail ) standardizing parameters give indices equivalent Glass’ delta, standardized difference expressed terms SD reference group. … note standardized differences different others! :)","code":"# Select portion of data containing the two levels of interest mtcars$am <- factor(mtcars$am, labels = c(\"Manual\", \"Automatic\"))  m <- lm(mpg ~ am, data = mtcars) standardize_parameters(m) cohens_d(mpg ~ am, data = mtcars) coef(m)[2] / sigma(m) model_parameters(m)  t_to_d(4.11, df_error = 30) m <- lm(mpg ~ am, data = mtcars)  standardize_parameters(m, method = \"smart\")  glass_delta(mpg ~ am, data = mtcars)"},{"path":"https://easystats.github.io/parameters/articles/standardize_parameters_effsize.html","id":"standardizing-parameters-of-linear-models","dir":"Articles","previous_headings":"Introduction","what":"Standardizing Parameters of Linear Models","title":"Parameter and Model Standardization","text":"mentioned , standardization parameters can also used compare among parameters within model. Essentially, prevents us normally able compare among different parameters underlying variables different scales.[^also noted , always issue. example, variables scale important interpretation results, standardization might fact hinder interpretation!] example, following example, use liner regression model predict worker’s salary (Shmekels) age (years), seniority (years), overtime (xtra_hours) many compliments give boss (n_comps). Let us explore different parameter standardization methods provided parameters.","code":""},{"path":"https://easystats.github.io/parameters/articles/standardize_parameters_effsize.html","id":"standardized-slopes-are-not-always-correlations","dir":"Articles","previous_headings":"Introduction > Standardizing Parameters of Linear Models","what":"Standardized Slopes are Not (Always) Correlations","title":"Parameter and Model Standardization","text":"saw simple linear models, standardized slope equal correlation outcome predictor - hold multiple regression well? effect regression model “adjusted” ones, might expect coefficients somewhat alike partial correlations. Let’s first start computing partial correlation numeric predictors outcome. Let’s compare standardized slopes: quite different! seems standardized slopes multiple linear regressions correlations partial correlations :( However, hope lost yet - can still try recover partial correlations model, another way: converting t-statistics (degrees freedom, df) partial correlation coefficient r. Wow, retrieved correlations coefficients regression model exactly partial correlations estimated ! “r” effect sizes can also used.","code":"data(\"hardlyworking\", package = \"effectsize\") head(hardlyworking)  correlation::correlation(   hardlyworking,   select = \"salary\",   select2 = c(\"xtra_hours\", \"n_comps\", \"age\", \"seniority\"),   partial = TRUE # get partial correlations ) mod <- lm(salary ~ xtra_hours + n_comps + age + seniority,   data = hardlyworking )  standardize_parameters(mod) params <- model_parameters(mod)  t_to_r(params$t[-1], df_error = params$df_error[-1])"},{"path":"https://easystats.github.io/parameters/articles/standardize_parameters_effsize.html","id":"methods-of-standardizing-parameters","dir":"Articles","previous_headings":"Introduction > Standardizing Parameters of Linear Models","what":"Methods of Standardizing Parameters","title":"Parameter and Model Standardization","text":"Let’s convert age 3-level factor: seems like best important predictor n_comps coefficient. However, hard compare among predictors, different scales. address issue, must predictors scale - usually arbitrary unit standard deviations.","code":"hardlyworking$age_g <- cut(hardlyworking$age,   breaks = c(25, 30, 35, 45) )  mod <- lm(salary ~ xtra_hours + n_comps + age_g + seniority,   data = hardlyworking )  model_parameters(mod)"},{"path":"https://easystats.github.io/parameters/articles/standardize_parameters_effsize.html","id":"refit-re-fitting-the-model-with-standardized-data","dir":"Articles","previous_headings":"Introduction > Standardizing Parameters of Linear Models > Methods of Standardizing Parameters","what":"\"refit\": Re-fitting the model with standardized data","title":"Parameter and Model Standardization","text":"method based complete model re-fit standardized version data. Hence, method equal standardizing variables fitting model. “purest” accurate (Neter, Wasserman, Kutner 1989), also computationally costly long (especially heavy models Bayesian models, complex mixed models). method particularly recommended models include interactions transformations (e.g., exponentiation, log, polynomial spline terms). standardize_parameters also robust argument (default FALSE), enables robust standardization data, .e., based median MAD instead mean SD: Note since age_g factor, numerically standardized, standardized parameter still directly comparable numeric variables. address , can set two_sd = TRUE, thereby scaling parameters 2 SDs (MADs) predictors (Gelman 2008). parameters also comes helper function returns re-fit model, without summarizing , can used original model :","code":"standardize_parameters(mod, method = \"refit\") standardize_parameters(mod, method = \"refit\", robust = TRUE) standardize_parameters(mod, method = \"refit\", two_sd = TRUE) mod_z <- standardize(mod, two_sd = FALSE, robust = FALSE) mod_z  model_parameters(mod_z)"},{"path":"https://easystats.github.io/parameters/articles/standardize_parameters_effsize.html","id":"posthoc-refit-without-refitting","dir":"Articles","previous_headings":"Introduction > Standardizing Parameters of Linear Models > Methods of Standardizing Parameters","what":"\"posthoc\": Refit without refitting","title":"Parameter and Model Standardization","text":"Post-hoc standardization parameters aims emulating results obtained \"refit\" without refitting model. coefficients divided standard deviation (MAD robust) outcome (becomes expression ‘unit’). , coefficients related numeric variables additionally multiplied standard deviation (MAD robust) related terms, correspond changes 1 SD predictor (e.g., “change 1 SD x related change 0.24 SD y). apply binary variables factors, coefficients still related changes levels. method accurate tend give aberrant results interactions specified.","code":"standardize_parameters(mod, method = \"posthoc\")"},{"path":"https://easystats.github.io/parameters/articles/standardize_parameters_effsize.html","id":"smart-standardization-of-models-parameters-with-adjustment-reconnaissance-and-transformation","dir":"Articles","previous_headings":"Introduction > Standardizing Parameters of Linear Models > Methods of Standardizing Parameters","what":"\"smart\": Standardization of Model’s parameters with Adjustment, Reconnaissance and Transformation","title":"Parameter and Model Standardization","text":"Experimental Similar method = \"posthoc\" involve model refitting. difference SD response computed relevant section data. instance, factor 3 levels (intercept), B C entered predictor, effect corresponding B vs. scaled variance response intercept . results, coefficients effects factors similar Glass’ delta.","code":"standardize_parameters(mod, method = \"smart\")"},{"path":"https://easystats.github.io/parameters/articles/standardize_parameters_effsize.html","id":"basic-raw-scaling-of-the-model-frame","dir":"Articles","previous_headings":"Introduction > Standardizing Parameters of Linear Models > Methods of Standardizing Parameters","what":"\"basic\": Raw scaling of the model frame","title":"Parameter and Model Standardization","text":"method similar method = \"posthoc\", treats variables continuous: scales coefficient standard deviation model’s matrix’ parameter factors levels (transformed integers) binary predictors. Although can argued might inappropriate cases, method allows easier importance judgment across predictor type (numeric, factor, interactions…). also type standardization implemented default software packages (also lm.beta::lm.beta()), , can used reproducibility replication purposes.","code":"standardize_parameters(mod, method = \"basic\")"},{"path":"https://easystats.github.io/parameters/articles/standardize_parameters_effsize.html","id":"standardizing-parameters-in-mixed-models","dir":"Articles","previous_headings":"Introduction > Standardizing Parameters of Linear Models","what":"Standardizing Parameters In Mixed Models","title":"Parameter and Model Standardization","text":"Linear mixed models (LMM/HLM/MLM) offer additional conundrum standardization - one even calculate SDs various predictors? response - deviations within group? perhaps ? solution: standardize according level predictor (Hoffman 2015, 342)! Level 1 parameters standardized according variance within groups, level 2 parameters standardized according variance groups. resulting standardized coefficient also called pseudo-standardized coefficients.[^Note like method \"basic\", based model matrix.]","code":"m <- lme4::lmer(Reaction ~ Days + (Days | Subject), data = lme4::sleepstudy)  standardize_parameters(m, method = \"pseudo\", ci_method = \"satterthwaite\")  # compare to: standardize_parameters(m, method = \"basic\", ci_method = \"satterthwaite\")"},{"path":"https://easystats.github.io/parameters/articles/standardize_parameters_effsize.html","id":"standardizing-parameters-in-generalized-linear-models","dir":"Articles","previous_headings":"Introduction > Standardizing Parameters of Linear Models","what":"Standardizing Parameters In Generalized Linear Models","title":"Parameter and Model Standardization","text":"Unlike linear (/mixed) models, generalized linear (/mixed) models (GLMs) less need standardization. ? many GLMs estimated coefficients measures effect size, odds-ratios () logistic regression, incidence rate ratios (IRR) Poisson regressions. model outcome arbitrary scale - , meaning rates probabilities changed arbitrary linear transformations. still, standardization sometimes needed, predictors. Luckily, standardize_parameters() (standardize()) smart enough know GLMs passed standardize according predictors: can converted (exp()) discussed “change Odds function change one SD x”. can directly ask coefficients exponentiated:","code":"mod_b <- glm(am ~ mpg + factor(cyl),   data = mtcars,   family = binomial() )  standardize_parameters(mod_b, method = \"refit\", two_sd = TRUE) # standardize_parameters(mod_b, method = \"posthoc\", two_sd = TRUE) # standardize_parameters(mod_b, method = \"basic\") std <- standardize_parameters(mod_b, method = \"refit\", two_sd = TRUE) exp(std$Std_Coefficient) standardize_parameters(mod_b, method = \"refit\", two_sd = TRUE, exponentiate = TRUE)"},{"path":"https://easystats.github.io/parameters/articles/standardize_parameters_effsize.html","id":"cohens-f","dir":"Articles","previous_headings":"Introduction","what":"Cohen’s f","title":"Parameter and Model Standardization","text":"Cohen’s \\(f\\) (ANOVA fame) can used measure effect size context sequential multiple regression (.e., nested models). , comparing two models, can examine ratio increase \\(R^2\\) unexplained variance: \\[ f^{2}={R_{AB}^{2}-R_{}^{2} \\1-R_{AB}^{2}} \\]","code":"m1 <- lm(salary ~ xtra_hours, data = hardlyworking) m2 <- lm(salary ~ xtra_hours + n_comps + seniority, data = hardlyworking)  cohens_f_squared(m1, model2 = m2)"},{"path":[]},{"path":"https://easystats.github.io/parameters/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Daniel Lüdecke. Author, maintainer.            @strengejacke Dominique Makowski. Author.            @Dom_Makowski Mattan S. Ben-Shachar. Author. Indrajeet Patil. Author.            @patilindrajeets Søren Højsgaard. Author. Brenton M. Wiernik. Author.            @bmwiernik Zen J. Lau. Contributor. Vincent Arel-Bundock. Contributor.            @vincentab Jeffrey Girard. Contributor.            @jeffreymgirard Christina Maimone. Reviewer. Niels Ohlsen. Reviewer.            @Niels_Bremen Douglas Ezra Morrison. Contributor.            @demstats1 Joseph Luchman. Contributor.","code":""},{"path":"https://easystats.github.io/parameters/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Lüdecke D, Ben-Shachar M, Patil , Makowski D (2020). “Extracting, Computing Exploring Parameters Statistical Models using R.” Journal Open Source Software, 5(53), 2445. doi:10.21105/joss.02445.","code":"@Article{,   title = {Extracting, Computing and Exploring the Parameters of Statistical Models using {R}.},   volume = {5},   doi = {10.21105/joss.02445},   number = {53},   journal = {Journal of Open Source Software},   author = {Daniel Lüdecke and Mattan S. Ben-Shachar and Indrajeet Patil and Dominique Makowski},   year = {2020},   pages = {2445}, }"},{"path":"https://easystats.github.io/parameters/index.html","id":"parameters-","dir":"","previous_headings":"","what":"Processing of Model Parameters","title":"Processing of Model Parameters","text":"Describe understand model’s parameters! parameters’ primary goal provide utilities processing parameters various statistical models (see list supported models). Beyond computing p-values, CIs, Bayesian indices measures wide variety models, package implements features like bootstrapping parameters models, feature reduction (feature extraction variable selection), tools data reduction like functions perform cluster, factor principal component analysis. Another important goal parameters package facilitate streamline process reporting results statistical models, includes easy intuitive calculation standardized estimates robust standard errors p-values. parameters therefor offers simple unified syntax process large variety (model) objects many different packages.","code":""},{"path":"https://easystats.github.io/parameters/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Processing of Model Parameters","text":"Run following install stable release parameters CRAN: one install latest development version R-universe… …GitHub:","code":"install.packages(\"parameters\") install.packages(\"parameters\", repos = \"https://easystats.r-universe.dev\") install.packages(\"remotes\") remotes::install_github(\"easystats/parameters\")"},{"path":"https://easystats.github.io/parameters/index.html","id":"documentation","dir":"","previous_headings":"","what":"Documentation","title":"Processing of Model Parameters","text":"Click buttons access package documentation easystats blog, check-vignettes: Summary Model Parameters Standardized Model Parameters Robust Estimation Standard Errors, Confidence Intervals p-values Model Parameters Missing Data Feature reduction (PCA, cMDS, ICA…) Structural models (EFA, CFA, SEM…) Parameters selection Practical Guide Panel Data Analysis","code":""},{"path":"https://easystats.github.io/parameters/index.html","id":"contributing-and-support","dir":"","previous_headings":"","what":"Contributing and Support","title":"Processing of Model Parameters","text":"case want file issue contribute another way package, please follow guide. questions functionality, may either contact us via email also file issue.","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/index.html","id":"models-parameters-description","dir":"","previous_headings":"","what":"Model’s parameters description","title":"Processing of Model Parameters","text":"model_parameters() function (can accessed via parameters() shortcut) allows extract parameters characteristics various models consistent way. can considered lightweight alternative broom::tidy(), notable differences: column names returned data frame specific content. instance, column containing statistic named following statistic name, .e., t, z, etc., instead generic name statistic (however, can get standardized (generic) column names using standardize_names()). able compute extract indices available default, p-values, CIs, etc. includes feature engineering capabilities, including parameters bootstrapping.","code":""},{"path":"https://easystats.github.io/parameters/index.html","id":"classical-regression-models","dir":"","previous_headings":"Model’s parameters description","what":"Classical Regression Models","title":"Processing of Model Parameters","text":"","code":"model <- lm(Sepal.Width ~ Petal.Length * Species + Petal.Width, data = iris)  # regular model parameters model_parameters(model) #> Parameter                           | Coefficient |   SE |         95% CI | t(143) |      p #> ------------------------------------------------------------------------------------------- #> (Intercept)                         |        2.89 | 0.36 | [ 2.18,  3.60] |   8.01 | < .001 #> Petal Length                        |        0.26 | 0.25 | [-0.22,  0.75] |   1.07 | 0.287  #> Species [versicolor]                |       -1.66 | 0.53 | [-2.71, -0.62] |  -3.14 | 0.002  #> Species [virginica]                 |       -1.92 | 0.59 | [-3.08, -0.76] |  -3.28 | 0.001  #> Petal Width                         |        0.62 | 0.14 | [ 0.34,  0.89] |   4.41 | < .001 #> Petal Length * Species [versicolor] |       -0.09 | 0.26 | [-0.61,  0.42] |  -0.36 | 0.721  #> Petal Length * Species [virginica]  |       -0.13 | 0.26 | [-0.64,  0.38] |  -0.50 | 0.618  # standardized parameters model_parameters(model, standardize = \"refit\") #> Parameter                           | Coefficient |   SE |         95% CI | t(143) |      p #> ------------------------------------------------------------------------------------------- #> (Intercept)                         |        3.59 | 1.30 | [ 1.01,  6.17] |   2.75 | 0.007  #> Petal Length                        |        1.07 | 1.00 | [-0.91,  3.04] |   1.07 | 0.287  #> Species [versicolor]                |       -4.62 | 1.31 | [-7.21, -2.03] |  -3.53 | < .001 #> Species [virginica]                 |       -5.51 | 1.38 | [-8.23, -2.79] |  -4.00 | < .001 #> Petal Width                         |        1.08 | 0.24 | [ 0.59,  1.56] |   4.41 | < .001 #> Petal Length * Species [versicolor] |       -0.38 | 1.06 | [-2.48,  1.72] |  -0.36 | 0.721  #> Petal Length * Species [virginica]  |       -0.52 | 1.04 | [-2.58,  1.54] |  -0.50 | 0.618"},{"path":"https://easystats.github.io/parameters/index.html","id":"mixed-models","dir":"","previous_headings":"Model’s parameters description","what":"Mixed Models","title":"Processing of Model Parameters","text":"","code":"library(lme4)  model <- lmer(Sepal.Width ~ Petal.Length + (1 | Species), data = iris)  # model parameters with CI, df and p-values based on Wald approximation model_parameters(model, effects = \"all\") #> # Fixed Effects #>  #> Parameter    | Coefficient |   SE |       95% CI | t(146) |      p #> ------------------------------------------------------------------ #> (Intercept)  |        2.00 | 0.56 | [0.89, 3.11] |   3.56 | < .001 #> Petal Length |        0.28 | 0.06 | [0.16, 0.40] |   4.75 | < .001 #>  #> # Random Effects #>  #> Parameter               | Coefficient |   SE |       95% CI #> ----------------------------------------------------------- #> SD (Intercept: Species) |        0.89 | 0.46 | [0.33, 2.43] #> SD (Residual)           |        0.32 | 0.02 | [0.28, 0.35]  # model parameters with CI, df and p-values based on Kenward-Roger approximation model_parameters(model, ci_method = \"kenward\") #> # Fixed Effects #>  #> Parameter    | Coefficient |   SE |       95% CI |    t |     df |      p #> ------------------------------------------------------------------------- #> (Intercept)  |        2.00 | 0.57 | [0.07, 3.93] | 3.53 |   2.67 | 0.046  #> Petal Length |        0.28 | 0.06 | [0.16, 0.40] | 4.58 | 140.98 | < .001 #>  #> # Random Effects #>  #> Parameter               | Coefficient |   SE |       95% CI #> ----------------------------------------------------------- #> SD (Intercept: Species) |        0.89 | 0.46 | [0.33, 2.43] #> SD (Residual)           |        0.32 | 0.02 | [0.28, 0.35]"},{"path":"https://easystats.github.io/parameters/index.html","id":"structural-models","dir":"","previous_headings":"Model’s parameters description","what":"Structural Models","title":"Processing of Model Parameters","text":"Besides many types regression models packages, also works types models, structural models (EFA, CFA, SEM…).","code":"library(psych)  model <- psych::fa(attitude, nfactors = 3) model_parameters(model) #> # Rotated loadings from Factor Analysis (oblimin-rotation) #>  #> Variable   |  MR1  |  MR2  |  MR3  | Complexity | Uniqueness #> ------------------------------------------------------------ #> rating     | 0.90  | -0.07 | -0.05 |    1.02    |    0.23    #> complaints | 0.97  | -0.06 | 0.04  |    1.01    |    0.10    #> privileges | 0.44  | 0.25  | -0.05 |    1.64    |    0.65    #> learning   | 0.47  | 0.54  | -0.28 |    2.51    |    0.24    #> raises     | 0.55  | 0.43  | 0.25  |    2.35    |    0.23    #> critical   | 0.16  | 0.17  | 0.48  |    1.46    |    0.67    #> advance    | -0.11 | 0.91  | 0.07  |    1.04    |    0.22    #>  #> The 3 latent factors (oblimin rotation) accounted for 66.60% of the total variance of the original data (MR1 = 38.19%, MR2 = 22.69%, MR3 = 5.72%)."},{"path":"https://easystats.github.io/parameters/index.html","id":"variable-and-parameters-selection","dir":"","previous_headings":"","what":"Variable and parameters selection","title":"Processing of Model Parameters","text":"select_parameters() can help quickly select retain relevant predictors using methods tailored model type.","code":"lm(disp ~ ., data = mtcars) |>   select_parameters() |>   model_parameters() #> Parameter   | Coefficient |     SE |            95% CI | t(26) |      p #> ----------------------------------------------------------------------- #> (Intercept) |      141.70 | 125.67 | [-116.62, 400.02] |  1.13 | 0.270  #> cyl         |       13.14 |   7.90 | [  -3.10,  29.38] |  1.66 | 0.108  #> hp          |        0.63 |   0.20 | [   0.22,   1.03] |  3.18 | 0.004  #> wt          |       80.45 |  12.22 | [  55.33, 105.57] |  6.58 | < .001 #> qsec        |      -14.68 |   6.14 | [ -27.31,  -2.05] | -2.39 | 0.024  #> carb        |      -28.75 |   5.60 | [ -40.28, -17.23] | -5.13 | < .001"},{"path":"https://easystats.github.io/parameters/index.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Processing of Model Parameters","text":"order cite package, please use following command:","code":"citation(\"parameters\")  To cite package 'parameters' in publications use:    Lüdecke D, Ben-Shachar M, Patil I, Makowski D (2020). \"Extracting,   Computing and Exploring the Parameters of Statistical Models using   R.\" _Journal of Open Source Software_, *5*(53), 2445.   doi:10.21105/joss.02445 <https://doi.org/10.21105/joss.02445>.  A BibTeX entry for LaTeX users is    @Article{,     title = {Extracting, Computing and Exploring the Parameters of Statistical Models using {R}.},     volume = {5},     doi = {10.21105/joss.02445},     number = {53},     journal = {Journal of Open Source Software},     author = {Daniel Lüdecke and Mattan S. Ben-Shachar and Indrajeet Patil and Dominique Makowski},     year = {2020},     pages = {2445},   }"},{"path":"https://easystats.github.io/parameters/index.html","id":"code-of-conduct","dir":"","previous_headings":"","what":"Code of Conduct","title":"Processing of Model Parameters","text":"Please note parameters project released Contributor Code Conduct. contributing project, agree abide terms.","code":""},{"path":"https://easystats.github.io/parameters/reference/bootstrap_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Model bootstrapping — bootstrap_model","title":"Model bootstrapping — bootstrap_model","text":"Bootstrap statistical model n times return data frame estimates.","code":""},{"path":"https://easystats.github.io/parameters/reference/bootstrap_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Model bootstrapping — bootstrap_model","text":"","code":"bootstrap_model(model, iterations = 1000, ...)  # S3 method for default bootstrap_model(   model,   iterations = 1000,   type = \"ordinary\",   parallel = c(\"no\", \"multicore\", \"snow\"),   n_cpus = 1,   verbose = FALSE,   ... )  # S3 method for merMod bootstrap_model(   model,   iterations = 1000,   type = \"parametric\",   parallel = c(\"no\", \"multicore\", \"snow\"),   n_cpus = 1,   cluster = NULL,   verbose = FALSE,   ... )"},{"path":"https://easystats.github.io/parameters/reference/bootstrap_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Model bootstrapping — bootstrap_model","text":"model Statistical model. iterations number draws simulate/bootstrap. ... Arguments passed methods. type Character string specifying type bootstrap. mixed models class merMod glmmTMB, may \"parametric\" (default) \"semiparametric\" (see ?lme4::bootMer details). models, see argument sim ?boot::boot (defaults \"ordinary\"). parallel type parallel operation used (). n_cpus Number processes used parallel operation. verbose Toggle warnings messages. cluster Optional cluster parallel = \"snow\". See ?lme4::bootMer details.","code":""},{"path":"https://easystats.github.io/parameters/reference/bootstrap_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Model bootstrapping — bootstrap_model","text":"data frame bootstrapped estimates.","code":""},{"path":"https://easystats.github.io/parameters/reference/bootstrap_model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Model bootstrapping — bootstrap_model","text":"default, boot::boot() used generate bootstraps model data, used update() model, .e. refit model bootstrapped samples. merMod objects (lme4) models glmmTMB, lme4::bootMer() function used obtain bootstrapped samples. bootstrap_parameters() summarizes bootstrapped model estimates.","code":""},{"path":"https://easystats.github.io/parameters/reference/bootstrap_model.html","id":"using-with-emmeans","dir":"Reference","previous_headings":"","what":"Using with emmeans","title":"Model bootstrapping — bootstrap_model","text":"output can passed directly various functions emmeans package, obtain bootstrapped estimates, contrasts, simple slopes, etc. confidence intervals. can passed model_parameter() obtain standard errors, p-values, etc. (see example).  Note p-values returned estimated assumption translation equivariance: shape sampling distribution unaffected null true . assumption hold, p-values can biased, suggested use proper permutation tests obtain non-parametric p-values.","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/bootstrap_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Model bootstrapping — bootstrap_model","text":"","code":"if (FALSE) { if (require(\"boot\", quietly = TRUE)) {   model <- lm(mpg ~ wt + factor(cyl), data = mtcars)   b <- bootstrap_model(model)   print(head(b))    if (require(\"emmeans\", quietly = TRUE)) {     est <- emmeans(b, consec ~ cyl)     print(model_parameters(est))   } } }"},{"path":"https://easystats.github.io/parameters/reference/bootstrap_parameters.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameters bootstrapping — bootstrap_parameters","title":"Parameters bootstrapping — bootstrap_parameters","text":"Compute bootstrapped parameters related indices Confidence Intervals (CI) p-values.","code":""},{"path":"https://easystats.github.io/parameters/reference/bootstrap_parameters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parameters bootstrapping — bootstrap_parameters","text":"","code":"bootstrap_parameters(   model,   iterations = 1000,   centrality = \"median\",   ci = 0.95,   ci_method = \"quantile\",   test = \"p-value\",   ... )"},{"path":"https://easystats.github.io/parameters/reference/bootstrap_parameters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameters bootstrapping — bootstrap_parameters","text":"model Statistical model. iterations number draws simulate/bootstrap. centrality point-estimates (centrality indices) compute.  Character (vector) list one options: \"median\", \"mean\", \"MAP\" \"\". ci Value vector probability CI (0 1) estimated. Default .95 (95%). ci_method type index used Credible Interval. Can \"ETI\" (default, see eti()), \"HDI\" (see hdi()), \"BCI\" (see bci()), \"SPI\" (see spi()), \"SI\" (see si()). test indices compute. Character (vector) one options: \"p-value\" (\"p\"), \"p_direction\" (\"pd\"), \"rope\", \"p_map\", \"equivalence_test\" (\"equitest\"), \"bayesfactor\" (\"bf\") \"\" compute tests. \"test\", corresponding bayestestR function called (e.g. bayestestR::rope() bayestestR::p_direction()) results included summary output. ... Arguments passed methods.","code":""},{"path":"https://easystats.github.io/parameters/reference/bootstrap_parameters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parameters bootstrapping — bootstrap_parameters","text":"data frame summarizing bootstrapped parameters.","code":""},{"path":"https://easystats.github.io/parameters/reference/bootstrap_parameters.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Parameters bootstrapping — bootstrap_parameters","text":"function first calls bootstrap_model() generate bootstrapped coefficients. resulting replicated coefficient treated \"distribution\", passed bayestestR::describe_posterior() calculate related indices defined \"test\" argument.  Note p-values returned estimated assumption translation equivariance: shape sampling distribution unaffected null true . assumption hold, p-values can biased, suggested use proper permutation tests obtain non-parametric p-values.","code":""},{"path":"https://easystats.github.io/parameters/reference/bootstrap_parameters.html","id":"using-with-emmeans","dir":"Reference","previous_headings":"","what":"Using with emmeans","title":"Parameters bootstrapping — bootstrap_parameters","text":"output can passed directly various functions emmeans package, obtain bootstrapped estimates, contrasts, simple slopes, etc. confidence intervals. can passed model_parameter() obtain standard errors, p-values, etc. (see example).  Note p-values returned estimated assumption translation equivariance: shape sampling distribution unaffected null true . assumption hold, p-values can biased, suggested use proper permutation tests obtain non-parametric p-values.","code":""},{"path":"https://easystats.github.io/parameters/reference/bootstrap_parameters.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Parameters bootstrapping — bootstrap_parameters","text":"Davison, . C., & Hinkley, D. V. (1997). Bootstrap methods application (Vol. 1). Cambridge university press.","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/bootstrap_parameters.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parameters bootstrapping — bootstrap_parameters","text":"","code":"if (FALSE) { if (require(\"boot\", quietly = TRUE)) {   set.seed(2)   model <- lm(Sepal.Length ~ Species * Petal.Width, data = iris)   b <- bootstrap_parameters(model)   print(b)    if (require(\"emmeans\")) {     est <- emmeans(b, trt.vs.ctrl ~ Species)     print(model_parameters(est))   } } }"},{"path":"https://easystats.github.io/parameters/reference/check_clusterstructure.html","id":null,"dir":"Reference","previous_headings":"","what":"Check suitability of data for clustering — check_clusterstructure","title":"Check suitability of data for clustering — check_clusterstructure","text":"checks whether data appropriate clustering using Hopkins' H statistic given data. value Hopkins statistic close 0 (0.5), can reject null hypothesis conclude dataset significantly clusterable. value H lower 0.25 indicates clustering tendency 90% confidence level. visual assessment cluster tendency (VAT) approach (Bezdek Hathaway, 2002) consists investigating heatmap ordered dissimilarity matrix. Following , one can potentially detect clustering tendency counting number square shaped blocks along diagonal.","code":""},{"path":"https://easystats.github.io/parameters/reference/check_clusterstructure.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check suitability of data for clustering — check_clusterstructure","text":"","code":"check_clusterstructure(x, standardize = TRUE, distance = \"euclidean\", ...)"},{"path":"https://easystats.github.io/parameters/reference/check_clusterstructure.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check suitability of data for clustering — check_clusterstructure","text":"x data frame. standardize Standardize dataframe clustering (default). distance Distance method used. methods \"euclidean\" (default) exploratory context clustering tendency. See stats::dist() list available methods. ... Arguments passed methods.","code":""},{"path":"https://easystats.github.io/parameters/reference/check_clusterstructure.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check suitability of data for clustering — check_clusterstructure","text":"H statistic (numeric)","code":""},{"path":"https://easystats.github.io/parameters/reference/check_clusterstructure.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Check suitability of data for clustering — check_clusterstructure","text":"Lawson, R. G., & Jurs, P. C. (1990). New index clustering tendency application chemical problems. Journal chemical information computer sciences, 30(1), 36-41. Bezdek, J. C., & Hathaway, R. J. (2002, May). VAT: tool visual assessment (cluster) tendency. Proceedings 2002 International Joint Conference Neural Networks. IJCNN02 (3), 2225-2230. IEEE.","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/check_clusterstructure.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check suitability of data for clustering — check_clusterstructure","text":"","code":"# \\donttest{ library(parameters) check_clusterstructure(iris[, 1:4]) #> # Clustering tendency #>  #> The dataset is suitable for clustering (Hopkins' H = 0.19). plot(check_clusterstructure(iris[, 1:4]))  # }"},{"path":"https://easystats.github.io/parameters/reference/check_factorstructure.html","id":null,"dir":"Reference","previous_headings":"","what":"Check suitability of data for Factor Analysis (FA) — check_factorstructure","title":"Check suitability of data for Factor Analysis (FA) — check_factorstructure","text":"checks whether data appropriate Factor Analysis (FA) running Bartlett's Test Sphericity Kaiser, Meyer, Olkin (KMO) Measure Sampling Adequacy (MSA).","code":""},{"path":"https://easystats.github.io/parameters/reference/check_factorstructure.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check suitability of data for Factor Analysis (FA) — check_factorstructure","text":"","code":"check_factorstructure(x, ...)"},{"path":"https://easystats.github.io/parameters/reference/check_factorstructure.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check suitability of data for Factor Analysis (FA) — check_factorstructure","text":"x dataframe. ... Arguments passed methods.","code":""},{"path":"https://easystats.github.io/parameters/reference/check_factorstructure.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check suitability of data for Factor Analysis (FA) — check_factorstructure","text":"list lists indices related sphericity KMO.","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/check_factorstructure.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check suitability of data for Factor Analysis (FA) — check_factorstructure","text":"","code":"library(parameters) check_factorstructure(mtcars) #> # Is the data suitable for Factor Analysis? #>  #>   - KMO: The Kaiser, Meyer, Olkin (KMO) measure of sampling adequacy suggests that data seems appropriate for factor analysis (KMO = 0.83). #>   - Sphericity: Bartlett's test of sphericity suggests that there is sufficient significant correlation in the data for factor analysis (Chisq(55) = 408.01, p < .001)."},{"path":"https://easystats.github.io/parameters/reference/check_heterogeneity.html","id":null,"dir":"Reference","previous_headings":"","what":"Check model predictor for heterogeneity bias — check_heterogeneity","title":"Check model predictor for heterogeneity bias — check_heterogeneity","text":"check_heterogeneity() checks model predictors variables may cause heterogeneity bias, .e. variables within- /-effect.","code":""},{"path":"https://easystats.github.io/parameters/reference/check_heterogeneity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check model predictor for heterogeneity bias — check_heterogeneity","text":"","code":"check_heterogeneity(x, select = NULL, group = NULL)"},{"path":"https://easystats.github.io/parameters/reference/check_heterogeneity.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check model predictor for heterogeneity bias — check_heterogeneity","text":"x data frame mixed model object. select Character vector (formula) names variables select checked. x mixed model object, argument ignored. group Character vector (formula) name variable indicates group- cluster-ID. x model object, argument ignored.","code":""},{"path":"https://easystats.github.io/parameters/reference/check_heterogeneity.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Check model predictor for heterogeneity bias — check_heterogeneity","text":"function removed future update. Please use performance::check_heterogeneity_bias().","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/check_kmo.html","id":null,"dir":"Reference","previous_headings":"","what":"Kaiser, Meyer, Olkin (KMO) Measure of Sampling Adequacy (MSA) for Factor Analysis — check_kmo","title":"Kaiser, Meyer, Olkin (KMO) Measure of Sampling Adequacy (MSA) for Factor Analysis — check_kmo","text":"Kaiser (1970) introduced Measure Sampling Adequacy (MSA), later modified Kaiser Rice (1974). Kaiser-Meyer-Olkin (KMO) statistic, can vary 0 1, indicates degree variable set predicted without error variables.","code":""},{"path":"https://easystats.github.io/parameters/reference/check_kmo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Kaiser, Meyer, Olkin (KMO) Measure of Sampling Adequacy (MSA) for Factor Analysis — check_kmo","text":"","code":"check_kmo(x, ...)"},{"path":"https://easystats.github.io/parameters/reference/check_kmo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Kaiser, Meyer, Olkin (KMO) Measure of Sampling Adequacy (MSA) for Factor Analysis — check_kmo","text":"x dataframe. ... Arguments passed methods.","code":""},{"path":"https://easystats.github.io/parameters/reference/check_kmo.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Kaiser, Meyer, Olkin (KMO) Measure of Sampling Adequacy (MSA) for Factor Analysis — check_kmo","text":"list indices related KMO.","code":""},{"path":"https://easystats.github.io/parameters/reference/check_kmo.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Kaiser, Meyer, Olkin (KMO) Measure of Sampling Adequacy (MSA) for Factor Analysis — check_kmo","text":"value 0 indicates sum partial correlations large relative sum correlations, indicating factor analysis likely inappropriate. KMO value close 1 indicates sum partial correlations large relative sum correlations factor analysis yield distinct reliable factors. Kaiser (1974) suggested KMO > .9 marvelous, .80s, meritorious, .70s, middling, .60s, mediocre, .50s, miserable, less .5, unacceptable. Hair et al. (2006) suggest accepting value > 0.5. Values 0.5 0.7 mediocre, values 0.7 0.8 good. function strongly inspired KMO function psych package (Revelle, 2016). credit goes author.","code":""},{"path":"https://easystats.github.io/parameters/reference/check_kmo.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Kaiser, Meyer, Olkin (KMO) Measure of Sampling Adequacy (MSA) for Factor Analysis — check_kmo","text":"Revelle, W. (2016). : Use psych package Factor Analysis data reduction. Kaiser, H. F. (1970). second generation little jiffy. Psychometrika, 35(4), 401-415. Kaiser, H. F., & Rice, J. (1974). Little jiffy, mark IV. Educational psychological measurement, 34(1), 111-117. Kaiser, H. F. (1974). index factorial simplicity. Psychometrika, 39(1), 31-36.","code":""},{"path":"https://easystats.github.io/parameters/reference/check_kmo.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Kaiser, Meyer, Olkin (KMO) Measure of Sampling Adequacy (MSA) for Factor Analysis — check_kmo","text":"","code":"library(parameters) check_kmo(mtcars) #> # KMO Measure of Sampling Adequacy #>  #> The Kaiser, Meyer, Olkin (KMO) measure of sampling adequacy suggests that data seems appropriate for factor analysis (KMO = 0.83)."},{"path":"https://easystats.github.io/parameters/reference/check_sphericity_bartlett.html","id":null,"dir":"Reference","previous_headings":"","what":"Bartlett's Test of Sphericity — check_sphericity_bartlett","title":"Bartlett's Test of Sphericity — check_sphericity_bartlett","text":"Bartlett's (1951) test sphericity tests whether matrix (correlations) significantly different identity matrix. test provides probability correlation matrix significant correlations among least variables dataset, prerequisite factor analysis work. words, starting factor analysis, one needs check whether Bartlett’s test sphericity significant.","code":""},{"path":"https://easystats.github.io/parameters/reference/check_sphericity_bartlett.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bartlett's Test of Sphericity — check_sphericity_bartlett","text":"","code":"check_sphericity_bartlett(x, ...)"},{"path":"https://easystats.github.io/parameters/reference/check_sphericity_bartlett.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bartlett's Test of Sphericity — check_sphericity_bartlett","text":"x dataframe. ... Arguments passed methods.","code":""},{"path":"https://easystats.github.io/parameters/reference/check_sphericity_bartlett.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bartlett's Test of Sphericity — check_sphericity_bartlett","text":"list indices related sphericity.","code":""},{"path":"https://easystats.github.io/parameters/reference/check_sphericity_bartlett.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Bartlett's Test of Sphericity — check_sphericity_bartlett","text":"function strongly inspired cortest.bartlett() function psych package (Revelle, 2016). credit goes author.","code":""},{"path":"https://easystats.github.io/parameters/reference/check_sphericity_bartlett.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Bartlett's Test of Sphericity — check_sphericity_bartlett","text":"Revelle, W. (2016). : Use psych package Factor Analysis data reduction. Bartlett, M. S. (1951). effect standardization Chi-square approximation factor analysis. Biometrika, 38(3/4), 337-344.","code":""},{"path":"https://easystats.github.io/parameters/reference/check_sphericity_bartlett.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bartlett's Test of Sphericity — check_sphericity_bartlett","text":"","code":"library(parameters) check_sphericity_bartlett(mtcars) #> # Test of Sphericity #>  #> Bartlett's test of sphericity suggests that there is sufficient significant correlation in the data for factor analysis (Chisq(55) = 408.01, p < .001)."},{"path":"https://easystats.github.io/parameters/reference/ci.default.html","id":null,"dir":"Reference","previous_headings":"","what":"Confidence Intervals (CI) — ci.default","title":"Confidence Intervals (CI) — ci.default","text":"Compute confidence intervals (CI) frequentist models.","code":""},{"path":"https://easystats.github.io/parameters/reference/ci.default.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Confidence Intervals (CI) — ci.default","text":"","code":"# S3 method for default ci(x, ci = 0.95, dof = NULL, method = NULL, ...)  # S3 method for glmmTMB ci(   x,   ci = 0.95,   dof = NULL,   method = \"wald\",   component = \"all\",   verbose = TRUE,   ... )  # S3 method for merMod ci(x, ci = 0.95, dof = NULL, method = \"wald\", iterations = 500, ...)"},{"path":"https://easystats.github.io/parameters/reference/ci.default.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Confidence Intervals (CI) — ci.default","text":"x statistical model. ci Confidence Interval (CI) level. Default 0.95 (95%). dof Number degrees freedom used calculating confidence intervals. NULL (default), degrees freedom retrieved calling degrees_of_freedom() approximation method defined method. NULL, use argument override default degrees freedom used compute confidence intervals. method Method computing degrees freedom confidence intervals (CI) related p-values. Allowed following options (vary depending model class): \"residual\", \"normal\", \"likelihood\", \"satterthwaite\", \"kenward\", \"wald\", \"profile\", \"boot\", \"uniroot\", \"ml1\", \"betwithin\", \"hdi\", \"quantile\", \"ci\", \"eti\", \"si\", \"bci\", \"bcai\". See section Confidence intervals approximation degrees freedom model_parameters() details. ... Additional arguments component Model component parameters shown. See documentation object's class model_parameters() p_value() details. verbose Toggle warnings messages. iterations number bootstrap replicates. applies models class merMod method=boot.","code":""},{"path":"https://easystats.github.io/parameters/reference/ci.default.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Confidence Intervals (CI) — ci.default","text":"data frame containing CI bounds.","code":""},{"path":"https://easystats.github.io/parameters/reference/ci.default.html","id":"confidence-intervals-and-approximation-of-degrees-of-freedom","dir":"Reference","previous_headings":"","what":"Confidence intervals and approximation of degrees of freedom","title":"Confidence Intervals (CI) — ci.default","text":"different ways approximating degrees freedom depending different assumptions nature model sampling distribution. ci_method argument modulates method computing degrees freedom (df) used calculate confidence intervals (CI) related p-values. Following options allowed, depending model class: Classical methods: Classical inference generally based Wald method. Wald approach inference computes test statistic dividing parameter estimate standard error (Coefficient / SE), comparing statistic t- normal distribution. approach can used compute CIs p-values. \"wald\": Applies non-Bayesian models. linear models, CIs computed using Wald method (SE t-distribution residual df); p-values computed using Wald method t-distribution residual df. models, CIs computed using Wald method (SE normal distribution); p-values computed using Wald method normal distribution. \"normal\" Applies non-Bayesian models. Compute Wald CIs p-values, always use normal distribution. \"residual\" Applies non-Bayesian models. Compute Wald CIs p-values, always use t-distribution residual df possible. residual df model determined, normal distribution used instead. Methods mixed models: Compared fixed effects (single-level) models, determining appropriate df Wald-based inference mixed models difficult. See R GLMM FAQ discussion. Several approximate methods computing df available, also consider instead using profile likelihood (\"profile\") bootstrap (\"boot\") CIs p-values instead. \"satterthwaite\" Applies linear mixed models. CIs computed using Wald method (SE t-distribution Satterthwaite df); p-values computed using Wald method t-distribution Satterthwaite df. \"kenward\" Applies linear mixed models. CIs computed using Wald method (Kenward-Roger SE t-distribution Kenward-Roger df); p-values computed using Wald method Kenward-Roger SE t-distribution Kenward-Roger df. \"ml1\" Applies linear mixed models. CIs computed using Wald method (SE t-distribution m-l-1 approximated df); p-values computed using Wald method t-distribution m-l-1 approximated df. See ci_ml1(). \"betwithin\" Applies linear mixed models generalized linear mixed models. CIs computed using Wald method (SE t-distribution -within df); p-values computed using Wald method t-distribution -within df. See ci_betwithin(). Likelihood-based methods: Likelihood-based inference based comparing likelihood maximum-likelihood estimate likelihood models one parameter values changed (e.g., set zero range alternative values). Likelihood ratios maximum-likelihood alternative models compared \\(\\chi\\)-squared distribution compute CIs p-values. \"profile\" Applies non-Bayesian models class glm, polr glmmTMB. CIs computed profiling likelihood curve parameter, using linear interpolation find likelihood ratio equals critical value; p-values computed using Wald method normal-distribution (note: might change future update!) \"uniroot\" Applies non-Bayesian models class glmmTMB. CIs computed profiling likelihood curve parameter, using root finding find likelihood ratio equals critical value; p-values computed using Wald method normal-distribution (note: might change future update!) Methods bootstrapped Bayesian models: Bootstrap-based inference based resampling refitting model resampled datasets. distribution parameter estimates across resampled datasets used approximate parameter's sampling distribution. Depending type model, several different methods bootstrapping constructing CIs p-values bootstrap distribution available. Bayesian models, inference based drawing samples model posterior distribution. \"quantile\" (\"eti\") Applies models (including Bayesian models). non-Bayesian models, applies bootstrap = TRUE. CIs computed equal tailed intervals using quantiles bootstrap posterior samples; p-values based probability direction. See bayestestR::eti(). \"hdi\" Applies models (including Bayesian models). non-Bayesian models, applies bootstrap = TRUE. CIs computed highest density intervals bootstrap posterior samples; p-values based probability direction. See bayestestR::hdi(). \"bci\" (\"bcai\") Applies models (including Bayesian models). non-Bayesian models, applies bootstrap = TRUE. CIs computed bias corrected accelerated intervals bootstrap posterior samples; p-values based probability direction. See bayestestR::bci(). \"si\" Applies Bayesian models proper priors. CIs computed support intervals comparing posterior samples prior samples; p-values based probability direction. See bayestestR::si(). \"boot\" Applies non-Bayesian models class merMod. CIs computed using parametric bootstrapping (simulating data fitted model); p-values computed using Wald method normal-distribution) (note: might change future update!). iteration-based methods \"boot\" (\"hdi\", \"quantile\", \"ci\", \"eti\", \"si\", \"bci\", \"bcai\"), p-values based probability direction (bayestestR::p_direction()), converted p-value using bayestestR::pd_to_p().","code":""},{"path":"https://easystats.github.io/parameters/reference/ci.default.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Confidence Intervals (CI) — ci.default","text":"","code":"# \\donttest{ library(parameters) if (require(\"glmmTMB\")) {   model <- glmmTMB(     count ~ spp + mined + (1 | site),     ziformula = ~mined,     family = poisson(),     data = Salamanders   )    ci(model)   ci(model, component = \"zi\") } #> Loading required package: glmmTMB #> Warning: Package version inconsistency detected. #> glmmTMB was built with TMB version 1.9.0 #> Current TMB version is 1.9.1 #> Please re-install glmmTMB from source or restore original ‘TMB’ package (see '?reinstalling' for more information) #>     Parameter   CI     CI_low   CI_high     Component #> 1 (Intercept) 0.95  0.2552453  1.324754 zero_inflated #> 2     minedno 0.95 -2.4604492 -1.229369 zero_inflated # }"},{"path":"https://easystats.github.io/parameters/reference/ci_robust.html","id":null,"dir":"Reference","previous_headings":"","what":"Robust confidence intervals. Superseded by the vcov* arguments in ci() — ci_robust","title":"Robust confidence intervals. Superseded by the vcov* arguments in ci() — ci_robust","text":"Robust confidence intervals. Superseded vcov* arguments ci()","code":""},{"path":"https://easystats.github.io/parameters/reference/ci_robust.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Robust confidence intervals. Superseded by the vcov* arguments in ci() — ci_robust","text":"","code":"ci_robust(   model,   ci = 0.95,   method = NULL,   vcov = \"HC\",   vcov_args = NULL,   component = \"conditional\",   ... )"},{"path":"https://easystats.github.io/parameters/reference/ci_robust.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Robust confidence intervals. Superseded by the vcov* arguments in ci() — ci_robust","text":"model model. ci Confidence Interval (CI) level. Default 0.95 (95%). method Method computing degrees freedom confidence intervals (CI) related p-values. Allowed following options (vary depending model class): \"residual\", \"normal\", \"likelihood\", \"satterthwaite\", \"kenward\", \"wald\", \"profile\", \"boot\", \"uniroot\", \"ml1\", \"betwithin\", \"hdi\", \"quantile\", \"ci\", \"eti\", \"si\", \"bci\", \"bcai\". See section Confidence intervals approximation degrees freedom model_parameters() details. vcov Variance-covariance matrix used compute uncertainty estimates (e.g., robust standard errors). argument accepts covariance matrix, function returns covariance matrix, string identifies function used compute covariance matrix. covariance matrix function returns covariance matrix (e.g., stats::vcov()) string indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"vcovHC\", \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC. Cluster-robust: \"vcovCR\", \"CR0\", \"CR1\", \"CR1p\", \"CR1S\", \"CR2\", \"CR3\". See ?clubSandwich::vcovCR. Bootstrap: \"vcovBS\", \"xy\", \"residual\", \"wild\", \"mammen\", \"webb\". See ?sandwich::vcovBS. sandwich package functions: \"vcovHAC\", \"vcovPC\", \"vcovCL\", \"vcovPL\". vcov_args List arguments passed function identified vcov argument. function typically supplied sandwich clubSandwich packages. Please refer documentation (e.g., ?sandwich::vcovHAC) see list available arguments. component Model component parameters shown. See documentation object's class model_parameters() p_value() details. ... Additional arguments","code":""},{"path":"https://easystats.github.io/parameters/reference/cluster_analysis.html","id":null,"dir":"Reference","previous_headings":"","what":"Cluster Analysis — cluster_analysis","title":"Cluster Analysis — cluster_analysis","text":"Compute hierarchical kmeans cluster analysis return group assignment observation vector.","code":""},{"path":"https://easystats.github.io/parameters/reference/cluster_analysis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cluster Analysis — cluster_analysis","text":"","code":"cluster_analysis(   x,   n = NULL,   method = \"kmeans\",   include_factors = FALSE,   standardize = TRUE,   verbose = TRUE,   distance_method = \"euclidean\",   hclust_method = \"complete\",   kmeans_method = \"Hartigan-Wong\",   dbscan_eps = 15,   iterations = 100,   ... )"},{"path":"https://easystats.github.io/parameters/reference/cluster_analysis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cluster Analysis — cluster_analysis","text":"x data frame. n Number clusters used supervised cluster methods. NULL, number clusters extract determined calling n_clusters(). Note argument apply unsupervised clustering methods like dbscan, hdbscan, mixture, pvclust, pamk. method Method computing cluster analysis. Can \"kmeans\" (default; k-means using kmeans()), \"hkmeans\" (hierarchical k-means using factoextra::hkmeans()), pam (K-Medoids using cluster::pam()), pamk (K-Medoids finds number clusters), \"hclust\" (hierarchical clustering using hclust() pvclust::pvclust()), dbscan (DBSCAN using dbscan::dbscan()), hdbscan (Hierarchical DBSCAN using dbscan::hdbscan()), mixture (Mixture modeling using mclust::Mclust(), requires user run library(mclust) ). include_factors Logical, TRUE, factors converted numerical values order included data determining number clusters. default, factors removed, methods determine number clusters need numeric input . standardize Standardize dataframe clustering (default). verbose Toggle warnings messages. distance_method Distance measure used methods based distances (e.g., method = \"hclust\" hierarchical clustering. methods, \"kmeans\", argument ignored). Must one \"euclidean\", \"maximum\", \"manhattan\", \"canberra\", \"binary\" \"minkowski\". See dist() pvclust::pvclust() information. hclust_method Agglomeration method used method = \"hclust\" method = \"hkmeans\" (hierarchical clustering). one \"ward\", \"ward.D2\", \"single\", \"complete\", \"average\", \"mcquitty\", \"median\" \"centroid\". Default \"complete\" (see hclust()). kmeans_method Algorithm used calculating kmeans cluster. applies, method = \"kmeans\". May one \"Hartigan-Wong\" (default), \"Lloyd\" (used SPSS), \"MacQueen\". See kmeans() details argument. dbscan_eps 'eps' argument DBSCAN method. See n_clusters_dbscan(). iterations number replications. ... Arguments passed methods.","code":""},{"path":"https://easystats.github.io/parameters/reference/cluster_analysis.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cluster Analysis — cluster_analysis","text":"group classification observation vector. returned vector includes missing values, length nrow(x).","code":""},{"path":"https://easystats.github.io/parameters/reference/cluster_analysis.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cluster Analysis — cluster_analysis","text":"print() plot() methods show (standardized) mean value variable within cluster. Thus, higher absolute value indicates certain variable characteristic pronounced within specific cluster (compared cluster groups lower absolute mean values). Clusters classification can obtained via print(x, newdata = NULL, ...).","code":""},{"path":"https://easystats.github.io/parameters/reference/cluster_analysis.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Cluster Analysis — cluster_analysis","text":"also plot()-method implemented see-package.","code":""},{"path":"https://easystats.github.io/parameters/reference/cluster_analysis.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cluster Analysis — cluster_analysis","text":"Maechler M, Rousseeuw P, Struyf , Hubert M, Hornik K (2014) cluster: Cluster Analysis Basics Extensions. R package.","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/cluster_analysis.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cluster Analysis — cluster_analysis","text":"","code":"set.seed(33) # K-Means ==================================================== rez <- cluster_analysis(iris[1:4], n = 3, method = \"kmeans\") rez # Show results #> # Clustering Solution #>  #> The 3 clusters accounted for 68.16% of the total variance of the original data. #>  #> Cluster | n_Obs | Sum_Squares | Sepal.Length | Sepal.Width | Petal.Length | Petal.Width #> --------------------------------------------------------------------------------------- #> 1       |    21 |       23.16 |        -1.32 |       -0.37 |        -1.13 |       -1.11 #> 2       |    33 |       17.33 |        -0.81 |        1.31 |        -1.28 |       -1.22 #> 3       |    96 |      149.26 |         0.57 |       -0.37 |         0.69 |        0.66 #>  #> # Indices of model performance #>  #> Sum_Squares_Total | Sum_Squares_Between | Sum_Squares_Within |    R2 #> -------------------------------------------------------------------- #> 596.000           |             406.249 |            189.751 | 0.682 #>  #> # You can access the predicted clusters via 'predict()'. predict(rez) # Get clusters #>   [1] 2 1 1 1 2 2 2 2 1 1 2 2 1 1 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 1 1 2 2 2 1 1 2 #>  [38] 2 1 2 2 1 1 2 2 1 2 1 2 2 3 3 3 3 3 3 3 1 3 3 1 3 3 3 3 3 3 3 3 3 3 3 3 3 #>  [75] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 1 3 3 3 3 1 3 3 3 3 3 3 3 3 3 3 3 3 #> [112] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 #> [149] 3 3 summary(rez) # Extract the centers values (can use 'plot()' on that) #>   Cluster Sepal.Length Sepal.Width Petal.Length Petal.Width #> 1       1   -1.3232208  -0.3718921   -1.1334386  -1.1111395 #> 2       2   -0.8135055   1.3145538   -1.2825372  -1.2156393 #> 3       3    0.5690971  -0.3705265    0.6888118   0.6609378 if (requireNamespace(\"MASS\", quietly = TRUE)) {   cluster_discrimination(rez) # Perform LDA } #> # Accuracy of Cluster Group Classification via Linear Discriminant Analysis (LDA) #>  #>  Group Accuracy #>      1  100.00% #>      2   71.43% #>      3  100.00% #>  #> Overall accuracy of classification: 96.00%  # Hierarchical k-means (more robust k-means) if (require(\"factoextra\", quietly = TRUE)) {   rez <- cluster_analysis(iris[1:4], n = 3, method = \"hkmeans\")   rez # Show results   predict(rez) # Get clusters } #> Welcome! Want to learn more? See two factoextra-related books at https://goo.gl/ve3WBa #>   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 #>  [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 3 3 3 2 2 2 3 2 2 2 2 2 2 2 2 3 2 2 2 2 3 2 2 2 #>  [75] 2 3 3 3 2 2 2 2 2 2 2 3 3 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2 3 3 3 3 2 3 3 3 3 #> [112] 3 3 2 2 3 3 3 3 2 3 2 3 2 3 3 2 3 3 3 3 3 3 2 2 3 3 3 2 3 3 3 2 3 3 3 2 3 #> [149] 3 2  # Hierarchical Clustering (hclust) =========================== rez <- cluster_analysis(iris[1:4], n = 3, method = \"hclust\") rez # Show results #> # Clustering Solution #>  #> The 3 clusters accounted for 74.35% of the total variance of the original data. #>  #> Cluster | n_Obs | Sum_Squares | Sepal.Length | Sepal.Width | Petal.Length | Petal.Width #> --------------------------------------------------------------------------------------- #> 1       |    49 |       40.12 |        -1.00 |        0.90 |        -1.30 |       -1.25 #> 2       |    24 |       18.65 |        -0.40 |       -1.36 |         0.06 |       -0.04 #> 3       |    77 |       94.08 |         0.76 |       -0.15 |         0.81 |        0.81 #>  #> # Indices of model performance #>  #> Sum_Squares_Total | Sum_Squares_Between | Sum_Squares_Within |    R2 #> -------------------------------------------------------------------- #> 596.000           |             443.143 |            152.857 | 0.744 #>  #> # You can access the predicted clusters via 'predict()'. predict(rez) # Get clusters #>   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 #>  [38] 1 1 1 1 2 1 1 1 1 1 1 1 1 3 3 3 2 3 2 3 2 3 2 2 3 2 3 3 3 3 2 2 2 3 3 3 3 #>  [75] 3 3 3 3 3 2 2 2 2 3 3 3 3 2 3 2 2 3 2 2 2 3 3 3 2 2 3 3 3 3 3 3 2 3 3 3 3 #> [112] 3 3 3 3 3 3 3 3 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 #> [149] 3 3  # K-Medoids (pam) ============================================ if (require(\"cluster\", quietly = TRUE)) {   rez <- cluster_analysis(iris[1:4], n = 3, method = \"pam\")   rez # Show results   predict(rez) # Get clusters } #>   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 #>  [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 3 3 3 2 3 3 3 3 3 3 3 3 2 3 3 3 3 3 3 3 3 #>  [75] 3 2 2 2 3 3 3 3 3 3 3 3 2 3 3 3 3 3 3 3 3 3 3 3 3 3 2 3 2 2 2 2 3 2 2 2 2 #> [112] 2 2 3 2 2 2 2 2 3 2 3 2 3 2 2 3 3 2 2 2 2 2 3 3 2 2 2 3 2 2 2 3 2 2 2 3 2 #> [149] 2 3  # PAM with automated number of clusters if (require(\"fpc\", quietly = TRUE)) {   rez <- cluster_analysis(iris[1:4], method = \"pamk\")   rez # Show results   predict(rez) # Get clusters } #>   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 #>  [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 #>  [75] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 #> [112] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 #> [149] 2 2  # DBSCAN ==================================================== if (require(\"dbscan\", quietly = TRUE)) {   # Note that you can assimilate more outliers (cluster 0) to neighbouring   # clusters by setting borderPoints = TRUE.   rez <- cluster_analysis(iris[1:4], method = \"dbscan\", dbscan_eps = 1.45)   rez # Show results   predict(rez) # Get clusters } #>  #> Attaching package: ‘dbscan’ #> The following object is masked from ‘package:fpc’: #>  #>     dbscan #>   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 #>  [38] 1 1 1 1 0 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 #>  [75] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 #> [112] 2 2 2 2 2 2 0 0 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 #> [149] 2 2  # Mixture ==================================================== if (require(\"mclust\", quietly = TRUE)) {   library(mclust) # Needs the package to be loaded   rez <- cluster_analysis(iris[1:4], method = \"mixture\")   rez # Show results   predict(rez) # Get clusters } #> Package 'mclust' version 5.4.10 #> Type 'citation(\"mclust\")' for citing this R package in publications. #>   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 #>  [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 #>  [75] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 #> [112] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 #> [149] 2 2"},{"path":"https://easystats.github.io/parameters/reference/cluster_centers.html","id":null,"dir":"Reference","previous_headings":"","what":"Find the cluster centers in your data — cluster_centers","title":"Find the cluster centers in your data — cluster_centers","text":"cluster, computes mean (indices) variables. Can used retrieve centers clusters. Also returns within Sum Squares.","code":""},{"path":"https://easystats.github.io/parameters/reference/cluster_centers.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find the cluster centers in your data — cluster_centers","text":"","code":"cluster_centers(data, clusters, fun = mean, ...)"},{"path":"https://easystats.github.io/parameters/reference/cluster_centers.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find the cluster centers in your data — cluster_centers","text":"data data.frame. clusters vector clusters assignments (must length rows data). fun function use, mean default. ... arguments passed functions.","code":""},{"path":"https://easystats.github.io/parameters/reference/cluster_centers.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find the cluster centers in your data — cluster_centers","text":"dataframe containing cluster centers. Attributes include performance statistics distance observation respective cluster centre.","code":""},{"path":"https://easystats.github.io/parameters/reference/cluster_centers.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find the cluster centers in your data — cluster_centers","text":"","code":"k <- kmeans(iris[1:4], 3) cluster_centers(iris[1:4], clusters = k$cluster) #>   Cluster n_Obs Sum_Squares Sepal.Length Sepal.Width Petal.Length Petal.Width #> 1       1    62    39.82097     5.901613    2.748387     4.393548    1.433871 #> 2       2    38    23.87947     6.850000    3.073684     5.742105    2.071053 #> 3       3    50    15.15100     5.006000    3.428000     1.462000    0.246000 cluster_centers(iris[1:4], clusters = k$cluster, fun = median) #>   Cluster n_Obs Sum_Squares Sepal.Length Sepal.Width Petal.Length Petal.Width #> 1       1    62    39.82097          5.9         2.8         4.50         1.4 #> 2       2    38    23.87947          6.7         3.0         5.65         2.1 #> 3       3    50    15.15100          5.0         3.4         1.50         0.2"},{"path":"https://easystats.github.io/parameters/reference/cluster_discrimination.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute a linear discriminant analysis on classified cluster groups — cluster_discrimination","title":"Compute a linear discriminant analysis on classified cluster groups — cluster_discrimination","text":"Computes linear discriminant analysis (LDA) classified cluster groups, determines goodness classification cluster group. See MASS::lda() details.","code":""},{"path":"https://easystats.github.io/parameters/reference/cluster_discrimination.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute a linear discriminant analysis on classified cluster groups — cluster_discrimination","text":"","code":"cluster_discrimination(x, cluster_groups = NULL, ...)"},{"path":"https://easystats.github.io/parameters/reference/cluster_discrimination.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute a linear discriminant analysis on classified cluster groups — cluster_discrimination","text":"x data frame cluster_groups Group classification cluster analysis, can retrieved cluster_analysis() function. ... arguments passed .","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/cluster_discrimination.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute a linear discriminant analysis on classified cluster groups — cluster_discrimination","text":"","code":"if (requireNamespace(\"MASS\", quietly = TRUE)) {   # Retrieve group classification from hierarchical cluster analysis   clustering <- cluster_analysis(iris[, 1:4], n = 3)    # Goodness of group classification   cluster_discrimination(clustering) } #> # Accuracy of Cluster Group Classification via Linear Discriminant Analysis (LDA) #>  #>  Group Accuracy #>      1   82.98% #>      2   94.34% #>      3  100.00% #>  #> Overall accuracy of classification: 92.67%"},{"path":"https://easystats.github.io/parameters/reference/cluster_meta.html","id":null,"dir":"Reference","previous_headings":"","what":"Metaclustering — cluster_meta","title":"Metaclustering — cluster_meta","text":"One core \"issue\" statistical clustering , many cases, different methods give different results. metaclustering approach proposed easystats (finds echoes consensus clustering; see Monti et al., 2003) consists treating unique clustering solutions ensemble, can derive probability matrix. matrix contains, pair observations, probability cluster. instance, 6th 9th row dataframe assigned similar cluster 5 10 clustering methods, probability grouped together 0.5.","code":""},{"path":"https://easystats.github.io/parameters/reference/cluster_meta.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Metaclustering — cluster_meta","text":"","code":"cluster_meta(list_of_clusters, rownames = NULL, ...)"},{"path":"https://easystats.github.io/parameters/reference/cluster_meta.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Metaclustering — cluster_meta","text":"list_of_clusters list vectors clustering assignments various methods. rownames optional vector row.names matrix. ... Currently used.","code":""},{"path":"https://easystats.github.io/parameters/reference/cluster_meta.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Metaclustering — cluster_meta","text":"matrix containing pairwise (observation) probabilities clustered together methods.","code":""},{"path":"https://easystats.github.io/parameters/reference/cluster_meta.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Metaclustering — cluster_meta","text":"Metaclustering based hypothesis , clustering algorithm embodies different prism sees data, running infinite amount algorithms result emergence \"true\" clusters. number algorithms parameters finite, probabilistic perspective useful proxy. method interesting obvious reasons prefer one another clustering method, well investigate robust clusters different algorithms. metaclustering probability matrix can transformed dissimilarity matrix (one produced dist()) submitted instance hierarchical clustering (hclust()). See example .","code":""},{"path":"https://easystats.github.io/parameters/reference/cluster_meta.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Metaclustering — cluster_meta","text":"","code":"if (FALSE) { data <- iris[1:4]  rez1 <- cluster_analysis(data, n = 2, method = \"kmeans\") rez2 <- cluster_analysis(data, n = 3, method = \"kmeans\") rez3 <- cluster_analysis(data, n = 6, method = \"kmeans\")  list_of_clusters <- list(rez1, rez2, rez3)  m <- cluster_meta(list_of_clusters)  # Visualize matrix without reordering heatmap(m, Rowv = NA, Colv = NA, scale = \"none\") # Without reordering # Reordered heatmap heatmap(m, scale = \"none\")  # Extract 3 clusters predict(m, n = 3)  # Convert to dissimilarity d <- as.dist(abs(m - 1)) model <- hclust(d) plot(model, hang = -1) }"},{"path":"https://easystats.github.io/parameters/reference/cluster_performance.html","id":null,"dir":"Reference","previous_headings":"","what":"Performance of clustering models — cluster_performance","title":"Performance of clustering models — cluster_performance","text":"Compute performance indices clustering solutions.","code":""},{"path":"https://easystats.github.io/parameters/reference/cluster_performance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Performance of clustering models — cluster_performance","text":"","code":"cluster_performance(model, ...)  # S3 method for kmeans cluster_performance(model, ...)  # S3 method for hclust cluster_performance(model, data, clusters, ...)  # S3 method for dbscan cluster_performance(model, data, ...)  # S3 method for parameters_clusters cluster_performance(model, ...)"},{"path":"https://easystats.github.io/parameters/reference/cluster_performance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Performance of clustering models — cluster_performance","text":"model Cluster model. ... Arguments passed methods. data data.frame. clusters vector clusters assignments (must length rows data).","code":""},{"path":"https://easystats.github.io/parameters/reference/cluster_performance.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Performance of clustering models — cluster_performance","text":"","code":"# kmeans model <- kmeans(iris[1:4], 3) cluster_performance(model) #> # Indices of model performance #>  #> Sum_Squares_Total | Sum_Squares_Between | Sum_Squares_Within |    R2 #> -------------------------------------------------------------------- #> 681.371           |             602.519 |             78.851 | 0.884 # hclust data <- iris[1:4] model <- hclust(dist(data)) clusters <- cutree(model, 3)  rez <- cluster_performance(model, data, clusters) rez #> # Indices of model performance #>  #> Sum_Squares_Total | Sum_Squares_Between | Sum_Squares_Within |    R2 #> -------------------------------------------------------------------- #> 681.371           |             591.846 |             89.525 | 0.869 # DBSCAN if (require(\"dbscan\", quietly = TRUE)) {   model <- dbscan::dbscan(iris[1:4], eps = 1.45, minPts = 10)    rez <- cluster_performance(model, iris[1:4])   rez } #> # Indices of model performance #>  #> Sum_Squares_Total | Sum_Squares_Between | Sum_Squares_Within |    R2 #> -------------------------------------------------------------------- #> 681.371           |             526.424 |            154.947 | 0.773 # Retrieve performance from parameters params <- model_parameters(kmeans(iris[1:4], 3)) cluster_performance(params) #> # Indices of model performance #>  #> Sum_Squares_Total | Sum_Squares_Between | Sum_Squares_Within |    R2 #> -------------------------------------------------------------------- #> 681.371           |             602.519 |             78.851 | 0.884"},{"path":"https://easystats.github.io/parameters/reference/compare_parameters.html","id":null,"dir":"Reference","previous_headings":"","what":"Compare model parameters of multiple models — compare_parameters","title":"Compare model parameters of multiple models — compare_parameters","text":"Compute extract model parameters multiple regression models. See model_parameters() details.","code":""},{"path":"https://easystats.github.io/parameters/reference/compare_parameters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compare model parameters of multiple models — compare_parameters","text":"","code":"compare_parameters(   ...,   ci = 0.95,   effects = \"fixed\",   component = \"conditional\",   standardize = NULL,   exponentiate = FALSE,   ci_method = \"wald\",   p_adjust = NULL,   style = NULL,   column_names = NULL,   keep = NULL,   drop = NULL,   verbose = TRUE,   df_method = ci_method )  compare_models(   ...,   ci = 0.95,   effects = \"fixed\",   component = \"conditional\",   standardize = NULL,   exponentiate = FALSE,   ci_method = \"wald\",   p_adjust = NULL,   style = NULL,   column_names = NULL,   keep = NULL,   drop = NULL,   verbose = TRUE,   df_method = ci_method )"},{"path":"https://easystats.github.io/parameters/reference/compare_parameters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compare model parameters of multiple models — compare_parameters","text":"... One regression model objects, objects returned model_parameters(). Regression models may different model types. Model objects may passed comma separated, list. model objects passed names list named elements, names used column names. ci Confidence Interval (CI) level. Default 0.95 (95%). effects parameters fixed effects (\"fixed\"), random effects (\"random\"), (\"\") returned? applies mixed models. May abbreviated. calculation random effects parameters takes long, may use effects = \"fixed\". component Model component parameters shown. See documentation related model class model_parameters(). standardize method used standardizing parameters. Can NULL (default; standardization), \"refit\" (re-fitting model standardized data) one \"basic\", \"posthoc\", \"smart\", \"pseudo\". See 'Details' standardize_parameters(). Important: \"refit\" method standardized categorical predictors (.e. factors), may different behaviour compared R packages (lm.beta) software packages (like SPSS). mimic behaviours, either use standardize=\"basic\" standardize data datawizard::standardize(force=TRUE) fitting model. mixed models, using methods \"refit\", fixed effects returned. Robust estimation (.e., vcov set value NULL) standardized parameters works standardize=\"refit\". exponentiate Logical, indicating whether exponentiate coefficients (related confidence intervals). typical logistic regression, generally speaking, models log logit links. also recommended use exponentiate = TRUE models log-transformed response values. Note: Delta-method standard errors also computed (multiplying standard errors transformed coefficients). mimic behaviour software packages, Stata, standard errors poorly estimate uncertainty transformed coefficient. transformed confidence interval clearly captures uncertainty. compare_parameters(), exponentiate = \"nongaussian\" exponentiate coefficients non-Gaussian families. ci_method Method computing degrees freedom p-values confidence intervals (CI). See documentation related model class model_parameters(). p_adjust Character vector, NULL, indicates method adjust p-values. See stats::p.adjust() details. possible adjustment methods \"tukey\", \"scheffe\", \"sidak\" \"none\" explicitly disable adjustment emmGrid objects (emmeans). style String, indicating style output requested. Following templates possible: \"ci\": Estimate confidence intervals, asterisks p-values. \"se\": Estimate standard errors, asterisks p-values. \"ci_p\": Estimate, confidence intervals asterisks p-values. \"se_p\": Estimate, standard errors asterisks p-values. \"ci_p2\": Estimate, confidence intervals numeric p-values, two columns. \"se_p2\": Estimate, standard errors numeric p-values, two columns. column_names Character vector strings used column headers. Must length number models .... keep Character containing regular expression pattern describes parameters included (keep) excluded (drop) returned data frame. keep may also named list regular expressions. non-matching parameters removed output. keep character vector, every parameter name \"Parameter\" column matches regular expression keep selected returned data frame (vice versa, parameter names matching drop excluded). Furthermore, keep one element, merged operator regular expression pattern like : \"(one|two|three)\". keep named list regular expression patterns, names list-element equal column name selection applied. useful model objects model_parameters() returns multiple columns parameter components, like model_parameters.lavaan(). Note regular expression pattern match parameter names stored returned data frame, can different printed. Inspect $Parameter column parameters table get exact parameter names. drop See keep. verbose Toggle warnings messages. df_method Deprecated. Please use ci_method.","code":""},{"path":"https://easystats.github.io/parameters/reference/compare_parameters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compare model parameters of multiple models — compare_parameters","text":"data frame indices related model's parameters.","code":""},{"path":"https://easystats.github.io/parameters/reference/compare_parameters.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compare model parameters of multiple models — compare_parameters","text":"function early stage yet cope complex models, probably yet properly render model components. also noted including models interaction terms, values parameters change, meaning (main effects, simple slopes), thereby making comparisons hard. Therefore, use function compare models interaction terms models without interaction terms.","code":""},{"path":"https://easystats.github.io/parameters/reference/compare_parameters.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compare model parameters of multiple models — compare_parameters","text":"","code":"data(iris) lm1 <- lm(Sepal.Length ~ Species, data = iris) lm2 <- lm(Sepal.Length ~ Species + Petal.Length, data = iris) compare_parameters(lm1, lm2) #> Parameter            |               lm1 |                  lm2 #> --------------------------------------------------------------- #> (Intercept)          | 5.01 (4.86, 5.15) |  3.68 ( 3.47,  3.89) #> Species (versicolor) | 0.93 (0.73, 1.13) | -1.60 (-1.98, -1.22) #> Species (virginica)  | 1.58 (1.38, 1.79) | -2.12 (-2.66, -1.58) #> Petal Length         |                   |  0.90 ( 0.78,  1.03) #> --------------------------------------------------------------- #> Observations         |               150 |                  150  data(mtcars) m1 <- lm(mpg ~ wt, data = mtcars) m2 <- glm(vs ~ wt + cyl, data = mtcars, family = \"binomial\") compare_parameters(m1, m2) #> Parameter    |                   m1 |                   m2 #> ---------------------------------------------------------- #> (Intercept)  | 37.29 (33.45, 41.12) | 10.62 ( 2.45, 18.79) #> wt           | -5.34 (-6.49, -4.20) |  2.10 (-0.93,  5.13) #> cyl          |                      | -2.93 (-5.63, -0.23) #> ---------------------------------------------------------- #> Observations |                   32 |                   32 if (FALSE) { # exponentiate coefficients, but not for lm compare_parameters(m1, m2, exponentiate = \"nongaussian\")  # change column names compare_parameters(\"linear model\" = m1, \"logistic reg.\" = m2) compare_parameters(m1, m2, column_names = c(\"linear model\", \"logistic reg.\"))  # or as list compare_parameters(list(m1, m2)) compare_parameters(list(\"linear model\" = m1, \"logistic reg.\" = m2)) }"},{"path":"https://easystats.github.io/parameters/reference/convert_efa_to_cfa.html","id":null,"dir":"Reference","previous_headings":"","what":"Conversion between EFA results and CFA structure — convert_efa_to_cfa","title":"Conversion between EFA results and CFA structure — convert_efa_to_cfa","text":"Enables conversion Exploratory Factor Analysis (EFA) Confirmatory Factor Analysis (CFA) lavaan-ready structure.","code":""},{"path":"https://easystats.github.io/parameters/reference/convert_efa_to_cfa.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conversion between EFA results and CFA structure — convert_efa_to_cfa","text":"","code":"convert_efa_to_cfa(model, ...)  # S3 method for fa convert_efa_to_cfa(model, threshold = \"max\", names = NULL, ...)  efa_to_cfa(model, ...)"},{"path":"https://easystats.github.io/parameters/reference/convert_efa_to_cfa.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conversion between EFA results and CFA structure — convert_efa_to_cfa","text":"model EFA model (e.g., psych::fa object). ... Arguments passed methods. threshold value 0 1 indicates (absolute) values loadings removed. integer higher 1 indicates n strongest loadings retain. Can also \"max\", case display maximum loading per variable (simple structure). names Vector containing dimension names.","code":""},{"path":"https://easystats.github.io/parameters/reference/convert_efa_to_cfa.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Conversion between EFA results and CFA structure — convert_efa_to_cfa","text":"Converted index.","code":""},{"path":"https://easystats.github.io/parameters/reference/convert_efa_to_cfa.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conversion between EFA results and CFA structure — convert_efa_to_cfa","text":"","code":"# \\donttest{ library(parameters) if (require(\"psych\") && require(\"lavaan\")) {   efa <- psych::fa(attitude, nfactors = 3)    model1 <- efa_to_cfa(efa)   model2 <- efa_to_cfa(efa, threshold = 0.3)    anova(     lavaan::cfa(model1, data = attitude),     lavaan::cfa(model2, data = attitude)   ) } #> Loading required package: psych #>  #> Attaching package: ‘psych’ #> The following object is masked from ‘package:mclust’: #>  #>     sim #> The following objects are masked from ‘package:ggplot2’: #>  #>     %+%, alpha #> Loading required package: lavaan #> This is lavaan 0.6-12 #> lavaan is FREE software! Please report any bugs. #>  #> Attaching package: ‘lavaan’ #> The following object is masked from ‘package:psych’: #>  #>     cor2cov #> Loading required namespace: GPArotation #> Warning: lavaan WARNING: some estimated ov variances are negative #> Chi-Squared Difference Test #>  #>                                      Df    AIC    BIC   Chisq Chisq diff #> lavaan::cfa(model2, data = attitude) 10 1540.5 1565.7  9.1827            #> lavaan::cfa(model1, data = attitude) 12 1549.8 1572.2 22.4374     13.255 #>                                      Df diff Pr(>Chisq)    #> lavaan::cfa(model2, data = attitude)                       #> lavaan::cfa(model1, data = attitude)       2   0.001324 ** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 # }"},{"path":"https://easystats.github.io/parameters/reference/degrees_of_freedom.html","id":null,"dir":"Reference","previous_headings":"","what":"Degrees of Freedom (DoF) — degrees_of_freedom","title":"Degrees of Freedom (DoF) — degrees_of_freedom","text":"Estimate extract degrees freedom models parameters.","code":""},{"path":"https://easystats.github.io/parameters/reference/degrees_of_freedom.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Degrees of Freedom (DoF) — degrees_of_freedom","text":"","code":"degrees_of_freedom(model, ...)  # S3 method for default degrees_of_freedom(model, method = \"analytical\", ...)  dof(model, ...)"},{"path":"https://easystats.github.io/parameters/reference/degrees_of_freedom.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Degrees of Freedom (DoF) — degrees_of_freedom","text":"model statistical model. ... Currently used. method Can \"analytical\" (default, DoFs estimated based model type), \"residual\" case directly taken model available (Bayesian models, goal (looking help make happen) refit model frequentist one extracting DoFs), \"ml1\" (see dof_ml1()), \"betwithin\" (see dof_betwithin()), \"satterthwaite\" (see dof_satterthwaite()), \"kenward\" (see dof_kenward()) \"\", tries extract DoF methods, whichever succeeds. See 'Details'.","code":""},{"path":"https://easystats.github.io/parameters/reference/degrees_of_freedom.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Degrees of Freedom (DoF) — degrees_of_freedom","text":"Methods calculating degrees freedom: \"analytical\" models class lmerMod, Kenward-Roger approximated degrees freedoms calculated, models, n-k (number observations minus number parameters). \"residual\" tries extract residual degrees freedom, returns Inf residual degrees freedom extracted. \"\" first tries extract residual degrees freedom, available, extracts analytical degrees freedom. \"nokr\" \"analytical\", Kenward-Roger approximation models class lmerMod. Instead, always uses n-k calculate df model. \"normal\" returns Inf. \"wald\" returns residual df models t-statistic, Inf models. \"kenward\" calls dof_kenward(). \"satterthwaite\" calls dof_satterthwaite(). \"ml1\" calls dof_ml1(). \"betwithin\" calls dof_betwithin(). models z-statistic, returned degrees freedom model parameters Inf (unless method = \"ml1\" method = \"betwithin\"), one distribution related test statistic.","code":""},{"path":"https://easystats.github.io/parameters/reference/degrees_of_freedom.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Degrees of Freedom (DoF) — degrees_of_freedom","text":"many cases, degrees_of_freedom() returns df.residuals(), n-k (number observations minus number parameters). However, degrees_of_freedom() refers model's parameters degrees freedom distribution related test statistic. Thus, models z-statistic, results degrees_of_freedom() df.residuals() differ. Furthermore, approximation methods like \"kenward\" \"satterthwaite\", model parameter can different degree freedom.","code":""},{"path":"https://easystats.github.io/parameters/reference/degrees_of_freedom.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Degrees of Freedom (DoF) — degrees_of_freedom","text":"","code":"model <- lm(Sepal.Length ~ Petal.Length * Species, data = iris) dof(model) #> [1] 144 144 144 144 144 144  model <- glm(vs ~ mpg * cyl, data = mtcars, family = \"binomial\") dof(model) #> [1] Inf if (FALSE) { if (require(\"lme4\", quietly = TRUE)) {   model <- lmer(Sepal.Length ~ Petal.Length + (1 | Species), data = iris)   dof(model) }  if (require(\"rstanarm\", quietly = TRUE)) {   model <- stan_glm(     Sepal.Length ~ Petal.Length * Species,     data = iris,     chains = 2,     refresh = 0   )   dof(model) } }"},{"path":"https://easystats.github.io/parameters/reference/display.parameters_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Print tables in different output formats — display.parameters_model","title":"Print tables in different output formats — display.parameters_model","text":"Prints tables (.e. data frame) different output formats. print_md() alias display(format = \"markdown\").","code":""},{"path":"https://easystats.github.io/parameters/reference/display.parameters_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print tables in different output formats — display.parameters_model","text":"","code":"# S3 method for parameters_model display(   object,   format = \"markdown\",   pretty_names = TRUE,   split_components = TRUE,   select = NULL,   caption = NULL,   subtitle = NULL,   footer = NULL,   align = NULL,   digits = 2,   ci_digits = 2,   p_digits = 3,   footer_digits = 3,   ci_brackets = c(\"(\", \")\"),   show_sigma = FALSE,   show_formula = FALSE,   zap_small = FALSE,   verbose = TRUE,   ... )  # S3 method for parameters_sem display(   object,   format = \"markdown\",   digits = 2,   ci_digits = 2,   p_digits = 3,   ci_brackets = c(\"(\", \")\"),   ... )  # S3 method for parameters_efa_summary display(object, format = \"markdown\", digits = 3, ...)  # S3 method for parameters_efa display(   object,   format = \"markdown\",   digits = 2,   sort = FALSE,   threshold = NULL,   labels = NULL,   ... )  # S3 method for equivalence_test_lm display(object, format = \"markdown\", digits = 2, ...)  # S3 method for parameters_model format(   x,   pretty_names = TRUE,   split_components = TRUE,   select = NULL,   digits = 2,   ci_digits = 2,   p_digits = 3,   ci_width = NULL,   ci_brackets = NULL,   zap_small = FALSE,   format = NULL,   groups = NULL,   ... )  # S3 method for parameters_model print_html(   x,   pretty_names = TRUE,   split_components = TRUE,   select = NULL,   caption = NULL,   subtitle = NULL,   footer = NULL,   align = NULL,   digits = 2,   ci_digits = 2,   p_digits = 3,   footer_digits = 3,   ci_brackets = c(\"(\", \")\"),   show_sigma = FALSE,   show_formula = FALSE,   zap_small = FALSE,   groups = NULL,   verbose = TRUE,   ... )  # S3 method for parameters_model print_md(   x,   pretty_names = TRUE,   split_components = TRUE,   select = NULL,   caption = NULL,   subtitle = NULL,   footer = NULL,   align = NULL,   digits = 2,   ci_digits = 2,   p_digits = 3,   footer_digits = 3,   ci_brackets = c(\"(\", \")\"),   show_sigma = FALSE,   show_formula = FALSE,   zap_small = FALSE,   groups = NULL,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/parameters/reference/display.parameters_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print tables in different output formats — display.parameters_model","text":"object object returned model_parameters(), simulate_parameters(), equivalence_test() principal_components(). format String, indicating output format. Can \"markdown\" \"html\". pretty_names Return \"pretty\" (.e. human readable) parameter names. split_components Logical, TRUE (default), models multiple components (zero-inflation, smooth terms, ...), component printed separate table. FALSE, model parameters printed single table Component column added output. select Character vector (numeric index) column names printed. NULL (default), columns printed. shortcut select = \"minimal\" prints coefficient, confidence intervals p-values, select = \"short\" prints coefficient, standard errors p-values. caption Table caption string. NULL, table caption printed. subtitle Table title (caption) subtitle, strings. NULL, title subtitle printed, unless stored attributes (table_title, alias table_caption, table_subtitle). x list data frames, caption may list table captions, one table. footer Table footer, string. markdown-formatted tables, table footers, due limitation markdown rendering, actually just new text line table. x list data frames, footer may list table captions, one table. align applies HTML tables. May one \"left\", \"right\" \"center\". digits, ci_digits, p_digits Number digits rounding significant figures. May also \"signif\" return significant figures \"scientific\" return scientific notation. Control number digits adding value suffix, e.g. digits = \"scientific4\" scientific notation 4 decimal places, digits = \"signif5\" 5 significant figures (see also signif()). footer_digits Number decimal places values footer summary. ci_brackets Logical, TRUE (default), CI-values encompassed square brackets (else parentheses). show_sigma Logical, TRUE, adds information residual standard deviation. show_formula Logical, TRUE, adds model formula output. zap_small Logical, TRUE, small values rounded digits decimal places. FALSE, values decimal places digits printed scientific notation. verbose Toggle messages warnings. ... Arguments passed methods. sort Sort loadings. threshold value 0 1 indicates (absolute) values loadings removed. integer higher 1 indicates n strongest loadings retain. Can also \"max\", case display maximum loading per variable (simple structure). labels character vector containing labels added loadings data. Usually, question related item. x object returned model_parameters(). ci_width Minimum width returned string confidence intervals. NULL width larger string's length, leading whitespaces added string. width=\"auto\", width set length longest string. groups Named list, can used group parameters printed output. List elements may either character vectors match name parameters belong one group, list elements can row numbers parameter rows belong one group. names list elements used group names, inserted \"header row\". possible use case might emphasize focal predictors control variables, see 'Examples'. Parameters re-ordered according order used groups, non-matching parameters added end.","code":""},{"path":"https://easystats.github.io/parameters/reference/display.parameters_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print tables in different output formats — display.parameters_model","text":"format = \"markdown\", return value character vector markdown-table format. format = \"html\", object class gt_tbl.","code":""},{"path":"https://easystats.github.io/parameters/reference/display.parameters_model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Print tables in different output formats — display.parameters_model","text":"display() useful table-output functions, usually printed formatted text-table console, formatted pretty table-rendering markdown documents, knitted rmarkdown PDF Word files. See vignette examples.","code":""},{"path":"https://easystats.github.io/parameters/reference/display.parameters_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print tables in different output formats — display.parameters_model","text":"","code":"model <- lm(mpg ~ wt + cyl, data = mtcars) mp <- model_parameters(model) display(mp) #>  #>  #> |Parameter   | Coefficient |   SE |         95% CI | t(29) |      p | #> |:-----------|:-----------:|:----:|:--------------:|:-----:|:------:| #> |(Intercept) |       39.69 | 1.71 | (36.18, 43.19) | 23.14 | < .001 | #> |wt          |       -3.19 | 0.76 | (-4.74, -1.64) | -4.22 | < .001 | #> |cyl         |       -1.51 | 0.41 | (-2.36, -0.66) | -3.64 | 0.001  |"},{"path":"https://easystats.github.io/parameters/reference/dominance_analysis.html","id":null,"dir":"Reference","previous_headings":"","what":"Dominance Analysis — dominance_analysis","title":"Dominance Analysis — dominance_analysis","text":"Computes Dominance Analysis Statistics Designations","code":""},{"path":"https://easystats.github.io/parameters/reference/dominance_analysis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dominance Analysis — dominance_analysis","text":"","code":"dominance_analysis(   model,   sets = NULL,   all = NULL,   conditional = TRUE,   complete = TRUE,   quote_args = NULL,   ... )"},{"path":"https://easystats.github.io/parameters/reference/dominance_analysis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Dominance Analysis — dominance_analysis","text":"model model object supported performance::r2(). See 'Details'. sets (named) list formula objects left hand side/response.  list names, name provided element used label set.  Unnamed list elements provided set number name based position among sets entered. Predictors formula bound together set dominance analysis dominance statistics designations computed predictors together.  Predictors sets must present model submitted model argument argument. formula left hand side/response. Predictors formula included subset dominance analysis R2 value associated subtracted overall value.  Predictors must present model submitted model argument sets argument. conditional Logical.  FALSE conditional dominance matrix computed. conditional dominance desired importance criterion, avoiding computing conditional dominance matrix can save computation time. complete Logical.  FALSE complete dominance matrix computed. complete dominance desired importance criterion, avoiding computing complete dominance designations can save computation time. quote_args character vector arguments model submitted model quote() prior submitting dominance analysis.  necessary data masked arguments (e.g., weights) prevent evaluated applied model causing error. ... used current.","code":""},{"path":"https://easystats.github.io/parameters/reference/dominance_analysis.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Dominance Analysis — dominance_analysis","text":"Object class \"parameters_da\". object class \"parameters_da\" list data.frames composed following elements: General data.frame associates dominance statistics model parameters. variables data.frame include: Parameter Parameter names. General_Dominance Vector general dominance statistics. R2 ascribed variables argument also reported though general dominance statistics. Percent Vector general dominance statistics normalized sum 1. Ranks Vector ranks applied general dominance statistics. Subset Names subset parameter belongs dominance analysis.  data.frame returned refer subset names. Conditional data.frame conditional dominance statistics.  observation represents subset variable represents average increment R2 specific number subsets model.  NULL conditional argument FALSE. Complete data.frame complete dominance designations. subsets observations compared subsets referenced variable. Whether subset variable dominates subset observation represented  logical value. NULL complete argument FALSE..","code":""},{"path":"https://easystats.github.io/parameters/reference/dominance_analysis.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Dominance Analysis — dominance_analysis","text":"Computes two decompositions model's R2 returns matrix designations predictor relative importance determinations can obtained. Note output \"constant\" subset associated component model directly contribute R2 intercept. \"\" subset apportioned component fit statistic considered part dominance analysis therefore receive rank, conditional dominance statistics, complete dominance designations. input model parsed using insight::find_predictors(), yet support interactions, transformations, offsets applied R formula, fail error terms detected. model submitted must accept formula object formula argument.  addition, model object must accept data model estimated data argument.  Formulas submitted using object references (.e., lm(mtcars$mpg ~ mtcars$vs)) functions accept data non-data argument (e.g., survey::svyglm() uses design) fail error. Models return TRUE insight::model_info() function's values \"is_bayesian\", \"is_mixed\", \"is_gam\", is_multivariate\", \"is_zero_inflated\", \"is_hurdle\" supported current. performance::r2() returns multiple values, first used default. underlying domir::domin() function implements dominance statistic designation computations tested R version 3.5 fail error called R versions < 3.5.","code":""},{"path":"https://easystats.github.io/parameters/reference/dominance_analysis.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Dominance Analysis — dominance_analysis","text":"Azen, R., & Budescu, D. V. (2003). dominance analysis approach comparing predictors multiple regression. Psychological Methods, 8(2), 129-148. doi:10.1037/1082-989X.8.2.129 Budescu, D. V. (1993). Dominance analysis: new approach problem relative importance predictors multiple regression. Psychological Bulletin, 114(3), 542-551. doi:10.1037/0033-2909.114.3.542 Groemping, U. (2007). Estimators relative importance linear regression based variance decomposition. American Statistician, 61(2), 139-147. doi:10.1198/000313007X188252","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/dominance_analysis.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Dominance Analysis — dominance_analysis","text":"Joseph Luchman","code":""},{"path":"https://easystats.github.io/parameters/reference/dominance_analysis.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Dominance Analysis — dominance_analysis","text":"","code":"if (getRversion() >= \"3.5.0\" && require(\"domir\") &&   require(\"performance\")) {   data(mtcars)    # Dominance Analysis with Logit Regression   model <- glm(vs ~ cyl + carb + mpg, data = mtcars, family = binomial())    performance::r2(model)   dominance_analysis(model)    # Dominance Analysis with Weighted Logit Regression   model_wt <- glm(vs ~ cyl + carb + mpg,     data = mtcars,     weights = wt, family = binomial()   )    dominance_analysis(model_wt, quote_args = \"weights\") } #> Loading required package: domir #> Loading required package: performance #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> # Dominance Analysis Results #>  #> Model R2 Value:  0.776  #>  #> General Dominance Statistics #>  #> Parameter   | General Dominance | Percent | Ranks |   Subset #> ------------------------------------------------------------ #> (Intercept) |                   |         |       | constant #> cyl         |             0.390 |   0.503 |     1 |      cyl #> carb        |             0.174 |   0.224 |     3 |     carb #> mpg         |             0.212 |   0.273 |     2 |      mpg #>  #> Conditional Dominance Statistics #>  #> Subset | IVs: 1 | IVs: 2 | IVs: 3 #> --------------------------------- #> cyl    |  0.679 |  0.279 |  0.213 #> carb   |  0.376 |  0.062 |  0.083 #> mpg    |  0.496 |  0.100 |  0.039 #>  #> Complete Dominance Designations #>  #> Subset | < cyl | < carb | < mpg #> ------------------------------- #> cyl    |       |  FALSE | FALSE #> carb   |  TRUE |        |       #> mpg    |  TRUE |        |"},{"path":"https://easystats.github.io/parameters/reference/dot-data_frame.html","id":null,"dir":"Reference","previous_headings":"","what":"help-functions — .data_frame","title":"help-functions — .data_frame","text":"help-functions","code":""},{"path":"https://easystats.github.io/parameters/reference/dot-data_frame.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"help-functions — .data_frame","text":"","code":".data_frame(...)"},{"path":"https://easystats.github.io/parameters/reference/dot-factor_to_dummy.html","id":null,"dir":"Reference","previous_headings":"","what":"Safe transformation from factor/character to numeric — .factor_to_dummy","title":"Safe transformation from factor/character to numeric — .factor_to_dummy","text":"Safe transformation factor/character numeric","code":""},{"path":"https://easystats.github.io/parameters/reference/dot-factor_to_dummy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Safe transformation from factor/character to numeric — .factor_to_dummy","text":"","code":".factor_to_dummy(x)"},{"path":"https://easystats.github.io/parameters/reference/dot-filter_component.html","id":null,"dir":"Reference","previous_headings":"","what":"for models with zero-inflation component, return required component of model-summary — .filter_component","title":"for models with zero-inflation component, return required component of model-summary — .filter_component","text":"models zero-inflation component, return required component model-summary","code":""},{"path":"https://easystats.github.io/parameters/reference/dot-filter_component.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"for models with zero-inflation component, return required component of model-summary — .filter_component","text":"","code":".filter_component(dat, component)"},{"path":"https://easystats.github.io/parameters/reference/dot-n_factors_bartlett.html","id":null,"dir":"Reference","previous_headings":"","what":"Bartlett, Anderson and Lawley Procedures — .n_factors_bartlett","title":"Bartlett, Anderson and Lawley Procedures — .n_factors_bartlett","text":"Bartlett, Anderson Lawley Procedures","code":""},{"path":"https://easystats.github.io/parameters/reference/dot-n_factors_bartlett.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bartlett, Anderson and Lawley Procedures — .n_factors_bartlett","text":"","code":".n_factors_bartlett(eigen_values = NULL, model = \"factors\", nobs = NULL)"},{"path":"https://easystats.github.io/parameters/reference/dot-n_factors_bentler.html","id":null,"dir":"Reference","previous_headings":"","what":"Bentler and Yuan's Procedure — .n_factors_bentler","title":"Bentler and Yuan's Procedure — .n_factors_bentler","text":"Bentler Yuan's Procedure","code":""},{"path":"https://easystats.github.io/parameters/reference/dot-n_factors_bentler.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bentler and Yuan's Procedure — .n_factors_bentler","text":"","code":".n_factors_bentler(eigen_values = NULL, model = \"factors\", nobs = NULL)"},{"path":"https://easystats.github.io/parameters/reference/dot-n_factors_cng.html","id":null,"dir":"Reference","previous_headings":"","what":"Cattell-Nelson-Gorsuch CNG Indices — .n_factors_cng","title":"Cattell-Nelson-Gorsuch CNG Indices — .n_factors_cng","text":"Cattell-Nelson-Gorsuch CNG Indices","code":""},{"path":"https://easystats.github.io/parameters/reference/dot-n_factors_cng.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cattell-Nelson-Gorsuch CNG Indices — .n_factors_cng","text":"","code":".n_factors_cng(eigen_values = NULL, model = \"factors\")"},{"path":"https://easystats.github.io/parameters/reference/dot-n_factors_mreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Multiple Regression Procedure — .n_factors_mreg","title":"Multiple Regression Procedure — .n_factors_mreg","text":"Multiple Regression Procedure","code":""},{"path":"https://easystats.github.io/parameters/reference/dot-n_factors_mreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multiple Regression Procedure — .n_factors_mreg","text":"","code":".n_factors_mreg(eigen_values = NULL, model = \"factors\")"},{"path":"https://easystats.github.io/parameters/reference/dot-n_factors_scree.html","id":null,"dir":"Reference","previous_headings":"","what":"Non Graphical Cattell's Scree Test — .n_factors_scree","title":"Non Graphical Cattell's Scree Test — .n_factors_scree","text":"Non Graphical Cattell's Scree Test","code":""},{"path":"https://easystats.github.io/parameters/reference/dot-n_factors_scree.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Non Graphical Cattell's Scree Test — .n_factors_scree","text":"","code":".n_factors_scree(eigen_values = NULL, model = \"factors\")"},{"path":"https://easystats.github.io/parameters/reference/dot-n_factors_sescree.html","id":null,"dir":"Reference","previous_headings":"","what":"Standard Error Scree and Coefficient of Determination Procedures — .n_factors_sescree","title":"Standard Error Scree and Coefficient of Determination Procedures — .n_factors_sescree","text":"Standard Error Scree Coefficient Determination Procedures","code":""},{"path":"https://easystats.github.io/parameters/reference/dot-n_factors_sescree.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Standard Error Scree and Coefficient of Determination Procedures — .n_factors_sescree","text":"","code":".n_factors_sescree(eigen_values = NULL, model = \"factors\")"},{"path":"https://easystats.github.io/parameters/reference/equivalence_test.lm.html","id":null,"dir":"Reference","previous_headings":"","what":"Equivalence test — equivalence_test.lm","title":"Equivalence test — equivalence_test.lm","text":"Compute (conditional) equivalence test frequentist models.","code":""},{"path":"https://easystats.github.io/parameters/reference/equivalence_test.lm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Equivalence test — equivalence_test.lm","text":"","code":"# S3 method for lm equivalence_test(   x,   range = \"default\",   ci = 0.95,   rule = \"classic\",   verbose = TRUE,   ... )  # S3 method for merMod equivalence_test(   x,   range = \"default\",   ci = 0.95,   rule = \"classic\",   effects = c(\"fixed\", \"random\"),   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/parameters/reference/equivalence_test.lm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Equivalence test — equivalence_test.lm","text":"x statistical model. range range practical equivalence effect. May \"default\", automatically define range based properties model's data. ci Confidence Interval (CI) level. Default 0.95 (95%). rule Character, indicating rules testing practical equivalence. Can \"bayes\", \"classic\" \"cet\". See 'Details'. verbose Toggle warnings messages. ... Arguments passed methods. effects parameters fixed effects (\"fixed\"), random effects (\"random\"), (\"\") returned? applies mixed models. May abbreviated. calculation random effects parameters takes long, may use effects = \"fixed\".","code":""},{"path":"https://easystats.github.io/parameters/reference/equivalence_test.lm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Equivalence test — equivalence_test.lm","text":"data frame.","code":""},{"path":"https://easystats.github.io/parameters/reference/equivalence_test.lm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Equivalence test — equivalence_test.lm","text":"classical null hypothesis significance testing (NHST) within frequentist framework, possible accept null hypothesis, H0 - unlike Bayesian statistics, probability statements possible. “... one can reject null hypothesis test statistics falls critical region(s), fail reject hypothesis. latter case, can say significant effect observed, one conclude null hypothesis true.” (Pernet 2017). One way address issues without Bayesian methods Equivalence Testing, implemented equivalence_test(). either can reject null hypothesis claim inconclusive result NHST, equivalence test adds third category, \"accept\". Roughly speaking, idea behind equivalence testing frequentist framework check whether estimate uncertainty (.e. confidence interval) falls within region \"practical equivalence\". Depending rule test (see ), statistical significance necessarily indicate whether null hypothesis can rejected , .e. classical interpretation p-value may differ results returned equivalence test.","code":""},{"path":"https://easystats.github.io/parameters/reference/equivalence_test.lm.html","id":"calculation-of-equivalence-testing","dir":"Reference","previous_headings":"","what":"Calculation of equivalence testing","title":"Equivalence test — equivalence_test.lm","text":"\"bayes\" - Bayesian rule (Kruschke 2018) rule follows “HDI+ROPE decision rule” (Kruschke, 2014, 2018) used Bayesian counterpart(). means, confidence intervals completely outside ROPE, \"null hypothesis\" parameter \"rejected\". ROPE completely covers CI, null hypothesis accepted. Else, undecided whether accept reject null hypothesis. Desirable results low proportions inside ROPE (closer zero better). \"classic\" - TOST rule (Lakens 2017) rule follows “TOST rule”, .e. two one-sided test procedure (Lakens 2017). Following rule, practical equivalence effect (.e. H0) rejected, coefficient statistically significant narrow confidence intervals (.e. 1-2*alpha) include exceed ROPE boundaries. Practical equivalence assumed (.e. H0 accepted) narrow confidence intervals completely inside ROPE, matter effect statistically significant . Else, decision whether accept reject H0 undecided. \"cet\" - Conditional Equivalence Testing (Campbell/Gustafson 2018) Conditional Equivalence Testing described Campbell Gustafson 2018. According rule, practical equivalence rejected coefficient statistically significant. effect significant narrow confidence intervals completely inside ROPE, accept H0, else undecided.","code":""},{"path":"https://easystats.github.io/parameters/reference/equivalence_test.lm.html","id":"levels-of-confidence-intervals-used-for-equivalence-testing","dir":"Reference","previous_headings":"","what":"Levels of Confidence Intervals used for Equivalence Testing","title":"Equivalence test — equivalence_test.lm","text":"rule = \"classic\", \"narrow\" confidence intervals used equivalence testing. \"Narrow\" means, intervals 1 - alpha, 1 - 2 * alpha. Thus, ci = .95, alpha assumed 0.05 internally ci-level 0.90 used. rule = \"cet\" uses regular narrow confidence intervals, rule = \"bayes\" uses regular intervals.","code":""},{"path":"https://easystats.github.io/parameters/reference/equivalence_test.lm.html","id":"p-values","dir":"Reference","previous_headings":"","what":"p-Values","title":"Equivalence test — equivalence_test.lm","text":"equivalence p-value area (cumulative) confidence distribution outside region equivalence. can interpreted p-value rejecting alternative hypothesis accepting null hypothesis.","code":""},{"path":"https://easystats.github.io/parameters/reference/equivalence_test.lm.html","id":"second-generation-p-value-sgpv-","dir":"Reference","previous_headings":"","what":"Second Generation p-Value (SGPV)","title":"Equivalence test — equivalence_test.lm","text":"Second generation p-values (SGPV) proposed statistic represents “proportion data-supported hypotheses also null hypotheses” (Blume et al. 2018). statistic actually computed way percentage inside ROPE returned equivalence_test() (see Lakens Delacre 2020 details computation SGPV). Thus, \"inside ROPE\" column reflects SGPV.","code":""},{"path":"https://easystats.github.io/parameters/reference/equivalence_test.lm.html","id":"rope-range","dir":"Reference","previous_headings":"","what":"ROPE range","title":"Equivalence test — equivalence_test.lm","text":"attention required finding suitable values ROPE limits (argument range). See 'Details' bayestestR::rope_range() information.","code":""},{"path":"https://easystats.github.io/parameters/reference/equivalence_test.lm.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Equivalence test — equivalence_test.lm","text":"also plot()-method implemented see-package.","code":""},{"path":"https://easystats.github.io/parameters/reference/equivalence_test.lm.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Equivalence test — equivalence_test.lm","text":"Blume, J. D., D'Agostino McGowan, L., Dupont, W. D., & Greevy, R. . (2018). Second-generation p-values: Improved rigor, reproducibility, & transparency statistical analyses. PLOS ONE, 13(3), e0188299. https://doi.org/10.1371/journal.pone.0188299 Campbell, H., & Gustafson, P. (2018). Conditional equivalence testing: alternative remedy publication bias. PLOS ONE, 13(4), e0195145. doi: 10.1371/journal.pone.0195145 Kruschke, J. K. (2014). Bayesian data analysis: tutorial R, JAGS, Stan. Academic Press Kruschke, J. K. (2018). Rejecting accepting parameter values Bayesian estimation. Advances Methods Practices Psychological Science, 1(2), 270-280. doi: 10.1177/2515245918771304 Lakens, D. (2017). Equivalence Tests: Practical Primer t Tests, Correlations, Meta-Analyses. Social Psychological Personality Science, 8(4), 355–362. doi: 10.1177/1948550617697177 Lakens, D., & Delacre, M. (2020). Equivalence Testing Second Generation P-Value. Meta-Psychology, 4. https://doi.org/10.15626/MP.2018.933 Pernet, C. (2017). Null hypothesis significance testing: guide commonly misunderstood concepts recommendations good practice. F1000Research, 4, 621. doi: 10.12688/f1000research.6963.5","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/equivalence_test.lm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Equivalence test — equivalence_test.lm","text":"","code":"data(qol_cancer) model <- lm(QoL ~ time + age + education, data = qol_cancer)  # default rule equivalence_test(model) #> # TOST-test for Practical Equivalence #>  #>   ROPE: [-1.99 1.99] #>  #> Parameter        |         90% CI | % in ROPE |        H0 |      p #> ------------------------------------------------------------------ #> (Intercept)      | [59.33, 68.41] |        0% |  Rejected | > .999 #> time             | [-0.76,  2.53] |    83.52% | Undecided | 0.137  #> age              | [-0.26,  0.32] |      100% |  Accepted | < .001 #> education [mid]  | [ 5.13, 12.39] |        0% |  Rejected | 0.999  #> education [high] | [10.14, 18.57] |        0% |  Rejected | > .999  # conditional equivalence test equivalence_test(model, rule = \"cet\") #> # Conditional Equivalence Testing #>  #>   ROPE: [-1.99 1.99] #>  #> Parameter        |         90% CI | % in ROPE |        H0 |      p #> ------------------------------------------------------------------ #> (Intercept)      | [59.33, 68.41] |        0% |  Rejected | > .999 #> time             | [-0.76,  2.53] |    83.52% | Undecided | 0.137  #> age              | [-0.26,  0.32] |      100% |  Accepted | < .001 #> education [mid]  | [ 5.13, 12.39] |        0% |  Rejected | 0.999  #> education [high] | [10.14, 18.57] |        0% |  Rejected | > .999  # plot method if (require(\"see\", quietly = TRUE)) {   result <- equivalence_test(model)   plot(result) }"},{"path":"https://easystats.github.io/parameters/reference/fish.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample data set — fish","title":"Sample data set — fish","text":"sample data set, used tests examples.","code":""},{"path":"https://easystats.github.io/parameters/reference/format_df_adjust.html","id":null,"dir":"Reference","previous_headings":"","what":"Format the name of the degrees-of-freedom adjustment methods — format_df_adjust","title":"Format the name of the degrees-of-freedom adjustment methods — format_df_adjust","text":"Format name degrees--freedom adjustment methods.","code":""},{"path":"https://easystats.github.io/parameters/reference/format_df_adjust.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Format the name of the degrees-of-freedom adjustment methods — format_df_adjust","text":"","code":"format_df_adjust(   method,   approx_string = \"-approximated\",   dof_string = \" degrees of freedom\" )"},{"path":"https://easystats.github.io/parameters/reference/format_df_adjust.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Format the name of the degrees-of-freedom adjustment methods — format_df_adjust","text":"method Name method. approx_string, dof_string Suffix added name method returned string.","code":""},{"path":"https://easystats.github.io/parameters/reference/format_df_adjust.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Format the name of the degrees-of-freedom adjustment methods — format_df_adjust","text":"formatted string.","code":""},{"path":"https://easystats.github.io/parameters/reference/format_df_adjust.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Format the name of the degrees-of-freedom adjustment methods — format_df_adjust","text":"","code":"library(parameters)  format_df_adjust(\"kenward\") #> [1] \"Kenward-Roger-approximated degrees of freedom\" format_df_adjust(\"kenward\", approx_string = \"\", dof_string = \" DoF\") #> [1] \"Kenward-Roger DoF\""},{"path":"https://easystats.github.io/parameters/reference/format_order.html","id":null,"dir":"Reference","previous_headings":"","what":"Order (first, second, ...) formatting — format_order","title":"Order (first, second, ...) formatting — format_order","text":"Format order.","code":""},{"path":"https://easystats.github.io/parameters/reference/format_order.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Order (first, second, ...) formatting — format_order","text":"","code":"format_order(order, textual = TRUE, ...)"},{"path":"https://easystats.github.io/parameters/reference/format_order.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Order (first, second, ...) formatting — format_order","text":"order value vector orders. textual Return number words. FALSE, run insight::format_value(). ... Arguments passed insight::format_value() textual FALSE.","code":""},{"path":"https://easystats.github.io/parameters/reference/format_order.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Order (first, second, ...) formatting — format_order","text":"formatted string.","code":""},{"path":"https://easystats.github.io/parameters/reference/format_order.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Order (first, second, ...) formatting — format_order","text":"","code":"format_order(2) #> [1] \"second\" format_order(8) #> [1] \"eigth\" format_order(25, textual = FALSE) #> [1] \"25th\""},{"path":"https://easystats.github.io/parameters/reference/format_p_adjust.html","id":null,"dir":"Reference","previous_headings":"","what":"Format the name of the p-value adjustment methods — format_p_adjust","title":"Format the name of the p-value adjustment methods — format_p_adjust","text":"Format name p-value adjustment methods.","code":""},{"path":"https://easystats.github.io/parameters/reference/format_p_adjust.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Format the name of the p-value adjustment methods — format_p_adjust","text":"","code":"format_p_adjust(method)"},{"path":"https://easystats.github.io/parameters/reference/format_p_adjust.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Format the name of the p-value adjustment methods — format_p_adjust","text":"method Name method.","code":""},{"path":"https://easystats.github.io/parameters/reference/format_p_adjust.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Format the name of the p-value adjustment methods — format_p_adjust","text":"string full surname(s) author(s), including year publication, adjustment-method.","code":""},{"path":"https://easystats.github.io/parameters/reference/format_p_adjust.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Format the name of the p-value adjustment methods — format_p_adjust","text":"","code":"library(parameters)  format_p_adjust(\"holm\") #> [1] \"Holm (1979)\" format_p_adjust(\"bonferroni\") #> [1] \"Bonferroni\""},{"path":"https://easystats.github.io/parameters/reference/format_parameters.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameter names formatting — format_parameters","title":"Parameter names formatting — format_parameters","text":"functions formats names model parameters (coefficients) make human-readable.","code":""},{"path":"https://easystats.github.io/parameters/reference/format_parameters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parameter names formatting — format_parameters","text":"","code":"format_parameters(model, ...)  # S3 method for default format_parameters(model, brackets = c(\"[\", \"]\"), ...)"},{"path":"https://easystats.github.io/parameters/reference/format_parameters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameter names formatting — format_parameters","text":"model statistical model. ... Currently used. brackets character vector length two, indicating opening closing brackets.","code":""},{"path":"https://easystats.github.io/parameters/reference/format_parameters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parameter names formatting — format_parameters","text":"(names) character vector formatted parameter names. value names refer original names coefficients.","code":""},{"path":"https://easystats.github.io/parameters/reference/format_parameters.html","id":"interpretation-of-interaction-terms","dir":"Reference","previous_headings":"","what":"Interpretation of Interaction Terms","title":"Parameter names formatting — format_parameters","text":"Note interpretation interaction terms depends many characteristics model. number parameters, overall performance model, can differ * b : b, / b, suggesting sometimes interaction terms give different parameterizations model, times gives completely different models (depending b factors covariates, included main effects , etc.). interpretation depends full context model, inferred parameters table alone - rather, recommend use packages calculate estimated marginal means marginal effects, modelbased, emmeans, ggeffects, marginaleffects. raise awareness issue, may use print(...,show_formula=TRUE) add model-specification output print() method model_parameters().","code":""},{"path":"https://easystats.github.io/parameters/reference/format_parameters.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parameter names formatting — format_parameters","text":"","code":"model <- lm(Sepal.Length ~ Species * Sepal.Width, data = iris) format_parameters(model) #>                          (Intercept)                    Speciesversicolor  #>                        \"(Intercept)\"               \"Species [versicolor]\"  #>                     Speciesvirginica                          Sepal.Width  #>                \"Species [virginica]\"                        \"Sepal Width\"  #>        Speciesversicolor:Sepal.Width         Speciesvirginica:Sepal.Width  #> \"Species [versicolor] * Sepal Width\"  \"Species [virginica] * Sepal Width\"   model <- lm(Sepal.Length ~ Petal.Length + (Species / Sepal.Width), data = iris) format_parameters(model) #>                          (Intercept)                         Petal.Length  #>                        \"(Intercept)\"                       \"Petal Length\"  #>                    Speciesversicolor                     Speciesvirginica  #>               \"Species [versicolor]\"                \"Species [virginica]\"  #>            Speciessetosa:Sepal.Width        Speciesversicolor:Sepal.Width  #>     \"Species [setosa] * Sepal Width\" \"Species [versicolor] * Sepal Width\"  #>         Speciesvirginica:Sepal.Width  #>  \"Species [virginica] * Sepal Width\"   model <- lm(Sepal.Length ~ Species + poly(Sepal.Width, 2), data = iris) format_parameters(model) #>                (Intercept)          Speciesversicolor  #>              \"(Intercept)\"     \"Species [versicolor]\"  #>           Speciesvirginica      poly(Sepal.Width, 2)1  #>      \"Species [virginica]\" \"Sepal Width [1st degree]\"  #>      poly(Sepal.Width, 2)2  #> \"Sepal Width [2nd degree]\"   model <- lm(Sepal.Length ~ Species + poly(Sepal.Width, 2, raw = TRUE), data = iris) format_parameters(model) #>                       (Intercept)                 Speciesversicolor  #>                     \"(Intercept)\"            \"Species [versicolor]\"  #>                  Speciesvirginica poly(Sepal.Width, 2, raw = TRUE)1  #>             \"Species [virginica]\"        \"Sepal Width [1st degree]\"  #> poly(Sepal.Width, 2, raw = TRUE)2  #>        \"Sepal Width [2nd degree]\""},{"path":"https://easystats.github.io/parameters/reference/get_scores.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Scores from Principal Component Analysis (PCA) — get_scores","title":"Get Scores from Principal Component Analysis (PCA) — get_scores","text":"get_scores() takes n_items amount items load (either loading cutoff number) component, computes average.","code":""},{"path":"https://easystats.github.io/parameters/reference/get_scores.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Scores from Principal Component Analysis (PCA) — get_scores","text":"","code":"get_scores(x, n_items = NULL)"},{"path":"https://easystats.github.io/parameters/reference/get_scores.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Scores from Principal Component Analysis (PCA) — get_scores","text":"x object returned principal_components(). n_items Number required (.e. non-missing) items build sum score. NULL, value chosen match half number columns data frame.","code":""},{"path":"https://easystats.github.io/parameters/reference/get_scores.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Scores from Principal Component Analysis (PCA) — get_scores","text":"data frame subscales, average sum scores items component.","code":""},{"path":"https://easystats.github.io/parameters/reference/get_scores.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get Scores from Principal Component Analysis (PCA) — get_scores","text":"get_scores() takes results principal_components() extracts variables component found PCA. , \"subscales\", row means calculated (equals adding single items dividing number items). results sum score component PCA, scale original, single items used compute PCA.","code":""},{"path":"https://easystats.github.io/parameters/reference/get_scores.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Scores from Principal Component Analysis (PCA) — get_scores","text":"","code":"if (require(\"psych\")) {   pca <- principal_components(mtcars[, 1:7], n = 2, rotation = \"varimax\")    # PCA extracted two components   pca    # assignment of items to each component   closest_component(pca)    # now we want to have sum scores for each component   get_scores(pca)    # compare to manually computed sum score for 2nd component, which   # consists of items \"hp\" and \"qsec\"   (mtcars$hp + mtcars$qsec) / 2 } #>  [1]  63.230  63.510  55.805  64.720  96.010  62.610 130.420  41.000  58.950 #> [10]  70.650  70.950  98.700  98.800  99.000 111.490 116.410 123.710  42.735 #> [19]  35.260  42.450  58.505  83.435  83.650 130.205  96.025  42.450  53.850 #> [28]  64.950 139.250  95.250 174.800  63.800"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.BFBayesFactor.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameters from BayesFactor objects — model_parameters.BFBayesFactor","title":"Parameters from BayesFactor objects — model_parameters.BFBayesFactor","text":"Parameters BFBayesFactor objects {BayesFactor} package.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.BFBayesFactor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parameters from BayesFactor objects — model_parameters.BFBayesFactor","text":"","code":"# S3 method for BFBayesFactor model_parameters(   model,   centrality = \"median\",   dispersion = FALSE,   ci = 0.95,   ci_method = \"eti\",   test = c(\"pd\", \"rope\"),   rope_range = \"default\",   rope_ci = 0.95,   priors = TRUE,   cohens_d = NULL,   cramers_v = NULL,   include_proportions = FALSE,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.BFBayesFactor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameters from BayesFactor objects — model_parameters.BFBayesFactor","text":"model Object class BFBayesFactor. centrality point-estimates (centrality indices) compute.  Character (vector) list one options: \"median\", \"mean\", \"MAP\" \"\". dispersion Logical, TRUE, computes indices dispersion related estimate(s) (SD MAD mean median, respectively). ci Value vector probability CI (0 1) estimated. Default .95 (95%). ci_method type index used Credible Interval. Can \"ETI\" (default, see eti()), \"HDI\" (see hdi()), \"BCI\" (see bci()), \"SPI\" (see spi()), \"SI\" (see si()). test indices effect existence compute. Character (vector) list one options: \"p_direction\" (\"pd\"), \"rope\", \"p_map\", \"equivalence_test\" (\"equitest\"), \"bayesfactor\" (\"bf\") \"\" compute tests. \"test\", corresponding bayestestR function called (e.g. rope() p_direction()) results included summary output. rope_range ROPE's lower higher bounds. list two values (e.g., c(-0.1, 0.1)) \"default\". \"default\", bounds set x +- 0.1*SD(response). rope_ci Credible Interval (CI) probability, corresponding proportion HDI, use percentage ROPE. priors Add prior used parameter. cohens_d TRUE, compute Cohens' d index effect size. applies objects ttestBF(). See effectsize::cohens_d() details. cramers_v Compute Cramer's V phi index effect size. Can \"raw\" \"adjusted\" (effect size bias-corrected). applies objects chisq.test(). include_proportions Logical decides whether include posterior cell proportions/counts Bayesian contingency table analysis (BayesFactor::contingencyTableBF()). Defaults FALSE, information often redundant. verbose Toggle warnings messages. ... Additional arguments passed methods.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.BFBayesFactor.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parameters from BayesFactor objects — model_parameters.BFBayesFactor","text":"data frame indices related model's parameters.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.BFBayesFactor.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Parameters from BayesFactor objects — model_parameters.BFBayesFactor","text":"meaning extracted parameters: BayesFactor::ttestBF(): Difference raw difference means. BayesFactor::correlationBF(): rho linear correlation estimate (equivalent Pearson's r). BayesFactor::lmBF() / BayesFactor::generalTestBF() / BayesFactor::regressionBF() / BayesFactor::anovaBF(): addition parameters fixed random effects, : mu (mean-centered) intercept; sig2 model's sigma; g / g_* g parameters; See Bayes Factors ANOVAs paper (doi:10.1016/j.jmp.2012.08.001 ).","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.BFBayesFactor.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parameters from BayesFactor objects — model_parameters.BFBayesFactor","text":"","code":"# \\donttest{ if (require(\"BayesFactor\")) {   # Bayesian t-test   model <- ttestBF(x = rnorm(100, 1, 1))   model_parameters(model)   model_parameters(model, cohens_d = TRUE, ci = .9)    # Bayesian contingency table analysis   data(raceDolls)   bf <- contingencyTableBF(raceDolls, sampleType = \"indepMulti\", fixedMargin = \"cols\")   model_parameters(bf,     centrality = \"mean\",     dispersion = TRUE,     verbose = FALSE,     cramers_v = TRUE   ) } #> Loading required package: BayesFactor #> Loading required package: coda #> Loading required package: Matrix #> ************ #> Welcome to BayesFactor 0.9.12-4.4. If you have questions, please contact Richard Morey (richarddmorey@gmail.com). #>  #> Type BFManual() to open the manual. #> ************ #> Bayesian contingency table analysis #>  #> Parameter | 95% CI | Cramer's V | Cramers 95% CI |                            Prior |   BF #> ------------------------------------------------------------------------------------------ #> Ratio     |        |       0.16 |   [0.02, 0.31] | Independent multinomial (0 +- 1) | 1.81 # }"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.aov.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameters from ANOVAs — model_parameters.aov","title":"Parameters from ANOVAs — model_parameters.aov","text":"Parameters ANOVAs","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.aov.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parameters from ANOVAs — model_parameters.aov","text":"","code":"# S3 method for aov model_parameters(   model,   omega_squared = NULL,   eta_squared = NULL,   epsilon_squared = NULL,   df_error = NULL,   type = NULL,   ci = NULL,   alternative = NULL,   test = NULL,   power = FALSE,   keep = NULL,   drop = NULL,   table_wide = FALSE,   verbose = TRUE,   ... )  # S3 method for anova model_parameters(   model,   omega_squared = NULL,   eta_squared = NULL,   epsilon_squared = NULL,   df_error = NULL,   type = NULL,   ci = NULL,   alternative = NULL,   test = NULL,   power = FALSE,   keep = NULL,   drop = NULL,   table_wide = FALSE,   verbose = TRUE,   ... )  # S3 method for aovlist model_parameters(   model,   omega_squared = NULL,   eta_squared = NULL,   epsilon_squared = NULL,   df_error = NULL,   type = NULL,   ci = NULL,   alternative = NULL,   test = NULL,   power = FALSE,   keep = NULL,   drop = NULL,   table_wide = FALSE,   verbose = TRUE,   ... )  # S3 method for afex_aov model_parameters(   model,   omega_squared = NULL,   eta_squared = NULL,   epsilon_squared = NULL,   df_error = NULL,   type = NULL,   keep = NULL,   drop = NULL,   verbose = TRUE,   ... )  # S3 method for anova.rms model_parameters(   model,   omega_squared = NULL,   eta_squared = NULL,   epsilon_squared = NULL,   df_error = NULL,   type = NULL,   ci = NULL,   alternative = NULL,   test = NULL,   power = FALSE,   keep = NULL,   drop = NULL,   table_wide = FALSE,   verbose = TRUE,   ... )  # S3 method for Anova.mlm model_parameters(   model,   omega_squared = NULL,   eta_squared = NULL,   epsilon_squared = NULL,   df_error = NULL,   type = NULL,   ci = NULL,   alternative = NULL,   test = NULL,   power = FALSE,   keep = NULL,   drop = NULL,   table_wide = FALSE,   verbose = TRUE,   ... )  # S3 method for maov model_parameters(   model,   omega_squared = NULL,   eta_squared = NULL,   epsilon_squared = NULL,   df_error = NULL,   type = NULL,   ci = NULL,   alternative = NULL,   test = NULL,   power = FALSE,   keep = NULL,   drop = NULL,   table_wide = FALSE,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.aov.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameters from ANOVAs — model_parameters.aov","text":"model Object class aov(), anova(), aovlist, Gam, manova(), Anova.mlm, afex_aov maov. omega_squared Compute omega squared index effect size. Can \"partial\" (default, adjusted effect size) \"raw\". eta_squared Compute eta squared index effect size. Can \"partial\" (default, adjusted effect size), \"raw\"  \"adjusted\" (latter option ANOVA-tables mixed models). epsilon_squared Compute epsilon squared index effect size. Can \"partial\" (default, adjusted effect size) \"raw\". df_error Denominator degrees freedom (degrees freedom error estimate, .e., residuals). used compute effect sizes ANOVA-tables mixed models. See 'Examples'. (Ignored afex_aov.) type Numeric, type sums squares. May 1, 2 3. 2 3, ANOVA-tables using car::Anova() returned. (Ignored afex_aov.) ci Confidence Interval (CI) level effect sizes omega_squared, eta_squared etc. default, NULL, compute confidence intervals. ci scalar 0 1. alternative character string specifying alternative hypothesis; Controls type CI returned: \"two.sided\" (default, two-sided CI), \"greater\" \"less\" (one-sided CI). Partial matching allowed (e.g., \"g\", \"l\", \"two\"...). See section One-Sided CIs effectsize_CIs vignette. test String, indicating type test Anova.mlm returned. \"multivariate\" (NULL), returns summary multivariate test (also given print-method). test = \"univariate\", returns summary univariate test. power Logical, TRUE, adds column power parameter. keep Character containing regular expression pattern describes parameters included (keep) excluded (drop) returned data frame. keep may also named list regular expressions. non-matching parameters removed output. keep character vector, every parameter name \"Parameter\" column matches regular expression keep selected returned data frame (vice versa, parameter names matching drop excluded). Furthermore, keep one element, merged operator regular expression pattern like : \"(one|two|three)\". keep named list regular expression patterns, names list-element equal column name selection applied. useful model objects model_parameters() returns multiple columns parameter components, like model_parameters.lavaan(). Note regular expression pattern match parameter names stored returned data frame, can different printed. Inspect $Parameter column parameters table get exact parameter names. drop See keep. table_wide Logical decides whether ANOVA table wide format, .e. numerator denominator degrees freedom row. Default: FALSE. verbose Toggle warnings messages. ... Arguments passed methods.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.aov.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parameters from ANOVAs — model_parameters.aov","text":"data frame indices related model's parameters.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.aov.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Parameters from ANOVAs — model_parameters.aov","text":"ANOVA-tables mixed models (.e. anova(lmer())), partial adjusted effect sizes can computed. Note type 3 ANOVAs interactions involved give sensible informative results covariates mean-centred factors coded orthogonal contrasts (produced contr.sum, contr.poly, contr.helmert, default contr.treatment).","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.aov.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parameters from ANOVAs — model_parameters.aov","text":"","code":"if (requireNamespace(\"effectsize\", quietly = TRUE)) {   df <- iris   df$Sepal.Big <- ifelse(df$Sepal.Width >= 3, \"Yes\", \"No\")    model <- aov(Sepal.Length ~ Sepal.Big, data = df)   model_parameters(     model,     omega_squared = \"partial\",     eta_squared = \"partial\",     epsilon_squared = \"partial\"   )    model_parameters(     model,     omega_squared = \"partial\",     eta_squared = \"partial\",     ci = .9   )    model <- anova(lm(Sepal.Length ~ Sepal.Big, data = df))   model_parameters(model)   model_parameters(     model,     omega_squared = \"partial\",     eta_squared = \"partial\",     epsilon_squared = \"partial\"   )    model <- aov(Sepal.Length ~ Sepal.Big + Error(Species), data = df)   model_parameters(model)    if (FALSE) {     if (require(\"lme4\")) {       mm <- lmer(Sepal.Length ~ Sepal.Big + Petal.Width + (1 | Species),         data = df       )       model <- anova(mm)        # simple parameters table       model_parameters(model)        # parameters table including effect sizes       model_parameters(         model,         eta_squared = \"partial\",         ci = .9,         df_error = dof_satterthwaite(mm)[2:3]       )     }   } }"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.averaging.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameters from special models — model_parameters.PMCMR","title":"Parameters from special models — model_parameters.PMCMR","text":"Parameters special regression models listed one previous categories yet. Parameters Hypothesis Testing.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.averaging.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parameters from special models — model_parameters.PMCMR","text":"","code":"# S3 method for PMCMR model_parameters(model, ...)  # S3 method for glimML model_parameters(   model,   ci = 0.95,   bootstrap = FALSE,   iterations = 1000,   component = c(\"conditional\", \"random\", \"dispersion\", \"all\"),   standardize = NULL,   exponentiate = FALSE,   p_adjust = NULL,   verbose = TRUE,   ... )  # S3 method for averaging model_parameters(   model,   ci = 0.95,   component = c(\"conditional\", \"full\"),   exponentiate = FALSE,   p_adjust = NULL,   verbose = TRUE,   ... )  # S3 method for mle2 model_parameters(   model,   ci = 0.95,   ci_method = NULL,   bootstrap = FALSE,   iterations = 1000,   standardize = NULL,   exponentiate = FALSE,   p_adjust = NULL,   summary = getOption(\"parameters_summary\", FALSE),   df_method = ci_method,   vcov = NULL,   vcov_args = NULL,   verbose = TRUE,   ... )  # S3 method for betareg model_parameters(   model,   ci = 0.95,   bootstrap = FALSE,   iterations = 1000,   component = c(\"conditional\", \"precision\", \"all\"),   standardize = NULL,   exponentiate = FALSE,   p_adjust = NULL,   verbose = TRUE,   ... )  # S3 method for bfsl model_parameters(   model,   ci = 0.95,   ci_method = \"residual\",   p_adjust = NULL,   verbose = TRUE,   ... )  # S3 method for deltaMethod model_parameters(model, p_adjust = NULL, verbose = TRUE, ...)  # S3 method for emmGrid model_parameters(   model,   ci = 0.95,   centrality = \"median\",   dispersion = FALSE,   ci_method = \"eti\",   test = c(\"pd\", \"rope\"),   rope_range = \"default\",   rope_ci = 0.95,   exponentiate = FALSE,   p_adjust = NULL,   keep = NULL,   drop = NULL,   verbose = TRUE,   ... )  # S3 method for emm_list model_parameters(   model,   ci = 0.95,   exponentiate = FALSE,   p_adjust = NULL,   verbose = TRUE,   ... )  # S3 method for epi.2by2 model_parameters(model, verbose = TRUE, ...)  # S3 method for fitdistr model_parameters(model, exponentiate = FALSE, verbose = TRUE, ...)  # S3 method for ggeffects model_parameters(model, keep = NULL, drop = NULL, verbose = TRUE, ...)  # S3 method for SemiParBIV model_parameters(   model,   ci = 0.95,   bootstrap = FALSE,   iterations = 1000,   standardize = NULL,   exponentiate = FALSE,   p_adjust = NULL,   verbose = TRUE,   ... )  # S3 method for glmm model_parameters(   model,   ci = 0.95,   effects = c(\"all\", \"fixed\", \"random\"),   bootstrap = FALSE,   iterations = 1000,   standardize = NULL,   exponentiate = FALSE,   verbose = TRUE,   ... )  # S3 method for glmx model_parameters(   model,   ci = 0.95,   bootstrap = FALSE,   iterations = 1000,   component = c(\"all\", \"conditional\", \"extra\"),   standardize = NULL,   exponentiate = FALSE,   p_adjust = NULL,   verbose = TRUE,   ... )  # S3 method for ivFixed model_parameters(model, ci = 0.95, ci_method = \"wald\", verbose = TRUE, ...)  # S3 method for ivprobit model_parameters(model, ci = 0.95, ci_method = \"wald\", verbose = TRUE, ...)  # S3 method for lmodel2 model_parameters(   model,   ci = 0.95,   exponentiate = FALSE,   p_adjust = NULL,   verbose = TRUE,   ... )  # S3 method for logistf model_parameters(   model,   ci = 0.95,   ci_method = NULL,   bootstrap = FALSE,   iterations = 1000,   standardize = NULL,   exponentiate = FALSE,   p_adjust = NULL,   summary = getOption(\"parameters_summary\", FALSE),   df_method = ci_method,   vcov = NULL,   vcov_args = NULL,   verbose = TRUE,   ... )  # S3 method for lqmm model_parameters(   model,   ci = 0.95,   bootstrap = FALSE,   iterations = 1000,   p_adjust = NULL,   verbose = TRUE,   ... )  # S3 method for marginaleffects model_parameters(model, ci = 0.95, ...)  # S3 method for comparisons model_parameters(model, ci = 0.95, ...)  # S3 method for marginalmeans model_parameters(model, ci = 0.95, ...)  # S3 method for deltamethod model_parameters(model, ci = 0.95, ...)  # S3 method for margins model_parameters(   model,   ci = 0.95,   exponentiate = FALSE,   p_adjust = NULL,   verbose = TRUE,   ... )  # S3 method for maxLik model_parameters(   model,   ci = 0.95,   ci_method = NULL,   bootstrap = FALSE,   iterations = 1000,   standardize = NULL,   exponentiate = FALSE,   p_adjust = NULL,   summary = getOption(\"parameters_summary\", FALSE),   keep = NULL,   drop = NULL,   verbose = TRUE,   vcov = NULL,   vcov_args = NULL,   ... )  # S3 method for maxim model_parameters(   model,   ci = 0.95,   ci_method = NULL,   bootstrap = FALSE,   iterations = 1000,   standardize = NULL,   exponentiate = FALSE,   p_adjust = NULL,   summary = getOption(\"parameters_summary\", FALSE),   keep = NULL,   drop = NULL,   verbose = TRUE,   vcov = NULL,   vcov_args = NULL,   ... )  # S3 method for mediate model_parameters(model, ci = 0.95, exponentiate = FALSE, verbose = TRUE, ...)  # S3 method for metaplus model_parameters(   model,   ci = 0.95,   bootstrap = FALSE,   iterations = 1000,   standardize = NULL,   exponentiate = FALSE,   include_studies = TRUE,   verbose = TRUE,   ... )  # S3 method for meta_random model_parameters(   model,   ci = 0.95,   ci_method = \"eti\",   exponentiate = FALSE,   include_studies = TRUE,   verbose = TRUE,   ... )  # S3 method for meta_fixed model_parameters(   model,   ci = 0.95,   ci_method = \"eti\",   exponentiate = FALSE,   include_studies = TRUE,   verbose = TRUE,   ... )  # S3 method for meta_bma model_parameters(   model,   ci = 0.95,   ci_method = \"eti\",   exponentiate = FALSE,   include_studies = TRUE,   verbose = TRUE,   ... )  # S3 method for logitor model_parameters(   model,   ci = 0.95,   bootstrap = FALSE,   iterations = 1000,   standardize = NULL,   exponentiate = TRUE,   p_adjust = NULL,   verbose = TRUE,   ... )  # S3 method for poissonirr model_parameters(   model,   ci = 0.95,   bootstrap = FALSE,   iterations = 1000,   standardize = NULL,   exponentiate = TRUE,   p_adjust = NULL,   verbose = TRUE,   ... )  # S3 method for negbinirr model_parameters(   model,   ci = 0.95,   bootstrap = FALSE,   iterations = 1000,   standardize = NULL,   exponentiate = TRUE,   p_adjust = NULL,   verbose = TRUE,   ... )  # S3 method for poissonmfx model_parameters(   model,   ci = 0.95,   bootstrap = FALSE,   iterations = 1000,   component = c(\"all\", \"conditional\", \"marginal\"),   standardize = NULL,   exponentiate = FALSE,   p_adjust = NULL,   verbose = TRUE,   ... )  # S3 method for logitmfx model_parameters(   model,   ci = 0.95,   bootstrap = FALSE,   iterations = 1000,   component = c(\"all\", \"conditional\", \"marginal\"),   standardize = NULL,   exponentiate = FALSE,   p_adjust = NULL,   verbose = TRUE,   ... )  # S3 method for probitmfx model_parameters(   model,   ci = 0.95,   bootstrap = FALSE,   iterations = 1000,   component = c(\"all\", \"conditional\", \"marginal\"),   standardize = NULL,   exponentiate = FALSE,   p_adjust = NULL,   verbose = TRUE,   ... )  # S3 method for negbinmfx model_parameters(   model,   ci = 0.95,   bootstrap = FALSE,   iterations = 1000,   component = c(\"all\", \"conditional\", \"marginal\"),   standardize = NULL,   exponentiate = FALSE,   p_adjust = NULL,   verbose = TRUE,   ... )  # S3 method for betaor model_parameters(   model,   ci = 0.95,   bootstrap = FALSE,   iterations = 1000,   component = c(\"conditional\", \"precision\", \"all\"),   standardize = NULL,   exponentiate = FALSE,   p_adjust = NULL,   verbose = TRUE,   ... )  # S3 method for betamfx model_parameters(   model,   ci = 0.95,   bootstrap = FALSE,   iterations = 1000,   component = c(\"all\", \"conditional\", \"precision\", \"marginal\"),   standardize = NULL,   exponentiate = FALSE,   p_adjust = NULL,   verbose = TRUE,   ... )  # S3 method for mjoint model_parameters(   model,   ci = 0.95,   effects = \"fixed\",   component = c(\"all\", \"conditional\", \"survival\"),   exponentiate = FALSE,   p_adjust = NULL,   keep = NULL,   drop = NULL,   verbose = TRUE,   ... )  # S3 method for model_fit model_parameters(   model,   ci = 0.95,   effects = \"fixed\",   component = \"conditional\",   ci_method = \"profile\",   bootstrap = FALSE,   iterations = 1000,   standardize = NULL,   exponentiate = FALSE,   p_adjust = NULL,   verbose = TRUE,   ... )  # S3 method for glht model_parameters(model, ci = 0.95, exponentiate = FALSE, verbose = TRUE, ...)  # S3 method for mvord model_parameters(   model,   ci = 0.95,   component = c(\"all\", \"conditional\", \"thresholds\", \"correlation\"),   standardize = NULL,   exponentiate = FALSE,   p_adjust = NULL,   verbose = TRUE,   ... )  # S3 method for pgmm model_parameters(   model,   ci = 0.95,   component = c(\"conditional\", \"all\"),   exponentiate = FALSE,   p_adjust = NULL,   keep = NULL,   drop = NULL,   verbose = TRUE,   ... )  # S3 method for rqss model_parameters(   model,   ci = 0.95,   ci_method = \"residual\",   bootstrap = FALSE,   iterations = 1000,   standardize = NULL,   exponentiate = FALSE,   p_adjust = NULL,   keep = NULL,   drop = NULL,   verbose = TRUE,   ... )  # S3 method for rqs model_parameters(   model,   ci = 0.95,   bootstrap = FALSE,   iterations = 1000,   standardize = NULL,   exponentiate = FALSE,   verbose = TRUE,   ... )  # S3 method for selection model_parameters(   model,   ci = 0.95,   component = c(\"all\", \"selection\", \"outcome\", \"auxiliary\"),   bootstrap = FALSE,   iterations = 1000,   standardize = NULL,   exponentiate = FALSE,   p_adjust = NULL,   verbose = TRUE,   ... )  # S3 method for mle model_parameters(   model,   ci = 0.95,   ci_method = NULL,   bootstrap = FALSE,   iterations = 1000,   standardize = NULL,   exponentiate = FALSE,   p_adjust = NULL,   summary = getOption(\"parameters_summary\", FALSE),   df_method = ci_method,   vcov = NULL,   vcov_args = NULL,   verbose = TRUE,   ... )  # S3 method for systemfit model_parameters(   model,   ci = 0.95,   ci_method = NULL,   bootstrap = FALSE,   iterations = 1000,   standardize = NULL,   exponentiate = FALSE,   p_adjust = NULL,   summary = FALSE,   verbose = TRUE,   ... )  # S3 method for varest model_parameters(   model,   ci = 0.95,   bootstrap = FALSE,   iterations = 1000,   standardize = NULL,   exponentiate = FALSE,   p_adjust = NULL,   verbose = TRUE,   ... )  # S3 method for t1way model_parameters(model, keep = NULL, verbose = TRUE, ...)  # S3 method for med1way model_parameters(model, verbose = TRUE, ...)  # S3 method for dep.effect model_parameters(model, keep = NULL, verbose = TRUE, ...)  # S3 method for yuen model_parameters(model, verbose = TRUE, ...)"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.averaging.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameters from special models — model_parameters.PMCMR","text":"model Object WRS2 package. ... Arguments passed methods. ci Confidence Interval (CI) level. Default 0.95 (95%). bootstrap estimates based bootstrapped model? TRUE, arguments Bayesian regressions apply (see also bootstrap_parameters()). iterations number bootstrap replicates. apply case bootstrapped frequentist models. component Model component parameters shown. May one \"conditional\", \"precision\" (betareg), \"scale\" (ordinal), \"extra\" (glmx), \"marginal\" (mfx), \"conditional\" \"full\" (MuMIn::model.avg()) \"\". standardize method used standardizing parameters. Can NULL (default; standardization), \"refit\" (re-fitting model standardized data) one \"basic\", \"posthoc\", \"smart\", \"pseudo\". See 'Details' standardize_parameters(). Important: \"refit\" method standardized categorical predictors (.e. factors), may different behaviour compared R packages (lm.beta) software packages (like SPSS). mimic behaviours, either use standardize=\"basic\" standardize data datawizard::standardize(force=TRUE) fitting model. mixed models, using methods \"refit\", fixed effects returned. Robust estimation (.e., vcov set value NULL) standardized parameters works standardize=\"refit\". exponentiate Logical, indicating whether exponentiate coefficients (related confidence intervals). typical logistic regression, generally speaking, models log logit links. also recommended use exponentiate = TRUE models log-transformed response values. Note: Delta-method standard errors also computed (multiplying standard errors transformed coefficients). mimic behaviour software packages, Stata, standard errors poorly estimate uncertainty transformed coefficient. transformed confidence interval clearly captures uncertainty. compare_parameters(), exponentiate = \"nongaussian\" exponentiate coefficients non-Gaussian families. p_adjust Character vector, NULL, indicates method adjust p-values. See stats::p.adjust() details. possible adjustment methods \"tukey\", \"scheffe\", \"sidak\" \"none\" explicitly disable adjustment emmGrid objects (emmeans). verbose Toggle warnings messages. ci_method Method computing degrees freedom confidence intervals (CI) related p-values. Allowed following options (vary depending model class): \"residual\", \"normal\", \"likelihood\", \"satterthwaite\", \"kenward\", \"wald\", \"profile\", \"boot\", \"uniroot\", \"ml1\", \"betwithin\", \"hdi\", \"quantile\", \"ci\", \"eti\", \"si\", \"bci\", \"bcai\". See section Confidence intervals approximation degrees freedom model_parameters() details. ci_method=NULL, cases \"wald\" used . summary Logical, TRUE, prints summary information model (model formula, number observations, residual standard deviation ). df_method Deprecated. Please use ci_method. vcov Variance-covariance matrix used compute uncertainty estimates (e.g., robust standard errors). argument accepts covariance matrix, function returns covariance matrix, string identifies function used compute covariance matrix. covariance matrix function returns covariance matrix (e.g., stats::vcov()) string indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"vcovHC\", \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC. Cluster-robust: \"vcovCR\", \"CR0\", \"CR1\", \"CR1p\", \"CR1S\", \"CR2\", \"CR3\". See ?clubSandwich::vcovCR. Bootstrap: \"vcovBS\", \"xy\", \"residual\", \"wild\", \"mammen\", \"webb\". See ?sandwich::vcovBS. sandwich package functions: \"vcovHAC\", \"vcovPC\", \"vcovCL\", \"vcovPL\". vcov_args List arguments passed function identified vcov argument. function typically supplied sandwich clubSandwich packages. Please refer documentation (e.g., ?sandwich::vcovHAC) see list available arguments. centrality point-estimates (centrality indices) compute.  Character (vector) list one options: \"median\", \"mean\", \"MAP\" \"\". dispersion Logical, TRUE, computes indices dispersion related estimate(s) (SD MAD mean median, respectively). test indices effect existence compute. Character (vector) list one options: \"p_direction\" (\"pd\"), \"rope\", \"p_map\", \"equivalence_test\" (\"equitest\"), \"bayesfactor\" (\"bf\") \"\" compute tests. \"test\", corresponding bayestestR function called (e.g. rope() p_direction()) results included summary output. rope_range ROPE's lower higher bounds. list two values (e.g., c(-0.1, 0.1)) \"default\". \"default\", bounds set x +- 0.1*SD(response). rope_ci Credible Interval (CI) probability, corresponding proportion HDI, use percentage ROPE. keep Character containing regular expression pattern describes parameters included (keep) excluded (drop) returned data frame. keep may also named list regular expressions. non-matching parameters removed output. keep character vector, every parameter name \"Parameter\" column matches regular expression keep selected returned data frame (vice versa, parameter names matching drop excluded). Furthermore, keep one element, merged operator regular expression pattern like : \"(one|two|three)\". keep named list regular expression patterns, names list-element equal column name selection applied. useful model objects model_parameters() returns multiple columns parameter components, like model_parameters.lavaan(). Note regular expression pattern match parameter names stored returned data frame, can different printed. Inspect $Parameter column parameters table get exact parameter names. drop See keep. effects results fixed effects, random effects returned? applies mixed models. May abbreviated. include_studies Logical, TRUE (default), includes parameters studies. Else, parameters overall-effects shown.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.averaging.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parameters from special models — model_parameters.PMCMR","text":"data frame indices related model's parameters. data frame indices related model's parameters. data frame indices related model's parameters.","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/model_parameters.averaging.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parameters from special models — model_parameters.PMCMR","text":"","code":"library(parameters) if (require(\"brglm2\", quietly = TRUE)) {   data(\"stemcell\")   model <- bracl(     research ~ as.numeric(religion) + gender,     weights = frequency,     data = stemcell,     type = \"ML\"   )   model_parameters(model) } #> # Response level: definitely #>  #> Parameter       | Log-Odds |   SE |         95% CI |     z |      p #> ------------------------------------------------------------------- #> (Intercept)     |    -1.25 | 0.26 | [-1.76, -0.73] | -4.76 | < .001 #> religion        |     0.44 | 0.10 | [ 0.23,  0.64] |  4.20 | < .001 #> gender [female] |    -0.14 | 0.17 | [-0.47,  0.19] | -0.82 | 0.414  #>  #> # Response level: probably #>  #> Parameter       | Log-Odds |   SE |        95% CI |    z |     p #> ---------------------------------------------------------------- #> (Intercept)     |     0.47 | 0.29 | [-0.10, 1.04] | 1.62 | 0.105 #> religion        |     0.26 | 0.13 | [ 0.01, 0.51] | 2.01 | 0.044 #> gender [female] |     0.19 | 0.21 | [-0.22, 0.60] | 0.90 | 0.370 #>  #> # Response level: probably not #>  #> Parameter       | Log-Odds |   SE |        95% CI |     z |     p #> ----------------------------------------------------------------- #> (Intercept)     |     0.43 | 0.39 | [-0.33, 1.18] |  1.11 | 0.268 #> religion        |     0.01 | 0.17 | [-0.33, 0.35] |  0.07 | 0.945 #> gender [female] |    -0.16 | 0.28 | [-0.71, 0.39] | -0.57 | 0.566 #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) computed #>   using a Wald z-distribution approximation. #>  #> The model has a log- or logit-link. Consider using `exponentiate = TRUE` #>   to interpret coefficients as ratios. # \\donttest{ if (require(\"multcomp\", quietly = TRUE)) {   # multiple linear model, swiss data   lmod <- lm(Fertility ~ ., data = swiss)   mod <- glht(     model = lmod,     linfct = c(       \"Agriculture = 0\",       \"Examination = 0\",       \"Education = 0\",       \"Catholic = 0\",       \"Infant.Mortality = 0\"     )   )   model_parameters(mod) } #>  #> Attaching package: ‘mvtnorm’ #> The following object is masked from ‘package:mclust’: #>  #>     dmvnorm #>  #> Attaching package: ‘TH.data’ #> The following object is masked from ‘package:MASS’: #>  #>     geyser #> # Fixed Effects #>  #> Parameter             | Coefficient |   SE |         95% CI | t(41) |      p #> ---------------------------------------------------------------------------- #> Agriculture == 0      |       -0.17 | 0.07 | [-0.36,  0.01] | -2.45 | 0.080  #> Examination == 0      |       -0.26 | 0.25 | [-0.93,  0.41] | -1.02 | 0.785  #> Education == 0        |       -0.87 | 0.18 | [-1.35, -0.39] | -4.76 | < .001 #> Catholic == 0         |        0.10 | 0.04 | [ 0.01,  0.20] |  2.95 | 0.023  #> Infant Mortality == 0 |        1.08 | 0.38 | [ 0.07,  2.09] |  2.82 | 0.033  #>  #> p-value adjustment method: single-step #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) computed #>   using a Wald t-distribution approximation. if (require(\"PMCMRplus\", quietly = TRUE)) {   model <- kwAllPairsConoverTest(count ~ spray, data = InsectSprays)   model_parameters(model) } #> Warning: Ties are present. Quantiles were corrected for ties. #> Conover's all-pairs test #>  #> Group1 | Group2 | Statistic |      p | alternative | Distribution | p_adjustment #> -------------------------------------------------------------------------------- #> B      |      A |      0.89 | 0.988  |   two.sided |            q |  single-step #> C      |      A |    -13.58 | < .001 |   two.sided |            q |  single-step #> C      |      B |    -14.47 | < .001 |   two.sided |            q |  single-step #> D      |      A |     -8.87 | < .001 |   two.sided |            q |  single-step #> D      |      B |     -9.76 | < .001 |   two.sided |            q |  single-step #> D      |      C |      4.71 | 0.017  |   two.sided |            q |  single-step #> E      |      A |    -10.95 | < .001 |   two.sided |            q |  single-step #> E      |      B |    -11.84 | < .001 |   two.sided |            q |  single-step #> E      |      C |      2.63 | 0.437  |   two.sided |            q |  single-step #> E      |      D |     -2.09 | 0.681  |   two.sided |            q |  single-step #> F      |      A |      1.15 | 0.964  |   two.sided |            q |  single-step #> F      |      B |      0.26 | > .999 |   two.sided |            q |  single-step #> F      |      C |     14.74 | < .001 |   two.sided |            q |  single-step #> F      |      D |     10.02 | < .001 |   two.sided |            q |  single-step #> F      |      E |     12.11 | < .001 |   two.sided |            q |  single-step # } if (require(\"WRS2\") && packageVersion(\"WRS2\") >= \"1.1.3\") {   model <- t1way(libido ~ dose, data = viagra)   model_parameters(model) } #> Loading required package: WRS2 #> A heteroscedastic one-way ANOVA for trimmed means #>  #> F    | df | df (error) |     p | Estimate |       95% CI |                         Effectsize #> --------------------------------------------------------------------------------------------- #> 3.00 |  2 |          4 | 0.160 |     0.79 | [0.41, 1.43] | Explanatory measure of effect size"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.befa.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameters from Bayesian Exploratory Factor Analysis — model_parameters.befa","title":"Parameters from Bayesian Exploratory Factor Analysis — model_parameters.befa","text":"Format Bayesian Exploratory Factor Analysis objects BayesFM package.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.befa.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parameters from Bayesian Exploratory Factor Analysis — model_parameters.befa","text":"","code":"# S3 method for befa model_parameters(   model,   sort = FALSE,   centrality = \"median\",   dispersion = FALSE,   ci = 0.95,   ci_method = \"eti\",   test = NULL,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.befa.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameters from Bayesian Exploratory Factor Analysis — model_parameters.befa","text":"model Bayesian EFA created BayesFM::befa. sort Sort loadings. centrality point-estimates (centrality indices) compute.  Character (vector) list one options: \"median\", \"mean\", \"MAP\" \"\". dispersion Logical, TRUE, computes indices dispersion related estimate(s) (SD MAD mean median, respectively). ci Value vector probability CI (0 1) estimated. Default .95 (95%). ci_method type index used Credible Interval. Can \"ETI\" (default, see eti()), \"HDI\" (see hdi()), \"BCI\" (see bci()), \"SPI\" (see spi()), \"SI\" (see si()). test indices effect existence compute. Character (vector) list one options: \"p_direction\" (\"pd\"), \"rope\", \"p_map\", \"equivalence_test\" (\"equitest\"), \"bayesfactor\" (\"bf\") \"\" compute tests. \"test\", corresponding bayestestR function called (e.g. rope() p_direction()) results included summary output. verbose Toggle warnings messages. ... Arguments passed methods.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.befa.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parameters from Bayesian Exploratory Factor Analysis — model_parameters.befa","text":"data frame loadings.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.befa.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parameters from Bayesian Exploratory Factor Analysis — model_parameters.befa","text":"","code":"library(parameters) # \\donttest{ if (require(\"BayesFM\")) {   efa <- BayesFM::befa(mtcars, iter = 1000)   results <- model_parameters(efa, sort = TRUE)   results   efa_to_cfa(results) } #> Loading required package: BayesFM #> starting MCMC sampling... #>     5% #>    10% #>    15% #>    20% #>    25% #>    30% #>    35% #>    40% #>    45% #> done with burn-in period #>    50% #>    55% #>    60% #>    65% #>    70% #>    75% #>    80% #>    85% #>    90% #>    95% #>   100% #> done with sampling! #> # Latent variables #> F1 =~ am + mpg + vs #> F2 =~ carb + cyl + disp + hp + wt #> F3 =~ drat + gear + qsec # }"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.cgam.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameters from Generalized Additive (Mixed) Models — model_parameters.cgam","title":"Parameters from Generalized Additive (Mixed) Models — model_parameters.cgam","text":"Extract compute indices measures describe parameters generalized additive models (GAM(M)s).","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.cgam.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parameters from Generalized Additive (Mixed) Models — model_parameters.cgam","text":"","code":"# S3 method for cgam model_parameters(   model,   ci = 0.95,   ci_method = \"residual\",   bootstrap = FALSE,   iterations = 1000,   standardize = NULL,   exponentiate = FALSE,   p_adjust = NULL,   keep = NULL,   drop = NULL,   verbose = TRUE,   ... )  # S3 method for gam model_parameters(   model,   ci = 0.95,   ci_method = \"residual\",   bootstrap = FALSE,   iterations = 1000,   standardize = NULL,   exponentiate = FALSE,   p_adjust = NULL,   keep = NULL,   drop = NULL,   verbose = TRUE,   ... )  # S3 method for gamlss model_parameters(   model,   ci = 0.95,   ci_method = \"residual\",   bootstrap = FALSE,   iterations = 1000,   standardize = NULL,   exponentiate = FALSE,   p_adjust = NULL,   keep = NULL,   drop = NULL,   verbose = TRUE,   ... )  # S3 method for gamm model_parameters(   model,   ci = 0.95,   bootstrap = FALSE,   iterations = 1000,   verbose = TRUE,   ... )  # S3 method for Gam model_parameters(   model,   omega_squared = NULL,   eta_squared = NULL,   epsilon_squared = NULL,   df_error = NULL,   type = NULL,   table_wide = FALSE,   verbose = TRUE,   ... )  # S3 method for scam model_parameters(   model,   ci = 0.95,   ci_method = \"residual\",   bootstrap = FALSE,   iterations = 1000,   standardize = NULL,   exponentiate = FALSE,   p_adjust = NULL,   keep = NULL,   drop = NULL,   verbose = TRUE,   ... )  # S3 method for vgam model_parameters(   model,   ci = 0.95,   ci_method = \"residual\",   bootstrap = FALSE,   iterations = 1000,   standardize = NULL,   exponentiate = FALSE,   p_adjust = NULL,   keep = NULL,   drop = NULL,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.cgam.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameters from Generalized Additive (Mixed) Models — model_parameters.cgam","text":"model gam/gamm model. ci Confidence Interval (CI) level. Default 0.95 (95%). ci_method Method computing degrees freedom confidence intervals (CI) related p-values. Allowed following options (vary depending model class): \"residual\", \"normal\", \"likelihood\", \"satterthwaite\", \"kenward\", \"wald\", \"profile\", \"boot\", \"uniroot\", \"ml1\", \"betwithin\", \"hdi\", \"quantile\", \"ci\", \"eti\", \"si\", \"bci\", \"bcai\". See section Confidence intervals approximation degrees freedom model_parameters() details. ci_method=NULL, cases \"wald\" used . bootstrap estimates based bootstrapped model? TRUE, arguments Bayesian regressions apply (see also bootstrap_parameters()). iterations number bootstrap replicates. apply case bootstrapped frequentist models. standardize method used standardizing parameters. Can NULL (default; standardization), \"refit\" (re-fitting model standardized data) one \"basic\", \"posthoc\", \"smart\", \"pseudo\". See 'Details' standardize_parameters(). Important: \"refit\" method standardized categorical predictors (.e. factors), may different behaviour compared R packages (lm.beta) software packages (like SPSS). mimic behaviours, either use standardize=\"basic\" standardize data datawizard::standardize(force=TRUE) fitting model. mixed models, using methods \"refit\", fixed effects returned. Robust estimation (.e., vcov set value NULL) standardized parameters works standardize=\"refit\". exponentiate Logical, indicating whether exponentiate coefficients (related confidence intervals). typical logistic regression, generally speaking, models log logit links. also recommended use exponentiate = TRUE models log-transformed response values. Note: Delta-method standard errors also computed (multiplying standard errors transformed coefficients). mimic behaviour software packages, Stata, standard errors poorly estimate uncertainty transformed coefficient. transformed confidence interval clearly captures uncertainty. compare_parameters(), exponentiate = \"nongaussian\" exponentiate coefficients non-Gaussian families. p_adjust Character vector, NULL, indicates method adjust p-values. See stats::p.adjust() details. possible adjustment methods \"tukey\", \"scheffe\", \"sidak\" \"none\" explicitly disable adjustment emmGrid objects (emmeans). keep Character containing regular expression pattern describes parameters included (keep) excluded (drop) returned data frame. keep may also named list regular expressions. non-matching parameters removed output. keep character vector, every parameter name \"Parameter\" column matches regular expression keep selected returned data frame (vice versa, parameter names matching drop excluded). Furthermore, keep one element, merged operator regular expression pattern like : \"(one|two|three)\". keep named list regular expression patterns, names list-element equal column name selection applied. useful model objects model_parameters() returns multiple columns parameter components, like model_parameters.lavaan(). Note regular expression pattern match parameter names stored returned data frame, can different printed. Inspect $Parameter column parameters table get exact parameter names. drop See keep. verbose Toggle warnings messages. ... Arguments passed methods. instance, bootstrap = TRUE, arguments like type parallel passed bootstrap_model(), arguments like ci_method passed bayestestR::describe_posterior(). omega_squared Compute omega squared index effect size. Can \"partial\" (default, adjusted effect size) \"raw\". eta_squared Compute eta squared index effect size. Can \"partial\" (default, adjusted effect size), \"raw\"  \"adjusted\" (latter option ANOVA-tables mixed models). epsilon_squared Compute epsilon squared index effect size. Can \"partial\" (default, adjusted effect size) \"raw\". df_error Denominator degrees freedom (degrees freedom error estimate, .e., residuals). used compute effect sizes ANOVA-tables mixed models. See 'Examples'. (Ignored afex_aov.) type Numeric, type sums squares. May 1, 2 3. 2 3, ANOVA-tables using car::Anova() returned. (Ignored afex_aov.) table_wide Logical decides whether ANOVA table wide format, .e. numerator denominator degrees freedom row. Default: FALSE.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.cgam.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parameters from Generalized Additive (Mixed) Models — model_parameters.cgam","text":"data frame indices related model's parameters.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.cgam.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Parameters from Generalized Additive (Mixed) Models — model_parameters.cgam","text":"reporting degrees freedom spline terms slightly differs output summary(model), example case mgcv::gam(). estimated degrees freedom, column edf summary-output, named df returned data frame, column df_error returned data frame refers residual degrees freedom returned df.residual(). Hence, values column df_error differ column Ref.df summary, intentional, reference degrees freedom “interpretable” (web).","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/model_parameters.cgam.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parameters from Generalized Additive (Mixed) Models — model_parameters.cgam","text":"","code":"library(parameters) if (require(\"mgcv\")) {   dat <- gamSim(1, n = 400, dist = \"normal\", scale = 2)   model <- gam(y ~ s(x0) + s(x1) + s(x2) + s(x3), data = dat)   model_parameters(model) } #> Loading required package: mgcv #> Loading required package: nlme #> This is mgcv 1.8-40. For overview type 'help(\"mgcv-package\")'. #>  #> Attaching package: ‘mgcv’ #> The following object is masked from ‘package:mclust’: #>  #>     mvn #> Gu & Wahba 4 term additive model #> # Fixed Effects #>  #> Parameter   | Coefficient |   SE |       95% CI | t(385.52) |      p #> -------------------------------------------------------------------- #> (Intercept) |        7.67 | 0.11 | [7.47, 7.88] |     72.98 | < .001 #>  #> # Smooth Terms #>  #> Parameter        |     F |   df |      p #> ---------------------------------------- #> Smooth term (x0) |  7.68 | 2.56 | < .001 #> Smooth term (x1) | 83.04 | 2.33 | < .001 #> Smooth term (x2) | 71.81 | 7.58 | < .001 #> Smooth term (x3) |  0.70 | 1.00 | 0.402"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.default.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameters from (General) Linear Models — model_parameters.default","title":"Parameters from (General) Linear Models — model_parameters.default","text":"Extract compute indices measures describe parameters (general) linear models (GLMs).","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.default.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parameters from (General) Linear Models — model_parameters.default","text":"","code":"# S3 method for default model_parameters(   model,   ci = 0.95,   ci_method = NULL,   bootstrap = FALSE,   iterations = 1000,   standardize = NULL,   exponentiate = FALSE,   p_adjust = NULL,   summary = getOption(\"parameters_summary\", FALSE),   keep = NULL,   drop = NULL,   verbose = TRUE,   vcov = NULL,   vcov_args = NULL,   ... )  # S3 method for glm model_parameters(   model,   ci = 0.95,   ci_method = NULL,   bootstrap = FALSE,   iterations = 1000,   standardize = NULL,   exponentiate = FALSE,   p_adjust = NULL,   summary = getOption(\"parameters_summary\", FALSE),   df_method = ci_method,   vcov = NULL,   vcov_args = NULL,   verbose = TRUE,   ... )  # S3 method for censReg model_parameters(   model,   ci = 0.95,   ci_method = NULL,   bootstrap = FALSE,   iterations = 1000,   standardize = NULL,   exponentiate = FALSE,   p_adjust = NULL,   summary = getOption(\"parameters_summary\", FALSE),   keep = NULL,   drop = NULL,   verbose = TRUE,   vcov = NULL,   vcov_args = NULL,   ... )  # S3 method for ridgelm model_parameters(model, verbose = TRUE, ...)  # S3 method for polr model_parameters(   model,   ci = 0.95,   ci_method = NULL,   bootstrap = FALSE,   iterations = 1000,   standardize = NULL,   exponentiate = FALSE,   p_adjust = NULL,   summary = getOption(\"parameters_summary\", FALSE),   df_method = ci_method,   vcov = NULL,   vcov_args = NULL,   verbose = TRUE,   ... )  # S3 method for negbin model_parameters(   model,   ci = 0.95,   ci_method = NULL,   bootstrap = FALSE,   iterations = 1000,   standardize = NULL,   exponentiate = FALSE,   p_adjust = NULL,   summary = getOption(\"parameters_summary\", FALSE),   df_method = ci_method,   vcov = NULL,   vcov_args = NULL,   verbose = TRUE,   ... )  # S3 method for svyglm model_parameters(   model,   ci = 0.95,   ci_method = \"wald\",   bootstrap = FALSE,   iterations = 1000,   standardize = NULL,   exponentiate = FALSE,   p_adjust = NULL,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.default.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameters from (General) Linear Models — model_parameters.default","text":"model Model object. ci Confidence Interval (CI) level. Default 0.95 (95%). ci_method Method computing degrees freedom confidence intervals (CI) related p-values. Allowed following options (vary depending model class): \"residual\", \"normal\", \"likelihood\", \"satterthwaite\", \"kenward\", \"wald\", \"profile\", \"boot\", \"uniroot\", \"ml1\", \"betwithin\", \"hdi\", \"quantile\", \"ci\", \"eti\", \"si\", \"bci\", \"bcai\". See section Confidence intervals approximation degrees freedom model_parameters() details. ci_method=NULL, cases \"wald\" used . bootstrap estimates based bootstrapped model? TRUE, arguments Bayesian regressions apply (see also bootstrap_parameters()). iterations number bootstrap replicates. apply case bootstrapped frequentist models. standardize method used standardizing parameters. Can NULL (default; standardization), \"refit\" (re-fitting model standardized data) one \"basic\", \"posthoc\", \"smart\", \"pseudo\". See 'Details' standardize_parameters(). Important: \"refit\" method standardized categorical predictors (.e. factors), may different behaviour compared R packages (lm.beta) software packages (like SPSS). mimic behaviours, either use standardize=\"basic\" standardize data datawizard::standardize(force=TRUE) fitting model. mixed models, using methods \"refit\", fixed effects returned. Robust estimation (.e., vcov set value NULL) standardized parameters works standardize=\"refit\". exponentiate Logical, indicating whether exponentiate coefficients (related confidence intervals). typical logistic regression, generally speaking, models log logit links. also recommended use exponentiate = TRUE models log-transformed response values. Note: Delta-method standard errors also computed (multiplying standard errors transformed coefficients). mimic behaviour software packages, Stata, standard errors poorly estimate uncertainty transformed coefficient. transformed confidence interval clearly captures uncertainty. compare_parameters(), exponentiate = \"nongaussian\" exponentiate coefficients non-Gaussian families. p_adjust Character vector, NULL, indicates method adjust p-values. See stats::p.adjust() details. possible adjustment methods \"tukey\", \"scheffe\", \"sidak\" \"none\" explicitly disable adjustment emmGrid objects (emmeans). summary Logical, TRUE, prints summary information model (model formula, number observations, residual standard deviation ). keep Character containing regular expression pattern describes parameters included (keep) excluded (drop) returned data frame. keep may also named list regular expressions. non-matching parameters removed output. keep character vector, every parameter name \"Parameter\" column matches regular expression keep selected returned data frame (vice versa, parameter names matching drop excluded). Furthermore, keep one element, merged operator regular expression pattern like : \"(one|two|three)\". keep named list regular expression patterns, names list-element equal column name selection applied. useful model objects model_parameters() returns multiple columns parameter components, like model_parameters.lavaan(). Note regular expression pattern match parameter names stored returned data frame, can different printed. Inspect $Parameter column parameters table get exact parameter names. drop See keep. verbose Toggle warnings messages. vcov Variance-covariance matrix used compute uncertainty estimates (e.g., robust standard errors). argument accepts covariance matrix, function returns covariance matrix, string identifies function used compute covariance matrix. covariance matrix function returns covariance matrix (e.g., stats::vcov()) string indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"vcovHC\", \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC. Cluster-robust: \"vcovCR\", \"CR0\", \"CR1\", \"CR1p\", \"CR1S\", \"CR2\", \"CR3\". See ?clubSandwich::vcovCR. Bootstrap: \"vcovBS\", \"xy\", \"residual\", \"wild\", \"mammen\", \"webb\". See ?sandwich::vcovBS. sandwich package functions: \"vcovHAC\", \"vcovPC\", \"vcovCL\", \"vcovPL\". vcov_args List arguments passed function identified vcov argument. function typically supplied sandwich clubSandwich packages. Please refer documentation (e.g., ?sandwich::vcovHAC) see list available arguments. ... Arguments passed methods. instance, bootstrap = TRUE, arguments like type parallel passed bootstrap_model(), arguments like ci_method passed bayestestR::describe_posterior(). df_method Deprecated. Please use ci_method.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.default.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parameters from (General) Linear Models — model_parameters.default","text":"data frame indices related model's parameters.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.default.html","id":"confidence-intervals-and-approximation-of-degrees-of-freedom","dir":"Reference","previous_headings":"","what":"Confidence intervals and approximation of degrees of freedom","title":"Parameters from (General) Linear Models — model_parameters.default","text":"different ways approximating degrees freedom depending different assumptions nature model sampling distribution. ci_method argument modulates method computing degrees freedom (df) used calculate confidence intervals (CI) related p-values. Following options allowed, depending model class: Classical methods: Classical inference generally based Wald method. Wald approach inference computes test statistic dividing parameter estimate standard error (Coefficient / SE), comparing statistic t- normal distribution. approach can used compute CIs p-values. \"wald\": Applies non-Bayesian models. linear models, CIs computed using Wald method (SE t-distribution residual df); p-values computed using Wald method t-distribution residual df. models, CIs computed using Wald method (SE normal distribution); p-values computed using Wald method normal distribution. \"normal\" Applies non-Bayesian models. Compute Wald CIs p-values, always use normal distribution. \"residual\" Applies non-Bayesian models. Compute Wald CIs p-values, always use t-distribution residual df possible. residual df model determined, normal distribution used instead. Methods mixed models: Compared fixed effects (single-level) models, determining appropriate df Wald-based inference mixed models difficult. See R GLMM FAQ discussion. Several approximate methods computing df available, also consider instead using profile likelihood (\"profile\") bootstrap (\"boot\") CIs p-values instead. \"satterthwaite\" Applies linear mixed models. CIs computed using Wald method (SE t-distribution Satterthwaite df); p-values computed using Wald method t-distribution Satterthwaite df. \"kenward\" Applies linear mixed models. CIs computed using Wald method (Kenward-Roger SE t-distribution Kenward-Roger df); p-values computed using Wald method Kenward-Roger SE t-distribution Kenward-Roger df. \"ml1\" Applies linear mixed models. CIs computed using Wald method (SE t-distribution m-l-1 approximated df); p-values computed using Wald method t-distribution m-l-1 approximated df. See ci_ml1(). \"betwithin\" Applies linear mixed models generalized linear mixed models. CIs computed using Wald method (SE t-distribution -within df); p-values computed using Wald method t-distribution -within df. See ci_betwithin(). Likelihood-based methods: Likelihood-based inference based comparing likelihood maximum-likelihood estimate likelihood models one parameter values changed (e.g., set zero range alternative values). Likelihood ratios maximum-likelihood alternative models compared \\(\\chi\\)-squared distribution compute CIs p-values. \"profile\" Applies non-Bayesian models class glm, polr glmmTMB. CIs computed profiling likelihood curve parameter, using linear interpolation find likelihood ratio equals critical value; p-values computed using Wald method normal-distribution (note: might change future update!) \"uniroot\" Applies non-Bayesian models class glmmTMB. CIs computed profiling likelihood curve parameter, using root finding find likelihood ratio equals critical value; p-values computed using Wald method normal-distribution (note: might change future update!) Methods bootstrapped Bayesian models: Bootstrap-based inference based resampling refitting model resampled datasets. distribution parameter estimates across resampled datasets used approximate parameter's sampling distribution. Depending type model, several different methods bootstrapping constructing CIs p-values bootstrap distribution available. Bayesian models, inference based drawing samples model posterior distribution. \"quantile\" (\"eti\") Applies models (including Bayesian models). non-Bayesian models, applies bootstrap = TRUE. CIs computed equal tailed intervals using quantiles bootstrap posterior samples; p-values based probability direction. See bayestestR::eti(). \"hdi\" Applies models (including Bayesian models). non-Bayesian models, applies bootstrap = TRUE. CIs computed highest density intervals bootstrap posterior samples; p-values based probability direction. See bayestestR::hdi(). \"bci\" (\"bcai\") Applies models (including Bayesian models). non-Bayesian models, applies bootstrap = TRUE. CIs computed bias corrected accelerated intervals bootstrap posterior samples; p-values based probability direction. See bayestestR::bci(). \"si\" Applies Bayesian models proper priors. CIs computed support intervals comparing posterior samples prior samples; p-values based probability direction. See bayestestR::si(). \"boot\" Applies non-Bayesian models class merMod. CIs computed using parametric bootstrapping (simulating data fitted model); p-values computed using Wald method normal-distribution) (note: might change future update!). iteration-based methods \"boot\" (\"hdi\", \"quantile\", \"ci\", \"eti\", \"si\", \"bci\", \"bcai\"), p-values based probability direction (bayestestR::p_direction()), converted p-value using bayestestR::pd_to_p().","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/model_parameters.default.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parameters from (General) Linear Models — model_parameters.default","text":"","code":"library(parameters) model <- lm(mpg ~ wt + cyl, data = mtcars)  model_parameters(model) #> Parameter   | Coefficient |   SE |         95% CI | t(29) |      p #> ------------------------------------------------------------------ #> (Intercept) |       39.69 | 1.71 | [36.18, 43.19] | 23.14 | < .001 #> wt          |       -3.19 | 0.76 | [-4.74, -1.64] | -4.22 | < .001 #> cyl         |       -1.51 | 0.41 | [-2.36, -0.66] | -3.64 | 0.001  #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) computed #>   using a Wald t-distribution approximation.  # bootstrapped parameters if (require(\"boot\", quietly = TRUE)) {   model_parameters(model, bootstrap = TRUE) } #>  #> Attaching package: ‘boot’ #> The following object is masked from ‘package:survival’: #>  #>     aml #> The following object is masked from ‘package:psych’: #>  #>     logit #> Parameter   | Coefficient |         95% CI |      p #> --------------------------------------------------- #> (Intercept) |       39.60 | [35.41, 43.88] | < .001 #> wt          |       -3.23 | [-4.85, -1.92] | < .001 #> cyl         |       -1.47 | [-2.18, -0.75] | 0.002  #>  #> Uncertainty intervals (equal-tailed) are naıve bootstrap intervals.  # standardized parameters model_parameters(model, standardize = \"refit\") #> Parameter   | Coefficient |   SE |         95% CI |    t(29) |      p #> --------------------------------------------------------------------- #> (Intercept) |    4.90e-17 | 0.08 | [-0.15,  0.15] | 6.50e-16 | > .999 #> wt          |       -0.52 | 0.12 | [-0.77, -0.27] |    -4.22 | < .001 #> cyl         |       -0.45 | 0.12 | [-0.70, -0.20] |    -3.64 | 0.001  #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) computed #>   using a Wald t-distribution approximation.  # robust, heteroskedasticity-consistent standard errors if (require(\"sandwich\") && require(\"clubSandwich\")) {   model_parameters(model, vcov = \"HC3\")    model_parameters(model,     vcov = \"vcovCL\",     vcov_args = list(cluster = mtcars$cyl)   ) } #> Loading required package: sandwich #> Loading required package: clubSandwich #> Parameter   | Coefficient |   SE |         95% CI | t(29) |      p #> ------------------------------------------------------------------ #> (Intercept) |       39.69 | 1.50 | [36.61, 42.76] | 26.43 | < .001 #> wt          |       -3.19 | 1.20 | [-5.65, -0.73] | -2.65 | 0.013  #> cyl         |       -1.51 | 0.40 | [-2.32, -0.70] | -3.82 | < .001 #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) computed #>   using a Wald t-distribution approximation.  # different p-value style in output model_parameters(model, p_digits = 5) #> Parameter   | Coefficient |   SE |         95% CI | t(29) |           p #> ----------------------------------------------------------------------- #> (Intercept) |       39.69 | 1.71 | [36.18, 43.19] | 23.14 | 3.04318e-20 #> wt          |       -3.19 | 0.76 | [-4.74, -1.64] | -4.22 | 0.00022     #> cyl         |       -1.51 | 0.41 | [-2.36, -0.66] | -3.64 | 0.00106     #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) computed #>   using a Wald t-distribution approximation. model_parameters(model, digits = 3, ci_digits = 4, p_digits = \"scientific\") #> Parameter   | Coefficient |    SE |             95% CI |  t(29) |           p #> ----------------------------------------------------------------------------- #> (Intercept) |      39.686 | 1.715 | [36.1787, 43.1938] | 23.141 | 3.04318e-20 #> wt          |      -3.191 | 0.757 | [-4.7390, -1.6429] | -4.216 | 2.22020e-04 #> cyl         |      -1.508 | 0.415 | [-2.3559, -0.6597] | -3.636 | 1.06428e-03 #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) computed #>   using a Wald t-distribution approximation. # \\donttest{ # logistic regression model model <- glm(vs ~ wt + cyl, data = mtcars, family = \"binomial\") model_parameters(model) #> Parameter   | Log-Odds |   SE |         95% CI |     z |     p #> -------------------------------------------------------------- #> (Intercept) |    10.62 | 4.17 | [ 4.79, 22.66] |  2.55 | 0.011 #> wt          |     2.10 | 1.55 | [-0.53,  6.24] |  1.36 | 0.174 #> cyl         |    -2.93 | 1.38 | [-6.92, -1.07] | -2.12 | 0.034 #>  #> Uncertainty intervals (profile-likelihood) and p-values (two-tailed) #>   computed using a Wald z-distribution approximation. #>  #> The model has a log- or logit-link. Consider using `exponentiate = TRUE` #>   to interpret coefficients as ratios.  # show odds ratio / exponentiated coefficients model_parameters(model, exponentiate = TRUE) #> Parameter   | Odds Ratio |       SE |             95% CI |     z |     p #> ------------------------------------------------------------------------ #> (Intercept) |   40911.34 | 1.71e+05 | [120.16, 6.95e+09] |  2.55 | 0.011 #> wt          |       8.17 |    12.63 | [  0.59,   514.10] |  1.36 | 0.174 #> cyl         |       0.05 |     0.07 | [  0.00,     0.34] | -2.12 | 0.034 #>  #> Uncertainty intervals (profile-likelihood) and p-values (two-tailed) #>   computed using a Wald z-distribution approximation. # }"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.htest.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameters from hypothesis tests — model_parameters.htest","title":"Parameters from hypothesis tests — model_parameters.htest","text":"Parameters h-tests (correlations, t-tests, chi-squared, ...).","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.htest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parameters from hypothesis tests — model_parameters.htest","text":"","code":"# S3 method for htest model_parameters(   model,   cramers_v = NULL,   phi = NULL,   standardized_d = NULL,   hedges_g = NULL,   omega_squared = NULL,   eta_squared = NULL,   epsilon_squared = NULL,   cohens_g = NULL,   rank_biserial = NULL,   rank_epsilon_squared = NULL,   kendalls_w = NULL,   ci = 0.95,   alternative = NULL,   bootstrap = FALSE,   verbose = TRUE,   ... )  # S3 method for pairwise.htest model_parameters(model, verbose = TRUE, ...)  # S3 method for coeftest model_parameters(model, ci = 0.95, ci_method = \"wald\", verbose = TRUE, ...)"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.htest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameters from hypothesis tests — model_parameters.htest","text":"model Object class htest pairwise.htest. cramers_v, phi Compute Cramer's V phi index effect size. Can \"raw\" \"adjusted\" (effect size bias-corrected). applies objects chisq.test(). standardized_d TRUE, compute standardized d index effect size. applies objects t.test(). Calculation d based t-value (see effectsize::t_to_d()) details. hedges_g TRUE, compute Hedge's g index effect size. applies objects t.test(). omega_squared, eta_squared, epsilon_squared Logical, TRUE, returns non-partial effect size Omega, Eta Epsilon squared. applies objects oneway.test(). cohens_g TRUE, compute Cohen's g index effect size. applies objects mcnemar.test(). rank_biserial TRUE, compute rank-biserial correlation effect size measure. applies objects wilcox.test(). rank_epsilon_squared TRUE, compute rank epsilon squared effect size measure. applies objects kruskal.test(). kendalls_w TRUE, compute Kendall's coefficient concordance effect size measure. applies objects friedman.test(). ci Level confidence intervals effect size statistic. Currently applies objects chisq.test() oneway.test(). alternative character string specifying alternative hypothesis; Controls type CI returned: \"two.sided\" (default, two-sided CI), \"greater\" \"less\" (one-sided CI). Partial matching allowed (e.g., \"g\", \"l\", \"two\"...). See section One-Sided CIs effectsize_CIs vignette. bootstrap estimates bootstrapped? verbose Toggle warnings messages. ... Arguments passed methods. ci_method Method computing degrees freedom confidence intervals (CI) related p-values. Allowed following options (vary depending model class): \"residual\", \"normal\", \"likelihood\", \"satterthwaite\", \"kenward\", \"wald\", \"profile\", \"boot\", \"uniroot\", \"ml1\", \"betwithin\", \"hdi\", \"quantile\", \"ci\", \"eti\", \"si\", \"bci\", \"bcai\". See section Confidence intervals approximation degrees freedom model_parameters() details. ci_method=NULL, cases \"wald\" used .","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.htest.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parameters from hypothesis tests — model_parameters.htest","text":"data frame indices related model's parameters.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.htest.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parameters from hypothesis tests — model_parameters.htest","text":"","code":"model <- cor.test(mtcars$mpg, mtcars$cyl, method = \"pearson\") model_parameters(model) #> Pearson's product-moment correlation #>  #> Parameter1 | Parameter2 |     r |         95% CI | t(30) |      p #> ----------------------------------------------------------------- #> mtcars$mpg | mtcars$cyl | -0.85 | [-0.93, -0.72] | -8.92 | < .001 #>  #> Alternative hypothesis: true correlation is not equal to 0  model <- t.test(iris$Sepal.Width, iris$Sepal.Length) model_parameters(model, hedges_g = TRUE) #> Welch Two Sample t-test #>  #> Parameter1       |        Parameter2 | Mean_Parameter1 | Mean_Parameter2 | Difference |         95% CI | t(225.68) | Hedges_g |       g 95% CI |      p #> ------------------------------------------------------------------------------------------------------------------------------------------------------- #> iris$Sepal.Width | iris$Sepal.Length |            3.06 |            5.84 |      -2.79 | [-2.94, -2.64] |    -36.46 |    -4.20 | [-4.64, -3.75] | < .001 #>  #> Alternative hypothesis: true difference in means is not equal to 0  model <- t.test(mtcars$mpg ~ mtcars$vs) model_parameters(model, hedges_g = TRUE) #> Welch Two Sample t-test #>  #> Parameter  |     Group | Mean_Group1 | Mean_Group2 | Difference |          95% CI | t(22.72) | Hedges_g |       g 95% CI |      p #> --------------------------------------------------------------------------------------------------------------------------------- #> mtcars$mpg | mtcars$vs |       16.62 |       24.56 |      -7.94 | [-11.46, -4.42] |    -4.67 |    -1.64 | [-2.46, -0.79] | < .001 #>  #> Alternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0  model <- t.test(iris$Sepal.Width, mu = 1) model_parameters(model, standardized_d = TRUE) #> One Sample t-test #>  #> Parameter        |   mu | Difference |       95% CI | t(149) | Cohen's d |     d 95% CI |      p #> ------------------------------------------------------------------------------------------------ #> iris$Sepal.Width | 1.00 |       2.06 | [2.99, 3.13] |  57.81 |      4.72 | [4.15, 5.27] | < .001 #>  #> Alternative hypothesis: true mean is not equal to 1  data(airquality) airquality$Month <- factor(airquality$Month, labels = month.abb[5:9]) model <- pairwise.t.test(airquality$Ozone, airquality$Month) model_parameters(model) #> # Fixed Effects #>  #> Group1 | Group2 |      p #> ------------------------ #> Jun    |    May | > .999 #> Jul    |    May | < .001 #> Jul    |    Jun | 0.051  #> Aug    |    May | < .001 #> Aug    |    Jun | 0.050  #> Aug    |    Jul | > .999 #> Sep    |    May | > .999 #> Sep    |    Jun | > .999 #> Sep    |    Jul | 0.005  #> Sep    |    Aug | 0.004  #>  #> p-value adjustment method: Holm (1979)  smokers <- c(83, 90, 129, 70) patients <- c(86, 93, 136, 82) model <- pairwise.prop.test(smokers, patients) #> Warning: Chi-squared approximation may be incorrect #> Warning: Chi-squared approximation may be incorrect #> Warning: Chi-squared approximation may be incorrect model_parameters(model) #> # Fixed Effects #>  #> Group1 | Group2 |      p #> ------------------------ #> 2      |      1 | > .999 #> 3      |      1 | > .999 #> 3      |      2 | > .999 #> 4      |      1 | 0.119  #> 4      |      2 | 0.093  #> 4      |      3 | 0.124  #>  #> p-value adjustment method: Holm (1979)  model <- stats::chisq.test(table(mtcars$am, mtcars$cyl)) #> Warning: Chi-squared approximation may be incorrect model_parameters(model, cramers_v = \"adjusted\") #> Pearson's Chi-squared test #>  #> Chi2(2) | Cramer's V (adj.) | Cramers 95% CI |     p #> ---------------------------------------------------- #> 8.74    |              0.46 |   [0.00, 1.00] | 0.013"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.html","id":null,"dir":"Reference","previous_headings":"","what":"Model Parameters — model_parameters","title":"Model Parameters — model_parameters","text":"Compute extract model parameters. available options arguments depend modeling package model class. Follow one links read model-specific documentation: Default method: lm, glm, stats, censReg, MASS, survey, ... Additive models: bamlss, gamlss, mgcv, scam, VGAM, Gam, gamm, ... ANOVA: afex, aov, anova, ... Bayesian: BayesFactor, blavaan, brms, MCMCglmm, posterior, rstanarm, bayesQR, bcplm, BGGM, blmrm, blrm, mcmc.list, MCMCglmm, ... Clustering: hclust, kmeans, mclust, pam, ... Correlations, t-tests, etc.: lmtest, htest, pairwise.htest, ... Meta-Analysis: metaBMA, metafor, metaplus, ... Mixed models: cplm, glmmTMB, lme4, lmerTest, nlme, ordinal, robustlmm, spaMM, mixed, MixMod, ... Multinomial, ordinal cumulative link: brglm2, DirichletReg, nnet, ordinal, mlm, ... Multiple imputation: mice PCA, FA, CFA, SEM: FactoMineR, lavaan, psych, sem, ... Zero-inflated hurdle: cplm, mhurdle, pscl, ... models: aod, bbmle, betareg, emmeans, epiR, ggeffects, glmx, ivfixed, ivprobit, JRM, lmodel2, logitsf, marginaleffects, margins, maxLik, mediation, mfx, multcomp, mvord, plm, PMCMRplus, quantreg, selection, systemfit, tidymodels, varEST, WRS2, bfsl, deltaMethod, fitdistr, mjoint, mle, model.avg, ...","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Model Parameters — model_parameters","text":"","code":"model_parameters(model, ...)  parameters(model, ...)"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Model Parameters — model_parameters","text":"model Statistical Model. ... Arguments passed methods. Non-documented arguments digits, p_digits, ci_digits footer_digits set number digits output. group can also passed print() method. See details print.parameters_model() 'Examples' model_parameters.default().","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Model Parameters — model_parameters","text":"data frame indices related model's parameters.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Model Parameters — model_parameters","text":"print() method several arguments tweak output. also plot()-method implemented see-package, dedicated method use inside rmarkdown files, print_md(). developers, speed performance issue, can use (undocumented) pretty_names argument, e.g. model_parameters(..., pretty_names = FALSE). skip formatting coefficient names make model_parameters() faster.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.html","id":"standardization-of-model-coefficients","dir":"Reference","previous_headings":"","what":"Standardization of model coefficients","title":"Model Parameters — model_parameters","text":"Standardization based standardize_parameters(). case standardize = \"refit\", data used fit model standardized model completely refitted. cases, standard errors confidence intervals refer standardized coefficient. default, standardize = \"refit\", never standardizes categorical predictors (.e. factors), may different behaviour compared R packages software packages (like SPSS). mimic behaviour SPSS packages lm.beta, use standardize = \"basic\".","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.html","id":"standardization-methods","dir":"Reference","previous_headings":"","what":"Standardization Methods","title":"Model Parameters — model_parameters","text":"refit: method based complete model re-fit standardized version data. Hence, method equal standardizing variables fitting model. \"purest\" accurate (Neter et al., 1989), also computationally costly long (especially heavy models Bayesian models). method particularly recommended complex models include interactions transformations (e.g., polynomial spline terms). robust (default FALSE) argument enables robust standardization data, .e., based median MAD instead mean SD. See standardize() details. Note standardize_parameters(method = \"refit\") may return results fitting model data standardized standardize(); standardize_parameters() used data used model fitting function, might data missing values. see remove_na argument standardize(). posthoc: Post-hoc standardization parameters, aiming emulating results obtained \"refit\" without refitting model. coefficients divided standard deviation (MAD robust) outcome (becomes expression 'unit'). , coefficients related numeric variables additionally multiplied standard deviation (MAD robust) related terms, correspond changes 1 SD predictor (e.g., \"change 1 SD x related change 0.24 SD y). apply binary variables factors, coefficients still related changes levels. method accurate tend give aberrant results interactions specified. basic: method similar method = \"posthoc\", treats variables continuous: also scales coefficient standard deviation model's matrix' parameter factors levels (transformed integers) binary predictors. Although inappropriate cases, method one implemented default software packages, lm.beta::lm.beta(). smart (Standardization Model's parameters Adjustment, Reconnaissance Transformation - experimental): Similar method = \"posthoc\" involve model refitting. difference SD (MAD robust) response computed relevant section data. instance, factor 3 levels (intercept), B C entered predictor, effect corresponding B vs. scaled variance response intercept . results, coefficients effects factors similar Glass' delta. pseudo (2-level (G)LMMs ): (post-hoc) method, response predictor standardized based level prediction (levels detected performance::check_heterogeneity_bias()): Predictors standardized based SD level prediction (see also datawizard::demean()); outcome (linear LMMs) standardized based fitted random-intercept-model, sqrt(random-intercept-variance) used level 2 predictors, sqrt(residual-variance) used level 1 predictors (Hoffman 2015, page 342). warning given within-group variable found access -group variance.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.html","id":"labeling-the-degrees-of-freedom","dir":"Reference","previous_headings":"","what":"Labeling the Degrees of Freedom","title":"Model Parameters — model_parameters","text":"Throughout parameters package, decided label residual degrees freedom df_error. reason degrees freedom always refer residuals. certain models, refer estimate error - linear model , - instance - mixed effects model, strictly true. Hence, think df_error generic label degrees freedom.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.html","id":"confidence-intervals-and-approximation-of-degrees-of-freedom","dir":"Reference","previous_headings":"","what":"Confidence intervals and approximation of degrees of freedom","title":"Model Parameters — model_parameters","text":"different ways approximating degrees freedom depending different assumptions nature model sampling distribution. ci_method argument modulates method computing degrees freedom (df) used calculate confidence intervals (CI) related p-values. Following options allowed, depending model class: Classical methods: Classical inference generally based Wald method. Wald approach inference computes test statistic dividing parameter estimate standard error (Coefficient / SE), comparing statistic t- normal distribution. approach can used compute CIs p-values. \"wald\": Applies non-Bayesian models. linear models, CIs computed using Wald method (SE t-distribution residual df); p-values computed using Wald method t-distribution residual df. models, CIs computed using Wald method (SE normal distribution); p-values computed using Wald method normal distribution. \"normal\" Applies non-Bayesian models. Compute Wald CIs p-values, always use normal distribution. \"residual\" Applies non-Bayesian models. Compute Wald CIs p-values, always use t-distribution residual df possible. residual df model determined, normal distribution used instead. Methods mixed models: Compared fixed effects (single-level) models, determining appropriate df Wald-based inference mixed models difficult. See R GLMM FAQ discussion. Several approximate methods computing df available, also consider instead using profile likelihood (\"profile\") bootstrap (\"boot\") CIs p-values instead. \"satterthwaite\" Applies linear mixed models. CIs computed using Wald method (SE t-distribution Satterthwaite df); p-values computed using Wald method t-distribution Satterthwaite df. \"kenward\" Applies linear mixed models. CIs computed using Wald method (Kenward-Roger SE t-distribution Kenward-Roger df); p-values computed using Wald method Kenward-Roger SE t-distribution Kenward-Roger df. \"ml1\" Applies linear mixed models. CIs computed using Wald method (SE t-distribution m-l-1 approximated df); p-values computed using Wald method t-distribution m-l-1 approximated df. See ci_ml1(). \"betwithin\" Applies linear mixed models generalized linear mixed models. CIs computed using Wald method (SE t-distribution -within df); p-values computed using Wald method t-distribution -within df. See ci_betwithin(). Likelihood-based methods: Likelihood-based inference based comparing likelihood maximum-likelihood estimate likelihood models one parameter values changed (e.g., set zero range alternative values). Likelihood ratios maximum-likelihood alternative models compared \\(\\chi\\)-squared distribution compute CIs p-values. \"profile\" Applies non-Bayesian models class glm, polr glmmTMB. CIs computed profiling likelihood curve parameter, using linear interpolation find likelihood ratio equals critical value; p-values computed using Wald method normal-distribution (note: might change future update!) \"uniroot\" Applies non-Bayesian models class glmmTMB. CIs computed profiling likelihood curve parameter, using root finding find likelihood ratio equals critical value; p-values computed using Wald method normal-distribution (note: might change future update!) Methods bootstrapped Bayesian models: Bootstrap-based inference based resampling refitting model resampled datasets. distribution parameter estimates across resampled datasets used approximate parameter's sampling distribution. Depending type model, several different methods bootstrapping constructing CIs p-values bootstrap distribution available. Bayesian models, inference based drawing samples model posterior distribution. \"quantile\" (\"eti\") Applies models (including Bayesian models). non-Bayesian models, applies bootstrap = TRUE. CIs computed equal tailed intervals using quantiles bootstrap posterior samples; p-values based probability direction. See bayestestR::eti(). \"hdi\" Applies models (including Bayesian models). non-Bayesian models, applies bootstrap = TRUE. CIs computed highest density intervals bootstrap posterior samples; p-values based probability direction. See bayestestR::hdi(). \"bci\" (\"bcai\") Applies models (including Bayesian models). non-Bayesian models, applies bootstrap = TRUE. CIs computed bias corrected accelerated intervals bootstrap posterior samples; p-values based probability direction. See bayestestR::bci(). \"si\" Applies Bayesian models proper priors. CIs computed support intervals comparing posterior samples prior samples; p-values based probability direction. See bayestestR::si(). \"boot\" Applies non-Bayesian models class merMod. CIs computed using parametric bootstrapping (simulating data fitted model); p-values computed using Wald method normal-distribution) (note: might change future update!). iteration-based methods \"boot\" (\"hdi\", \"quantile\", \"ci\", \"eti\", \"si\", \"bci\", \"bcai\"), p-values based probability direction (bayestestR::p_direction()), converted p-value using bayestestR::pd_to_p().","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.html","id":"interpretation-of-interaction-terms","dir":"Reference","previous_headings":"","what":"Interpretation of Interaction Terms","title":"Model Parameters — model_parameters","text":"Note interpretation interaction terms depends many characteristics model. number parameters, overall performance model, can differ * b : b, / b, suggesting sometimes interaction terms give different parameterizations model, times gives completely different models (depending b factors covariates, included main effects , etc.). interpretation depends full context model, inferred parameters table alone - rather, recommend use packages calculate estimated marginal means marginal effects, modelbased, emmeans, ggeffects, marginaleffects. raise awareness issue, may use print(...,show_formula=TRUE) add model-specification output print() method model_parameters().","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.html","id":"global-options-to-customize-messages-when-printing","dir":"Reference","previous_headings":"","what":"Global Options to Customize Messages when Printing","title":"Model Parameters — model_parameters","text":"verbose argument can used display silence messages warnings different functions parameters package. However, messages providing additional information can displayed suppressed using options(): parameters_summary: options(parameters_summary = TRUE) override summary argument model_parameters() always show model summary non-mixed models. parameters_mixed_summary: options(parameters_mixed_summary = TRUE) override summary argument model_parameters() mixed models, always show model summary. parameters_cimethod: options(parameters_cimethod = TRUE) show additional information approximation method used calculate confidence intervals p-values. Set FALSE hide message printing model_parameters() objects. parameters_exponentiate: options(parameters_exponentiate = TRUE) show additional information interpret coefficients models log-transformed response variables log-/logit-links exponentiate argument model_parameters() TRUE. Set option FALSE hide message printing model_parameters() objects.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Model Parameters — model_parameters","text":"Hoffman, L. (2015). Longitudinal analysis: Modeling within-person fluctuation change. Routledge. Neter, J., Wasserman, W., & Kutner, M. H. (1989). Applied linear regression models.","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/model_parameters.kmeans.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameters from Cluster Models (k-means, ...) — model_parameters.dbscan","title":"Parameters from Cluster Models (k-means, ...) — model_parameters.dbscan","text":"Format cluster models obtained example kmeans().","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.kmeans.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parameters from Cluster Models (k-means, ...) — model_parameters.dbscan","text":"","code":"# S3 method for dbscan model_parameters(model, data = NULL, clusters = NULL, ...)  # S3 method for hclust model_parameters(model, data = NULL, clusters = NULL, ...)  # S3 method for pvclust model_parameters(model, data = NULL, clusters = NULL, ci = 0.95, ...)  # S3 method for kmeans model_parameters(model, ...)  # S3 method for hkmeans model_parameters(model, ...)  # S3 method for Mclust model_parameters(model, data = NULL, clusters = NULL, ...)  # S3 method for pam model_parameters(model, data = NULL, clusters = NULL, ...)"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.kmeans.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameters from Cluster Models (k-means, ...) — model_parameters.dbscan","text":"model Cluster model. data data.frame. clusters vector clusters assignments (must length rows data). ... Arguments passed methods. ci Confidence Interval (CI) level. Default 0.95 (95%).","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.kmeans.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parameters from Cluster Models (k-means, ...) — model_parameters.dbscan","text":"","code":"# \\donttest{ # DBSCAN --------------------------- if (require(\"dbscan\", quietly = TRUE)) {   model <- dbscan::dbscan(iris[1:4], eps = 1.45, minPts = 10)    rez <- model_parameters(model, iris[1:4])   rez    # Get clusters   predict(rez)    # Clusters centers in long form   attributes(rez)$means    # Between and Total Sum of Squares   attributes(rez)$Sum_Squares_Total   attributes(rez)$Sum_Squares_Between    # HDBSCAN   model <- dbscan::hdbscan(iris[1:4], minPts = 10)   model_parameters(model, iris[1:4]) } #> # Clustering Solution #>  #> The 2 clusters accounted for 77.26% of the total variance of the original data. #>  #> Cluster | n_Obs | Sum_Squares | Sepal.Length | Sepal.Width | Petal.Length | Petal.Width #> --------------------------------------------------------------------------------------- #> 1       |   100 |      139.80 |         6.26 |        2.87 |         4.91 |        1.68 #> 2       |    50 |       15.15 |         5.01 |        3.43 |         1.46 |        0.25 # } # # Hierarchical clustering (hclust) --------------------------- data <- iris[1:4] model <- hclust(dist(data)) clusters <- cutree(model, 3)  rez <- model_parameters(model, data, clusters) rez #> # Clustering Solution #>  #> The 3 clusters accounted for 86.86% of the total variance of the original data. #>  #> Cluster | n_Obs | Sum_Squares | Sepal.Length | Sepal.Width | Petal.Length | Petal.Width #> --------------------------------------------------------------------------------------- #> 1       |    50 |       15.15 |         5.01 |        3.43 |         1.46 |        0.25 #> 2       |    72 |       64.62 |         6.55 |        2.96 |         5.27 |        1.85 #> 3       |    28 |        9.75 |         5.53 |        2.64 |         3.96 |        1.23  # Get clusters predict(rez) #>   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 #>  [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 3 2 3 2 3 2 3 3 3 3 2 3 2 3 3 2 3 2 3 2 2 #>  [75] 2 2 2 2 2 3 3 3 3 2 3 2 2 2 3 3 3 2 3 3 3 3 3 2 3 3 2 2 2 2 2 2 3 2 2 2 2 #> [112] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 #> [149] 2 2  # Clusters centers in long form attributes(rez)$means #>    Cluster n_Obs Sum_Squares     Variable     Mean #> 1        1    50   15.151000 Sepal.Length 5.006000 #> 2        1    50   15.151000  Sepal.Width 3.428000 #> 3        1    50   15.151000 Petal.Length 1.462000 #> 4        1    50   15.151000  Petal.Width 0.246000 #> 5        2    72   64.624722 Sepal.Length 6.545833 #> 6        2    72   64.624722  Sepal.Width 2.963889 #> 7        2    72   64.624722 Petal.Length 5.273611 #> 8        2    72   64.624722  Petal.Width 1.850000 #> 9        3    28    9.749286 Sepal.Length 5.532143 #> 10       3    28    9.749286  Sepal.Width 2.635714 #> 11       3    28    9.749286 Petal.Length 3.960714 #> 12       3    28    9.749286  Petal.Width 1.228571  # Between and Total Sum of Squares attributes(rez)$Total_Sum_Squares #> NULL attributes(rez)$Between_Sum_Squares #> NULL # \\donttest{ # # pvclust (finds \"significant\" clusters) --------------------------- if (require(\"pvclust\", quietly = TRUE)) {   data <- iris[1:4]   # NOTE: pvclust works on transposed data   model <- pvclust::pvclust(datawizard::data_transpose(data),     method.dist = \"euclidean\",     nboot = 50,     quiet = TRUE   )    rez <- model_parameters(model, data, ci = 0.90)   rez    # Get clusters   predict(rez)    # Clusters centers in long form   attributes(rez)$means    # Between and Total Sum of Squares   attributes(rez)$Sum_Squares_Total   attributes(rez)$Sum_Squares_Between } #> [1] 280.8487 # } if (FALSE) { # # K-means ------------------------------- model <- kmeans(iris[1:4], centers = 3) rez <- model_parameters(model) rez  # Get clusters predict(rez)  # Clusters centers in long form attributes(rez)$means  # Between and Total Sum of Squares attributes(rez)$Sum_Squares_Total attributes(rez)$Sum_Squares_Between } if (FALSE) { # # Hierarchical K-means (factoextra::hkclust) ---------------------- if (require(\"factoextra\", quietly = TRUE)) {   data <- iris[1:4]   model <- factoextra::hkmeans(data, k = 3)    rez <- model_parameters(model)   rez    # Get clusters   predict(rez)    # Clusters centers in long form   attributes(rez)$means    # Between and Total Sum of Squares   attributes(rez)$Sum_Squares_Total   attributes(rez)$Sum_Squares_Between } } if (require(\"mclust\", quietly = TRUE)) {   model <- mclust::Mclust(iris[1:4], verbose = FALSE)   model_parameters(model) } #> # Clustering Solution #>  #> The 2 clusters accounted for 77.26% of the total variance of the original data. #>  #> Cluster | n_Obs | Sum_Squares | Sepal.Length | Sepal.Width | Petal.Length | Petal.Width #> --------------------------------------------------------------------------------------- #> 1       |    50 |       15.15 |         5.01 |        3.43 |         1.46 |        0.25 #> 2       |   100 |      139.80 |         6.26 |        2.87 |         4.91 |        1.68 if (FALSE) { # # K-Medoids (PAM and HPAM) ============== if (require(\"cluster\", quietly = TRUE)) {   model <- cluster::pam(iris[1:4], k = 3)   model_parameters(model) } if (require(\"fpc\", quietly = TRUE)) {   model <- fpc::pamk(iris[1:4], criterion = \"ch\")   model_parameters(model) } }"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.merMod.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameters from Mixed Models — model_parameters.cpglmm","title":"Parameters from Mixed Models — model_parameters.cpglmm","text":"Parameters (linear) mixed models.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.merMod.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parameters from Mixed Models — model_parameters.cpglmm","text":"","code":"# S3 method for cpglmm model_parameters(   model,   ci = 0.95,   ci_method = NULL,   ci_random = NULL,   bootstrap = FALSE,   iterations = 1000,   standardize = NULL,   effects = \"all\",   group_level = FALSE,   exponentiate = FALSE,   p_adjust = NULL,   include_sigma = FALSE,   verbose = TRUE,   df_method = ci_method,   ... )  # S3 method for glmmTMB model_parameters(   model,   ci = 0.95,   ci_method = \"wald\",   ci_random = NULL,   bootstrap = FALSE,   iterations = 1000,   standardize = NULL,   effects = \"all\",   component = \"all\",   group_level = FALSE,   exponentiate = FALSE,   p_adjust = NULL,   wb_component = TRUE,   summary = getOption(\"parameters_mixed_summary\", FALSE),   keep = NULL,   drop = NULL,   verbose = TRUE,   df_method = ci_method,   include_sigma = FALSE,   ... )  # S3 method for merMod model_parameters(   model,   ci = 0.95,   ci_method = NULL,   ci_random = NULL,   bootstrap = FALSE,   iterations = 1000,   standardize = NULL,   effects = \"all\",   group_level = FALSE,   exponentiate = FALSE,   p_adjust = NULL,   wb_component = TRUE,   summary = getOption(\"parameters_mixed_summary\", FALSE),   keep = NULL,   drop = NULL,   verbose = TRUE,   df_method = ci_method,   include_sigma = FALSE,   vcov = NULL,   vcov_args = NULL,   ... )  # S3 method for merModList model_parameters(   model,   ci = 0.95,   exponentiate = FALSE,   p_adjust = NULL,   verbose = TRUE,   ... )  # S3 method for mixed model_parameters(   model,   ci = 0.95,   ci_method = \"wald\",   ci_random = NULL,   bootstrap = FALSE,   iterations = 1000,   standardize = NULL,   effects = \"all\",   component = \"all\",   group_level = FALSE,   exponentiate = FALSE,   p_adjust = NULL,   wb_component = TRUE,   summary = getOption(\"parameters_mixed_summary\", FALSE),   keep = NULL,   drop = NULL,   verbose = TRUE,   df_method = ci_method,   include_sigma = FALSE,   ... )  # S3 method for MixMod model_parameters(   model,   ci = 0.95,   ci_method = \"wald\",   ci_random = NULL,   bootstrap = FALSE,   iterations = 1000,   standardize = NULL,   effects = \"all\",   component = \"all\",   group_level = FALSE,   exponentiate = FALSE,   p_adjust = NULL,   wb_component = TRUE,   summary = getOption(\"parameters_mixed_summary\", FALSE),   keep = NULL,   drop = NULL,   verbose = TRUE,   df_method = ci_method,   include_sigma = FALSE,   ... )  # S3 method for mixor model_parameters(   model,   ci = 0.95,   effects = \"all\",   bootstrap = FALSE,   iterations = 1000,   standardize = NULL,   exponentiate = FALSE,   verbose = TRUE,   include_sigma = FALSE,   ... )  # S3 method for lme model_parameters(   model,   ci = 0.95,   ci_method = NULL,   ci_random = NULL,   bootstrap = FALSE,   iterations = 1000,   standardize = NULL,   effects = \"all\",   group_level = FALSE,   exponentiate = FALSE,   p_adjust = NULL,   wb_component = TRUE,   summary = getOption(\"parameters_mixed_summary\", FALSE),   keep = NULL,   drop = NULL,   verbose = TRUE,   df_method = ci_method,   include_sigma = FALSE,   vcov = NULL,   vcov_args = NULL,   ... )  # S3 method for clmm2 model_parameters(   model,   ci = 0.95,   bootstrap = FALSE,   iterations = 1000,   component = c(\"all\", \"conditional\", \"scale\"),   standardize = NULL,   exponentiate = FALSE,   p_adjust = NULL,   verbose = TRUE,   ... )  # S3 method for clmm model_parameters(   model,   ci = 0.95,   ci_method = NULL,   ci_random = NULL,   bootstrap = FALSE,   iterations = 1000,   standardize = NULL,   effects = \"all\",   group_level = FALSE,   exponentiate = FALSE,   p_adjust = NULL,   include_sigma = FALSE,   verbose = TRUE,   df_method = ci_method,   ... )  # S3 method for rlmerMod model_parameters(   model,   ci = 0.95,   ci_method = NULL,   ci_random = NULL,   bootstrap = FALSE,   iterations = 1000,   standardize = NULL,   effects = \"all\",   group_level = FALSE,   exponentiate = FALSE,   p_adjust = NULL,   include_sigma = FALSE,   verbose = TRUE,   df_method = ci_method,   ... )  # S3 method for HLfit model_parameters(   model,   ci = 0.95,   ci_method = NULL,   bootstrap = FALSE,   iterations = 1000,   standardize = NULL,   exponentiate = FALSE,   p_adjust = NULL,   summary = getOption(\"parameters_summary\", FALSE),   keep = NULL,   drop = NULL,   verbose = TRUE,   vcov = NULL,   vcov_args = NULL,   ... )"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.merMod.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameters from Mixed Models — model_parameters.cpglmm","text":"model mixed model. ci Confidence Interval (CI) level. Default 0.95 (95%). ci_method Method computing degrees freedom confidence intervals (CI) related p-values. Allowed following options (vary depending model class): \"residual\", \"normal\", \"likelihood\", \"satterthwaite\", \"kenward\", \"wald\", \"profile\", \"boot\", \"uniroot\", \"ml1\", \"betwithin\", \"hdi\", \"quantile\", \"ci\", \"eti\", \"si\", \"bci\", \"bcai\". See section Confidence intervals approximation degrees freedom model_parameters() details. ci_method=NULL, cases \"wald\" used . ci_random Logical, TRUE, includes confidence intervals random effects parameters. applies effects \"fixed\" ci NULL. Set ci_random = FALSE computation model summary much time consuming. default, ci_random = NULL, uses heuristic guess computation confidence intervals random effects fast enough . models larger sample size /complex random effects structures, confidence intervals computed default, simpler models fewer observations, confidence intervals included. Set explicitly TRUE FALSE enforce omit calculation confidence intervals. bootstrap estimates based bootstrapped model? TRUE, arguments Bayesian regressions apply (see also bootstrap_parameters()). iterations number draws simulate/bootstrap. standardize method used standardizing parameters. Can NULL (default; standardization), \"refit\" (re-fitting model standardized data) one \"basic\", \"posthoc\", \"smart\", \"pseudo\". See 'Details' standardize_parameters(). Important: \"refit\" method standardized categorical predictors (.e. factors), may different behaviour compared R packages (lm.beta) software packages (like SPSS). mimic behaviours, either use standardize=\"basic\" standardize data datawizard::standardize(force=TRUE) fitting model. mixed models, using methods \"refit\", fixed effects returned. Robust estimation (.e., vcov set value NULL) standardized parameters works standardize=\"refit\". effects parameters fixed effects (\"fixed\"), random effects (\"random\"), (\"\") returned? applies mixed models. May abbreviated. calculation random effects parameters takes long, may use effects = \"fixed\". group_level Logical, multilevel models (.e. models random effects) effects = \"\" effects = \"random\", include parameters group level random effects. group_level = FALSE (default), information SD COR shown. exponentiate Logical, indicating whether exponentiate coefficients (related confidence intervals). typical logistic regression, generally speaking, models log logit links. also recommended use exponentiate = TRUE models log-transformed response values. Note: Delta-method standard errors also computed (multiplying standard errors transformed coefficients). mimic behaviour software packages, Stata, standard errors poorly estimate uncertainty transformed coefficient. transformed confidence interval clearly captures uncertainty. compare_parameters(), exponentiate = \"nongaussian\" exponentiate coefficients non-Gaussian families. p_adjust Character vector, NULL, indicates method adjust p-values. See stats::p.adjust() details. possible adjustment methods \"tukey\", \"scheffe\", \"sidak\" \"none\" explicitly disable adjustment emmGrid objects (emmeans). include_sigma Logical, TRUE, includes residual standard deviation. mixed models, defined sum distribution-specific variance variance additive overdispersion term (see insight::get_variance() details). Defaults FALSE mixed models due longer computation time. verbose Toggle warnings messages. df_method Deprecated. Please use ci_method. ... Arguments passed methods. component parameters, parameters conditional model, zero-inflated part model, dispersion model returned? Applies models zero-inflated /dispersion component. component may one \"conditional\", \"zi\", \"zero-inflated\", \"dispersion\" \"\" (default). May abbreviated. wb_component Logical, TRUE models contains within- -effects (see datawizard::demean()), Component column indicate variables belong within-effects, -effects, cross-level interactions. default, Component column indicates, parameters belong conditional zero-inflated component model. summary Logical, TRUE, prints summary information model (model formula, number observations, residual standard deviation ). keep Character containing regular expression pattern describes parameters included (keep) excluded (drop) returned data frame. keep may also named list regular expressions. non-matching parameters removed output. keep character vector, every parameter name \"Parameter\" column matches regular expression keep selected returned data frame (vice versa, parameter names matching drop excluded). Furthermore, keep one element, merged operator regular expression pattern like : \"(one|two|three)\". keep named list regular expression patterns, names list-element equal column name selection applied. useful model objects model_parameters() returns multiple columns parameter components, like model_parameters.lavaan(). Note regular expression pattern match parameter names stored returned data frame, can different printed. Inspect $Parameter column parameters table get exact parameter names. drop See keep. vcov Variance-covariance matrix used compute uncertainty estimates (e.g., robust standard errors). argument accepts covariance matrix, function returns covariance matrix, string identifies function used compute covariance matrix. covariance matrix function returns covariance matrix (e.g., stats::vcov()) string indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"vcovHC\", \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC. Cluster-robust: \"vcovCR\", \"CR0\", \"CR1\", \"CR1p\", \"CR1S\", \"CR2\", \"CR3\". See ?clubSandwich::vcovCR. Bootstrap: \"vcovBS\", \"xy\", \"residual\", \"wild\", \"mammen\", \"webb\". See ?sandwich::vcovBS. sandwich package functions: \"vcovHAC\", \"vcovPC\", \"vcovCL\", \"vcovPL\". vcov_args List arguments passed function identified vcov argument. function typically supplied sandwich clubSandwich packages. Please refer documentation (e.g., ?sandwich::vcovHAC) see list available arguments.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.merMod.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parameters from Mixed Models — model_parameters.cpglmm","text":"data frame indices related model's parameters.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.merMod.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Parameters from Mixed Models — model_parameters.cpglmm","text":"calculation random effects parameters takes long, may use effects = \"fixed\". also plot()-method implemented see-package.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.merMod.html","id":"confidence-intervals-for-random-effect-variances","dir":"Reference","previous_headings":"","what":"Confidence intervals for random effect variances","title":"Parameters from Mixed Models — model_parameters.cpglmm","text":"models class merMod glmmTMB, confidence intervals random effect variances can calculated. models package lme4, ci_method either \"profile\" \"boot\", effects either \"random\" \"\", profiled resp. bootstrapped confidence intervals computed random effects. options ci_method, merDeriv package installed, confidence intervals random effects based normal-distribution approximation, using delta-method transform standard errors constructing intervals around log-transformed SD parameters. back-transformed, random effect variances, standard errors confidence intervals shown original scale. Due transformation, intervals asymmetrical, however, within correct bounds (.e. negative interval SD, interval correlations within range -1 +1). models class glmmTMB, confidence intervals random effect variances always use Wald t-distribution approximation.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.merMod.html","id":"dispersion-parameters-in-glmmtmb","dir":"Reference","previous_headings":"","what":"Dispersion parameters in glmmTMB","title":"Parameters from Mixed Models — model_parameters.cpglmm","text":"models package glmmTMB, dispersion parameter residual variance random effects parameters shown. Usually, presented different scales, e.g.   models dispersion parameter residual variance , residual variance shown output.","code":"model <- glmmTMB(Sepal.Width ~ Petal.Length + (1|Species), data = iris) exp(fixef(model)$disp) # 0.09902987 sigma(model)^2         # 0.09902987"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.merMod.html","id":"confidence-intervals-and-approximation-of-degrees-of-freedom","dir":"Reference","previous_headings":"","what":"Confidence intervals and approximation of degrees of freedom","title":"Parameters from Mixed Models — model_parameters.cpglmm","text":"different ways approximating degrees freedom depending different assumptions nature model sampling distribution. ci_method argument modulates method computing degrees freedom (df) used calculate confidence intervals (CI) related p-values. Following options allowed, depending model class: Classical methods: Classical inference generally based Wald method. Wald approach inference computes test statistic dividing parameter estimate standard error (Coefficient / SE), comparing statistic t- normal distribution. approach can used compute CIs p-values. \"wald\": Applies non-Bayesian models. linear models, CIs computed using Wald method (SE t-distribution residual df); p-values computed using Wald method t-distribution residual df. models, CIs computed using Wald method (SE normal distribution); p-values computed using Wald method normal distribution. \"normal\" Applies non-Bayesian models. Compute Wald CIs p-values, always use normal distribution. \"residual\" Applies non-Bayesian models. Compute Wald CIs p-values, always use t-distribution residual df possible. residual df model determined, normal distribution used instead. Methods mixed models: Compared fixed effects (single-level) models, determining appropriate df Wald-based inference mixed models difficult. See R GLMM FAQ discussion. Several approximate methods computing df available, also consider instead using profile likelihood (\"profile\") bootstrap (\"boot\") CIs p-values instead. \"satterthwaite\" Applies linear mixed models. CIs computed using Wald method (SE t-distribution Satterthwaite df); p-values computed using Wald method t-distribution Satterthwaite df. \"kenward\" Applies linear mixed models. CIs computed using Wald method (Kenward-Roger SE t-distribution Kenward-Roger df); p-values computed using Wald method Kenward-Roger SE t-distribution Kenward-Roger df. \"ml1\" Applies linear mixed models. CIs computed using Wald method (SE t-distribution m-l-1 approximated df); p-values computed using Wald method t-distribution m-l-1 approximated df. See ci_ml1(). \"betwithin\" Applies linear mixed models generalized linear mixed models. CIs computed using Wald method (SE t-distribution -within df); p-values computed using Wald method t-distribution -within df. See ci_betwithin(). Likelihood-based methods: Likelihood-based inference based comparing likelihood maximum-likelihood estimate likelihood models one parameter values changed (e.g., set zero range alternative values). Likelihood ratios maximum-likelihood alternative models compared \\(\\chi\\)-squared distribution compute CIs p-values. \"profile\" Applies non-Bayesian models class glm, polr glmmTMB. CIs computed profiling likelihood curve parameter, using linear interpolation find likelihood ratio equals critical value; p-values computed using Wald method normal-distribution (note: might change future update!) \"uniroot\" Applies non-Bayesian models class glmmTMB. CIs computed profiling likelihood curve parameter, using root finding find likelihood ratio equals critical value; p-values computed using Wald method normal-distribution (note: might change future update!) Methods bootstrapped Bayesian models: Bootstrap-based inference based resampling refitting model resampled datasets. distribution parameter estimates across resampled datasets used approximate parameter's sampling distribution. Depending type model, several different methods bootstrapping constructing CIs p-values bootstrap distribution available. Bayesian models, inference based drawing samples model posterior distribution. \"quantile\" (\"eti\") Applies models (including Bayesian models). non-Bayesian models, applies bootstrap = TRUE. CIs computed equal tailed intervals using quantiles bootstrap posterior samples; p-values based probability direction. See bayestestR::eti(). \"hdi\" Applies models (including Bayesian models). non-Bayesian models, applies bootstrap = TRUE. CIs computed highest density intervals bootstrap posterior samples; p-values based probability direction. See bayestestR::hdi(). \"bci\" (\"bcai\") Applies models (including Bayesian models). non-Bayesian models, applies bootstrap = TRUE. CIs computed bias corrected accelerated intervals bootstrap posterior samples; p-values based probability direction. See bayestestR::bci(). \"si\" Applies Bayesian models proper priors. CIs computed support intervals comparing posterior samples prior samples; p-values based probability direction. See bayestestR::si(). \"boot\" Applies non-Bayesian models class merMod. CIs computed using parametric bootstrapping (simulating data fitted model); p-values computed using Wald method normal-distribution) (note: might change future update!). iteration-based methods \"boot\" (\"hdi\", \"quantile\", \"ci\", \"eti\", \"si\", \"bci\", \"bcai\"), p-values based probability direction (bayestestR::p_direction()), converted p-value using bayestestR::pd_to_p().","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/model_parameters.merMod.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parameters from Mixed Models — model_parameters.cpglmm","text":"","code":"library(parameters) if (require(\"lme4\")) {   data(mtcars)   model <- lmer(mpg ~ wt + (1 | gear), data = mtcars)   model_parameters(model) } #> Loading required package: lme4 #>  #> Attaching package: ‘lme4’ #> The following object is masked from ‘package:nlme’: #>  #>     lmList #> # Fixed Effects #>  #> Parameter   | Coefficient |   SE |         95% CI | t(28) |      p #> ------------------------------------------------------------------ #> (Intercept) |       36.19 | 2.19 | [31.70, 40.68] | 16.52 | < .001 #> wt          |       -5.05 | 0.64 | [-6.36, -3.73] | -7.89 | < .001 #>  #> # Random Effects #>  #> Parameter            | Coefficient |   SE |       95% CI #> -------------------------------------------------------- #> SD (Intercept: gear) |        1.26 | 1.12 | [0.22, 7.17] #> SD (Residual)        |        2.91 | 0.39 | [2.24, 3.78] #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) computed #>   using a Wald t-distribution approximation. # \\donttest{ if (require(\"glmmTMB\")) {   data(Salamanders)   model <- glmmTMB(     count ~ spp + mined + (1 | site),     ziformula = ~mined,     family = poisson(),     data = Salamanders   )   model_parameters(model, effects = \"all\") } #> # Fixed Effects (Count Model) #>  #> Parameter   | Log-Mean |   SE |         95% CI |     z |      p #> --------------------------------------------------------------- #> (Intercept) |    -0.36 | 0.28 | [-0.90,  0.18] | -1.30 | 0.194  #> spp [PR]    |    -1.27 | 0.24 | [-1.74, -0.80] | -5.27 | < .001 #> spp [DM]    |     0.27 | 0.14 | [ 0.00,  0.54] |  1.95 | 0.051  #> spp [EC-A]  |    -0.57 | 0.21 | [-0.97, -0.16] | -2.75 | 0.006  #> spp [EC-L]  |     0.67 | 0.13 | [ 0.41,  0.92] |  5.20 | < .001 #> spp [DES-L] |     0.63 | 0.13 | [ 0.38,  0.87] |  4.96 | < .001 #> spp [DF]    |     0.12 | 0.15 | [-0.17,  0.40] |  0.78 | 0.435  #> mined [no]  |     1.27 | 0.27 | [ 0.74,  1.80] |  4.72 | < .001 #>  #> # Fixed Effects (Zero-Inflated Model) #>  #> Parameter   | Log-Odds |   SE |         95% CI |     z |      p #> --------------------------------------------------------------- #> (Intercept) |     0.79 | 0.27 | [ 0.26,  1.32] |  2.90 | 0.004  #> mined [no]  |    -1.84 | 0.31 | [-2.46, -1.23] | -5.87 | < .001 #>  #> # Random Effects Variances #>  #> Parameter            | Coefficient |       95% CI #> ------------------------------------------------- #> SD (Intercept: site) |        0.33 | [0.18, 0.63] #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) computed #>   using a Wald z-distribution approximation. #>  #> The model has a log- or logit-link. Consider using `exponentiate = TRUE` #>   to interpret coefficients as ratios.  if (require(\"lme4\")) {   model <- lmer(mpg ~ wt + (1 | gear), data = mtcars)   model_parameters(model, bootstrap = TRUE, iterations = 50) } #> Warning: Bootstrapping only returns fixed effects of the mixed model. #> # Fixed Effects #>  #> Parameter   | Coefficient |         95% CI |      p #> --------------------------------------------------- #> (Intercept) |       36.26 | [32.08, 40.38] | < .001 #> wt          |       -5.05 | [-6.46, -3.95] | < .001 #>  #> Uncertainty intervals (equal-tailed) are naıve bootstrap intervals. # }"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.mira.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameters from multiply imputed repeated analyses — model_parameters.mipo","title":"Parameters from multiply imputed repeated analyses — model_parameters.mipo","text":"Format models class mira, obtained mice::width.mids().","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.mira.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parameters from multiply imputed repeated analyses — model_parameters.mipo","text":"","code":"# S3 method for mipo model_parameters(   model,   ci = 0.95,   ci_method = NULL,   bootstrap = FALSE,   iterations = 1000,   standardize = NULL,   exponentiate = FALSE,   p_adjust = NULL,   summary = getOption(\"parameters_summary\", FALSE),   keep = NULL,   drop = NULL,   verbose = TRUE,   vcov = NULL,   vcov_args = NULL,   ... )  # S3 method for mira model_parameters(   model,   ci = 0.95,   exponentiate = FALSE,   p_adjust = NULL,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.mira.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameters from multiply imputed repeated analyses — model_parameters.mipo","text":"model object class mira. ci Confidence Interval (CI) level. Default 0.95 (95%). ci_method Method computing degrees freedom confidence intervals (CI) related p-values. Allowed following options (vary depending model class): \"residual\", \"normal\", \"likelihood\", \"satterthwaite\", \"kenward\", \"wald\", \"profile\", \"boot\", \"uniroot\", \"ml1\", \"betwithin\", \"hdi\", \"quantile\", \"ci\", \"eti\", \"si\", \"bci\", \"bcai\". See section Confidence intervals approximation degrees freedom model_parameters() details. ci_method=NULL, cases \"wald\" used . bootstrap estimates based bootstrapped model? TRUE, arguments Bayesian regressions apply (see also bootstrap_parameters()). iterations number bootstrap replicates. apply case bootstrapped frequentist models. standardize method used standardizing parameters. Can NULL (default; standardization), \"refit\" (re-fitting model standardized data) one \"basic\", \"posthoc\", \"smart\", \"pseudo\". See 'Details' standardize_parameters(). Important: \"refit\" method standardized categorical predictors (.e. factors), may different behaviour compared R packages (lm.beta) software packages (like SPSS). mimic behaviours, either use standardize=\"basic\" standardize data datawizard::standardize(force=TRUE) fitting model. mixed models, using methods \"refit\", fixed effects returned. Robust estimation (.e., vcov set value NULL) standardized parameters works standardize=\"refit\". exponentiate Logical, indicating whether exponentiate coefficients (related confidence intervals). typical logistic regression, generally speaking, models log logit links. also recommended use exponentiate = TRUE models log-transformed response values. Note: Delta-method standard errors also computed (multiplying standard errors transformed coefficients). mimic behaviour software packages, Stata, standard errors poorly estimate uncertainty transformed coefficient. transformed confidence interval clearly captures uncertainty. compare_parameters(), exponentiate = \"nongaussian\" exponentiate coefficients non-Gaussian families. p_adjust Character vector, NULL, indicates method adjust p-values. See stats::p.adjust() details. possible adjustment methods \"tukey\", \"scheffe\", \"sidak\" \"none\" explicitly disable adjustment emmGrid objects (emmeans). summary Logical, TRUE, prints summary information model (model formula, number observations, residual standard deviation ). keep Character containing regular expression pattern describes parameters included (keep) excluded (drop) returned data frame. keep may also named list regular expressions. non-matching parameters removed output. keep character vector, every parameter name \"Parameter\" column matches regular expression keep selected returned data frame (vice versa, parameter names matching drop excluded). Furthermore, keep one element, merged operator regular expression pattern like : \"(one|two|three)\". keep named list regular expression patterns, names list-element equal column name selection applied. useful model objects model_parameters() returns multiple columns parameter components, like model_parameters.lavaan(). Note regular expression pattern match parameter names stored returned data frame, can different printed. Inspect $Parameter column parameters table get exact parameter names. drop See keep. verbose Toggle warnings messages. vcov Variance-covariance matrix used compute uncertainty estimates (e.g., robust standard errors). argument accepts covariance matrix, function returns covariance matrix, string identifies function used compute covariance matrix. covariance matrix function returns covariance matrix (e.g., stats::vcov()) string indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"vcovHC\", \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC. Cluster-robust: \"vcovCR\", \"CR0\", \"CR1\", \"CR1p\", \"CR1S\", \"CR2\", \"CR3\". See ?clubSandwich::vcovCR. Bootstrap: \"vcovBS\", \"xy\", \"residual\", \"wild\", \"mammen\", \"webb\". See ?sandwich::vcovBS. sandwich package functions: \"vcovHAC\", \"vcovPC\", \"vcovCL\", \"vcovPL\". vcov_args List arguments passed function identified vcov argument. function typically supplied sandwich clubSandwich packages. Please refer documentation (e.g., ?sandwich::vcovHAC) see list available arguments. ... Arguments passed methods.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.mira.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Parameters from multiply imputed repeated analyses — model_parameters.mipo","text":"model_parameters() objects class mira works similar summary(mice::pool()), .e. generates pooled summary multiple imputed repeated regression analyses.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.mira.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parameters from multiply imputed repeated analyses — model_parameters.mipo","text":"","code":"library(parameters) if (require(\"mice\", quietly = TRUE)) {   data(nhanes2)   imp <- mice(nhanes2)   fit <- with(data = imp, exp = lm(bmi ~ age + hyp + chl))   model_parameters(fit) } #>  #> Attaching package: ‘mice’ #> The following object is masked from ‘package:stats’: #>  #>     filter #> The following objects are masked from ‘package:base’: #>  #>     cbind, rbind #>  #>  iter imp variable #>   1   1  bmi  hyp  chl #>   1   2  bmi  hyp  chl #>   1   3  bmi  hyp  chl #>   1   4  bmi  hyp  chl #>   1   5  bmi  hyp  chl #>   2   1  bmi  hyp  chl #>   2   2  bmi  hyp  chl #>   2   3  bmi  hyp  chl #>   2   4  bmi  hyp  chl #>   2   5  bmi  hyp  chl #>   3   1  bmi  hyp  chl #>   3   2  bmi  hyp  chl #>   3   3  bmi  hyp  chl #>   3   4  bmi  hyp  chl #>   3   5  bmi  hyp  chl #>   4   1  bmi  hyp  chl #>   4   2  bmi  hyp  chl #>   4   3  bmi  hyp  chl #>   4   4  bmi  hyp  chl #>   4   5  bmi  hyp  chl #>   5   1  bmi  hyp  chl #>   5   2  bmi  hyp  chl #>   5   3  bmi  hyp  chl #>   5   4  bmi  hyp  chl #>   5   5  bmi  hyp  chl #> # Fixed Effects #>  #> Parameter   | Coefficient |   SE |          95% CI | Statistic |    df |     p #> ------------------------------------------------------------------------------ #> (Intercept) |       19.07 | 4.55 | [  8.40, 29.73] |      4.19 |  7.35 | 0.004 #> age40-59    |       -4.77 | 2.07 | [ -9.32, -0.22] |     -2.31 | 10.95 | 0.041 #> age60-99    |       -5.89 | 2.49 | [-11.62, -0.17] |     -2.37 |  8.10 | 0.045 #> hypyes      |        2.34 | 2.42 | [ -3.23,  7.91] |      0.97 |  8.13 | 0.362 #> chl         |        0.05 | 0.03 | [ -0.02,  0.12] |      1.84 |  5.76 | 0.118 #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) computed #>   using a Wald distribution approximation. if (FALSE) { # model_parameters() also works for models that have no \"tidy\"-method in mice if (require(\"mice\", quietly = TRUE) && require(\"gee\", quietly = TRUE)) {   data(warpbreaks)   set.seed(1234)   warpbreaks$tension[sample(1:nrow(warpbreaks), size = 10)] <- NA   imp <- mice(warpbreaks)   fit <- with(data = imp, expr = gee(breaks ~ tension, id = wool))    # does not work:   # summary(pool(fit))    model_parameters(fit) } }    # and it works with pooled results if (require(\"mice\")) {   data(\"nhanes2\")   imp <- mice(nhanes2)   fit <- with(data = imp, exp = lm(bmi ~ age + hyp + chl))   pooled <- pool(fit)    model_parameters(pooled) } #>  #>  iter imp variable #>   1   1  bmi  hyp  chl #>   1   2  bmi  hyp  chl #>   1   3  bmi  hyp  chl #>   1   4  bmi  hyp  chl #>   1   5  bmi  hyp  chl #>   2   1  bmi  hyp  chl #>   2   2  bmi  hyp  chl #>   2   3  bmi  hyp  chl #>   2   4  bmi  hyp  chl #>   2   5  bmi  hyp  chl #>   3   1  bmi  hyp  chl #>   3   2  bmi  hyp  chl #>   3   3  bmi  hyp  chl #>   3   4  bmi  hyp  chl #>   3   5  bmi  hyp  chl #>   4   1  bmi  hyp  chl #>   4   2  bmi  hyp  chl #>   4   3  bmi  hyp  chl #>   4   4  bmi  hyp  chl #>   4   5  bmi  hyp  chl #>   5   1  bmi  hyp  chl #>   5   2  bmi  hyp  chl #>   5   3  bmi  hyp  chl #>   5   4  bmi  hyp  chl #>   5   5  bmi  hyp  chl #> # Fixed Effects #>  #> Parameter   | Coefficient |   SE |          95% CI | Statistic |    df |     p #> ------------------------------------------------------------------------------ #> (Intercept) |       19.07 | 4.55 | [  8.40, 29.73] |      4.19 |  7.35 | 0.004 #> age40-59    |       -4.77 | 2.07 | [ -9.32, -0.22] |     -2.31 | 10.95 | 0.041 #> age60-99    |       -5.89 | 2.49 | [-11.62, -0.17] |     -2.37 |  8.10 | 0.045 #> hypyes      |        2.34 | 2.42 | [ -3.23,  7.91] |      0.97 |  8.13 | 0.362 #> chl         |        0.05 | 0.03 | [ -0.02,  0.12] |      1.84 |  5.76 | 0.118 #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) computed #>   using a Wald distribution approximation."},{"path":"https://easystats.github.io/parameters/reference/model_parameters.mlm.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameters from multinomial or cumulative link models — model_parameters.DirichletRegModel","title":"Parameters from multinomial or cumulative link models — model_parameters.DirichletRegModel","text":"Parameters multinomial cumulative link models","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.mlm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parameters from multinomial or cumulative link models — model_parameters.DirichletRegModel","text":"","code":"# S3 method for DirichletRegModel model_parameters(   model,   ci = 0.95,   bootstrap = FALSE,   iterations = 1000,   component = c(\"all\", \"conditional\", \"precision\"),   standardize = NULL,   exponentiate = FALSE,   verbose = TRUE,   ... )  # S3 method for bifeAPEs model_parameters(model, ...)  # S3 method for bracl model_parameters(   model,   ci = 0.95,   bootstrap = FALSE,   iterations = 1000,   standardize = NULL,   exponentiate = FALSE,   p_adjust = NULL,   verbose = TRUE,   ... )  # S3 method for mlm model_parameters(   model,   ci = 0.95,   vcov = NULL,   vcov_args = NULL,   bootstrap = FALSE,   iterations = 1000,   standardize = NULL,   exponentiate = FALSE,   p_adjust = NULL,   verbose = TRUE,   ... )  # S3 method for clm2 model_parameters(   model,   ci = 0.95,   bootstrap = FALSE,   iterations = 1000,   component = c(\"all\", \"conditional\", \"scale\"),   standardize = NULL,   exponentiate = FALSE,   p_adjust = NULL,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.mlm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameters from multinomial or cumulative link models — model_parameters.DirichletRegModel","text":"model model multinomial categorical response value. ci Confidence Interval (CI) level. Default 0.95 (95%). bootstrap estimates based bootstrapped model? TRUE, arguments Bayesian regressions apply (see also bootstrap_parameters()). iterations number bootstrap replicates. apply case bootstrapped frequentist models. component parameters, parameters conditional model, zero-inflated part model, dispersion model returned? Applies models zero-inflated /dispersion component. component may one \"conditional\", \"zi\", \"zero-inflated\", \"dispersion\" \"\" (default). May abbreviated. standardize method used standardizing parameters. Can NULL (default; standardization), \"refit\" (re-fitting model standardized data) one \"basic\", \"posthoc\", \"smart\", \"pseudo\". See 'Details' standardize_parameters(). Important: \"refit\" method standardized categorical predictors (.e. factors), may different behaviour compared R packages (lm.beta) software packages (like SPSS). mimic behaviours, either use standardize=\"basic\" standardize data datawizard::standardize(force=TRUE) fitting model. mixed models, using methods \"refit\", fixed effects returned. Robust estimation (.e., vcov set value NULL) standardized parameters works standardize=\"refit\". exponentiate Logical, indicating whether exponentiate coefficients (related confidence intervals). typical logistic regression, generally speaking, models log logit links. also recommended use exponentiate = TRUE models log-transformed response values. Note: Delta-method standard errors also computed (multiplying standard errors transformed coefficients). mimic behaviour software packages, Stata, standard errors poorly estimate uncertainty transformed coefficient. transformed confidence interval clearly captures uncertainty. compare_parameters(), exponentiate = \"nongaussian\" exponentiate coefficients non-Gaussian families. verbose Toggle warnings messages. ... Arguments passed methods. instance, bootstrap = TRUE, arguments like type parallel passed bootstrap_model(), arguments like ci_method passed bayestestR::describe_posterior(). p_adjust Character vector, NULL, indicates method adjust p-values. See stats::p.adjust() details. possible adjustment methods \"tukey\", \"scheffe\", \"sidak\" \"none\" explicitly disable adjustment emmGrid objects (emmeans). vcov Variance-covariance matrix used compute uncertainty estimates (e.g., robust standard errors). argument accepts covariance matrix, function returns covariance matrix, string identifies function used compute covariance matrix. covariance matrix function returns covariance matrix (e.g., stats::vcov()) string indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"vcovHC\", \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC. Cluster-robust: \"vcovCR\", \"CR0\", \"CR1\", \"CR1p\", \"CR1S\", \"CR2\", \"CR3\". See ?clubSandwich::vcovCR. Bootstrap: \"vcovBS\", \"xy\", \"residual\", \"wild\", \"mammen\", \"webb\". See ?sandwich::vcovBS. sandwich package functions: \"vcovHAC\", \"vcovPC\", \"vcovCL\", \"vcovPL\". vcov_args List arguments passed function identified vcov argument. function typically supplied sandwich clubSandwich packages. Please refer documentation (e.g., ?sandwich::vcovHAC) see list available arguments.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.mlm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parameters from multinomial or cumulative link models — model_parameters.DirichletRegModel","text":"data frame indices related model's parameters.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.mlm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Parameters from multinomial or cumulative link models — model_parameters.DirichletRegModel","text":"Multinomial cumulative link models, .e. models response value (dependent variable) categorical two levels, usually return coefficients response level. Hence, output model_parameters() split coefficient tables different levels model's response.","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/model_parameters.mlm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parameters from multinomial or cumulative link models — model_parameters.DirichletRegModel","text":"","code":"library(parameters) if (require(\"brglm2\", quietly = TRUE)) {   data(\"stemcell\")   model <- bracl(     research ~ as.numeric(religion) + gender,     weights = frequency,     data = stemcell,     type = \"ML\"   )   model_parameters(model) } #> # Response level: definitely #>  #> Parameter       | Log-Odds |   SE |         95% CI |     z |      p #> ------------------------------------------------------------------- #> (Intercept)     |    -1.25 | 0.26 | [-1.76, -0.73] | -4.76 | < .001 #> religion        |     0.44 | 0.10 | [ 0.23,  0.64] |  4.20 | < .001 #> gender [female] |    -0.14 | 0.17 | [-0.47,  0.19] | -0.82 | 0.414  #>  #> # Response level: probably #>  #> Parameter       | Log-Odds |   SE |        95% CI |    z |     p #> ---------------------------------------------------------------- #> (Intercept)     |     0.47 | 0.29 | [-0.10, 1.04] | 1.62 | 0.105 #> religion        |     0.26 | 0.13 | [ 0.01, 0.51] | 2.01 | 0.044 #> gender [female] |     0.19 | 0.21 | [-0.22, 0.60] | 0.90 | 0.370 #>  #> # Response level: probably not #>  #> Parameter       | Log-Odds |   SE |        95% CI |     z |     p #> ----------------------------------------------------------------- #> (Intercept)     |     0.43 | 0.39 | [-0.33, 1.18] |  1.11 | 0.268 #> religion        |     0.01 | 0.17 | [-0.33, 0.35] |  0.07 | 0.945 #> gender [female] |    -0.16 | 0.28 | [-0.71, 0.39] | -0.57 | 0.566 #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) computed #>   using a Wald z-distribution approximation. #>  #> The model has a log- or logit-link. Consider using `exponentiate = TRUE` #>   to interpret coefficients as ratios."},{"path":"https://easystats.github.io/parameters/reference/model_parameters.principal.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameters from PCA, FA, CFA, SEM — model_parameters.PCA","title":"Parameters from PCA, FA, CFA, SEM — model_parameters.PCA","text":"Format structural models psych FactoMineR packages.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.principal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parameters from PCA, FA, CFA, SEM — model_parameters.PCA","text":"","code":"# S3 method for PCA model_parameters(   model,   sort = FALSE,   threshold = NULL,   labels = NULL,   verbose = TRUE,   ... )  # S3 method for FAMD model_parameters(   model,   sort = FALSE,   threshold = NULL,   labels = NULL,   verbose = TRUE,   ... )  # S3 method for lavaan model_parameters(   model,   ci = 0.95,   standardize = FALSE,   component = c(\"regression\", \"correlation\", \"loading\", \"defined\"),   keep = NULL,   drop = NULL,   verbose = TRUE,   ... )  # S3 method for principal model_parameters(   model,   sort = FALSE,   threshold = NULL,   labels = NULL,   verbose = TRUE,   ... )  # S3 method for omega model_parameters(model, verbose = TRUE, ...)  # S3 method for sem model_parameters(   model,   ci = 0.95,   ci_method = NULL,   bootstrap = FALSE,   iterations = 1000,   standardize = NULL,   exponentiate = FALSE,   p_adjust = NULL,   summary = getOption(\"parameters_summary\", FALSE),   keep = NULL,   drop = NULL,   verbose = TRUE,   vcov = NULL,   vcov_args = NULL,   ... )"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.principal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameters from PCA, FA, CFA, SEM — model_parameters.PCA","text":"model Model object. sort Sort loadings. threshold value 0 1 indicates (absolute) values loadings removed. integer higher 1 indicates n strongest loadings retain. Can also \"max\", case display maximum loading per variable (simple structure). labels character vector containing labels added loadings data. Usually, question related item. verbose Toggle warnings messages. ... Arguments passed methods. ci Confidence Interval (CI) level. Default 0.95 (95%). standardize Return standardized parameters (standardized coefficients). Can TRUE (\"\" \"std.\") standardized estimates based variances observed latent variables; \"latent\" (\"std.lv\") standardized estimates based variances latent variables ; \"no_exogenous\" (\"std.nox\") standardized estimates based variances observed latent variables, variances exogenous covariates. See lavaan::standardizedsolution details. component type links return. Can \"\" c(\"regression\", \"correlation\", \"loading\", \"variance\", \"mean\"). keep Character containing regular expression pattern describes parameters included (keep) excluded (drop) returned data frame. keep may also named list regular expressions. non-matching parameters removed output. keep character vector, every parameter name \"Parameter\" column matches regular expression keep selected returned data frame (vice versa, parameter names matching drop excluded). Furthermore, keep one element, merged operator regular expression pattern like : \"(one|two|three)\". keep named list regular expression patterns, names list-element equal column name selection applied. useful model objects model_parameters() returns multiple columns parameter components, like model_parameters.lavaan(). Note regular expression pattern match parameter names stored returned data frame, can different printed. Inspect $Parameter column parameters table get exact parameter names. drop See keep. ci_method Method computing degrees freedom confidence intervals (CI) related p-values. Allowed following options (vary depending model class): \"residual\", \"normal\", \"likelihood\", \"satterthwaite\", \"kenward\", \"wald\", \"profile\", \"boot\", \"uniroot\", \"ml1\", \"betwithin\", \"hdi\", \"quantile\", \"ci\", \"eti\", \"si\", \"bci\", \"bcai\". See section Confidence intervals approximation degrees freedom model_parameters() details. ci_method=NULL, cases \"wald\" used . bootstrap estimates based bootstrapped model? TRUE, arguments Bayesian regressions apply (see also bootstrap_parameters()). iterations number bootstrap replicates. apply case bootstrapped frequentist models. exponentiate Logical, indicating whether exponentiate coefficients (related confidence intervals). typical logistic regression, generally speaking, models log logit links. also recommended use exponentiate = TRUE models log-transformed response values. Note: Delta-method standard errors also computed (multiplying standard errors transformed coefficients). mimic behaviour software packages, Stata, standard errors poorly estimate uncertainty transformed coefficient. transformed confidence interval clearly captures uncertainty. compare_parameters(), exponentiate = \"nongaussian\" exponentiate coefficients non-Gaussian families. p_adjust Character vector, NULL, indicates method adjust p-values. See stats::p.adjust() details. possible adjustment methods \"tukey\", \"scheffe\", \"sidak\" \"none\" explicitly disable adjustment emmGrid objects (emmeans). summary Logical, TRUE, prints summary information model (model formula, number observations, residual standard deviation ). vcov Variance-covariance matrix used compute uncertainty estimates (e.g., robust standard errors). argument accepts covariance matrix, function returns covariance matrix, string identifies function used compute covariance matrix. covariance matrix function returns covariance matrix (e.g., stats::vcov()) string indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"vcovHC\", \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC. Cluster-robust: \"vcovCR\", \"CR0\", \"CR1\", \"CR1p\", \"CR1S\", \"CR2\", \"CR3\". See ?clubSandwich::vcovCR. Bootstrap: \"vcovBS\", \"xy\", \"residual\", \"wild\", \"mammen\", \"webb\". See ?sandwich::vcovBS. sandwich package functions: \"vcovHAC\", \"vcovPC\", \"vcovCL\", \"vcovPL\". vcov_args List arguments passed function identified vcov argument. function typically supplied sandwich clubSandwich packages. Please refer documentation (e.g., ?sandwich::vcovHAC) see list available arguments.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.principal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parameters from PCA, FA, CFA, SEM — model_parameters.PCA","text":"data frame indices loadings.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.principal.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Parameters from PCA, FA, CFA, SEM — model_parameters.PCA","text":"structural models obtained psych, following indices present: Complexity (Hoffman's, 1978; Pettersson Turkheimer, 2010) represents number latent components needed account observed variables. Whereas perfect simple structure solution complexity 1 item load one factor, solution evenly distributed items complexity greater 1. Uniqueness represents variance 'unique' variable shared variables. equal 1 – communality (variance shared variables). uniqueness 0.20 suggests 20% variable's variance shared variables overall factor model. greater 'uniqueness' lower relevance variable factor model. MSA represents Kaiser-Meyer-Olkin Measure Sampling Adequacy (Kaiser Rice, 1974) item. indicates whether enough data factor give reliable results PCA. value > 0.6, desirable values > 0.8 (Tabachnick Fidell, 2013).","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.principal.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Parameters from PCA, FA, CFA, SEM — model_parameters.PCA","text":"also plot()-method lavaan models implemented see-package.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.principal.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Parameters from PCA, FA, CFA, SEM — model_parameters.PCA","text":"Kaiser, H.F. Rice. J. (1974). Little jiffy, mark iv. Educational Psychological Measurement, 34(1):111–117 Pettersson, E., Turkheimer, E. (2010). Item selection, evaluation, simple structure personality data. Journal research personality, 44(4), 407-420. Revelle, W. (2016). : Use psych package Factor Analysis data reduction. Tabachnick, B. G., Fidell, L. S. (2013). Using multivariate statistics (6th ed.). Boston: Pearson Education. Rosseel Y (2012). lavaan: R Package Structural Equation Modeling. Journal Statistical Software, 48(2), 1-36. Merkle EC , Rosseel Y (2018). blavaan: Bayesian Structural Equation Models via Parameter Expansion. Journal Statistical Software, 85(4), 1-30. http://www.jstatsoft.org/v85/i04/","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.principal.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parameters from PCA, FA, CFA, SEM — model_parameters.PCA","text":"","code":"# \\donttest{ library(parameters) if (require(\"psych\", quietly = TRUE)) {   # Principal Component Analysis (PCA) ---------   pca <- psych::principal(attitude)   model_parameters(pca)    pca <- psych::principal(attitude, nfactors = 3, rotate = \"none\")   model_parameters(pca, sort = TRUE, threshold = 0.2)    principal_components(attitude, n = 3, sort = TRUE, threshold = 0.2)     # Exploratory Factor Analysis (EFA) ---------   efa <- psych::fa(attitude, nfactors = 3)   model_parameters(efa, threshold = \"max\", sort = TRUE,                    labels = as.character(1:ncol(attitude)))     # Omega ---------   omega <- psych::omega(mtcars, nfactors = 3)   params <- model_parameters(omega)   params   summary(params) }  #> Composite | Total Variance (%) | Variance due to General Factor (%) | Variance due to Group Factor (%) #> ------------------------------------------------------------------------------------------------------ #> g         |              97.28 |                              56.64 |                            26.42 #> F1*       |              90.12 |                              31.07 |                            59.05 #> F2*       |              91.37 |                              69.32 |                            22.04 #> F3*       |              87.36 |                              59.65 |                            27.71  # FactoMineR --------- if (require(\"FactoMineR\", quietly = TRUE)) {   model <- FactoMineR::PCA(iris[, 1:4], ncp = 2)   model_parameters(model)   attributes(model_parameters(model))$scores    model <- FactoMineR::FAMD(iris, ncp = 2)   model_parameters(model) } #> Warning: ggrepel: 93 unlabeled data points (too many overlaps). Consider increasing max.overlaps #> Warning: ggrepel: 93 unlabeled data points (too many overlaps). Consider increasing max.overlaps #> # Loadings from Factor Analysis (no rotation) #>  #> Variable     | Dim.1 |  Dim.2   | Complexity #> -------------------------------------------- #> Sepal.Length | 0.75  |   0.07   |    1.02    #> Sepal.Width  | 0.23  |   0.51   |    1.41    #> Petal.Length | 0.98  | 1.32e-03 |    1.00    #> Petal.Width  | 0.94  |   0.01   |    1.00    #> Species      | 0.96  |   0.75   |    1.88    #>  #> The 2 latent factors accounted for 86.87% of the total variance of the original data (Dim.1 = 64.50%, Dim.2 = 22.37%). # }  # lavaan  library(parameters)  # lavaan ------------------------------------- if (require(\"lavaan\", quietly = TRUE)) {   # Confirmatory Factor Analysis (CFA) ---------    structure <- \" visual  =~ x1 + x2 + x3                  textual =~ x4 + x5 + x6                  speed   =~ x7 + x8 + x9 \"   model <- lavaan::cfa(structure, data = HolzingerSwineford1939)   model_parameters(model)   model_parameters(model, standardize = TRUE)    # filter parameters   model_parameters(     model,     parameters = list(       To = \"^(?!visual)\",       From = \"^(?!(x7|x8))\"     )   )    # Structural Equation Model (SEM) ------------    structure <- \"     # latent variable definitions       ind60 =~ x1 + x2 + x3       dem60 =~ y1 + a*y2 + b*y3 + c*y4       dem65 =~ y5 + a*y6 + b*y7 + c*y8     # regressions       dem60 ~ ind60       dem65 ~ ind60 + dem60     # residual correlations       y1 ~~ y5       y2 ~~ y4 + y6       y3 ~~ y7       y4 ~~ y8       y6 ~~ y8   \"   model <- lavaan::sem(structure, data = PoliticalDemocracy)   model_parameters(model)   model_parameters(model, standardize = TRUE) } #> # Loading #>  #> Link            | Coefficient |   SE |       95% CI |     z |      p #> -------------------------------------------------------------------- #> ind60 =~ x1     |        0.92 | 0.02 | [0.88, 0.97] | 40.08 | < .001 #> ind60 =~ x2     |        0.97 | 0.02 | [0.94, 1.01] | 59.14 | < .001 #> ind60 =~ x3     |        0.87 | 0.03 | [0.81, 0.93] | 28.09 | < .001 #> dem60 =~ y1     |        0.85 | 0.04 | [0.77, 0.93] | 20.92 | < .001 #> dem60 =~ y2 (a) |        0.69 | 0.06 | [0.57, 0.81] | 11.58 | < .001 #> dem60 =~ y3 (b) |        0.76 | 0.05 | [0.66, 0.86] | 14.70 | < .001 #> dem60 =~ y4 (c) |        0.84 | 0.04 | [0.76, 0.92] | 20.12 | < .001 #> dem65 =~ y5     |        0.82 | 0.04 | [0.73, 0.90] | 18.52 | < .001 #> dem65 =~ y6 (a) |        0.75 | 0.05 | [0.65, 0.86] | 14.01 | < .001 #> dem65 =~ y7 (b) |        0.80 | 0.05 | [0.71, 0.89] | 17.40 | < .001 #> dem65 =~ y8 (c) |        0.83 | 0.04 | [0.75, 0.91] | 19.79 | < .001 #>  #> # Regression #>  #> Link          | Coefficient |   SE |       95% CI |     z |      p #> ------------------------------------------------------------------ #> dem60 ~ ind60 |        0.45 | 0.10 | [0.25, 0.65] |  4.33 | < .001 #> dem65 ~ ind60 |        0.19 | 0.07 | [0.05, 0.33] |  2.64 | 0.008  #> dem65 ~ dem60 |        0.88 | 0.05 | [0.78, 0.98] | 17.24 | < .001 #>  #> # Correlation #>  #> Link     | Coefficient |   SE |        95% CI |    z |      p #> ------------------------------------------------------------- #> y1 ~~ y5 |        0.28 | 0.14 | [ 0.00, 0.56] | 1.97 | 0.049  #> y2 ~~ y4 |        0.29 | 0.11 | [ 0.07, 0.52] | 2.55 | 0.011  #> y2 ~~ y6 |        0.36 | 0.10 | [ 0.17, 0.54] | 3.71 | < .001 #> y3 ~~ y7 |        0.17 | 0.13 | [-0.09, 0.43] | 1.26 | 0.208  #> y4 ~~ y8 |        0.11 | 0.13 | [-0.14, 0.36] | 0.86 | 0.388  #> y6 ~~ y8 |        0.34 | 0.11 | [ 0.12, 0.55] | 3.08 | 0.002"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.rma.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameters from Meta-Analysis — model_parameters.rma","title":"Parameters from Meta-Analysis — model_parameters.rma","text":"Extract compute indices measures describe parameters meta-analysis models.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.rma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parameters from Meta-Analysis — model_parameters.rma","text":"","code":"# S3 method for rma model_parameters(   model,   ci = 0.95,   bootstrap = FALSE,   iterations = 1000,   standardize = NULL,   exponentiate = FALSE,   include_studies = TRUE,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.rma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameters from Meta-Analysis — model_parameters.rma","text":"model Model object. ci Confidence Interval (CI) level. Default 0.95 (95%). bootstrap estimates based bootstrapped model? TRUE, arguments Bayesian regressions apply (see also bootstrap_parameters()). iterations number bootstrap replicates. apply case bootstrapped frequentist models. standardize method used standardizing parameters. Can NULL (default; standardization), \"refit\" (re-fitting model standardized data) one \"basic\", \"posthoc\", \"smart\", \"pseudo\". See 'Details' standardize_parameters(). Important: \"refit\" method standardized categorical predictors (.e. factors), may different behaviour compared R packages (lm.beta) software packages (like SPSS). mimic behaviours, either use standardize=\"basic\" standardize data datawizard::standardize(force=TRUE) fitting model. mixed models, using methods \"refit\", fixed effects returned. Robust estimation (.e., vcov set value NULL) standardized parameters works standardize=\"refit\". exponentiate Logical, indicating whether exponentiate coefficients (related confidence intervals). typical logistic regression, generally speaking, models log logit links. also recommended use exponentiate = TRUE models log-transformed response values. Note: Delta-method standard errors also computed (multiplying standard errors transformed coefficients). mimic behaviour software packages, Stata, standard errors poorly estimate uncertainty transformed coefficient. transformed confidence interval clearly captures uncertainty. compare_parameters(), exponentiate = \"nongaussian\" exponentiate coefficients non-Gaussian families. include_studies Logical, TRUE (default), includes parameters studies. Else, parameters overall-effects shown. verbose Toggle warnings messages. ... Arguments passed methods. instance, bootstrap = TRUE, arguments like type parallel passed bootstrap_model(), arguments like ci_method passed bayestestR::describe_posterior().","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.rma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parameters from Meta-Analysis — model_parameters.rma","text":"data frame indices related model's parameters.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.rma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parameters from Meta-Analysis — model_parameters.rma","text":"","code":"library(parameters) mydat <<- data.frame(   effectsize = c(-0.393, 0.675, 0.282, -1.398),   stderr = c(0.317, 0.317, 0.13, 0.36) ) if (require(\"metafor\", quietly = TRUE)) {   model <- rma(yi = effectsize, sei = stderr, method = \"REML\", data = mydat)   model_parameters(model) } #>  #> Loading the 'metafor' package (version 3.4-0). For an #> introduction to the package please type: help(metafor) #>  #> Attaching package: ‘metafor’ #> The following object is masked from ‘package:mclust’: #>  #>     hc #> Meta-analysis using 'metafor' #>  #> Parameter | Coefficient |   SE |         95% CI |     z |      p | Weight #> ------------------------------------------------------------------------- #> Study 1   |       -0.39 | 0.32 | [-1.01,  0.23] | -1.24 | 0.215  |   9.95 #> Study 2   |        0.68 | 0.32 | [ 0.05,  1.30] |  2.13 | 0.033  |   9.95 #> Study 3   |        0.28 | 0.13 | [ 0.03,  0.54] |  2.17 | 0.030  |  59.17 #> Study 4   |       -1.40 | 0.36 | [-2.10, -0.69] | -3.88 | < .001 |   7.72 #> Overall   |       -0.18 | 0.44 | [-1.05,  0.68] | -0.42 | 0.676  |        #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) computed #>   using a Wald z-distribution approximation. if (FALSE) { # with subgroups if (require(\"metafor\", quietly = TRUE)) {   data(dat.bcg)   dat <- escalc(     measure = \"RR\",     ai = tpos,     bi = tneg,     ci = cpos,     di = cneg,     data = dat.bcg   )   dat$alloc <- ifelse(dat$alloc == \"random\", \"random\", \"other\")   model <- rma(yi, vi, mods = ~alloc, data = dat, digits = 3, slab = author)   model_parameters(model) }  if (require(\"metaBMA\", quietly = TRUE)) {   data(towels)   m <- meta_random(logOR, SE, study, data = towels)   model_parameters(m) } }"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.stanreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameters from Bayesian Models — model_parameters.MCMCglmm","title":"Parameters from Bayesian Models — model_parameters.MCMCglmm","text":"Parameters Bayesian models.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.stanreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parameters from Bayesian Models — model_parameters.MCMCglmm","text":"","code":"# S3 method for MCMCglmm model_parameters(   model,   centrality = \"median\",   dispersion = FALSE,   ci = 0.95,   ci_method = \"eti\",   test = c(\"pd\", \"rope\"),   rope_range = \"default\",   rope_ci = 0.95,   bf_prior = NULL,   diagnostic = c(\"ESS\", \"Rhat\"),   priors = TRUE,   keep = NULL,   drop = NULL,   verbose = TRUE,   ... )  # S3 method for bamlss model_parameters(   model,   centrality = \"median\",   dispersion = FALSE,   ci = 0.95,   ci_method = \"eti\",   test = c(\"pd\", \"rope\"),   rope_range = \"default\",   rope_ci = 0.95,   component = \"all\",   exponentiate = FALSE,   standardize = NULL,   keep = NULL,   drop = NULL,   verbose = TRUE,   ... )  # S3 method for data.frame model_parameters(model, as_draws = FALSE, verbose = TRUE, ...)  # S3 method for bayesQR model_parameters(   model,   centrality = \"median\",   dispersion = FALSE,   ci = 0.95,   ci_method = \"eti\",   test = c(\"pd\", \"rope\"),   rope_range = \"default\",   rope_ci = 0.95,   bf_prior = NULL,   diagnostic = c(\"ESS\", \"Rhat\"),   priors = TRUE,   keep = NULL,   drop = NULL,   verbose = TRUE,   ... )  # S3 method for brmsfit model_parameters(   model,   centrality = \"median\",   dispersion = FALSE,   ci = 0.95,   ci_method = \"eti\",   test = c(\"pd\", \"rope\"),   rope_range = \"default\",   rope_ci = 0.95,   bf_prior = NULL,   diagnostic = c(\"ESS\", \"Rhat\"),   priors = FALSE,   effects = \"fixed\",   component = \"all\",   exponentiate = FALSE,   standardize = NULL,   group_level = FALSE,   keep = NULL,   drop = NULL,   verbose = TRUE,   ... )  # S3 method for mcmc.list model_parameters(model, as_draws = FALSE, verbose = TRUE, ...)  # S3 method for bcplm model_parameters(   model,   centrality = \"median\",   dispersion = FALSE,   ci = 0.95,   ci_method = \"eti\",   test = c(\"pd\", \"rope\"),   rope_range = \"default\",   rope_ci = 0.95,   bf_prior = NULL,   diagnostic = c(\"ESS\", \"Rhat\"),   priors = TRUE,   keep = NULL,   drop = NULL,   verbose = TRUE,   ... )  # S3 method for blrm model_parameters(   model,   centrality = \"median\",   dispersion = FALSE,   ci = 0.95,   ci_method = \"eti\",   test = c(\"pd\", \"rope\"),   rope_range = \"default\",   rope_ci = 0.95,   bf_prior = NULL,   diagnostic = c(\"ESS\", \"Rhat\"),   priors = TRUE,   keep = NULL,   drop = NULL,   verbose = TRUE,   ... )  # S3 method for draws model_parameters(   model,   centrality = \"median\",   dispersion = FALSE,   ci = 0.95,   ci_method = \"eti\",   test = c(\"pd\", \"rope\"),   rope_range = \"default\",   rope_ci = 0.95,   keep = NULL,   drop = NULL,   verbose = TRUE,   ... )  # S3 method for stanfit model_parameters(   model,   centrality = \"median\",   dispersion = FALSE,   ci = 0.95,   ci_method = \"eti\",   test = c(\"pd\", \"rope\"),   rope_range = \"default\",   rope_ci = 0.95,   diagnostic = c(\"ESS\", \"Rhat\"),   effects = \"fixed\",   exponentiate = FALSE,   standardize = NULL,   group_level = FALSE,   keep = NULL,   drop = NULL,   verbose = TRUE,   ... )  # S3 method for stanreg model_parameters(   model,   centrality = \"median\",   dispersion = FALSE,   ci = 0.95,   ci_method = \"eti\",   test = c(\"pd\", \"rope\"),   rope_range = \"default\",   rope_ci = 0.95,   bf_prior = NULL,   diagnostic = c(\"ESS\", \"Rhat\"),   priors = TRUE,   effects = \"fixed\",   exponentiate = FALSE,   standardize = NULL,   group_level = FALSE,   keep = NULL,   drop = NULL,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.stanreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameters from Bayesian Models — model_parameters.MCMCglmm","text":"model Bayesian model (including SEM blavaan. May also data frame posterior samples, however, as_draws must set TRUE (else, data frames NULL returned). centrality point-estimates (centrality indices) compute.  Character (vector) list one options: \"median\", \"mean\", \"MAP\" \"\". dispersion Logical, TRUE, computes indices dispersion related estimate(s) (SD MAD mean median, respectively). ci Credible Interval (CI) level. Default 0.95 (95%). See bayestestR::ci() details. ci_method Method computing degrees freedom confidence intervals (CI) related p-values. Allowed following options (vary depending model class): \"residual\", \"normal\", \"likelihood\", \"satterthwaite\", \"kenward\", \"wald\", \"profile\", \"boot\", \"uniroot\", \"ml1\", \"betwithin\", \"hdi\", \"quantile\", \"ci\", \"eti\", \"si\", \"bci\", \"bcai\". See section Confidence intervals approximation degrees freedom model_parameters() details. ci_method=NULL, cases \"wald\" used . test indices effect existence compute. Character (vector) list one options: \"p_direction\" (\"pd\"), \"rope\", \"p_map\", \"equivalence_test\" (\"equitest\"), \"bayesfactor\" (\"bf\") \"\" compute tests. \"test\", corresponding bayestestR function called (e.g. rope() p_direction()) results included summary output. rope_range ROPE's lower higher bounds. list two values (e.g., c(-0.1, 0.1)) \"default\". \"default\", bounds set x +- 0.1*SD(response). rope_ci Credible Interval (CI) probability, corresponding proportion HDI, use percentage ROPE. bf_prior Distribution representing prior computation Bayes factors / SI. Used input posterior, otherwise (case models) ignored. diagnostic Diagnostic metrics compute.  Character (vector) list one options: \"ESS\", \"Rhat\", \"MCSE\" \"\". priors Add prior used parameter. keep Character containing regular expression pattern describes parameters included (keep) excluded (drop) returned data frame. keep may also named list regular expressions. non-matching parameters removed output. keep character vector, every parameter name \"Parameter\" column matches regular expression keep selected returned data frame (vice versa, parameter names matching drop excluded). Furthermore, keep one element, merged operator regular expression pattern like : \"(one|two|three)\". keep named list regular expression patterns, names list-element equal column name selection applied. useful model objects model_parameters() returns multiple columns parameter components, like model_parameters.lavaan(). Note regular expression pattern match parameter names stored returned data frame, can different printed. Inspect $Parameter column parameters table get exact parameter names. drop See keep. verbose Toggle messages warnings. ... Currently used. component type parameters return, parameters conditional model, zero-inflated part model, dispersion term, auxiliary parameters returned? Applies models zero-inflated /dispersion formula, parameters sigma included. May abbreviated. Note conditional component also called count mean component, depending model. three convenient shortcuts: component = \"\" returns possible parameters. component = \"location\", location parameters conditional, zero_inflated, smooth_terms, returned (everything fixed random effects - depending effects argument - auxiliary parameters). component = \"distributional\" (\"auxiliary\"), components like sigma, dispersion, beta (auxiliary parameters) returned. exponentiate Logical, indicating whether exponentiate coefficients (related confidence intervals). typical logistic regression, generally speaking, models log logit links. also recommended use exponentiate = TRUE models log-transformed response values. Note: Delta-method standard errors also computed (multiplying standard errors transformed coefficients). mimic behaviour software packages, Stata, standard errors poorly estimate uncertainty transformed coefficient. transformed confidence interval clearly captures uncertainty. compare_parameters(), exponentiate = \"nongaussian\" exponentiate coefficients non-Gaussian families. standardize method used standardizing parameters. Can NULL (default; standardization), \"refit\" (re-fitting model standardized data) one \"basic\", \"posthoc\", \"smart\", \"pseudo\". See 'Details' standardize_parameters(). Important: \"refit\" method standardized categorical predictors (.e. factors), may different behaviour compared R packages (lm.beta) software packages (like SPSS). mimic behaviours, either use standardize=\"basic\" standardize data datawizard::standardize(force=TRUE) fitting model. mixed models, using methods \"refit\", fixed effects returned. Robust estimation (.e., vcov set value NULL) standardized parameters works standardize=\"refit\". as_draws Logical, TRUE model class data.frame, data frame treated posterior samples handled similar Bayesian models. arguments ... passed model_parameters.draws(). effects results fixed effects, random effects returned? applies mixed models. May abbreviated. group_level Logical, multilevel models (.e. models random effects) effects = \"\" effects = \"random\", include parameters group level random effects. group_level = FALSE (default), information SD COR shown.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.stanreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parameters from Bayesian Models — model_parameters.MCMCglmm","text":"data frame indices related model's parameters.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.stanreg.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Parameters from Bayesian Models — model_parameters.MCMCglmm","text":"standardize = \"refit\", columns diagnostic, bf_prior priors refer original model. model data frame, arguments diagnostic, bf_prior priors ignored.  also plot()-method implemented see-package.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.stanreg.html","id":"confidence-intervals-and-approximation-of-degrees-of-freedom","dir":"Reference","previous_headings":"","what":"Confidence intervals and approximation of degrees of freedom","title":"Parameters from Bayesian Models — model_parameters.MCMCglmm","text":"different ways approximating degrees freedom depending different assumptions nature model sampling distribution. ci_method argument modulates method computing degrees freedom (df) used calculate confidence intervals (CI) related p-values. Following options allowed, depending model class: Classical methods: Classical inference generally based Wald method. Wald approach inference computes test statistic dividing parameter estimate standard error (Coefficient / SE), comparing statistic t- normal distribution. approach can used compute CIs p-values. \"wald\": Applies non-Bayesian models. linear models, CIs computed using Wald method (SE t-distribution residual df); p-values computed using Wald method t-distribution residual df. models, CIs computed using Wald method (SE normal distribution); p-values computed using Wald method normal distribution. \"normal\" Applies non-Bayesian models. Compute Wald CIs p-values, always use normal distribution. \"residual\" Applies non-Bayesian models. Compute Wald CIs p-values, always use t-distribution residual df possible. residual df model determined, normal distribution used instead. Methods mixed models: Compared fixed effects (single-level) models, determining appropriate df Wald-based inference mixed models difficult. See R GLMM FAQ discussion. Several approximate methods computing df available, also consider instead using profile likelihood (\"profile\") bootstrap (\"boot\") CIs p-values instead. \"satterthwaite\" Applies linear mixed models. CIs computed using Wald method (SE t-distribution Satterthwaite df); p-values computed using Wald method t-distribution Satterthwaite df. \"kenward\" Applies linear mixed models. CIs computed using Wald method (Kenward-Roger SE t-distribution Kenward-Roger df); p-values computed using Wald method Kenward-Roger SE t-distribution Kenward-Roger df. \"ml1\" Applies linear mixed models. CIs computed using Wald method (SE t-distribution m-l-1 approximated df); p-values computed using Wald method t-distribution m-l-1 approximated df. See ci_ml1(). \"betwithin\" Applies linear mixed models generalized linear mixed models. CIs computed using Wald method (SE t-distribution -within df); p-values computed using Wald method t-distribution -within df. See ci_betwithin(). Likelihood-based methods: Likelihood-based inference based comparing likelihood maximum-likelihood estimate likelihood models one parameter values changed (e.g., set zero range alternative values). Likelihood ratios maximum-likelihood alternative models compared \\(\\chi\\)-squared distribution compute CIs p-values. \"profile\" Applies non-Bayesian models class glm, polr glmmTMB. CIs computed profiling likelihood curve parameter, using linear interpolation find likelihood ratio equals critical value; p-values computed using Wald method normal-distribution (note: might change future update!) \"uniroot\" Applies non-Bayesian models class glmmTMB. CIs computed profiling likelihood curve parameter, using root finding find likelihood ratio equals critical value; p-values computed using Wald method normal-distribution (note: might change future update!) Methods bootstrapped Bayesian models: Bootstrap-based inference based resampling refitting model resampled datasets. distribution parameter estimates across resampled datasets used approximate parameter's sampling distribution. Depending type model, several different methods bootstrapping constructing CIs p-values bootstrap distribution available. Bayesian models, inference based drawing samples model posterior distribution. \"quantile\" (\"eti\") Applies models (including Bayesian models). non-Bayesian models, applies bootstrap = TRUE. CIs computed equal tailed intervals using quantiles bootstrap posterior samples; p-values based probability direction. See bayestestR::eti(). \"hdi\" Applies models (including Bayesian models). non-Bayesian models, applies bootstrap = TRUE. CIs computed highest density intervals bootstrap posterior samples; p-values based probability direction. See bayestestR::hdi(). \"bci\" (\"bcai\") Applies models (including Bayesian models). non-Bayesian models, applies bootstrap = TRUE. CIs computed bias corrected accelerated intervals bootstrap posterior samples; p-values based probability direction. See bayestestR::bci(). \"si\" Applies Bayesian models proper priors. CIs computed support intervals comparing posterior samples prior samples; p-values based probability direction. See bayestestR::si(). \"boot\" Applies non-Bayesian models class merMod. CIs computed using parametric bootstrapping (simulating data fitted model); p-values computed using Wald method normal-distribution) (note: might change future update!). iteration-based methods \"boot\" (\"hdi\", \"quantile\", \"ci\", \"eti\", \"si\", \"bci\", \"bcai\"), p-values based probability direction (bayestestR::p_direction()), converted p-value using bayestestR::pd_to_p().","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/model_parameters.stanreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parameters from Bayesian Models — model_parameters.MCMCglmm","text":"","code":"if (FALSE) { library(parameters) if (require(\"rstanarm\")) {   model <- stan_glm(     Sepal.Length ~ Petal.Length * Species,     data = iris, iter = 500, refresh = 0   )   model_parameters(model) } }"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.zcpglm.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameters from Zero-Inflated Models — model_parameters.zcpglm","title":"Parameters from Zero-Inflated Models — model_parameters.zcpglm","text":"Parameters zero-inflated models (packages like pscl, cplm countreg).","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.zcpglm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parameters from Zero-Inflated Models — model_parameters.zcpglm","text":"","code":"# S3 method for zcpglm model_parameters(   model,   ci = 0.95,   bootstrap = FALSE,   iterations = 1000,   component = c(\"all\", \"conditional\", \"zi\", \"zero_inflated\"),   standardize = NULL,   exponentiate = FALSE,   p_adjust = NULL,   keep = NULL,   drop = NULL,   summary = getOption(\"parameters_summary\", FALSE),   verbose = TRUE,   ... )  # S3 method for mhurdle model_parameters(   model,   ci = 0.95,   component = c(\"all\", \"conditional\", \"zi\", \"zero_inflated\", \"infrequent_purchase\", \"ip\",     \"auxiliary\"),   exponentiate = FALSE,   p_adjust = NULL,   verbose = TRUE,   ... )  # S3 method for zeroinfl model_parameters(   model,   ci = 0.95,   bootstrap = FALSE,   iterations = 1000,   component = c(\"all\", \"conditional\", \"zi\", \"zero_inflated\"),   standardize = NULL,   exponentiate = FALSE,   p_adjust = NULL,   keep = NULL,   drop = NULL,   summary = getOption(\"parameters_summary\", FALSE),   verbose = TRUE,   ... )  # S3 method for hurdle model_parameters(   model,   ci = 0.95,   bootstrap = FALSE,   iterations = 1000,   component = c(\"all\", \"conditional\", \"zi\", \"zero_inflated\"),   standardize = NULL,   exponentiate = FALSE,   p_adjust = NULL,   keep = NULL,   drop = NULL,   summary = getOption(\"parameters_summary\", FALSE),   verbose = TRUE,   ... )  # S3 method for zerocount model_parameters(   model,   ci = 0.95,   bootstrap = FALSE,   iterations = 1000,   component = c(\"all\", \"conditional\", \"zi\", \"zero_inflated\"),   standardize = NULL,   exponentiate = FALSE,   p_adjust = NULL,   keep = NULL,   drop = NULL,   summary = getOption(\"parameters_summary\", FALSE),   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.zcpglm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameters from Zero-Inflated Models — model_parameters.zcpglm","text":"model model zero-inflation component. ci Confidence Interval (CI) level. Default 0.95 (95%). bootstrap estimates based bootstrapped model? TRUE, arguments Bayesian regressions apply (see also bootstrap_parameters()). iterations number bootstrap replicates. apply case bootstrapped frequentist models. component parameters, parameters conditional model, zero-inflated part model, dispersion model returned? Applies models zero-inflated /dispersion component. component may one \"conditional\", \"zi\", \"zero-inflated\", \"dispersion\" \"\" (default). May abbreviated. standardize method used standardizing parameters. Can NULL (default; standardization), \"refit\" (re-fitting model standardized data) one \"basic\", \"posthoc\", \"smart\", \"pseudo\". See 'Details' standardize_parameters(). Important: \"refit\" method standardized categorical predictors (.e. factors), may different behaviour compared R packages (lm.beta) software packages (like SPSS). mimic behaviours, either use standardize=\"basic\" standardize data datawizard::standardize(force=TRUE) fitting model. mixed models, using methods \"refit\", fixed effects returned. Robust estimation (.e., vcov set value NULL) standardized parameters works standardize=\"refit\". exponentiate Logical, indicating whether exponentiate coefficients (related confidence intervals). typical logistic regression, generally speaking, models log logit links. also recommended use exponentiate = TRUE models log-transformed response values. Note: Delta-method standard errors also computed (multiplying standard errors transformed coefficients). mimic behaviour software packages, Stata, standard errors poorly estimate uncertainty transformed coefficient. transformed confidence interval clearly captures uncertainty. compare_parameters(), exponentiate = \"nongaussian\" exponentiate coefficients non-Gaussian families. p_adjust Character vector, NULL, indicates method adjust p-values. See stats::p.adjust() details. possible adjustment methods \"tukey\", \"scheffe\", \"sidak\" \"none\" explicitly disable adjustment emmGrid objects (emmeans). keep Character containing regular expression pattern describes parameters included (keep) excluded (drop) returned data frame. keep may also named list regular expressions. non-matching parameters removed output. keep character vector, every parameter name \"Parameter\" column matches regular expression keep selected returned data frame (vice versa, parameter names matching drop excluded). Furthermore, keep one element, merged operator regular expression pattern like : \"(one|two|three)\". keep named list regular expression patterns, names list-element equal column name selection applied. useful model objects model_parameters() returns multiple columns parameter components, like model_parameters.lavaan(). Note regular expression pattern match parameter names stored returned data frame, can different printed. Inspect $Parameter column parameters table get exact parameter names. drop See keep. summary Logical, TRUE, prints summary information model (model formula, number observations, residual standard deviation ). verbose Toggle warnings messages. ... Arguments passed methods. instance, bootstrap = TRUE, arguments like type parallel passed bootstrap_model(), arguments like ci_method passed bayestestR::describe_posterior().","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.zcpglm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parameters from Zero-Inflated Models — model_parameters.zcpglm","text":"data frame indices related model's parameters.","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/model_parameters.zcpglm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parameters from Zero-Inflated Models — model_parameters.zcpglm","text":"","code":"library(parameters) if (require(\"pscl\")) {   data(\"bioChemists\")   model <- zeroinfl(art ~ fem + mar + kid5 + ment | kid5 + phd, data = bioChemists)   model_parameters(model) } #> Loading required package: pscl #> Classes and Methods for R developed in the #> Political Science Computational Laboratory #> Department of Political Science #> Stanford University #> Simon Jackman #> hurdle and zeroinfl functions by Achim Zeileis #> # Fixed Effects #>  #> Parameter     | Log-Mean |       SE |         95% CI |     z |      p #> --------------------------------------------------------------------- #> (Intercept)   |     0.56 |     0.07 | [ 0.43,  0.69] |  8.26 | < .001 #> fem [Women]   |    -0.23 |     0.06 | [-0.34, -0.11] | -3.91 | < .001 #> mar [Married] |     0.14 |     0.07 | [ 0.01,  0.27] |  2.07 | 0.038  #> kid5          |    -0.17 |     0.05 | [-0.26, -0.07] | -3.43 | < .001 #> ment          |     0.02 | 2.12e-03 | [ 0.02,  0.03] | 10.05 | < .001 #>  #> # Zero-Inflated #>  #> Parameter   | Log-Odds |   SE |         95% CI |     z |     p #> -------------------------------------------------------------- #> (Intercept) |    -0.93 | 0.43 | [-1.78, -0.08] | -2.14 | 0.032 #> kid5        |     0.05 | 0.22 | [-0.38,  0.47] |  0.21 | 0.831 #> phd         |    -0.25 | 0.14 | [-0.51,  0.02] | -1.84 | 0.065 #>  #> The model has a log- or logit-link. Consider using `exponentiate = TRUE` #>   to interpret coefficients as ratios."},{"path":"https://easystats.github.io/parameters/reference/n_clusters.html","id":null,"dir":"Reference","previous_headings":"","what":"Find number of clusters in your data — n_clusters","title":"Find number of clusters in your data — n_clusters","text":"Similarly n_factors() factor / principal component analysis, n_clusters main function find optimal numbers clusters present data based maximum consensus large number methods.  Essentially, exist many methods determine optimal number clusters, pros cons, benefits limitations. main n_clusters function proposes run , find number clusters suggested majority methods (case ties, select parsimonious solution fewer clusters).  Note also implement specific, commonly used methods, like Elbow Gap method, visualization functionalities. See examples details.","code":""},{"path":"https://easystats.github.io/parameters/reference/n_clusters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find number of clusters in your data — n_clusters","text":"","code":"n_clusters(   x,   standardize = TRUE,   include_factors = FALSE,   package = c(\"easystats\", \"NbClust\", \"mclust\"),   fast = TRUE,   nbclust_method = \"kmeans\",   n_max = 10,   ... )  n_clusters_elbow(   x,   standardize = TRUE,   include_factors = FALSE,   clustering_function = stats::kmeans,   n_max = 10,   ... )  n_clusters_gap(   x,   standardize = TRUE,   include_factors = FALSE,   clustering_function = stats::kmeans,   n_max = 10,   gap_method = \"firstSEmax\",   ... )  n_clusters_silhouette(   x,   standardize = TRUE,   include_factors = FALSE,   clustering_function = stats::kmeans,   n_max = 10,   ... )  n_clusters_dbscan(   x,   standardize = TRUE,   include_factors = FALSE,   method = c(\"kNN\", \"SS\"),   min_size = 0.1,   eps_n = 50,   eps_range = c(0.1, 3),   ... )  n_clusters_hclust(   x,   standardize = TRUE,   include_factors = FALSE,   distance_method = \"correlation\",   hclust_method = \"average\",   ci = 0.95,   iterations = 100,   ... )"},{"path":"https://easystats.github.io/parameters/reference/n_clusters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find number of clusters in your data — n_clusters","text":"x data frame. standardize Standardize dataframe clustering (default). include_factors Logical, TRUE, factors converted numerical values order included data determining number clusters. default, factors removed, methods determine number clusters need numeric input . package Package methods called determine number clusters. Can \"\" vector containing \"easystats\", \"NbClust\", \"mclust\", \"M3C\". fast FALSE, compute 4 indices (sets index = \"allong\" NbClust). deactivated default computationally heavy. nbclust_method clustering method (passed NbClust::NbClust() method). n_max Maximal number clusters test. ... Arguments passed methods. clustering_function, gap_method arguments passed functions. clustering_function used fviz_nbclust can kmeans, codecluster::pam, codecluster::clara, codecluster::fanny, . gap_method used cluster::maxSE extract optimal numbers clusters (see method argument). method, min_size, eps_n, eps_range Arguments DBSCAN algorithm. distance_method distance method (passed dist()). Used algorithms relying distance matrix, hclust dbscan. hclust_method hierarchical clustering method (passed hclust()). ci Confidence Interval (CI) level. Default 0.95 (95%). iterations number bootstrap replicates. apply case bootstrapped frequentist models.","code":""},{"path":"https://easystats.github.io/parameters/reference/n_clusters.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Find number of clusters in your data — n_clusters","text":"also plot()-method implemented see-package.","code":""},{"path":"https://easystats.github.io/parameters/reference/n_clusters.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find number of clusters in your data — n_clusters","text":"","code":"if (FALSE) { library(parameters)  # The main 'n_clusters' function =============================== if (require(\"mclust\", quietly = TRUE) && require(\"NbClust\", quietly = TRUE) &&   require(\"cluster\", quietly = TRUE) && require(\"see\", quietly = TRUE)) {   n <- n_clusters(iris[, 1:4], package = c(\"NbClust\", \"mclust\")) # package can be \"all\"   n   summary(n)   as.data.frame(n) # Duration is the time elapsed for each method in seconds   plot(n)    # The following runs all the method but it significantly slower   # n_clusters(iris[1:4], standardize = FALSE, package = \"all\", fast = FALSE) } } # \\donttest{ # # Specific Methods ========================= # Elbow method -------------------- if (require(\"openxlsx\", quietly = TRUE) &&   require(\"see\", quietly = TRUE) &&   require(\"factoextra\", quietly = TRUE)) {   x <- n_clusters_elbow(iris[1:4])   x   as.data.frame(x)   plot(x) }  # } # \\donttest{ # # Gap method -------------------- if (require(\"see\", quietly = TRUE) &&   require(\"cluster\", quietly = TRUE) &&   require(\"factoextra\", quietly = TRUE)) {   x <- n_clusters_gap(iris[1:4])   x   as.data.frame(x)   plot(x) }  # } # \\donttest{ # # Silhouette method -------------------------- if (require(\"factoextra\", quietly = TRUE)) {   x <- n_clusters_silhouette(iris[1:4])   x   as.data.frame(x)   plot(x) }  # } # \\donttest{ # if (require(\"dbscan\", quietly = TRUE)) {   # DBSCAN method -------------------------   # NOTE: This actually primarily estimates the 'eps' parameter, the number of   # clusters is a side effect (it's the number of clusters corresponding to   # this 'optimal' EPS parameter).   x <- n_clusters_dbscan(iris[1:4], method = \"kNN\", min_size = 0.05) # 5 percent   x   head(as.data.frame(x))   plot(x)    x <- n_clusters_dbscan(iris[1:4], method = \"SS\", eps_n = 100, eps_range = c(0.1, 2))   x   head(as.data.frame(x))   plot(x) }  # } # \\donttest{ # # hclust method ------------------------------- if (require(\"pvclust\", quietly = TRUE) &&   getRversion() >= \"3.6.0\") {   # iterations should be higher for real analyses   x <- n_clusters_hclust(iris[1:4], iterations = 50, ci = 0.90)   x   head(as.data.frame(x), n = 10) # Print 10 first rows   plot(x) } #> Warning: inappropriate distance matrices are omitted in computation: r =  0.5 #> Warning: inappropriate distance matrices are omitted in computation: r =  0.75 #> Warning: inappropriate distance matrices are omitted in computation: r =  1  # }"},{"path":"https://easystats.github.io/parameters/reference/n_factors.html","id":null,"dir":"Reference","previous_headings":"","what":"Number of components/factors to retain in PCA/FA — n_factors","title":"Number of components/factors to retain in PCA/FA — n_factors","text":"function runs many existing procedures determining many factors retain/extract factor analysis (FA) dimension reduction (PCA). returns number factors based maximum consensus methods. case ties, keep simplest model select solution fewer factors.","code":""},{"path":"https://easystats.github.io/parameters/reference/n_factors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Number of components/factors to retain in PCA/FA — n_factors","text":"","code":"n_factors(   x,   type = \"FA\",   rotation = \"varimax\",   algorithm = \"default\",   package = c(\"nFactors\", \"psych\"),   cor = NULL,   safe = TRUE,   n_max = NULL,   ... )  n_components(   x,   type = \"PCA\",   rotation = \"varimax\",   algorithm = \"default\",   package = c(\"nFactors\", \"psych\"),   cor = NULL,   safe = TRUE,   ... )"},{"path":"https://easystats.github.io/parameters/reference/n_factors.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Number of components/factors to retain in PCA/FA — n_factors","text":"x data frame. type Can \"FA\" \"PCA\", depending want . rotation used VSS (Simple Structure criterion, see psych::VSS()). rotation apply. Can \"none\", \"varimax\", \"quartimax\", \"bentlerT\", \"equamax\", \"varimin\", \"geominT\" \"bifactor\" orthogonal rotations, \"promax\", \"oblimin\", \"simplimax\", \"bentlerQ\", \"geominQ\", \"biquartimin\" \"cluster\" oblique transformations. algorithm Factoring method used VSS. Can \"pa\" Principal Axis Factor Analysis, \"minres\" minimum residual (OLS) factoring, \"mle\" Maximum Likelihood FA \"pc\" Principal Components. \"default\" select \"minres\" type = \"FA\" \"pc\" type = \"PCA\". package Package respective methods used. Can \"\" vector containing \"nFactors\", \"psych\", \"PCDimension\", \"fit\" \"EGAnet\". Note \"fit\" (actually also relies psych package) \"EGAnet\" can slow bigger datasets. Thus, default c(\"nFactors\", \"psych\"). must respective packages installed methods used. cor optional correlation matrix can used (note data must still passed first argument). NULL, compute running cor() passed data. safe TRUE, function run procedures try blocks, return work silently skip ones may fail. n_max set value (e.g., 10), drop results methods suggest higher number components. interpretation becomes 'methods suggested number lower n_max, results ...'. ... Arguments passed methods.","code":""},{"path":"https://easystats.github.io/parameters/reference/n_factors.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Number of components/factors to retain in PCA/FA — n_factors","text":"data frame.","code":""},{"path":"https://easystats.github.io/parameters/reference/n_factors.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Number of components/factors to retain in PCA/FA — n_factors","text":"n_components actually alias n_factors, different defaults function arguments.","code":""},{"path":"https://easystats.github.io/parameters/reference/n_factors.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Number of components/factors to retain in PCA/FA — n_factors","text":"also plot()-method implemented see-package.. n_components() convenient short n_factors(type = \"PCA\").","code":""},{"path":"https://easystats.github.io/parameters/reference/n_factors.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Number of components/factors to retain in PCA/FA — n_factors","text":"Bartlett, M. S. (1950). Tests significance factor analysis. British Journal statistical psychology, 3(2), 77-85. Bentler, P. M., & Yuan, K. H. (1996). Test linear trend eigenvalues covariance matrix application data analysis. British Journal Mathematical Statistical Psychology, 49(2), 299-312. Cattell, R. B. (1966). scree test number factors. Multivariate behavioral research, 1(2), 245-276. Finch, W. H. (2019). Using Fit Statistic Differences Determine Optimal Number Factors Retain Exploratory Factor Analysis. Educational Psychological Measurement. Zoski, K. W., & Jurs, S. (1996). objective counterpart visual scree test factor analysis: standard error scree. Educational Psychological Measurement, 56(3), 443-451. Zoski, K., & Jurs, S. (1993). Using multiple regression determine number factors retain factor analysis. Multiple Linear Regression Viewpoints, 20(1), 5-9. Nasser, F., Benson, J., & Wisenbaker, J. (2002). performance regression-based variations visual scree determining number common factors. Educational psychological measurement, 62(3), 397-419. Golino, H., Shi, D., Garrido, L. E., Christensen, . P., Nieto, M. D., Sadana, R., & Thiyagarajan, J. . (2018). Investigating performance Exploratory Graph Analysis traditional techniques identify number latent factors: simulation tutorial. Golino, H. F., & Epskamp, S. (2017). Exploratory graph analysis: new approach estimating number dimensions psychological research. PloS one, 12(6), e0174035. Revelle, W., & Rocklin, T. (1979). simple structure: alternative procedure estimating optimal number interpretable factors. Multivariate Behavioral Research, 14(4), 403-414. Velicer, W. F. (1976). Determining number components matrix partial correlations. Psychometrika, 41(3), 321-327.","code":""},{"path":"https://easystats.github.io/parameters/reference/n_factors.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Number of components/factors to retain in PCA/FA — n_factors","text":"","code":"library(parameters) if (require(\"nFactors\", quietly = TRUE) && require(\"EGAnet\", quietly = TRUE)) {   n_factors(mtcars, type = \"PCA\")    result <- n_factors(mtcars[1:5], type = \"FA\")   as.data.frame(result)   summary(result)   if (FALSE) {   if (require(\"PCDimension\", quietly = TRUE)) {     # Setting package = 'all' will increase the number of methods (but is slow)     n_factors(mtcars, type = \"PCA\", package = \"all\")     n_factors(mtcars, type = \"FA\", algorithm = \"mle\", package = \"all\")   }   } } #>  #> Attaching package: ‘lattice’ #> The following object is masked from ‘package:boot’: #>  #>     melanoma #>  #> Attaching package: ‘nFactors’ #> The following object is masked from ‘package:lattice’: #>  #>     parallel #>  #> EGAnet (version 1.2.0)  #> For help getting started, type browseVignettes(\"EGAnet\") #>   #> For bugs and errors, submit an issue to <https://github.com/hfgolino/EGAnet/issues>"},{"path":"https://easystats.github.io/parameters/reference/p_value.BFBayesFactor.html","id":null,"dir":"Reference","previous_headings":"","what":"p-values for Bayesian Models — p_value.BFBayesFactor","title":"p-values for Bayesian Models — p_value.BFBayesFactor","text":"function attempts return, compute, p-values Bayesian models.","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value.BFBayesFactor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"p-values for Bayesian Models — p_value.BFBayesFactor","text":"","code":"# S3 method for BFBayesFactor p_value(model, ...)"},{"path":"https://easystats.github.io/parameters/reference/p_value.BFBayesFactor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"p-values for Bayesian Models — p_value.BFBayesFactor","text":"model statistical model. ... Additional arguments","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value.BFBayesFactor.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"p-values for Bayesian Models — p_value.BFBayesFactor","text":"p-values.","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value.BFBayesFactor.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"p-values for Bayesian Models — p_value.BFBayesFactor","text":"Bayesian models, p-values corresponds probability direction (bayestestR::p_direction()), converted p-value using bayestestR::convert_pd_to_p().","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value.BFBayesFactor.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"p-values for Bayesian Models — p_value.BFBayesFactor","text":"","code":"data(iris) model <- lm(Petal.Length ~ Sepal.Length + Species, data = iris) p_value(model) #>           Parameter            p #> 1       (Intercept) 1.005180e-11 #> 2      Sepal.Length 1.121002e-28 #> 3 Speciesversicolor 9.645641e-67 #> 4  Speciesvirginica 4.917626e-71"},{"path":"https://easystats.github.io/parameters/reference/p_value.DirichletRegModel.html","id":null,"dir":"Reference","previous_headings":"","what":"p-values for Models with Special Components — p_value.DirichletRegModel","title":"p-values for Models with Special Components — p_value.DirichletRegModel","text":"function attempts return, compute, p-values models special model components.","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value.DirichletRegModel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"p-values for Models with Special Components — p_value.DirichletRegModel","text":"","code":"# S3 method for DirichletRegModel p_value(model, component = c(\"all\", \"conditional\", \"precision\"), ...)  # S3 method for averaging p_value(model, component = c(\"conditional\", \"full\"), ...)  # S3 method for betareg p_value(   model,   component = c(\"all\", \"conditional\", \"precision\"),   verbose = TRUE,   ... )  # S3 method for cgam p_value(model, component = c(\"all\", \"conditional\", \"smooth_terms\"), ...)  # S3 method for clm2 p_value(model, component = c(\"all\", \"conditional\", \"scale\"), ...)"},{"path":"https://easystats.github.io/parameters/reference/p_value.DirichletRegModel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"p-values for Models with Special Components — p_value.DirichletRegModel","text":"model statistical model. component parameters, parameters conditional model, precision- scale-component smooth_terms returned? component may one \"conditional\", \"precision\", \"scale\", \"smooth_terms\", \"full\" \"\" (default). ... Additional arguments verbose Toggle warnings messages.","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value.DirichletRegModel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"p-values for Models with Special Components — p_value.DirichletRegModel","text":"p-values.","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value.html","id":null,"dir":"Reference","previous_headings":"","what":"p-values — p_value","title":"p-values — p_value","text":"function attempts return, compute, p-values model's parameters. See documentation object's class: Bayesian models (rstanarm, brms, MCMCglmm, ...) Zero-inflated models (hurdle, zeroinfl, zerocount, ...) Marginal effects models (mfx) Models special components (DirichletRegModel, clm2, cgam, ...)","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"p-values — p_value","text":"","code":"p_value(model, ...)  # S3 method for default p_value(   model,   dof = NULL,   method = NULL,   component = \"all\",   vcov = NULL,   vcov_args = NULL,   verbose = TRUE,   ... )  # S3 method for emmGrid p_value(model, ci = 0.95, adjust = \"none\", ...)"},{"path":"https://easystats.github.io/parameters/reference/p_value.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"p-values — p_value","text":"model statistical model. ... Additional arguments dof Number degrees freedom used calculating confidence intervals. NULL (default), degrees freedom retrieved calling degrees_of_freedom() approximation method defined method. NULL, use argument override default degrees freedom used compute confidence intervals. method Method computing degrees freedom confidence intervals (CI) related p-values. Allowed following options (vary depending model class): \"residual\", \"normal\", \"likelihood\", \"satterthwaite\", \"kenward\", \"wald\", \"profile\", \"boot\", \"uniroot\", \"ml1\", \"betwithin\", \"hdi\", \"quantile\", \"ci\", \"eti\", \"si\", \"bci\", \"bcai\". See section Confidence intervals approximation degrees freedom model_parameters() details. component Model component parameters shown. See documentation object's class model_parameters() p_value() details. vcov Variance-covariance matrix used compute uncertainty estimates (e.g., robust standard errors). argument accepts covariance matrix, function returns covariance matrix, string identifies function used compute covariance matrix. covariance matrix function returns covariance matrix (e.g., stats::vcov()) string indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"vcovHC\", \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC. Cluster-robust: \"vcovCR\", \"CR0\", \"CR1\", \"CR1p\", \"CR1S\", \"CR2\", \"CR3\". See ?clubSandwich::vcovCR. Bootstrap: \"vcovBS\", \"xy\", \"residual\", \"wild\", \"mammen\", \"webb\". See ?sandwich::vcovBS. sandwich package functions: \"vcovHAC\", \"vcovPC\", \"vcovCL\", \"vcovPL\". vcov_args List arguments passed function identified vcov argument. function typically supplied sandwich clubSandwich packages. Please refer documentation (e.g., ?sandwich::vcovHAC) see list available arguments. verbose Toggle warnings messages. ci Confidence Interval (CI) level. Default 0.95 (95%). adjust Character value naming method used adjust p-values confidence intervals. See ?emmeans::summary.emmGrid details.","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"p-values — p_value","text":"data frame least two columns: parameter names p-values. Depending model, may also include columns model components etc.","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value.html","id":"confidence-intervals-and-approximation-of-degrees-of-freedom","dir":"Reference","previous_headings":"","what":"Confidence intervals and approximation of degrees of freedom","title":"p-values — p_value","text":"different ways approximating degrees freedom depending different assumptions nature model sampling distribution. ci_method argument modulates method computing degrees freedom (df) used calculate confidence intervals (CI) related p-values. Following options allowed, depending model class: Classical methods: Classical inference generally based Wald method. Wald approach inference computes test statistic dividing parameter estimate standard error (Coefficient / SE), comparing statistic t- normal distribution. approach can used compute CIs p-values. \"wald\": Applies non-Bayesian models. linear models, CIs computed using Wald method (SE t-distribution residual df); p-values computed using Wald method t-distribution residual df. models, CIs computed using Wald method (SE normal distribution); p-values computed using Wald method normal distribution. \"normal\" Applies non-Bayesian models. Compute Wald CIs p-values, always use normal distribution. \"residual\" Applies non-Bayesian models. Compute Wald CIs p-values, always use t-distribution residual df possible. residual df model determined, normal distribution used instead. Methods mixed models: Compared fixed effects (single-level) models, determining appropriate df Wald-based inference mixed models difficult. See R GLMM FAQ discussion. Several approximate methods computing df available, also consider instead using profile likelihood (\"profile\") bootstrap (\"boot\") CIs p-values instead. \"satterthwaite\" Applies linear mixed models. CIs computed using Wald method (SE t-distribution Satterthwaite df); p-values computed using Wald method t-distribution Satterthwaite df. \"kenward\" Applies linear mixed models. CIs computed using Wald method (Kenward-Roger SE t-distribution Kenward-Roger df); p-values computed using Wald method Kenward-Roger SE t-distribution Kenward-Roger df. \"ml1\" Applies linear mixed models. CIs computed using Wald method (SE t-distribution m-l-1 approximated df); p-values computed using Wald method t-distribution m-l-1 approximated df. See ci_ml1(). \"betwithin\" Applies linear mixed models generalized linear mixed models. CIs computed using Wald method (SE t-distribution -within df); p-values computed using Wald method t-distribution -within df. See ci_betwithin(). Likelihood-based methods: Likelihood-based inference based comparing likelihood maximum-likelihood estimate likelihood models one parameter values changed (e.g., set zero range alternative values). Likelihood ratios maximum-likelihood alternative models compared \\(\\chi\\)-squared distribution compute CIs p-values. \"profile\" Applies non-Bayesian models class glm, polr glmmTMB. CIs computed profiling likelihood curve parameter, using linear interpolation find likelihood ratio equals critical value; p-values computed using Wald method normal-distribution (note: might change future update!) \"uniroot\" Applies non-Bayesian models class glmmTMB. CIs computed profiling likelihood curve parameter, using root finding find likelihood ratio equals critical value; p-values computed using Wald method normal-distribution (note: might change future update!) Methods bootstrapped Bayesian models: Bootstrap-based inference based resampling refitting model resampled datasets. distribution parameter estimates across resampled datasets used approximate parameter's sampling distribution. Depending type model, several different methods bootstrapping constructing CIs p-values bootstrap distribution available. Bayesian models, inference based drawing samples model posterior distribution. \"quantile\" (\"eti\") Applies models (including Bayesian models). non-Bayesian models, applies bootstrap = TRUE. CIs computed equal tailed intervals using quantiles bootstrap posterior samples; p-values based probability direction. See bayestestR::eti(). \"hdi\" Applies models (including Bayesian models). non-Bayesian models, applies bootstrap = TRUE. CIs computed highest density intervals bootstrap posterior samples; p-values based probability direction. See bayestestR::hdi(). \"bci\" (\"bcai\") Applies models (including Bayesian models). non-Bayesian models, applies bootstrap = TRUE. CIs computed bias corrected accelerated intervals bootstrap posterior samples; p-values based probability direction. See bayestestR::bci(). \"si\" Applies Bayesian models proper priors. CIs computed support intervals comparing posterior samples prior samples; p-values based probability direction. See bayestestR::si(). \"boot\" Applies non-Bayesian models class merMod. CIs computed using parametric bootstrapping (simulating data fitted model); p-values computed using Wald method normal-distribution) (note: might change future update!). iteration-based methods \"boot\" (\"hdi\", \"quantile\", \"ci\", \"eti\", \"si\", \"bci\", \"bcai\"), p-values based probability direction (bayestestR::p_direction()), converted p-value using bayestestR::pd_to_p().","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"p-values — p_value","text":"","code":"data(iris) model <- lm(Petal.Length ~ Sepal.Length + Species, data = iris) p_value(model) #>           Parameter            p #> 1       (Intercept) 1.005180e-11 #> 2      Sepal.Length 1.121002e-28 #> 3 Speciesversicolor 9.645641e-67 #> 4  Speciesvirginica 4.917626e-71"},{"path":"https://easystats.github.io/parameters/reference/p_value.poissonmfx.html","id":null,"dir":"Reference","previous_headings":"","what":"p-values for Marginal Effects Models — p_value.poissonmfx","title":"p-values for Marginal Effects Models — p_value.poissonmfx","text":"function attempts return, compute, p-values marginal effects models package mfx.","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value.poissonmfx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"p-values for Marginal Effects Models — p_value.poissonmfx","text":"","code":"# S3 method for poissonmfx p_value(model, component = c(\"all\", \"conditional\", \"marginal\"), ...)  # S3 method for betaor p_value(model, component = c(\"all\", \"conditional\", \"precision\"), ...)  # S3 method for betamfx p_value(   model,   component = c(\"all\", \"conditional\", \"precision\", \"marginal\"),   ... )"},{"path":"https://easystats.github.io/parameters/reference/p_value.poissonmfx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"p-values for Marginal Effects Models — p_value.poissonmfx","text":"model statistical model. component parameters, parameters conditional model, precision-component marginal effects returned? component may one \"conditional\", \"precision\", \"marginal\" \"\" (default). ... Currently used.","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value.poissonmfx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"p-values for Marginal Effects Models — p_value.poissonmfx","text":"data frame least two columns: parameter names p-values. Depending model, may also include columns model components etc.","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value.poissonmfx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"p-values for Marginal Effects Models — p_value.poissonmfx","text":"","code":"if (require(\"mfx\", quietly = TRUE)) {   set.seed(12345)   n <- 1000   x <- rnorm(n)   y <- rnegbin(n, mu = exp(1 + 0.5 * x), theta = 0.5)   d <- data.frame(y, x)   model <- poissonmfx(y ~ x, data = d)    p_value(model)   p_value(model, component = \"marginal\") } #>  #> Attaching package: ‘zoo’ #> The following objects are masked from ‘package:base’: #>  #>     as.Date, as.Date.numeric #>   Parameter             p Component #> 1         x 9.631324e-254  marginal"},{"path":"https://easystats.github.io/parameters/reference/p_value.zcpglm.html","id":null,"dir":"Reference","previous_headings":"","what":"p-values for Models with Zero-Inflation — p_value.zcpglm","title":"p-values for Models with Zero-Inflation — p_value.zcpglm","text":"function attempts return, compute, p-values hurdle zero-inflated models.","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value.zcpglm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"p-values for Models with Zero-Inflation — p_value.zcpglm","text":"","code":"# S3 method for zcpglm p_value(model, component = c(\"all\", \"conditional\", \"zi\", \"zero_inflated\"), ...)  # S3 method for zeroinfl p_value(   model,   component = c(\"all\", \"conditional\", \"zi\", \"zero_inflated\"),   method = NULL,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/parameters/reference/p_value.zcpglm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"p-values for Models with Zero-Inflation — p_value.zcpglm","text":"model statistical model. component Model component parameters shown. See documentation object's class model_parameters() p_value() details. ... Additional arguments method Method computing degrees freedom confidence intervals (CI) related p-values. Allowed following options (vary depending model class): \"residual\", \"normal\", \"likelihood\", \"satterthwaite\", \"kenward\", \"wald\", \"profile\", \"boot\", \"uniroot\", \"ml1\", \"betwithin\", \"hdi\", \"quantile\", \"ci\", \"eti\", \"si\", \"bci\", \"bcai\". See section Confidence intervals approximation degrees freedom model_parameters() details. verbose Toggle warnings messages.","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value.zcpglm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"p-values for Models with Zero-Inflation — p_value.zcpglm","text":"data frame least two columns: parameter names p-values. Depending model, may also include columns model components etc.","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value.zcpglm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"p-values for Models with Zero-Inflation — p_value.zcpglm","text":"","code":"if (require(\"pscl\", quietly = TRUE)) {   data(\"bioChemists\")   model <- zeroinfl(art ~ fem + mar + kid5 | kid5 + phd, data = bioChemists)   p_value(model)   p_value(model, component = \"zi\") } #>          Parameter         p     Component #> 5 zero_(Intercept) 0.0446362 zero_inflated #> 6        zero_kid5 0.4146050 zero_inflated #> 7         zero_phd 0.0248504 zero_inflated"},{"path":"https://easystats.github.io/parameters/reference/p_value_betwithin.html","id":null,"dir":"Reference","previous_headings":"","what":"Between-within approximation for SEs, CIs and p-values — ci_betwithin","title":"Between-within approximation for SEs, CIs and p-values — ci_betwithin","text":"Approximation degrees freedom based \"-within\" heuristic.","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value_betwithin.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Between-within approximation for SEs, CIs and p-values — ci_betwithin","text":"","code":"ci_betwithin(model, ci = 0.95, ...)  dof_betwithin(model)  p_value_betwithin(model, dof = NULL, ...)"},{"path":"https://easystats.github.io/parameters/reference/p_value_betwithin.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Between-within approximation for SEs, CIs and p-values — ci_betwithin","text":"model mixed model. ci Confidence Interval (CI) level. Default 0.95 (95%). ... Additional arguments dof Degrees Freedom.","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value_betwithin.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Between-within approximation for SEs, CIs and p-values — ci_betwithin","text":"data frame.","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/p_value_betwithin.html","id":"small-sample-cluster-corrected-degrees-of-freedom","dir":"Reference","previous_headings":"","what":"Small Sample Cluster corrected Degrees of Freedom","title":"Between-within approximation for SEs, CIs and p-values — ci_betwithin","text":"Inferential statistics (like p-values, confidence intervals standard errors) may biased mixed models number clusters small (even sample size level-1 units high). cases recommended approximate accurate number degrees freedom inferential statistics (see Li Redden 2015). -within denominator degrees freedom approximation recommended particular (generalized) linear mixed models repeated measurements (longitudinal design). dof_betwithin() implements heuristic based -within approach. Note implementation return exactly results shown Li Redden 2015, similar.","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value_betwithin.html","id":"degrees-of-freedom-for-longitudinal-designs-repeated-measures-","dir":"Reference","previous_headings":"","what":"Degrees of Freedom for Longitudinal Designs (Repeated Measures)","title":"Between-within approximation for SEs, CIs and p-values — ci_betwithin","text":"particular repeated measure designs (longitudinal data analysis), -within heuristic likely accurate simply using residual infinite degrees freedom, dof_betwithin() returns different degrees freedom within-cluster -cluster effects.","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value_betwithin.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Between-within approximation for SEs, CIs and p-values — ci_betwithin","text":"Elff, M.; Heisig, J.P.; Schaeffer, M.; Shikano, S. (2019). Multilevel Analysis Clusters: Improving Likelihood-based Methods Provide Unbiased Estimates Accurate Inference, British Journal Political Science. Li, P., Redden, D. T. (2015). Comparing denominator degrees freedom approximations generalized linear mixed model analyzing binary outcome small sample cluster-randomized trials. BMC Medical Research Methodology, 15(1), 38. doi:10.1186/s12874-015-0026-x","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/p_value_betwithin.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Between-within approximation for SEs, CIs and p-values — ci_betwithin","text":"","code":"# \\donttest{ if (require(\"lme4\")) {   data(sleepstudy)   model <- lmer(Reaction ~ Days + (1 + Days | Subject), data = sleepstudy)   dof_betwithin(model)   p_value_betwithin(model) } #>     Parameter            p #> 1 (Intercept) 9.306054e-80 #> 2        Days 6.290140e-06 # }"},{"path":"https://easystats.github.io/parameters/reference/p_value_kenward.html","id":null,"dir":"Reference","previous_headings":"","what":"Kenward-Roger approximation for SEs, CIs and p-values — ci_kenward","title":"Kenward-Roger approximation for SEs, CIs and p-values — ci_kenward","text":"approximate F-test based Kenward-Roger (1997) approach.","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value_kenward.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Kenward-Roger approximation for SEs, CIs and p-values — ci_kenward","text":"","code":"ci_kenward(model, ci = 0.95)  dof_kenward(model)  p_value_kenward(model, dof = NULL)  se_kenward(model)"},{"path":"https://easystats.github.io/parameters/reference/p_value_kenward.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Kenward-Roger approximation for SEs, CIs and p-values — ci_kenward","text":"model statistical model. ci Confidence Interval (CI) level. Default 0.95 (95%). dof Degrees Freedom.","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value_kenward.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Kenward-Roger approximation for SEs, CIs and p-values — ci_kenward","text":"data frame.","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value_kenward.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Kenward-Roger approximation for SEs, CIs and p-values — ci_kenward","text":"Inferential statistics (like p-values, confidence intervals standard errors) may biased mixed models number clusters small (even sample size level-1 units high). cases recommended approximate accurate number degrees freedom inferential statistics. Unlike simpler approximation heuristics like \"m-l-1\" rule (dof_ml1), Kenward-Roger approximation also applicable complex multilevel designs, e.g. cross-classified clusters. However, \"m-l-1\" heuristic also applies generalized mixed models, approaches like Kenward-Roger Satterthwaite limited linear mixed models .","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value_kenward.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Kenward-Roger approximation for SEs, CIs and p-values — ci_kenward","text":"Kenward, M. G., & Roger, J. H. (1997). Small sample inference fixed effects restricted maximum likelihood. Biometrics, 983-997.","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/p_value_kenward.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Kenward-Roger approximation for SEs, CIs and p-values — ci_kenward","text":"","code":"# \\donttest{ if (require(\"lme4\", quietly = TRUE)) {   model <- lmer(Petal.Length ~ Sepal.Length + (1 | Species), data = iris)   p_value_kenward(model) } #>      Parameter            p #> 1  (Intercept) 9.605137e-01 #> 2 Sepal.Length 8.598429e-29 # }"},{"path":"https://easystats.github.io/parameters/reference/p_value_ml1.html","id":null,"dir":"Reference","previous_headings":"","what":"","title":"","text":"Approximation degrees freedom based \"m-l-1\" heuristic suggested Elff et al. (2019).","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value_ml1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"","text":"","code":"ci_ml1(model, ci = 0.95, ...)  dof_ml1(model)  p_value_ml1(model, dof = NULL, ...)"},{"path":"https://easystats.github.io/parameters/reference/p_value_ml1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"","text":"model mixed model. ci Confidence Interval (CI) level. Default 0.95 (95%). ... Additional arguments dof Degrees Freedom.","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value_ml1.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"","text":"data frame.","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/p_value_ml1.html","id":"small-sample-cluster-corrected-degrees-of-freedom","dir":"Reference","previous_headings":"","what":"Small Sample Cluster corrected Degrees of Freedom","title":"","text":"Inferential statistics (like p-values, confidence intervals standard errors) may biased mixed models number clusters small (even sample size level-1 units high). cases recommended approximate accurate number degrees freedom inferential statistics (see Li Redden 2015). m-l-1 heuristic approach uses t-distribution fewer degrees freedom (dof_ml1()) calculate p-values (p_value_ml1()) confidence intervals (ci(method = \"ml1\")).","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value_ml1.html","id":"degrees-of-freedom-for-longitudinal-designs-repeated-measures-","dir":"Reference","previous_headings":"","what":"Degrees of Freedom for Longitudinal Designs (Repeated Measures)","title":"","text":"particular repeated measure designs (longitudinal data analysis), m-l-1 heuristic likely accurate simply using residual infinite degrees freedom, dof_ml1() returns different degrees freedom within-cluster -cluster effects.","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value_ml1.html","id":"limitations-of-the-m-l-heuristic","dir":"Reference","previous_headings":"","what":"Limitations of the \"m-l-1\" Heuristic","title":"","text":"Note \"m-l-1\" heuristic applicable (least less accurate) complex multilevel designs, e.g. cross-classified clusters. cases, accurate approaches like Kenward-Roger approximation (dof_kenward()) recommended. However, \"m-l-1\" heuristic also applies generalized mixed models, approaches like Kenward-Roger Satterthwaite limited linear mixed models .","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value_ml1.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"","text":"Elff, M.; Heisig, J.P.; Schaeffer, M.; Shikano, S. (2019). Multilevel Analysis Clusters: Improving Likelihood-based Methods Provide Unbiased Estimates Accurate Inference, British Journal Political Science. Li, P., Redden, D. T. (2015). Comparing denominator degrees freedom approximations generalized linear mixed model analyzing binary outcome small sample cluster-randomized trials. BMC Medical Research Methodology, 15(1), 38. doi:10.1186/s12874-015-0026-x","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/p_value_ml1.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"","text":"","code":"# \\donttest{ if (require(\"lme4\")) {   model <- lmer(Petal.Length ~ Sepal.Length + (1 | Species), data = iris)   p_value_ml1(model) } #>      Parameter          p #> 1  (Intercept) 0.96504927 #> 2 Sepal.Length 0.04534945 # }"},{"path":"https://easystats.github.io/parameters/reference/p_value_robust.html","id":null,"dir":"Reference","previous_headings":"","what":"Robust p-values. Superseded by the vcov* arguments in p_value() — p_value_robust","title":"Robust p-values. Superseded by the vcov* arguments in p_value() — p_value_robust","text":"Robust p-values. Superseded vcov* arguments p_value()","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value_robust.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Robust p-values. Superseded by the vcov* arguments in p_value() — p_value_robust","text":"","code":"p_value_robust(   model,   vcov = \"HC\",   vcov_args = NULL,   component = \"conditional\",   method = NULL,   ... )"},{"path":"https://easystats.github.io/parameters/reference/p_value_robust.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Robust p-values. Superseded by the vcov* arguments in p_value() — p_value_robust","text":"model statistical model. vcov Variance-covariance matrix used compute uncertainty estimates (e.g., robust standard errors). argument accepts covariance matrix, function returns covariance matrix, string identifies function used compute covariance matrix. covariance matrix function returns covariance matrix (e.g., stats::vcov()) string indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"vcovHC\", \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC. Cluster-robust: \"vcovCR\", \"CR0\", \"CR1\", \"CR1p\", \"CR1S\", \"CR2\", \"CR3\". See ?clubSandwich::vcovCR. Bootstrap: \"vcovBS\", \"xy\", \"residual\", \"wild\", \"mammen\", \"webb\". See ?sandwich::vcovBS. sandwich package functions: \"vcovHAC\", \"vcovPC\", \"vcovCL\", \"vcovPL\". vcov_args List arguments passed function identified vcov argument. function typically supplied sandwich clubSandwich packages. Please refer documentation (e.g., ?sandwich::vcovHAC) see list available arguments. component Model component parameters shown. See documentation object's class model_parameters() p_value() details. method Method computing degrees freedom confidence intervals (CI) related p-values. Allowed following options (vary depending model class): \"residual\", \"normal\", \"likelihood\", \"satterthwaite\", \"kenward\", \"wald\", \"profile\", \"boot\", \"uniroot\", \"ml1\", \"betwithin\", \"hdi\", \"quantile\", \"ci\", \"eti\", \"si\", \"bci\", \"bcai\". See section Confidence intervals approximation degrees freedom model_parameters() details. ... Additional arguments","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value_satterthwaite.html","id":null,"dir":"Reference","previous_headings":"","what":"Satterthwaite approximation for SEs, CIs and p-values — ci_satterthwaite","title":"Satterthwaite approximation for SEs, CIs and p-values — ci_satterthwaite","text":"approximate F-test based Satterthwaite (1946) approach.","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value_satterthwaite.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Satterthwaite approximation for SEs, CIs and p-values — ci_satterthwaite","text":"","code":"ci_satterthwaite(model, ci = 0.95, ...)  dof_satterthwaite(model)  p_value_satterthwaite(model, dof = NULL, ...)  se_satterthwaite(model)"},{"path":"https://easystats.github.io/parameters/reference/p_value_satterthwaite.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Satterthwaite approximation for SEs, CIs and p-values — ci_satterthwaite","text":"model statistical model. ci Confidence Interval (CI) level. Default 0.95 (95%). ... Additional arguments dof Degrees Freedom.","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value_satterthwaite.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Satterthwaite approximation for SEs, CIs and p-values — ci_satterthwaite","text":"data frame.","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value_satterthwaite.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Satterthwaite approximation for SEs, CIs and p-values — ci_satterthwaite","text":"Inferential statistics (like p-values, confidence intervals standard errors) may biased mixed models number clusters small (even sample size level-1 units high). cases recommended approximate accurate number degrees freedom inferential statitics. Unlike simpler approximation heuristics like \"m-l-1\" rule (dof_ml1), Satterthwaite approximation also applicable complex multilevel designs. However, \"m-l-1\" heuristic also applies generalized mixed models, approaches like Kenward-Roger Satterthwaite limited linear mixed models .","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value_satterthwaite.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Satterthwaite approximation for SEs, CIs and p-values — ci_satterthwaite","text":"Satterthwaite FE (1946) approximate distribution estimates variance components. Biometrics Bulletin 2 (6):110–4.","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/p_value_satterthwaite.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Satterthwaite approximation for SEs, CIs and p-values — ci_satterthwaite","text":"","code":"# \\donttest{ if (require(\"lme4\", quietly = TRUE)) {   model <- lmer(Petal.Length ~ Sepal.Length + (1 | Species), data = iris)   p_value_satterthwaite(model) } #>      Parameter            p #> 1  (Intercept) 9.605145e-01 #> 2 Sepal.Length 7.882014e-29 # }"},{"path":"https://easystats.github.io/parameters/reference/parameters_type.html","id":null,"dir":"Reference","previous_headings":"","what":"Type of model parameters — parameters_type","title":"Type of model parameters — parameters_type","text":"regression model, parameters meaning. instance, intercept interpreted theoretical outcome value conditions (predictors set 0), whereas coefficients interpreted amounts change. Others, interactions, represent changes another parameter. parameters_type function attempts retrieve information meaning parameters. outputs dataframe information parameters, Type (whether parameter corresponds factor numeric predictor, whether (regular) interaction nested one), Link (whether parameter can interpreted mean value, slope association difference two levels) , case interactions, parameters impacted parameter.","code":""},{"path":"https://easystats.github.io/parameters/reference/parameters_type.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Type of model parameters — parameters_type","text":"","code":"parameters_type(model, ...)"},{"path":"https://easystats.github.io/parameters/reference/parameters_type.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Type of model parameters — parameters_type","text":"model statistical model. ... Arguments passed methods.","code":""},{"path":"https://easystats.github.io/parameters/reference/parameters_type.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Type of model parameters — parameters_type","text":"data frame.","code":""},{"path":"https://easystats.github.io/parameters/reference/parameters_type.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Type of model parameters — parameters_type","text":"","code":"library(parameters)  model <- lm(Sepal.Length ~ Petal.Length + Species, data = iris) parameters_type(model) #>           Parameter      Type        Link              Term     Variable #> 1       (Intercept) intercept        Mean       (Intercept)         <NA> #> 2      Petal.Length   numeric Association      Petal.Length Petal.Length #> 3 Speciesversicolor    factor  Difference Speciesversicolor      Species #> 4  Speciesvirginica    factor  Difference  Speciesvirginica      Species #>        Level Secondary_Parameter Secondary_Type Secondary_Link Secondary_Term #> 1       <NA>                <NA>             NA             NA             NA #> 2       <NA>                <NA>             NA             NA             NA #> 3 versicolor                <NA>             NA             NA             NA #> 4  virginica                <NA>             NA             NA             NA #>   Secondary_Variable Secondary_Level Tertiary_Parameter #> 1                 NA              NA                 NA #> 2                 NA              NA                 NA #> 3                 NA              NA                 NA #> 4                 NA              NA                 NA  model <- lm(Sepal.Length ~ Species + poly(Sepal.Width, 2), data = iris) parameters_type(model) #>               Parameter      Type        Link                  Term    Variable #> 1           (Intercept) intercept        Mean           (Intercept)        <NA> #> 2     Speciesversicolor    factor  Difference     Speciesversicolor     Species #> 3      Speciesvirginica    factor  Difference      Speciesvirginica     Species #> 4 poly(Sepal.Width, 2)1      poly Association poly(Sepal.Width, 2)1 Sepal.Width #> 5 poly(Sepal.Width, 2)2      poly Association poly(Sepal.Width, 2)2 Sepal.Width #>        Level Secondary_Parameter Secondary_Type Secondary_Link Secondary_Term #> 1       <NA>                <NA>             NA             NA             NA #> 2 versicolor                <NA>             NA             NA             NA #> 3  virginica                <NA>             NA             NA             NA #> 4          1                <NA>             NA             NA             NA #> 5          2                <NA>             NA             NA             NA #>   Secondary_Variable Secondary_Level Tertiary_Parameter #> 1                 NA              NA                 NA #> 2                 NA              NA                 NA #> 3                 NA              NA                 NA #> 4                 NA              NA                 NA #> 5                 NA              NA                 NA  model <- lm(Sepal.Length ~ Species + poly(Sepal.Width, 2, raw = TRUE), data = iris) parameters_type(model) #>                           Parameter      Type        Link                  Term #> 1                       (Intercept) intercept        Mean           (Intercept) #> 2                 Speciesversicolor    factor  Difference     Speciesversicolor #> 3                  Speciesvirginica    factor  Difference      Speciesvirginica #> 4 poly(Sepal.Width, 2, raw = TRUE)1  poly_raw Association poly(Sepal.Width, 2)1 #> 5 poly(Sepal.Width, 2, raw = TRUE)2  poly_raw Association poly(Sepal.Width, 2)2 #>      Variable      Level Secondary_Parameter Secondary_Type Secondary_Link #> 1        <NA>       <NA>                <NA>             NA             NA #> 2     Species versicolor                <NA>             NA             NA #> 3     Species  virginica                <NA>             NA             NA #> 4 Sepal.Width          1                <NA>             NA             NA #> 5 Sepal.Width          2                <NA>             NA             NA #>   Secondary_Term Secondary_Variable Secondary_Level Tertiary_Parameter #> 1             NA                 NA              NA                 NA #> 2             NA                 NA              NA                 NA #> 3             NA                 NA              NA                 NA #> 4             NA                 NA              NA                 NA #> 5             NA                 NA              NA                 NA  # Interactions model <- lm(Sepal.Length ~ Sepal.Width * Species, data = iris) parameters_type(model) #>                       Parameter        Type        Link              Term #> 1                   (Intercept)   intercept        Mean       (Intercept) #> 2                   Sepal.Width     numeric Association       Sepal.Width #> 3             Speciesversicolor      factor  Difference Speciesversicolor #> 4              Speciesvirginica      factor  Difference  Speciesvirginica #> 5 Sepal.Width:Speciesversicolor interaction  Difference Speciesversicolor #> 6  Sepal.Width:Speciesvirginica interaction  Difference  Speciesvirginica #>      Variable      Level Secondary_Parameter Secondary_Type Secondary_Link #> 1        <NA>       <NA>                <NA>           <NA>           <NA> #> 2 Sepal.Width       <NA>                <NA>           <NA>           <NA> #> 3     Species versicolor                <NA>           <NA>           <NA> #> 4     Species  virginica                <NA>           <NA>           <NA> #> 5     Species versicolor         Sepal.Width        numeric    Association #> 6     Species  virginica         Sepal.Width        numeric    Association #>   Secondary_Term Secondary_Variable Secondary_Level Tertiary_Parameter #> 1           <NA>               <NA>            <NA>               <NA> #> 2           <NA>               <NA>            <NA>               <NA> #> 3           <NA>               <NA>            <NA>               <NA> #> 4           <NA>               <NA>            <NA>               <NA> #> 5    Sepal.Width        Sepal.Width            <NA>               <NA> #> 6    Sepal.Width        Sepal.Width            <NA>               <NA>  model <- lm(Sepal.Length ~ Sepal.Width * Species * Petal.Length, data = iris) parameters_type(model) #>                                     Parameter        Type        Link #> 1                                 (Intercept)   intercept        Mean #> 2                                 Sepal.Width     numeric Association #> 3                           Speciesversicolor      factor  Difference #> 4                            Speciesvirginica      factor  Difference #> 5                                Petal.Length     numeric Association #> 6               Sepal.Width:Speciesversicolor interaction  Difference #> 7                Sepal.Width:Speciesvirginica interaction  Difference #> 8                    Sepal.Width:Petal.Length interaction Association #> 9              Speciesversicolor:Petal.Length interaction  Difference #> 10              Speciesvirginica:Petal.Length interaction  Difference #> 11 Sepal.Width:Speciesversicolor:Petal.Length interaction Association #> 12  Sepal.Width:Speciesvirginica:Petal.Length interaction Association #>                 Term     Variable      Level           Secondary_Parameter #> 1        (Intercept)         <NA>       <NA>                          <NA> #> 2        Sepal.Width  Sepal.Width       <NA>                          <NA> #> 3  Speciesversicolor      Species versicolor                          <NA> #> 4   Speciesvirginica      Species  virginica                          <NA> #> 5       Petal.Length Petal.Length       <NA>                          <NA> #> 6  Speciesversicolor      Species versicolor                   Sepal.Width #> 7   Speciesvirginica      Species  virginica                   Sepal.Width #> 8       Petal.Length Petal.Length       <NA>                   Sepal.Width #> 9       Petal.Length Petal.Length       <NA>             Speciesversicolor #> 10      Petal.Length Petal.Length       <NA>              Speciesvirginica #> 11      Petal.Length Petal.Length       <NA> Sepal.Width:Speciesversicolor #> 12      Petal.Length Petal.Length       <NA>  Sepal.Width:Speciesvirginica #>    Secondary_Type Secondary_Link    Secondary_Term Secondary_Variable #> 1            <NA>           <NA>              <NA>               <NA> #> 2            <NA>           <NA>              <NA>               <NA> #> 3            <NA>           <NA>              <NA>               <NA> #> 4            <NA>           <NA>              <NA>               <NA> #> 5            <NA>           <NA>              <NA>               <NA> #> 6         numeric    Association       Sepal.Width        Sepal.Width #> 7         numeric    Association       Sepal.Width        Sepal.Width #> 8         numeric    Association       Sepal.Width        Sepal.Width #> 9          factor     Difference Speciesversicolor            Species #> 10         factor     Difference  Speciesvirginica            Species #> 11    interaction     Difference Speciesversicolor            Species #> 12    interaction     Difference  Speciesvirginica            Species #>    Secondary_Level Tertiary_Parameter #> 1             <NA>               <NA> #> 2             <NA>               <NA> #> 3             <NA>               <NA> #> 4             <NA>               <NA> #> 5             <NA>               <NA> #> 6             <NA>               <NA> #> 7             <NA>               <NA> #> 8             <NA>               <NA> #> 9       versicolor               <NA> #> 10       virginica               <NA> #> 11      versicolor        Sepal.Width #> 12       virginica        Sepal.Width  model <- lm(Sepal.Length ~ Species * Sepal.Width, data = iris) parameters_type(model) #>                       Parameter        Type        Link              Term #> 1                   (Intercept)   intercept        Mean       (Intercept) #> 2             Speciesversicolor      factor  Difference Speciesversicolor #> 3              Speciesvirginica      factor  Difference  Speciesvirginica #> 4                   Sepal.Width     numeric Association       Sepal.Width #> 5 Speciesversicolor:Sepal.Width interaction  Difference       Sepal.Width #> 6  Speciesvirginica:Sepal.Width interaction  Difference       Sepal.Width #>      Variable      Level Secondary_Parameter Secondary_Type Secondary_Link #> 1        <NA>       <NA>                <NA>           <NA>           <NA> #> 2     Species versicolor                <NA>           <NA>           <NA> #> 3     Species  virginica                <NA>           <NA>           <NA> #> 4 Sepal.Width       <NA>                <NA>           <NA>           <NA> #> 5 Sepal.Width       <NA>   Speciesversicolor         factor     Difference #> 6 Sepal.Width       <NA>    Speciesvirginica         factor     Difference #>      Secondary_Term Secondary_Variable Secondary_Level Tertiary_Parameter #> 1              <NA>               <NA>            <NA>               <NA> #> 2              <NA>               <NA>            <NA>               <NA> #> 3              <NA>               <NA>            <NA>               <NA> #> 4              <NA>               <NA>            <NA>               <NA> #> 5 Speciesversicolor            Species      versicolor               <NA> #> 6  Speciesvirginica            Species       virginica               <NA>  model <- lm(Sepal.Length ~ Species / Sepal.Width, data = iris) parameters_type(model) #>                       Parameter      Type       Link              Term #> 1                   (Intercept) intercept       Mean       (Intercept) #> 2             Speciesversicolor    factor Difference Speciesversicolor #> 3              Speciesvirginica    factor Difference  Speciesvirginica #> 4     Speciessetosa:Sepal.Width    nested Difference       Sepal.Width #> 5 Speciesversicolor:Sepal.Width    nested Difference       Sepal.Width #> 6  Speciesvirginica:Sepal.Width    nested Difference       Sepal.Width #>      Variable      Level Secondary_Parameter Secondary_Type Secondary_Link #> 1        <NA>       <NA>                <NA>           <NA>           <NA> #> 2     Species versicolor                <NA>           <NA>           <NA> #> 3     Species  virginica                <NA>           <NA>           <NA> #> 4 Sepal.Width       <NA>       Speciessetosa         factor     Difference #> 5 Sepal.Width       <NA>   Speciesversicolor         factor     Difference #> 6 Sepal.Width       <NA>    Speciesvirginica         factor     Difference #>      Secondary_Term Secondary_Variable Secondary_Level Tertiary_Parameter #> 1              <NA>               <NA>            <NA>               <NA> #> 2              <NA>               <NA>            <NA>               <NA> #> 3              <NA>               <NA>            <NA>               <NA> #> 4     Speciessetosa            Species          setosa               <NA> #> 5 Speciesversicolor            Species      versicolor               <NA> #> 6  Speciesvirginica            Species       virginica               <NA>   # Complex interactions data <- iris data$fac2 <- ifelse(data$Sepal.Width > mean(data$Sepal.Width), \"A\", \"B\") model <- lm(Sepal.Length ~ Species / fac2 / Petal.Length, data = data) parameters_type(model) #>                               Parameter      Type        Link              Term #> 1                           (Intercept) intercept        Mean       (Intercept) #> 2                     Speciesversicolor    factor  Difference Speciesversicolor #> 3                      Speciesvirginica    factor  Difference  Speciesvirginica #> 4                   Speciessetosa:fac2B    nested  Difference             fac2B #> 5               Speciesversicolor:fac2B    nested  Difference             fac2B #> 6                Speciesvirginica:fac2B    nested  Difference             fac2B #> 7      Speciessetosa:fac2A:Petal.Length    nested Association      Petal.Length #> 8  Speciesversicolor:fac2A:Petal.Length    nested Association      Petal.Length #> 9   Speciesvirginica:fac2A:Petal.Length    nested Association      Petal.Length #> 10     Speciessetosa:fac2B:Petal.Length    nested Association      Petal.Length #> 11 Speciesversicolor:fac2B:Petal.Length    nested Association      Petal.Length #> 12  Speciesvirginica:fac2B:Petal.Length    nested Association      Petal.Length #>        Variable      Level     Secondary_Parameter Secondary_Type #> 1          <NA>       <NA>                    <NA>           <NA> #> 2       Species versicolor                    <NA>           <NA> #> 3       Species  virginica                    <NA>           <NA> #> 4          fac2          B           Speciessetosa         factor #> 5          fac2          B       Speciesversicolor         factor #> 6          fac2          B        Speciesvirginica         factor #> 7  Petal.Length       <NA>     Speciessetosa:fac2A    interaction #> 8  Petal.Length       <NA> Speciesversicolor:fac2A    interaction #> 9  Petal.Length       <NA>  Speciesvirginica:fac2A    interaction #> 10 Petal.Length       <NA>     Speciessetosa:fac2B         nested #> 11 Petal.Length       <NA> Speciesversicolor:fac2B         nested #> 12 Petal.Length       <NA>  Speciesvirginica:fac2B         nested #>    Secondary_Link    Secondary_Term Secondary_Variable Secondary_Level #> 1            <NA>              <NA>               <NA>            <NA> #> 2            <NA>              <NA>               <NA>            <NA> #> 3            <NA>              <NA>               <NA>            <NA> #> 4      Difference     Speciessetosa            Species          setosa #> 5      Difference Speciesversicolor            Species      versicolor #> 6      Difference  Speciesvirginica            Species       virginica #> 7      Difference             fac2A               fac2               A #> 8      Difference             fac2A               fac2               A #> 9      Difference             fac2A               fac2               A #> 10     Difference             fac2B               fac2               B #> 11     Difference             fac2B               fac2               B #> 12     Difference             fac2B               fac2               B #>    Tertiary_Parameter #> 1                <NA> #> 2                <NA> #> 3                <NA> #> 4                <NA> #> 5                <NA> #> 6                <NA> #> 7       Speciessetosa #> 8   Speciesversicolor #> 9    Speciesvirginica #> 10      Speciessetosa #> 11  Speciesversicolor #> 12   Speciesvirginica  model <- lm(Sepal.Length ~ Species / fac2 * Petal.Length, data = data) parameters_type(model) #>                               Parameter        Type        Link #> 1                           (Intercept)   intercept        Mean #> 2                     Speciesversicolor      factor  Difference #> 3                      Speciesvirginica      factor  Difference #> 4                          Petal.Length     numeric Association #> 5                   Speciessetosa:fac2B      nested  Difference #> 6               Speciesversicolor:fac2B      nested  Difference #> 7                Speciesvirginica:fac2B      nested  Difference #> 8        Speciesversicolor:Petal.Length interaction  Difference #> 9         Speciesvirginica:Petal.Length interaction  Difference #> 10     Speciessetosa:fac2B:Petal.Length      simple Association #> 11 Speciesversicolor:fac2B:Petal.Length      simple Association #> 12  Speciesvirginica:fac2B:Petal.Length      simple Association #>                 Term     Variable      Level     Secondary_Parameter #> 1        (Intercept)         <NA>       <NA>                    <NA> #> 2  Speciesversicolor      Species versicolor                    <NA> #> 3   Speciesvirginica      Species  virginica                    <NA> #> 4       Petal.Length Petal.Length       <NA>                    <NA> #> 5              fac2B         fac2          B           Speciessetosa #> 6              fac2B         fac2          B       Speciesversicolor #> 7              fac2B         fac2          B        Speciesvirginica #> 8       Petal.Length Petal.Length       <NA>       Speciesversicolor #> 9       Petal.Length Petal.Length       <NA>        Speciesvirginica #> 10      Petal.Length Petal.Length       <NA>     Speciessetosa:fac2B #> 11      Petal.Length Petal.Length       <NA> Speciesversicolor:fac2B #> 12      Petal.Length Petal.Length       <NA>  Speciesvirginica:fac2B #>    Secondary_Type Secondary_Link    Secondary_Term Secondary_Variable #> 1            <NA>           <NA>              <NA>               <NA> #> 2            <NA>           <NA>              <NA>               <NA> #> 3            <NA>           <NA>              <NA>               <NA> #> 4            <NA>           <NA>              <NA>               <NA> #> 5          factor     Difference     Speciessetosa            Species #> 6          factor     Difference Speciesversicolor            Species #> 7          factor     Difference  Speciesvirginica            Species #> 8          factor     Difference Speciesversicolor            Species #> 9          factor     Difference  Speciesvirginica            Species #> 10         nested     Difference             fac2B               fac2 #> 11         nested     Difference             fac2B               fac2 #> 12         nested     Difference             fac2B               fac2 #>    Secondary_Level Tertiary_Parameter #> 1             <NA>               <NA> #> 2             <NA>               <NA> #> 3             <NA>               <NA> #> 4             <NA>               <NA> #> 5           setosa               <NA> #> 6       versicolor               <NA> #> 7        virginica               <NA> #> 8       versicolor               <NA> #> 9        virginica               <NA> #> 10               B      Speciessetosa #> 11               B  Speciesversicolor #> 12               B   Speciesvirginica"},{"path":"https://easystats.github.io/parameters/reference/pool_parameters.html","id":null,"dir":"Reference","previous_headings":"","what":"Pool Model Parameters — pool_parameters","title":"Pool Model Parameters — pool_parameters","text":"function \"pools\" (.e. combines) model parameters similar fashion mice::pool(). However, function pools parameters parameters_model objects, returned model_parameters().","code":""},{"path":"https://easystats.github.io/parameters/reference/pool_parameters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pool Model Parameters — pool_parameters","text":"","code":"pool_parameters(   x,   exponentiate = FALSE,   effects = \"fixed\",   component = \"conditional\",   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/parameters/reference/pool_parameters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pool Model Parameters — pool_parameters","text":"x list parameters_model objects, returned model_parameters(), list model-objects supported model_parameters(). exponentiate Logical, indicating whether exponentiate coefficients (related confidence intervals). typical logistic regression, generally speaking, models log logit links. also recommended use exponentiate = TRUE models log-transformed response values. Note: Delta-method standard errors also computed (multiplying standard errors transformed coefficients). mimic behaviour software packages, Stata, standard errors poorly estimate uncertainty transformed coefficient. transformed confidence interval clearly captures uncertainty. compare_parameters(), exponentiate = \"nongaussian\" exponentiate coefficients non-Gaussian families. effects parameters fixed effects (\"fixed\"), random effects (\"random\"), (\"\") returned? applies mixed models. May abbreviated. calculation random effects parameters takes long, may use effects = \"fixed\". component parameters, parameters conditional model, zero-inflated part model, dispersion model returned? Applies models zero-inflated /dispersion component. component may one \"conditional\", \"zi\", \"zero-inflated\", \"dispersion\" \"\" (default). May abbreviated. verbose Toggle warnings messages. ... Currently used.","code":""},{"path":"https://easystats.github.io/parameters/reference/pool_parameters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pool Model Parameters — pool_parameters","text":"data frame indices related model's parameters.","code":""},{"path":"https://easystats.github.io/parameters/reference/pool_parameters.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Pool Model Parameters — pool_parameters","text":"Averaging parameters follows Rubin's rules (Rubin, 1987, p. 76). pooled degrees freedom based Barnard-Rubin adjustment small samples (Barnard Rubin, 1999).","code":""},{"path":"https://easystats.github.io/parameters/reference/pool_parameters.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Pool Model Parameters — pool_parameters","text":"Models multiple components, (instance, models zero-inflation, predictors appear count zero-inflated part) may fail case identical names coefficients different model components, since coefficient table grouped coefficient names pooling. cases, coefficients count zero-inflated model parts combined. Therefore, component argument defaults \"conditional\" avoid .","code":""},{"path":"https://easystats.github.io/parameters/reference/pool_parameters.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Pool Model Parameters — pool_parameters","text":"Barnard, J. Rubin, D.B. (1999). Small sample degrees freedom multiple imputation. Biometrika, 86, 948-955. Rubin, D.B. (1987). Multiple Imputation Nonresponse Surveys. New York: John Wiley Sons.","code":""},{"path":"https://easystats.github.io/parameters/reference/pool_parameters.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Pool Model Parameters — pool_parameters","text":"","code":"# example for multiple imputed datasets if (require(\"mice\")) {   data(\"nhanes2\")   imp <- mice(nhanes2, printFlag = FALSE)   models <- lapply(1:5, function(i) {     lm(bmi ~ age + hyp + chl, data = complete(imp, action = i))   })   pool_parameters(models)    # should be identical to:   m <- with(data = imp, exp = lm(bmi ~ age + hyp + chl))   summary(pool(m)) } #>          term    estimate  std.error statistic        df      p.value #> 1 (Intercept) 18.14256305 3.54562901  5.116881 11.625350 0.0002813879 #> 2    age40-59 -6.15715380 2.19792337 -2.801351  5.969005 0.0312810653 #> 3    age60-99 -7.72866592 2.45997959 -3.141760  6.642762 0.0174969755 #> 4      hypyes  2.46673562 2.07396774  1.189380  6.147560 0.2781911871 #> 5         chl  0.06028557 0.02078061  2.901050 10.206904 0.0154916183"},{"path":"https://easystats.github.io/parameters/reference/predict.parameters_clusters.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict method for parameters_clusters objects — predict.parameters_clusters","title":"Predict method for parameters_clusters objects — predict.parameters_clusters","text":"Predict method parameters_clusters objects","code":""},{"path":"https://easystats.github.io/parameters/reference/predict.parameters_clusters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict method for parameters_clusters objects — predict.parameters_clusters","text":"","code":"# S3 method for parameters_clusters predict(object, newdata = NULL, names = NULL, ...)"},{"path":"https://easystats.github.io/parameters/reference/predict.parameters_clusters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict method for parameters_clusters objects — predict.parameters_clusters","text":"object model object prediction desired. newdata data.frame names character vector list ... additional arguments affecting predictions produced.","code":""},{"path":"https://easystats.github.io/parameters/reference/principal_components.html","id":null,"dir":"Reference","previous_headings":"","what":"Principal Component Analysis (PCA) and Factor Analysis (FA) — factor_analysis","title":"Principal Component Analysis (PCA) and Factor Analysis (FA) — factor_analysis","text":"functions principal_components() factor_analysis() can used perform principal component analysis (PCA) factor analysis (FA). return loadings data frame, various methods functions available access / display information (see Details section).","code":""},{"path":"https://easystats.github.io/parameters/reference/principal_components.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Principal Component Analysis (PCA) and Factor Analysis (FA) — factor_analysis","text":"","code":"factor_analysis(   x,   n = \"auto\",   rotation = \"none\",   sort = FALSE,   threshold = NULL,   standardize = TRUE,   cor = NULL,   ... )  principal_components(   x,   n = \"auto\",   rotation = \"none\",   sort = FALSE,   threshold = NULL,   standardize = TRUE,   ... )  rotated_data(pca_results)  # S3 method for parameters_efa predict(object, newdata = NULL, names = NULL, keep_na = TRUE, ...)  # S3 method for parameters_efa print(x, digits = 2, sort = FALSE, threshold = NULL, labels = NULL, ...)  # S3 method for parameters_efa sort(x, ...)  closest_component(pca_results)"},{"path":"https://easystats.github.io/parameters/reference/principal_components.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Principal Component Analysis (PCA) and Factor Analysis (FA) — factor_analysis","text":"x data frame statistical model. n Number components extract. n=\"\", n set number variables minus 1 (ncol(x)-1). n=\"auto\" (default) n=NULL, number components selected n_factors() resp. n_components(). reduce_parameters(), can also \"max\", case select components maximally pseudo-loaded (.e., correlated) least one variable. rotation \"none\", PCA / FA computed using psych package. Possible options include \"varimax\", \"quartimax\", \"promax\", \"oblimin\", \"simplimax\", \"cluster\" (). See psych::fa() details. sort Sort loadings. threshold value 0 1 indicates (absolute) values loadings removed. integer higher 1 indicates n strongest loadings retain. Can also \"max\", case display maximum loading per variable (simple structure). standardize logical value indicating whether variables standardized (centered scaled) unit variance analysis (general, scaling advisable). cor optional correlation matrix can used (note data must still passed first argument). NULL, compute running cor() passed data. ... Arguments passed methods. pca_results output principal_components() function. object object class parameters_pca parameters_efa newdata optional data frame look variables predict. omitted, fitted values used. names Optional character vector name columns returned data frame. keep_na Logical, TRUE, predictions also return observations missing values original data, hence number rows predicted data original data equal. digits, labels Arguments print().","code":""},{"path":"https://easystats.github.io/parameters/reference/principal_components.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Principal Component Analysis (PCA) and Factor Analysis (FA) — factor_analysis","text":"data frame loadings.","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/principal_components.html","id":"methods-and-utilities","dir":"Reference","previous_headings":"","what":"Methods and Utilities","title":"Principal Component Analysis (PCA) and Factor Analysis (FA) — factor_analysis","text":"n_components() n_factors() automatically estimates optimal number dimensions retain. check_factorstructure() checks suitability data factor analysis using sphericity() sphericity() KMO measure. performance::check_itemscale() computes various measures internal consistencies applied (sub)scales (.e., components) extracted PCA. Running summary returns information related component/factor, explained variance Eivenvalues. Running get_scores() computes scores subscale. Running closest_component() return numeric vector assigned component index column original data frame. Running rotated_data() return rotated data, including missing values, matches original data frame. Running plot() visually displays loadings (requires see-package work).","code":""},{"path":"https://easystats.github.io/parameters/reference/principal_components.html","id":"complexity","dir":"Reference","previous_headings":"","what":"Complexity","title":"Principal Component Analysis (PCA) and Factor Analysis (FA) — factor_analysis","text":"Complexity represents number latent components needed account observed variables. Whereas perfect simple structure solution complexity 1 item load one factor, solution evenly distributed items complexity greater 1 (Hofman, 1978; Pettersson Turkheimer, 2010) .","code":""},{"path":"https://easystats.github.io/parameters/reference/principal_components.html","id":"uniqueness","dir":"Reference","previous_headings":"","what":"Uniqueness","title":"Principal Component Analysis (PCA) and Factor Analysis (FA) — factor_analysis","text":"Uniqueness represents variance 'unique' variable shared variables. equal 1 – communality (variance shared variables). uniqueness 0.20 suggests 20% variable's variance shared variables overall factor model. greater 'uniqueness' lower relevance variable factor model.","code":""},{"path":"https://easystats.github.io/parameters/reference/principal_components.html","id":"msa","dir":"Reference","previous_headings":"","what":"MSA","title":"Principal Component Analysis (PCA) and Factor Analysis (FA) — factor_analysis","text":"MSA represents Kaiser-Meyer-Olkin Measure Sampling Adequacy (Kaiser Rice, 1974) item. indicates whether enough data factor give reliable results PCA. value > 0.6, desirable values > 0.8 (Tabachnick Fidell, 2013).","code":""},{"path":"https://easystats.github.io/parameters/reference/principal_components.html","id":"pca-or-fa-","dir":"Reference","previous_headings":"","what":"PCA or FA?","title":"Principal Component Analysis (PCA) and Factor Analysis (FA) — factor_analysis","text":"simplified rule thumb may help decide whether run factor analysis principal component analysis: Run factor analysis assume wish test theoretical model latent factors causing observed variables. Run principal component analysis want simply reduce correlated observed variables smaller set important independent composite variables. (Source: CrossValidated)","code":""},{"path":"https://easystats.github.io/parameters/reference/principal_components.html","id":"computing-item-scores","dir":"Reference","previous_headings":"","what":"Computing Item Scores","title":"Principal Component Analysis (PCA) and Factor Analysis (FA) — factor_analysis","text":"Use get_scores() compute scores \"subscales\" represented extracted principal components. get_scores() takes results principal_components() extracts variables component found PCA. , \"subscales\", raw means calculated (equals adding single items dividing number items). results sum score component PCA, scale original, single items used compute PCA. One can also use predict() back-predict scores component, one can provide newdata vector names components.","code":""},{"path":"https://easystats.github.io/parameters/reference/principal_components.html","id":"explained-variance-and-eingenvalues","dir":"Reference","previous_headings":"","what":"Explained Variance and Eingenvalues","title":"Principal Component Analysis (PCA) and Factor Analysis (FA) — factor_analysis","text":"Use summary() get Eigenvalues explained variance extracted component. eigenvectors eigenvalues represent \"core\" PCA: eigenvectors (principal components) determine directions new feature space, eigenvalues determine magnitude. words, eigenvalues explain variance data along new feature axes.","code":""},{"path":"https://easystats.github.io/parameters/reference/principal_components.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Principal Component Analysis (PCA) and Factor Analysis (FA) — factor_analysis","text":"Kaiser, H.F. Rice. J. (1974). Little jiffy, mark iv. Educational Psychological Measurement, 34(1):111–117 Hofmann, R. (1978). Complexity simplicity objective indices descriptive factor solutions. Multivariate Behavioral Research, 13:2, 247-250, doi:10.1207/s15327906mbr1302_9 Pettersson, E., & Turkheimer, E. (2010). Item selection, evaluation, simple structure personality data. Journal research personality, 44(4), 407-420, doi:10.1016/j.jrp.2010.03.002 Tabachnick, B. G., Fidell, L. S. (2013). Using multivariate statistics (6th ed.). Boston: Pearson Education.","code":""},{"path":"https://easystats.github.io/parameters/reference/principal_components.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Principal Component Analysis (PCA) and Factor Analysis (FA) — factor_analysis","text":"","code":"library(parameters)  # \\donttest{ # Principal Component Analysis (PCA) ------------------- if (require(\"psych\")) {   principal_components(mtcars[, 1:7], n = \"all\", threshold = 0.2)   principal_components(mtcars[, 1:7],     n = 2, rotation = \"oblimin\",     threshold = \"max\", sort = TRUE   )   principal_components(mtcars[, 1:7], n = 2, threshold = 2, sort = TRUE)    pca <- principal_components(mtcars[, 1:5], n = 2, rotation = \"varimax\")   pca # Print loadings   summary(pca) # Print information about the factors   predict(pca, names = c(\"Component1\", \"Component2\")) # Back-predict scores    # which variables from the original data belong to which extracted component?   closest_component(pca)   # rotated_data(pca)  # TODO: doesn't work    # Automated number of components   principal_components(mtcars[, 1:4], n = \"auto\") } #> # Loadings from Principal Component Analysis (no rotation) #>  #> Variable |  PC1  | Complexity #> ----------------------------- #> mpg      | -0.93 |    1.00    #> cyl      | 0.96  |    1.00    #> disp     | 0.95  |    1.00    #> hp       | 0.91  |    1.00    #>  #> The unique principal component accounted for 87.55% of the total variance of the original data. # }    # Factor Analysis (FA) ------------------------ if (require(\"psych\")) {   factor_analysis(mtcars[, 1:7], n = \"all\", threshold = 0.2)   factor_analysis(mtcars[, 1:7], n = 2, rotation = \"oblimin\", threshold = \"max\", sort = TRUE)   factor_analysis(mtcars[, 1:7], n = 2, threshold = 2, sort = TRUE)    efa <- factor_analysis(mtcars[, 1:5], n = 2)   summary(efa)   predict(efa) # \\donttest{   # Automated number of components   factor_analysis(mtcars[, 1:4], n = \"auto\") # } } #> Warning: Could not retrieve information about missing data. Returning only #>   complete cases. #> # Loadings from Factor Analysis (no rotation) #>  #> Variable |  MR1  | Complexity | Uniqueness #> ------------------------------------------ #> mpg      | -0.90 |    1.00    |    0.19    #> cyl      | 0.96  |    1.00    |    0.08    #> disp     | 0.93  |    1.00    |    0.13    #> hp       | 0.86  |    1.00    |    0.26    #>  #> The unique latent factor accounted for 83.55% of the total variance of the original data."},{"path":"https://easystats.github.io/parameters/reference/print.parameters_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Print model parameters — print.parameters_model","title":"Print model parameters — print.parameters_model","text":"print()-method objects model_parameters().","code":""},{"path":"https://easystats.github.io/parameters/reference/print.parameters_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print model parameters — print.parameters_model","text":"","code":"# S3 method for parameters_model print(   x,   pretty_names = TRUE,   split_components = TRUE,   select = NULL,   caption = NULL,   digits = 2,   ci_digits = 2,   p_digits = 3,   footer_digits = 3,   show_sigma = FALSE,   show_formula = FALSE,   zap_small = FALSE,   groups = NULL,   column_width = NULL,   ci_brackets = c(\"[\", \"]\"),   ... )  # S3 method for parameters_model summary(object, ...)"},{"path":"https://easystats.github.io/parameters/reference/print.parameters_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print model parameters — print.parameters_model","text":"x, object object returned model_parameters(). pretty_names Return \"pretty\" (.e. human readable) parameter names. split_components Logical, TRUE (default), models multiple components (zero-inflation, smooth terms, ...), component printed separate table. FALSE, model parameters printed single table Component column added output. select Character vector (numeric index) column names printed. NULL (default), columns printed. shortcut select = \"minimal\" prints coefficient, confidence intervals p-values, select = \"short\" prints coefficient, standard errors p-values. caption Table caption string. NULL, table caption printed. digits, ci_digits, p_digits Number digits rounding significant figures. May also \"signif\" return significant figures \"scientific\" return scientific notation. Control number digits adding value suffix, e.g. digits = \"scientific4\" scientific notation 4 decimal places, digits = \"signif5\" 5 significant figures (see also signif()). footer_digits Number decimal places values footer summary. show_sigma Logical, TRUE, adds information residual standard deviation. show_formula Logical, TRUE, adds model formula output. zap_small Logical, TRUE, small values rounded digits decimal places. FALSE, values decimal places digits printed scientific notation. groups Named list, can used group parameters printed output. List elements may either character vectors match name parameters belong one group, list elements can row numbers parameter rows belong one group. names list elements used group names, inserted \"header row\". possible use case might emphasize focal predictors control variables, see 'Examples'. Parameters re-ordered according order used groups, non-matching parameters added end. column_width Width table columns. Can either NULL, named numeric vector, \"fixed\". NULL, width table column adjusted minimum required width. named numeric vector, value names matched column names, match, specified width used. \"fixed\", table split multiple components, columns across table components adjusted width. ci_brackets Logical, TRUE (default), CI-values encompassed square brackets (else parentheses). ... Arguments passed methods.","code":""},{"path":"https://easystats.github.io/parameters/reference/print.parameters_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print model parameters — print.parameters_model","text":"Invisibly returns original input object.","code":""},{"path":"https://easystats.github.io/parameters/reference/print.parameters_model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Print model parameters — print.parameters_model","text":"summary() convenient shortcut print(object, select = \"minimal\", show_sigma = TRUE, show_formula = TRUE).","code":""},{"path":"https://easystats.github.io/parameters/reference/print.parameters_model.html","id":"global-options-to-customize-messages-when-printing","dir":"Reference","previous_headings":"","what":"Global Options to Customize Messages when Printing","title":"Print model parameters — print.parameters_model","text":"verbose argument can used display silence messages warnings different functions parameters package. However, messages providing additional information can displayed suppressed using options(): parameters_summary: options(parameters_summary = TRUE) override summary argument model_parameters() always show model summary non-mixed models. parameters_mixed_summary: options(parameters_mixed_summary = TRUE) override summary argument model_parameters() mixed models, always show model summary. parameters_cimethod: options(parameters_cimethod = TRUE) show additional information approximation method used calculate confidence intervals p-values. Set FALSE hide message printing model_parameters() objects. parameters_exponentiate: options(parameters_exponentiate = TRUE) show additional information interpret coefficients models log-transformed response variables log-/logit-links exponentiate argument model_parameters() TRUE. Set option FALSE hide message printing model_parameters() objects.","code":""},{"path":"https://easystats.github.io/parameters/reference/print.parameters_model.html","id":"interpretation-of-interaction-terms","dir":"Reference","previous_headings":"","what":"Interpretation of Interaction Terms","title":"Print model parameters — print.parameters_model","text":"Note interpretation interaction terms depends many characteristics model. number parameters, overall performance model, can differ * b : b, / b, suggesting sometimes interaction terms give different parameterizations model, times gives completely different models (depending b factors covariates, included main effects , etc.). interpretation depends full context model, inferred parameters table alone - rather, recommend use packages calculate estimated marginal means marginal effects, modelbased, emmeans, ggeffects, marginaleffects. raise awareness issue, may use print(...,show_formula=TRUE) add model-specification output print() method model_parameters().","code":""},{"path":"https://easystats.github.io/parameters/reference/print.parameters_model.html","id":"labeling-the-degrees-of-freedom","dir":"Reference","previous_headings":"","what":"Labeling the Degrees of Freedom","title":"Print model parameters — print.parameters_model","text":"Throughout parameters package, decided label residual degrees freedom df_error. reason degrees freedom always refer residuals. certain models, refer estimate error - linear model , - instance - mixed effects model, strictly true. Hence, think df_error generic label degrees freedom.","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/print.parameters_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print model parameters — print.parameters_model","text":"","code":"# \\donttest{ library(parameters) if (require(\"glmmTMB\", quietly = TRUE)) {   model <- glmmTMB(     count ~ spp + mined + (1 | site),     ziformula = ~mined,     family = poisson(),     data = Salamanders   )   mp <- model_parameters(model)    print(mp, pretty_names = FALSE)    print(mp, split_components = FALSE)    print(mp, select = c(\"Parameter\", \"Coefficient\", \"SE\"))    print(mp, select = \"minimal\") } #> # Fixed Effects (Count Model) #>  #> Parameter   | Log-Mean |   SE |         95% CI |     z |      p #> --------------------------------------------------------------- #> (Intercept) |    -0.36 | 0.28 | [-0.90,  0.18] | -1.30 | 0.194  #> sppPR       |    -1.27 | 0.24 | [-1.74, -0.80] | -5.27 | < .001 #> sppDM       |     0.27 | 0.14 | [ 0.00,  0.54] |  1.95 | 0.051  #> sppEC-A     |    -0.57 | 0.21 | [-0.97, -0.16] | -2.75 | 0.006  #> sppEC-L     |     0.67 | 0.13 | [ 0.41,  0.92] |  5.20 | < .001 #> sppDES-L    |     0.63 | 0.13 | [ 0.38,  0.87] |  4.96 | < .001 #> sppDF       |     0.12 | 0.15 | [-0.17,  0.40] |  0.78 | 0.435  #> minedno     |     1.27 | 0.27 | [ 0.74,  1.80] |  4.72 | < .001 #>  #> # Fixed Effects (Zero-Inflated Model) #>  #> Parameter   | Log-Odds |   SE |         95% CI |     z |      p #> --------------------------------------------------------------- #> (Intercept) |     0.79 | 0.27 | [ 0.26,  1.32] |  2.90 | 0.004  #> minedno     |    -1.84 | 0.31 | [-2.46, -1.23] | -5.87 | < .001 #>  #> # Random Effects Variances #>  #> Parameter            | Coefficient |       95% CI #> ------------------------------------------------- #> SD (Intercept: site) |        0.33 | [0.18, 0.63] #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) computed #>   using a Wald z-distribution approximation. #>  #> The model has a log- or logit-link. Consider using `exponentiate = TRUE` #>   to interpret coefficients as ratios. #> # Fixed Effects #>  #> Parameter            | Coefficient |   SE |         95% CI |     z |      p | Effects |     Component #> ----------------------------------------------------------------------------------------------------- #> (Intercept)          |       -0.36 | 0.28 | [-0.90,  0.18] | -1.30 | 0.194  |   fixed |   conditional #> spp [PR]             |       -1.27 | 0.24 | [-1.74, -0.80] | -5.27 | < .001 |   fixed |   conditional #> spp [DM]             |        0.27 | 0.14 | [ 0.00,  0.54] |  1.95 | 0.051  |   fixed |   conditional #> spp [EC-A]           |       -0.57 | 0.21 | [-0.97, -0.16] | -2.75 | 0.006  |   fixed |   conditional #> spp [EC-L]           |        0.67 | 0.13 | [ 0.41,  0.92] |  5.20 | < .001 |   fixed |   conditional #> spp [DES-L]          |        0.63 | 0.13 | [ 0.38,  0.87] |  4.96 | < .001 |   fixed |   conditional #> spp [DF]             |        0.12 | 0.15 | [-0.17,  0.40] |  0.78 | 0.435  |   fixed |   conditional #> mined [no]           |        1.27 | 0.27 | [ 0.74,  1.80] |  4.72 | < .001 |   fixed |   conditional #> (Intercept)          |        0.79 | 0.27 | [ 0.26,  1.32] |  2.90 | 0.004  |   fixed | zero_inflated #> minedno              |       -1.84 | 0.31 | [-2.46, -1.23] | -5.87 | < .001 |   fixed | zero_inflated #> SD (Intercept: site) |        0.33 |      | [ 0.18,  0.63] |       |        |  random |   conditional #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) computed #>   using a Wald z-distribution approximation. #>  #> The model has a log- or logit-link. Consider using `exponentiate = TRUE` #>   to interpret coefficients as ratios. #> # Fixed Effects (Count Model) #>  #> Parameter   | Log-Mean |   SE #> ----------------------------- #> (Intercept) |    -0.36 | 0.28 #> spp [PR]    |    -1.27 | 0.24 #> spp [DM]    |     0.27 | 0.14 #> spp [EC-A]  |    -0.57 | 0.21 #> spp [EC-L]  |     0.67 | 0.13 #> spp [DES-L] |     0.63 | 0.13 #> spp [DF]    |     0.12 | 0.15 #> mined [no]  |     1.27 | 0.27 #>  #> # Fixed Effects (Zero-Inflated Model) #>  #> Parameter   | Log-Odds |   SE #> ----------------------------- #> (Intercept) |     0.79 | 0.27 #> mined [no]  |    -1.84 | 0.31 #>  #> # Random Effects Variances #>  #> Parameter            | Coefficient #> ---------------------------------- #> SD (Intercept: site) |        0.33 #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) computed #>   using a Wald z-distribution approximation. #>  #> The model has a log- or logit-link. Consider using `exponentiate = TRUE` #>   to interpret coefficients as ratios. #> # Fixed Effects (Count Model) #>  #> Parameter   | Log-Mean |         95% CI |      p #> ------------------------------------------------ #> (Intercept) |    -0.36 | [-0.90,  0.18] | 0.194  #> spp [PR]    |    -1.27 | [-1.74, -0.80] | < .001 #> spp [DM]    |     0.27 | [ 0.00,  0.54] | 0.051  #> spp [EC-A]  |    -0.57 | [-0.97, -0.16] | 0.006  #> spp [EC-L]  |     0.67 | [ 0.41,  0.92] | < .001 #> spp [DES-L] |     0.63 | [ 0.38,  0.87] | < .001 #> spp [DF]    |     0.12 | [-0.17,  0.40] | 0.435  #> mined [no]  |     1.27 | [ 0.74,  1.80] | < .001 #>  #> # Fixed Effects (Zero-Inflated Model) #>  #> Parameter   | Log-Odds |         95% CI |      p #> ------------------------------------------------ #> (Intercept) |     0.79 | [ 0.26,  1.32] | 0.004  #> mined [no]  |    -1.84 | [-2.46, -1.23] | < .001 #>  #> # Random Effects Variances #>  #> Parameter            | Coefficient |       95% CI #> ------------------------------------------------- #> SD (Intercept: site) |        0.33 | [0.18, 0.63] #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) computed #>   using a Wald z-distribution approximation. #>  #> The model has a log- or logit-link. Consider using `exponentiate = TRUE` #>   to interpret coefficients as ratios.   # group parameters ------  data(iris) model <- lm(   Sepal.Width ~ Sepal.Length + Species + Petal.Length,   data = iris ) # don't select \"Intercept\" parameter mp <- model_parameters(model, parameters = \"^(?!\\\\(Intercept)\") groups <- list(   \"Focal Predictors\" = c(\"Speciesversicolor\", \"Speciesvirginica\"),   \"Controls\" = c(\"Sepal.Length\", \"Petal.Length\") ) print(mp, groups = groups) #> Parameter              | Coefficient |   SE |         95% CI | t(145) |      p #> ------------------------------------------------------------------------------ #> Focal Predictors       |             |      |                |        |        #>   Species [versicolor] |       -0.89 | 0.20 | [-1.29, -0.49] |  -4.43 | < .001 #>   Species [virginica]  |       -0.88 | 0.28 | [-1.43, -0.33] |  -3.15 | 0.002  #> Controls               |             |      |                |        |        #>   Sepal Length         |        0.38 | 0.07 | [ 0.24,  0.52] |   5.31 | < .001 #>   Petal Length         |       -0.04 | 0.08 | [-0.21,  0.13] |  -0.50 | 0.618  #> (Intercept)            |        1.60 | 0.28 | [ 1.06,  2.15] |   5.80 | < .001 #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) computed #>   using a Wald t-distribution approximation.  # or use row indices print(mp, groups = list(   \"Focal Predictors\" = c(1, 4),   \"Controls\" = c(2, 3) )) #> Parameter              | Coefficient |   SE |         95% CI | t(145) |      p #> ------------------------------------------------------------------------------ #> Focal Predictors       |             |      |                |        |        #>   (Intercept)          |        1.60 | 0.28 | [ 1.06,  2.15] |   5.80 | < .001 #>   Species [virginica]  |       -0.88 | 0.28 | [-1.43, -0.33] |  -3.15 | 0.002  #> Controls               |             |      |                |        |        #>   Sepal Length         |        0.38 | 0.07 | [ 0.24,  0.52] |   5.31 | < .001 #>   Species [versicolor] |       -0.89 | 0.20 | [-1.29, -0.49] |  -4.43 | < .001 #> Petal Length           |       -0.04 | 0.08 | [-0.21,  0.13] |  -0.50 | 0.618  #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) computed #>   using a Wald t-distribution approximation.  # only show coefficients, CI and p, # put non-matched parameters to the end  data(mtcars) mtcars$cyl <- as.factor(mtcars$cyl) mtcars$gear <- as.factor(mtcars$gear) model <- lm(mpg ~ hp + gear * vs + cyl + drat, data = mtcars)  # don't select \"Intercept\" parameter mp <- model_parameters(model, parameters = \"^(?!\\\\(Intercept)\") print(mp, groups = list(   \"Engine\" = c(\"cyl6\", \"cyl8\", \"vs\", \"hp\"),   \"Interactions\" = c(\"gear4:vs\", \"gear5:vs\") )) #> Parameter        | Coefficient |   SE |          95% CI | t(22) |     p #> ----------------------------------------------------------------------- #> Engine           |             |      |                 |       |       #>   cyl [6]        |       -2.47 | 2.21 | [ -7.05,  2.12] | -1.12 | 0.276 #>   cyl [8]        |        1.97 | 5.11 | [ -8.63, 12.58] |  0.39 | 0.703 #>   vs             |        3.18 | 3.79 | [ -4.68, 11.04] |  0.84 | 0.410 #>   hp             |       -0.06 | 0.02 | [ -0.11, -0.02] | -2.91 | 0.008 #> Interactions     |             |      |                 |       |       #>   gear [4] * vs  |       -2.90 | 4.67 | [-12.57,  6.78] | -0.62 | 0.541 #>   gear [5] * vs  |        2.59 | 4.54 | [ -6.82, 12.00] |  0.57 | 0.574 #> (Intercept)      |       16.63 | 7.77 | [  0.53, 32.74] |  2.14 | 0.044 #> gear [4]         |        3.10 | 4.34 | [ -5.90, 12.10] |  0.71 | 0.482 #> gear [5]         |        4.80 | 3.48 | [ -2.42, 12.01] |  1.38 | 0.182 #> drat             |        2.70 | 2.03 | [ -1.52,  6.91] |  1.33 | 0.198 #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) computed #>   using a Wald t-distribution approximation. # }"},{"path":"https://easystats.github.io/parameters/reference/qol_cancer.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample data set — qol_cancer","title":"Sample data set — qol_cancer","text":"sample data set longitudinal data, used vignette describing datawizard::demean() function. Health-related quality life cancer-patients measured three time points (pre-surgery, 6 12 months surgery).","code":""},{"path":"https://easystats.github.io/parameters/reference/qol_cancer.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Sample data set — qol_cancer","text":"data frame 564 rows 7 variables: ID Patient ID QoL Quality Life Score time Timepoint measurement age Age years phq4 Patients' Health Questionnaire, 4-item version hospital Hospital ID, patient treated education Patients' educational level","code":""},{"path":"https://easystats.github.io/parameters/reference/random_parameters.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary information from random effects — random_parameters","title":"Summary information from random effects — random_parameters","text":"function extracts different variance components mixed model returns result data frame.","code":""},{"path":"https://easystats.github.io/parameters/reference/random_parameters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary information from random effects — random_parameters","text":"","code":"random_parameters(model, component = \"conditional\")"},{"path":"https://easystats.github.io/parameters/reference/random_parameters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary information from random effects — random_parameters","text":"model mixed effects model (including stanreg models). component parameters, parameters conditional model, zero-inflated part model, dispersion model returned? Applies models zero-inflated /dispersion component. component may one \"conditional\", \"zi\", \"zero-inflated\", \"dispersion\" \"\" (default). May abbreviated.","code":""},{"path":"https://easystats.github.io/parameters/reference/random_parameters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary information from random effects — random_parameters","text":"data frame random effects statistics variance components, including number levels per random effect group, well complete observations model.","code":""},{"path":"https://easystats.github.io/parameters/reference/random_parameters.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summary information from random effects — random_parameters","text":"variance components obtained insight::get_variance() denoted following: Note: within-group -group variance, variance standard deviations (simply square root variance) shown.","code":""},{"path":"https://easystats.github.io/parameters/reference/random_parameters.html","id":"within-group-or-residual-variance","dir":"Reference","previous_headings":"","what":"Within-group (or residual) variance","title":"Summary information from random effects — random_parameters","text":"residual variance, σ2ε, sum distribution-specific variance variance due additive dispersion. indicates within-group variance.","code":""},{"path":"https://easystats.github.io/parameters/reference/random_parameters.html","id":"between-group-random-intercept-variance","dir":"Reference","previous_headings":"","what":"Between-group random intercept variance","title":"Summary information from random effects — random_parameters","text":"random intercept variance, -group variance intercept (τ00), obtained VarCorr(). indicates much groups subjects differ .","code":""},{"path":"https://easystats.github.io/parameters/reference/random_parameters.html","id":"between-group-random-slope-variance","dir":"Reference","previous_headings":"","what":"Between-group random slope variance","title":"Summary information from random effects — random_parameters","text":"random slope variance, -group variance slopes (τ11) obtained VarCorr(). measure available mixed models random slopes. indicates much groups subjects differ according slopes.","code":""},{"path":"https://easystats.github.io/parameters/reference/random_parameters.html","id":"random-slope-intercept-correlation","dir":"Reference","previous_headings":"","what":"Random slope-intercept correlation","title":"Summary information from random effects — random_parameters","text":"random slope-intercept correlation (ρ01) obtained VarCorr(). measure available mixed models random intercepts slopes.","code":""},{"path":"https://easystats.github.io/parameters/reference/random_parameters.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary information from random effects — random_parameters","text":"","code":"if (require(\"lme4\")) {   data(sleepstudy)   model <- lmer(Reaction ~ Days + (1 + Days | Subject), data = sleepstudy)   random_parameters(model) } #> # Random Effects #>  #> Within-Group Variance          654.94 (25.59) #> Between-Group Variance #>   Random Intercept (Subject)    612.1 (24.74) #>   Random Slope (Subject.Days)   35.07  (5.92) #> Correlations #>   Subject.Days                   0.07 #> N (groups per factor) #>   Subject                          18 #> Observations                      180"},{"path":"https://easystats.github.io/parameters/reference/reduce_parameters.html","id":null,"dir":"Reference","previous_headings":"","what":"Dimensionality reduction (DR) / Features Reduction — reduce_parameters","title":"Dimensionality reduction (DR) / Features Reduction — reduce_parameters","text":"function performs reduction parameter space (number variables). starts creating new set variables, based given method (default method \"PCA\", available via method argument, \"cMDS\", \"DRR\" \"ICA\"). , names new dimensions using original variables correlates . instance, variable named 'V1_0.97/V4_-0.88' means V1 V4 variables correlate maximally (respective coefficients .97 -.88) dimension. Although function can useful exploratory data analysis, best perform dimension reduction step separate dedicated stage, important process data analysis workflow. reduce_data() alias reduce_parameters.data.frame().","code":""},{"path":"https://easystats.github.io/parameters/reference/reduce_parameters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dimensionality reduction (DR) / Features Reduction — reduce_parameters","text":"","code":"reduce_parameters(x, method = \"PCA\", n = \"max\", distance = \"euclidean\", ...)  reduce_data(x, method = \"PCA\", n = \"max\", distance = \"euclidean\", ...)"},{"path":"https://easystats.github.io/parameters/reference/reduce_parameters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Dimensionality reduction (DR) / Features Reduction — reduce_parameters","text":"x data frame statistical model. method feature reduction method. Can one \"PCA\", \"cMDS\", \"DRR\", \"ICA\" (see 'Details' section). n Number components extract. n=\"\", n set number variables minus 1 (ncol(x)-1). n=\"auto\" (default) n=NULL, number components selected n_factors() resp. n_components(). reduce_parameters(), can also \"max\", case select components maximally pseudo-loaded (.e., correlated) least one variable. distance distance measure used. applies method = \"cMDS\". must one \"euclidean\", \"maximum\", \"manhattan\", \"canberra\", \"binary\" \"minkowski\". unambiguous substring can given. ... Arguments passed methods.","code":""},{"path":"https://easystats.github.io/parameters/reference/reduce_parameters.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Dimensionality reduction (DR) / Features Reduction — reduce_parameters","text":"different methods available described : See also package vignette.","code":""},{"path":"https://easystats.github.io/parameters/reference/reduce_parameters.html","id":"supervised-methods","dir":"Reference","previous_headings":"","what":"Supervised Methods","title":"Dimensionality reduction (DR) / Features Reduction — reduce_parameters","text":"PCA: See principal_components(). cMDS / PCoA: Classical Multidimensional Scaling (cMDS) takes set dissimilarities (.e., distance matrix) returns set points distances points approximately equal dissimilarities. DRR: Dimensionality Reduction via Regression (DRR) recent technique extending PCA (Laparra et al., 2015). Starting rotated PCA, predicts redundant information remaining components using non-linear regression. notable advantages performing DRR avoidance multicollinearity predictors overfitting mitigation. DRR tends perform well first principal component enough explain variation predictors. Requires DRR package installed. ICA: Performs Independent Component Analysis using FastICA algorithm. Contrary PCA, attempts find uncorrelated sources (least squares minimization), ICA attempts find independent sources, .e., source space maximizes \"non-gaussianity\" sources. Contrary PCA, ICA rank source, makes poor tool dimensionality reduction. Requires fastICA package installed.","code":""},{"path":"https://easystats.github.io/parameters/reference/reduce_parameters.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Dimensionality reduction (DR) / Features Reduction — reduce_parameters","text":"Nguyen, L. H., Holmes, S. (2019). Ten quick tips effective dimensionality reduction. PLOS Computational Biology, 15(6). Laparra, V., Malo, J., Camps-Valls, G. (2015). Dimensionality reduction via regression hyperspectral imagery. IEEE Journal Selected Topics Signal Processing, 9(6), 1026-1036.","code":""},{"path":"https://easystats.github.io/parameters/reference/reduce_parameters.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Dimensionality reduction (DR) / Features Reduction — reduce_parameters","text":"","code":"data(iris) model <- lm(Sepal.Width ~ Species * Sepal.Length + Petal.Width, data = iris) model #>  #> Call: #> lm(formula = Sepal.Width ~ Species * Sepal.Length + Petal.Width,  #>     data = iris) #>  #> Coefficients: #>                    (Intercept)               Speciesversicolor   #>                        -0.4731                          1.2981   #>               Speciesvirginica                    Sepal.Length   #>                         1.2252                          0.7515   #>                    Petal.Width  Speciesversicolor:Sepal.Length   #>                         0.5662                         -0.5503   #>  Speciesvirginica:Sepal.Length   #>                        -0.5883   #>  reduce_parameters(model) #>  #> Call: #> lm(formula = Sepal.Width ~ `Petal.Width_0.98/Species.setosa_-0.90/Sepal.Length_0.89/Species.virginica_0.78` +  #>     `Species.versicolor_-0.99`, data = cbind(data, y)) #>  #> Coefficients: #>                                                                      (Intercept)   #>                                                                          3.05733   #> `Petal.Width_0.98/Species.setosa_-0.90/Sepal.Length_0.89/Species.virginica_0.78`   #>                                                                         -0.08903   #>                                                       `Species.versicolor_-0.99`   #>                                                                          0.14879   #>   out <- reduce_data(iris, method = \"PCA\", n = \"max\") head(out) #>   Petal.Length_0.99/Petal.Width_0.97/Species.setosa_-0.94/Sepal.Length_0.86/Species.virginica_0.73 #> 1                                                                                        -2.803852 #> 2                                                                                        -2.633035 #> 3                                                                                        -2.866923 #> 4                                                                                        -2.808656 #> 5                                                                                        -2.907343 #> 6                                                                                        -2.668523 #>   Species.versicolor_0.93 Sepal.Width_0.62 #> 1             -0.65195900        0.1365792 #> 2             -0.09924539       -0.8296167 #> 3             -0.26560467       -0.5984029 #> 4             -0.14622405       -0.8154592 #> 5             -0.73579102        0.2543209 #> 6             -1.14741717        1.0076406"},{"path":"https://easystats.github.io/parameters/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. bayestestR ci, equivalence_test datawizard demean, describe_distribution, kurtosis, rescale_weights, skewness, visualisation_recipe insight display, n_parameters, print_html, print_md, standardize_names, supported_models","code":""},{"path":"https://easystats.github.io/parameters/reference/reshape_loadings.html","id":null,"dir":"Reference","previous_headings":"","what":"Reshape loadings between wide/long formats — reshape_loadings","title":"Reshape loadings between wide/long formats — reshape_loadings","text":"Reshape loadings wide/long formats.","code":""},{"path":"https://easystats.github.io/parameters/reference/reshape_loadings.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reshape loadings between wide/long formats — reshape_loadings","text":"","code":"reshape_loadings(x, ...)  # S3 method for parameters_efa reshape_loadings(x, threshold = NULL, ...)  # S3 method for data.frame reshape_loadings(x, threshold = NULL, loadings_columns = NULL, ...)"},{"path":"https://easystats.github.io/parameters/reference/reshape_loadings.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reshape loadings between wide/long formats — reshape_loadings","text":"x data frame statistical model. ... Arguments passed methods. threshold value 0 1 indicates (absolute) values loadings removed. integer higher 1 indicates n strongest loadings retain. Can also \"max\", case display maximum loading per variable (simple structure). loadings_columns Vector indicating columns corresponding loadings.","code":""},{"path":"https://easystats.github.io/parameters/reference/reshape_loadings.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reshape loadings between wide/long formats — reshape_loadings","text":"","code":"if (require(\"psych\")) {   pca <- model_parameters(psych::fa(attitude, nfactors = 3))   loadings <- reshape_loadings(pca)    loadings   reshape_loadings(loadings) } #> Variable   |   MR1 |   MR2 |   MR3 | Complexity | Uniqueness #> ------------------------------------------------------------ #> rating     |  0.90 | -0.07 | -0.05 |       1.02 |       0.23 #> complaints |  0.97 | -0.06 |  0.04 |       1.01 |       0.10 #> privileges |  0.44 |  0.25 | -0.05 |       1.64 |       0.65 #> learning   |  0.47 |  0.54 | -0.28 |       2.51 |       0.24 #> raises     |  0.55 |  0.43 |  0.25 |       2.35 |       0.23 #> critical   |  0.16 |  0.17 |  0.48 |       1.46 |       0.67 #> advance    | -0.11 |  0.91 |  0.07 |       1.04 |       0.22"},{"path":"https://easystats.github.io/parameters/reference/select_parameters.html","id":null,"dir":"Reference","previous_headings":"","what":"Automated selection of model parameters — select_parameters","title":"Automated selection of model parameters — select_parameters","text":"function performs automated selection 'best' parameters, updating returning \"best\" model.","code":""},{"path":"https://easystats.github.io/parameters/reference/select_parameters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Automated selection of model parameters — select_parameters","text":"","code":"select_parameters(model, ...)  # S3 method for lm select_parameters(model, direction = \"both\", steps = 1000, k = 2, ...)  # S3 method for merMod select_parameters(model, direction = \"backward\", steps = 1000, ...)"},{"path":"https://easystats.github.io/parameters/reference/select_parameters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Automated selection of model parameters — select_parameters","text":"model statistical model (class lm, glm, merMod). ... Arguments passed methods. direction mode stepwise search, can one \"\",     \"backward\", \"forward\", default \"\".     scope argument missing default     direction \"backward\".  Values can abbreviated. steps maximum number steps considered.  default 1000     (essentially many required).  typically used stop     process early. k multiple number degrees freedom used penalty.     k = 2 gives genuine AIC: k = log(n) sometimes     referred BIC SBC.","code":""},{"path":"https://easystats.github.io/parameters/reference/select_parameters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Automated selection of model parameters — select_parameters","text":"model refitted optimal number parameters.","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/select_parameters.html","id":"classical-lm-and-glm","dir":"Reference","previous_headings":"","what":"Classical lm and glm","title":"Automated selection of model parameters — select_parameters","text":"frequentist GLMs, select_parameters() performs AIC-based stepwise selection.","code":""},{"path":"https://easystats.github.io/parameters/reference/select_parameters.html","id":"mixed-models","dir":"Reference","previous_headings":"","what":"Mixed models","title":"Automated selection of model parameters — select_parameters","text":"mixed-effects models class merMod, stepwise selection based cAIC4::stepcAIC(). step function searches \"best\" model based random-effects structure, .e. select_parameters() adds excludes random-effects cAIC improved .","code":""},{"path":"https://easystats.github.io/parameters/reference/select_parameters.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Automated selection of model parameters — select_parameters","text":"","code":"model <- lm(mpg ~ ., data = mtcars) select_parameters(model) #>  #> Call: #> lm(formula = mpg ~ wt + qsec + am, data = mtcars) #>  #> Coefficients: #> (Intercept)           wt         qsec           am   #>       9.618       -3.917        1.226        2.936   #>   model <- lm(mpg ~ cyl * disp * hp * wt, data = mtcars) select_parameters(model) #>  #> Call: #> lm(formula = mpg ~ cyl + disp + hp + wt + cyl:disp + cyl:hp +  #>     disp:hp + cyl:wt + disp:wt + hp:wt + cyl:disp:hp + cyl:hp:wt,  #>     data = mtcars) #>  #> Coefficients: #> (Intercept)          cyl         disp           hp           wt     cyl:disp   #>  49.1436077   -3.6167276   -1.2955318   -0.0004854   58.8328841    0.1704703   #>      cyl:hp      disp:hp       cyl:wt      disp:wt        hp:wt  cyl:disp:hp   #>  -0.0134573    0.0132124   -7.4915051   -0.0167172   -0.6524341   -0.0016542   #>   cyl:hp:wt   #>   0.0850798   #>  # \\donttest{ # lme4 ------------------------------------------- if (require(\"lme4\")) {   model <- lmer(     Sepal.Width ~ Sepal.Length * Petal.Width * Petal.Length + (1 | Species),     data = iris   )   select_parameters(model) } #> Linear mixed model fit by REML ['lmerMod'] #> Formula: Sepal.Width ~ Sepal.Length * Petal.Width * Petal.Length + (1 |   #>     Species) #>    Data: iris #> REML criterion at convergence: 50.9896 #> Random effects: #>  Groups   Name        Std.Dev. #>  Species  (Intercept) 0.8259   #>  Residual             0.2536   #> Number of obs: 150, groups:  Species, 3 #> Fixed Effects: #>                           (Intercept)                           Sepal.Length   #>                             -2.000229                               0.936730   #>                           Petal.Width                           Petal.Length   #>                              1.575526                               0.265556   #>              Sepal.Length:Petal.Width              Sepal.Length:Petal.Length   #>                             -0.282960                              -0.088409   #>              Petal.Width:Petal.Length  Sepal.Length:Petal.Width:Petal.Length   #>                              0.001866                               0.023319   # }"},{"path":"https://easystats.github.io/parameters/reference/simulate_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulated draws from model coefficients — simulate_model","title":"Simulated draws from model coefficients — simulate_model","text":"Simulate draws statistical model return data frame estimates.","code":""},{"path":"https://easystats.github.io/parameters/reference/simulate_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulated draws from model coefficients — simulate_model","text":"","code":"simulate_model(model, iterations = 1000, ...)  # S3 method for glmmTMB simulate_model(   model,   iterations = 1000,   component = c(\"all\", \"conditional\", \"zi\", \"zero_inflated\", \"dispersion\"),   verbose = FALSE,   ... )"},{"path":"https://easystats.github.io/parameters/reference/simulate_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulated draws from model coefficients — simulate_model","text":"model Statistical model (Bayesian models). iterations number draws simulate/bootstrap. ... Arguments passed methods. component parameters, parameters conditional model, zero-inflated part model, dispersion model returned? Applies models zero-inflated /dispersion component. component may one \"conditional\", \"zi\", \"zero-inflated\", \"dispersion\" \"\" (default). May abbreviated. verbose Toggle warnings messages.","code":""},{"path":"https://easystats.github.io/parameters/reference/simulate_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulated draws from model coefficients — simulate_model","text":"data frame.","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/simulate_model.html","id":"technical-details","dir":"Reference","previous_headings":"","what":"Technical Details","title":"Simulated draws from model coefficients — simulate_model","text":"simulate_model() computationally faster alternative bootstrap_model(). Simulated draws coefficients based multivariate normal distribution (MASS::mvrnorm()) mean mu = coef(model) variance Sigma = vcov(model).","code":""},{"path":"https://easystats.github.io/parameters/reference/simulate_model.html","id":"models-with-zero-inflation-component","dir":"Reference","previous_headings":"","what":"Models with Zero-Inflation Component","title":"Simulated draws from model coefficients — simulate_model","text":"models packages glmmTMB, pscl, GLMMadaptive countreg, component argument can used specify parameters simulated. models, parameters conditional component (fixed effects) simulated. may include smooth terms, random effects.","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/simulate_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulated draws from model coefficients — simulate_model","text":"","code":"model <- lm(Sepal.Length ~ Species * Petal.Width + Petal.Length, data = iris) head(simulate_model(model)) #>   (Intercept) Speciesversicolor Speciesvirginica Petal.Width Petal.Length #> 1    3.578917        -1.0559263        -1.901074   0.2631122    0.8899609 #> 2    3.376076        -1.1403367        -2.259263   0.9036852    0.9529287 #> 3    3.368157        -1.2242870        -2.254244   0.3834852    1.0085005 #> 4    3.738519        -0.8723322        -2.024824   0.4050788    0.8064803 #> 5    3.422207        -1.5791960        -2.419367   0.5907752    1.0237815 #> 6    3.312718        -0.9868987        -2.484990   0.4966756    1.0425791 #>   Speciesversicolor:Petal.Width Speciesvirginica:Petal.Width #> 1                    -0.5618509                   -0.3078486 #> 2                    -1.2019234                   -0.8205002 #> 3                    -0.7542596                   -0.4593781 #> 4                    -0.6722688                   -0.1876670 #> 5                    -0.8418091                   -0.6718195 #> 6                    -1.0995665                   -0.4683228 # \\donttest{ if (require(\"glmmTMB\", quietly = TRUE)) {   model <- glmmTMB(     count ~ spp + mined + (1 | site),     ziformula = ~mined,     family = poisson(),     data = Salamanders   )   head(simulate_model(model))   head(simulate_model(model, component = \"zero_inflated\")) } #>   (Intercept)   minedno #> 1   0.3039142 -1.508739 #> 2   0.7911131 -1.855135 #> 3   1.0665096 -1.872993 #> 4   0.4080663 -1.583814 #> 5   0.4679905 -1.533138 #> 6   1.2337763 -2.092550 # }"},{"path":"https://easystats.github.io/parameters/reference/simulate_parameters.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate Model Parameters — simulate_parameters.glmmTMB","title":"Simulate Model Parameters — simulate_parameters.glmmTMB","text":"Compute simulated draws parameters related indices Confidence Intervals (CI) p-values. Simulating parameter draws can seen (computationally faster) alternative bootstrapping.","code":""},{"path":"https://easystats.github.io/parameters/reference/simulate_parameters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate Model Parameters — simulate_parameters.glmmTMB","text":"","code":"# S3 method for glmmTMB simulate_parameters(   model,   iterations = 1000,   centrality = \"median\",   ci = 0.95,   ci_method = \"quantile\",   test = \"p-value\",   ... )  simulate_parameters(model, ...)  # S3 method for default simulate_parameters(   model,   iterations = 1000,   centrality = \"median\",   ci = 0.95,   ci_method = \"quantile\",   test = \"p-value\",   ... )"},{"path":"https://easystats.github.io/parameters/reference/simulate_parameters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate Model Parameters — simulate_parameters.glmmTMB","text":"model Statistical model (Bayesian models). iterations number draws simulate/bootstrap. centrality point-estimates (centrality indices) compute.  Character (vector) list one options: \"median\", \"mean\", \"MAP\" \"\". ci Value vector probability CI (0 1) estimated. Default .95 (95%). ci_method type index used Credible Interval. Can \"ETI\" (default, see eti()), \"HDI\" (see hdi()), \"BCI\" (see bci()), \"SPI\" (see spi()), \"SI\" (see si()). test indices effect existence compute. Character (vector) list one options: \"p_direction\" (\"pd\"), \"rope\", \"p_map\", \"equivalence_test\" (\"equitest\"), \"bayesfactor\" (\"bf\") \"\" compute tests. \"test\", corresponding bayestestR function called (e.g. rope() p_direction()) results included summary output. ... Arguments passed methods.","code":""},{"path":"https://easystats.github.io/parameters/reference/simulate_parameters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate Model Parameters — simulate_parameters.glmmTMB","text":"data frame simulated parameters.","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/simulate_parameters.html","id":"technical-details","dir":"Reference","previous_headings":"","what":"Technical Details","title":"Simulate Model Parameters — simulate_parameters.glmmTMB","text":"simulate_parameters() computationally faster alternative bootstrap_parameters(). Simulated draws coefficients based multivariate normal distribution (MASS::mvrnorm()) mean mu = coef(model) variance Sigma = vcov(model).","code":""},{"path":"https://easystats.github.io/parameters/reference/simulate_parameters.html","id":"models-with-zero-inflation-component","dir":"Reference","previous_headings":"","what":"Models with Zero-Inflation Component","title":"Simulate Model Parameters — simulate_parameters.glmmTMB","text":"models packages glmmTMB, pscl, GLMMadaptive countreg, component argument can used specify parameters simulated. models, parameters conditional component (fixed effects) simulated. may include smooth terms, random effects.","code":""},{"path":"https://easystats.github.io/parameters/reference/simulate_parameters.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Simulate Model Parameters — simulate_parameters.glmmTMB","text":"also plot()-method implemented see-package.","code":""},{"path":"https://easystats.github.io/parameters/reference/simulate_parameters.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Simulate Model Parameters — simulate_parameters.glmmTMB","text":"Gelman , Hill J. Data analysis using regression multilevel/hierarchical models. Cambridge; New York: Cambridge University Press 2007: 140-143","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/simulate_parameters.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate Model Parameters — simulate_parameters.glmmTMB","text":"","code":"model <- lm(Sepal.Length ~ Species * Petal.Width + Petal.Length, data = iris) simulate_parameters(model) #> # Fixed Effects #>  #> Parameter                     | Coefficient |         95% CI |      p #> --------------------------------------------------------------------- #> (Intercept)                   |        3.53 | [ 3.22,  3.86] | < .001 #> Speciesversicolor             |       -1.17 | [-1.90, -0.38] | 0.002  #> Speciesvirginica              |       -2.26 | [-3.09, -1.42] | < .001 #> Petal.Width                   |        0.41 | [-0.46,  1.33] | 0.388  #> Petal.Length                  |        0.94 | [ 0.79,  1.09] | < .001 #> Speciesversicolor:Petal.Width |       -0.76 | [-1.84,  0.34] | 0.182  #> Speciesvirginica:Petal.Width  |       -0.38 | [-1.33,  0.61] | 0.468  #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) computed #>   using a MCMC distribution approximation.  if (FALSE) { if (require(\"glmmTMB\", quietly = TRUE)) {   model <- glmmTMB(     count ~ spp + mined + (1 | site),     ziformula = ~mined,     family = poisson(),     data = Salamanders   )   simulate_parameters(model, centrality = \"mean\")   simulate_parameters(model, ci = c(.8, .95), component = \"zero_inflated\") } }"},{"path":"https://easystats.github.io/parameters/reference/sort_parameters.html","id":null,"dir":"Reference","previous_headings":"","what":"Sort parameters by coefficient values — sort_parameters","title":"Sort parameters by coefficient values — sort_parameters","text":"Sort parameters coefficient values","code":""},{"path":"https://easystats.github.io/parameters/reference/sort_parameters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sort parameters by coefficient values — sort_parameters","text":"","code":"sort_parameters(x, ...)  # S3 method for default sort_parameters(x, sort = \"none\", column = \"Coefficient\", ...)"},{"path":"https://easystats.github.io/parameters/reference/sort_parameters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sort parameters by coefficient values — sort_parameters","text":"x data frame parameters_model object. ... Arguments passed methods. sort \"none\" (default) sort, \"ascending\" sort increasing coefficient value, \"descending\" sort decreasing coefficient value. column column containing model parameter estimates. \"Coefficient\" (default) easystats packages, \"estimate\" broom package, etc.","code":""},{"path":"https://easystats.github.io/parameters/reference/sort_parameters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sort parameters by coefficient values — sort_parameters","text":"sorted data frame original object.","code":""},{"path":"https://easystats.github.io/parameters/reference/sort_parameters.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sort parameters by coefficient values — sort_parameters","text":"","code":"# creating object to sort (can also be a regular data frame) mod <- model_parameters(stats::lm(wt ~ am * cyl, data = mtcars))  # original output mod #> Parameter   | Coefficient |   SE |        95% CI | t(28) |      p #> ----------------------------------------------------------------- #> (Intercept) |        1.66 | 0.59 | [ 0.46, 2.86] |  2.82 | 0.009  #> am          |       -0.96 | 0.79 | [-2.58, 0.67] | -1.21 | 0.238  #> cyl         |        0.30 | 0.08 | [ 0.13, 0.47] |  3.68 | < .001 #> am * cyl    |        0.03 | 0.13 | [-0.23, 0.30] |  0.25 | 0.803  #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) computed #>   using a Wald t-distribution approximation.  # sorted outputs sort_parameters(mod, sort = \"ascending\") #> Parameter   | Coefficient |   SE |        95% CI | t(28) |      p #> ----------------------------------------------------------------- #> am          |       -0.96 | 0.79 | [-2.58, 0.67] | -1.21 | 0.238  #> am * cyl    |        0.03 | 0.13 | [-0.23, 0.30] |  0.25 | 0.803  #> cyl         |        0.30 | 0.08 | [ 0.13, 0.47] |  3.68 | < .001 #> (Intercept) |        1.66 | 0.59 | [ 0.46, 2.86] |  2.82 | 0.009  #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) computed #>   using a Wald t-distribution approximation. sort_parameters(mod, sort = \"descending\") #> Parameter   | Coefficient |   SE |        95% CI | t(28) |      p #> ----------------------------------------------------------------- #> (Intercept) |        1.66 | 0.59 | [ 0.46, 2.86] |  2.82 | 0.009  #> cyl         |        0.30 | 0.08 | [ 0.13, 0.47] |  3.68 | < .001 #> am * cyl    |        0.03 | 0.13 | [-0.23, 0.30] |  0.25 | 0.803  #> am          |       -0.96 | 0.79 | [-2.58, 0.67] | -1.21 | 0.238  #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) computed #>   using a Wald t-distribution approximation."},{"path":"https://easystats.github.io/parameters/reference/standard_error.html","id":null,"dir":"Reference","previous_headings":"","what":"Standard Errors — standard_error","title":"Standard Errors — standard_error","text":"standard_error() attempts return standard errors model parameters","code":""},{"path":"https://easystats.github.io/parameters/reference/standard_error.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Standard Errors — standard_error","text":"","code":"standard_error(model, ...)  # S3 method for default standard_error(   model,   component = \"all\",   vcov = NULL,   vcov_args = NULL,   verbose = TRUE,   ... )  # S3 method for factor standard_error(model, force = FALSE, verbose = TRUE, ...)  # S3 method for glmmTMB standard_error(   model,   effects = \"fixed\",   component = \"all\",   verbose = TRUE,   ... )  # S3 method for merMod standard_error(   model,   effects = \"fixed\",   method = NULL,   vcov = NULL,   vcov_args = NULL,   ... )"},{"path":"https://easystats.github.io/parameters/reference/standard_error.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Standard Errors — standard_error","text":"model model. ... Arguments passed methods. component Model component standard errors shown. See documentation object's class model_parameters() p_value() details. vcov Variance-covariance matrix used compute uncertainty estimates (e.g., robust standard errors). argument accepts covariance matrix, function returns covariance matrix, string identifies function used compute covariance matrix. covariance matrix function returns covariance matrix (e.g., stats::vcov()) string indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"vcovHC\", \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC. Cluster-robust: \"vcovCR\", \"CR0\", \"CR1\", \"CR1p\", \"CR1S\", \"CR2\", \"CR3\". See ?clubSandwich::vcovCR. Bootstrap: \"vcovBS\", \"xy\", \"residual\", \"wild\", \"mammen\", \"webb\". See ?sandwich::vcovBS. sandwich package functions: \"vcovHAC\", \"vcovPC\", \"vcovCL\", \"vcovPL\". vcov_args List arguments passed function identified vcov argument. function typically supplied sandwich clubSandwich packages. Please refer documentation (e.g., ?sandwich::vcovHAC) see list available arguments. verbose Toggle warnings messages. force Logical, TRUE, factors converted numerical values calculate standard error, lowest level value 1 (unless factor numeric levels, converted corresponding numeric value). default, NA returned factors character vectors. effects standard errors fixed effects (\"fixed\"), random effects (\"random\"), (\"\") returned? applies mixed models. May abbreviated. standard errors random effects requested, grouping factor list standard errors (per group level) random intercepts slopes returned. method Method computing degrees freedom confidence intervals (CI) related p-values. Allowed following options (vary depending model class): \"residual\", \"normal\", \"likelihood\", \"satterthwaite\", \"kenward\", \"wald\", \"profile\", \"boot\", \"uniroot\", \"ml1\", \"betwithin\", \"hdi\", \"quantile\", \"ci\", \"eti\", \"si\", \"bci\", \"bcai\". See section Confidence intervals approximation degrees freedom model_parameters() details.","code":""},{"path":"https://easystats.github.io/parameters/reference/standard_error.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Standard Errors — standard_error","text":"data frame least two columns: parameter names standard errors. Depending model, may also include columns model components etc.","code":""},{"path":"https://easystats.github.io/parameters/reference/standard_error.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Standard Errors — standard_error","text":"Bayesian models (rstanarm brms), standard error SD posterior samples.","code":""},{"path":"https://easystats.github.io/parameters/reference/standard_error.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Standard Errors — standard_error","text":"","code":"model <- lm(Petal.Length ~ Sepal.Length * Species, data = iris) standard_error(model) #>                        Parameter        SE #> 1                    (Intercept) 0.5310388 #> 2                   Sepal.Length 0.1058237 #> 3              Speciesversicolor 0.6836543 #> 4               Speciesvirginica 0.6578142 #> 5 Sepal.Length:Speciesversicolor 0.1281447 #> 6  Sepal.Length:Speciesvirginica 0.1209952  if (require(\"sandwich\") && require(\"clubSandwich\")) {   standard_error(model, vcov = \"HC3\")    standard_error(model,     vcov = \"vcovCL\",     vcov_args = list(cluster = iris$Species)   ) } #>                        Parameter           SE #> 1                    (Intercept) 1.397486e-15 #> 2                   Sepal.Length 2.784715e-16 #> 3              Speciesversicolor 1.528110e-15 #> 4               Speciesvirginica 1.758550e-15 #> 5 Sepal.Length:Speciesversicolor 2.977050e-16 #> 6  Sepal.Length:Speciesvirginica 3.226855e-16"},{"path":"https://easystats.github.io/parameters/reference/standard_error_robust.html","id":null,"dir":"Reference","previous_headings":"","what":"Robust standard errors. Superseded by the vcov* arguments in standard_error() — standard_error_robust","title":"Robust standard errors. Superseded by the vcov* arguments in standard_error() — standard_error_robust","text":"Robust standard errors. Superseded vcov* arguments standard_error()","code":""},{"path":"https://easystats.github.io/parameters/reference/standard_error_robust.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Robust standard errors. Superseded by the vcov* arguments in standard_error() — standard_error_robust","text":"","code":"standard_error_robust(   model,   vcov = \"HC3\",   vcov_args = NULL,   component = \"conditional\",   ... )"},{"path":"https://easystats.github.io/parameters/reference/standard_error_robust.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Robust standard errors. Superseded by the vcov* arguments in standard_error() — standard_error_robust","text":"model model. vcov Variance-covariance matrix used compute uncertainty estimates (e.g., robust standard errors). argument accepts covariance matrix, function returns covariance matrix, string identifies function used compute covariance matrix. covariance matrix function returns covariance matrix (e.g., stats::vcov()) string indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"vcovHC\", \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC. Cluster-robust: \"vcovCR\", \"CR0\", \"CR1\", \"CR1p\", \"CR1S\", \"CR2\", \"CR3\". See ?clubSandwich::vcovCR. Bootstrap: \"vcovBS\", \"xy\", \"residual\", \"wild\", \"mammen\", \"webb\". See ?sandwich::vcovBS. sandwich package functions: \"vcovHAC\", \"vcovPC\", \"vcovCL\", \"vcovPL\". vcov_args List arguments passed function identified vcov argument. function typically supplied sandwich clubSandwich packages. Please refer documentation (e.g., ?sandwich::vcovHAC) see list available arguments. component Model component standard errors shown. See documentation object's class model_parameters() p_value() details. ... Arguments passed methods.","code":""},{"path":"https://easystats.github.io/parameters/reference/standardize_info.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Standardization Information — standardize_info","title":"Get Standardization Information — standardize_info","text":"function extracts information, deviations (SD MAD) parent variables, necessary post-hoc standardization parameters. function gives window standardized obtained, .e., divided. \"basic\" method standardization uses.","code":""},{"path":"https://easystats.github.io/parameters/reference/standardize_info.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Standardization Information — standardize_info","text":"","code":"standardize_info(   model,   robust = FALSE,   two_sd = FALSE,   include_pseudo = FALSE,   ... )"},{"path":"https://easystats.github.io/parameters/reference/standardize_info.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Standardization Information — standardize_info","text":"model statistical model. robust Logical, TRUE, centering done subtracting median variables dividing median absolute deviation (MAD). FALSE, variables standardized subtracting mean dividing standard deviation (SD). two_sd TRUE, variables scaled two times deviation (SD MAD depending robust). method can useful obtain model coefficients continuous parameters comparable coefficients related binary predictors, applied predictors (outcome) (Gelman, 2008). include_pseudo ((G)LMMs) Pseudo-standardized information included? ... Arguments passed methods.","code":""},{"path":"https://easystats.github.io/parameters/reference/standardize_info.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Standardization Information — standardize_info","text":"data frame information parameter (see parameters_type()), various standardization coefficients post-hoc methods (see standardize_parameters()) predictor response.","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/standardize_info.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Standardization Information — standardize_info","text":"","code":"model <- lm(mpg ~ ., data = mtcars) standardize_info(model) #>      Parameter      Type        Link Secondary_Parameter EffectSize_Type #> 1  (Intercept) intercept        Mean                <NA>            <NA> #> 2          cyl   numeric Association                <NA>               r #> 3         disp   numeric Association                <NA>               r #> 4           hp   numeric Association                <NA>               r #> 5         drat   numeric Association                <NA>               r #> 6           wt   numeric Association                <NA>               r #> 7         qsec   numeric Association                <NA>               r #> 8           vs   numeric Association                <NA>               r #> 9           am   numeric Association                <NA>               r #> 10        gear   numeric Association                <NA>               r #> 11        carb   numeric Association                <NA>               r #>    Deviation_Response_Basic Deviation_Response_Smart Deviation_Basic #> 1                  6.026948                 6.026948       0.0000000 #> 2                  6.026948                 6.026948       1.7859216 #> 3                  6.026948                 6.026948     123.9386938 #> 4                  6.026948                 6.026948      68.5628685 #> 5                  6.026948                 6.026948       0.5346787 #> 6                  6.026948                 6.026948       0.9784574 #> 7                  6.026948                 6.026948       1.7869432 #> 8                  6.026948                 6.026948       0.5040161 #> 9                  6.026948                 6.026948       0.4989909 #> 10                 6.026948                 6.026948       0.7378041 #> 11                 6.026948                 6.026948       1.6152000 #>    Deviation_Smart #> 1        0.0000000 #> 2        1.7859216 #> 3      123.9386938 #> 4       68.5628685 #> 5        0.5346787 #> 6        0.9784574 #> 7        1.7869432 #> 8        0.5040161 #> 9        0.4989909 #> 10       0.7378041 #> 11       1.6152000 standardize_info(model, robust = TRUE) #>      Parameter      Type        Link Secondary_Parameter EffectSize_Type #> 1  (Intercept) intercept        Mean                <NA>            <NA> #> 2          cyl   numeric Association                <NA>               r #> 3         disp   numeric Association                <NA>               r #> 4           hp   numeric Association                <NA>               r #> 5         drat   numeric Association                <NA>               r #> 6           wt   numeric Association                <NA>               r #> 7         qsec   numeric Association                <NA>               r #> 8           vs   numeric Association                <NA>               r #> 9           am   numeric Association                <NA>               r #> 10        gear   numeric Association                <NA>               r #> 11        carb   numeric Association                <NA>               r #>    Deviation_Response_Basic Deviation_Response_Smart Deviation_Basic #> 1                   5.41149                  5.41149       0.0000000 #> 2                   5.41149                  5.41149       2.9652000 #> 3                   5.41149                  5.41149     140.4763500 #> 4                   5.41149                  5.41149      77.0952000 #> 5                   5.41149                  5.41149       0.7042350 #> 6                   5.41149                  5.41149       0.7672455 #> 7                   5.41149                  5.41149       1.4158830 #> 8                   5.41149                  5.41149       0.0000000 #> 9                   5.41149                  5.41149       0.0000000 #> 10                  5.41149                  5.41149       1.4826000 #> 11                  5.41149                  5.41149       1.4826000 #>    Deviation_Smart #> 1        0.0000000 #> 2        2.9652000 #> 3      140.4763500 #> 4       77.0952000 #> 5        0.7042350 #> 6        0.7672455 #> 7        1.4158830 #> 8        0.0000000 #> 9        0.0000000 #> 10       1.4826000 #> 11       1.4826000 standardize_info(model, two_sd = TRUE) #>      Parameter      Type        Link Secondary_Parameter EffectSize_Type #> 1  (Intercept) intercept        Mean                <NA>            <NA> #> 2          cyl   numeric Association                <NA>               r #> 3         disp   numeric Association                <NA>               r #> 4           hp   numeric Association                <NA>               r #> 5         drat   numeric Association                <NA>               r #> 6           wt   numeric Association                <NA>               r #> 7         qsec   numeric Association                <NA>               r #> 8           vs   numeric Association                <NA>               r #> 9           am   numeric Association                <NA>               r #> 10        gear   numeric Association                <NA>               r #> 11        carb   numeric Association                <NA>               r #>    Deviation_Response_Basic Deviation_Response_Smart Deviation_Basic #> 1                  6.026948                 6.026948       0.0000000 #> 2                  6.026948                 6.026948       3.5718433 #> 3                  6.026948                 6.026948     247.8773877 #> 4                  6.026948                 6.026948     137.1257370 #> 5                  6.026948                 6.026948       1.0693575 #> 6                  6.026948                 6.026948       1.9569149 #> 7                  6.026948                 6.026948       3.5738865 #> 8                  6.026948                 6.026948       1.0080323 #> 9                  6.026948                 6.026948       0.9979818 #> 10                 6.026948                 6.026948       1.4756081 #> 11                 6.026948                 6.026948       3.2304000 #>    Deviation_Smart #> 1        0.0000000 #> 2        3.5718433 #> 3      247.8773877 #> 4      137.1257370 #> 5        1.0693575 #> 6        1.9569149 #> 7        3.5738865 #> 8        1.0080323 #> 9        0.9979818 #> 10       1.4756081 #> 11       3.2304000"},{"path":"https://easystats.github.io/parameters/reference/standardize_parameters.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameters standardization — standardize_parameters","title":"Parameters standardization — standardize_parameters","text":"Compute standardized model parameters (coefficients).","code":""},{"path":"https://easystats.github.io/parameters/reference/standardize_parameters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parameters standardization — standardize_parameters","text":"","code":"standardize_parameters(   model,   method = \"refit\",   ci = 0.95,   robust = FALSE,   two_sd = FALSE,   include_response = TRUE,   verbose = TRUE,   ... )  standardize_posteriors(   model,   method = \"refit\",   robust = FALSE,   two_sd = FALSE,   include_response = TRUE,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/parameters/reference/standardize_parameters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameters standardization — standardize_parameters","text":"model statistical model. method method used standardizing parameters. Can \"refit\" (default), \"posthoc\", \"smart\", \"basic\" \"pseudo\". See 'Details'. ci Confidence Interval (CI) level robust Logical, TRUE, centering done subtracting median variables dividing median absolute deviation (MAD). FALSE, variables standardized subtracting mean dividing standard deviation (SD). two_sd TRUE, variables scaled two times deviation (SD MAD depending robust). method can useful obtain model coefficients continuous parameters comparable coefficients related binary predictors, applied predictors (outcome) (Gelman, 2008). include_response TRUE (default), response value also standardized. FALSE, predictors standardized. GLMs response value never standardized (see Generalized Linear Models section). verbose Toggle warnings messages . ... standardize_parameters(), arguments passed model_parameters(), : ci_method, centrality Mixed models Bayesian models... exponentiate, ... etc.","code":""},{"path":"https://easystats.github.io/parameters/reference/standardize_parameters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parameters standardization — standardize_parameters","text":"data frame standardized parameters (Std_*, depending model type) CIs (CI_low CI_high). applicable, standard errors (SEs) returned attribute (attr(x, \"standard_error\")).","code":""},{"path":"https://easystats.github.io/parameters/reference/standardize_parameters.html","id":"standardization-methods","dir":"Reference","previous_headings":"","what":"Standardization Methods","title":"Parameters standardization — standardize_parameters","text":"refit: method based complete model re-fit standardized version data. Hence, method equal standardizing variables fitting model. \"purest\" accurate (Neter et al., 1989), also computationally costly long (especially heavy models Bayesian models). method particularly recommended complex models include interactions transformations (e.g., polynomial spline terms). robust (default FALSE) argument enables robust standardization data, .e., based median MAD instead mean SD. See standardize() details. Note standardize_parameters(method = \"refit\") may return results fitting model data standardized standardize(); standardize_parameters() used data used model fitting function, might data missing values. see remove_na argument standardize(). posthoc: Post-hoc standardization parameters, aiming emulating results obtained \"refit\" without refitting model. coefficients divided standard deviation (MAD robust) outcome (becomes expression 'unit'). , coefficients related numeric variables additionally multiplied standard deviation (MAD robust) related terms, correspond changes 1 SD predictor (e.g., \"change 1 SD x related change 0.24 SD y). apply binary variables factors, coefficients still related changes levels. method accurate tend give aberrant results interactions specified. basic: method similar method = \"posthoc\", treats variables continuous: also scales coefficient standard deviation model's matrix' parameter factors levels (transformed integers) binary predictors. Although inappropriate cases, method one implemented default software packages, lm.beta::lm.beta(). smart (Standardization Model's parameters Adjustment, Reconnaissance Transformation - experimental): Similar method = \"posthoc\" involve model refitting. difference SD (MAD robust) response computed relevant section data. instance, factor 3 levels (intercept), B C entered predictor, effect corresponding B vs. scaled variance response intercept . results, coefficients effects factors similar Glass' delta. pseudo (2-level (G)LMMs ): (post-hoc) method, response predictor standardized based level prediction (levels detected performance::check_heterogeneity_bias()): Predictors standardized based SD level prediction (see also datawizard::demean()); outcome (linear LMMs) standardized based fitted random-intercept-model, sqrt(random-intercept-variance) used level 2 predictors, sqrt(residual-variance) used level 1 predictors (Hoffman 2015, page 342). warning given within-group variable found access -group variance.","code":""},{"path":"https://easystats.github.io/parameters/reference/standardize_parameters.html","id":"transformed-variables","dir":"Reference","previous_headings":"","what":"Transformed Variables","title":"Parameters standardization — standardize_parameters","text":"model's formula contains transformations (e.g. y ~ exp(X)) method = \"refit\" give different results compared method = \"basic\" (\"posthoc\" \"smart\" support transformations): \"refit\" standardizes data prior transformation (e.g. equivalent exp(scale(X))), \"basic\" method standardizes transformed data (e.g. equivalent scale(exp(X))).  See Transformed Variables section standardize.default() details different transformations dealt method = \"refit\".","code":""},{"path":"https://easystats.github.io/parameters/reference/standardize_parameters.html","id":"confidence-intervals","dir":"Reference","previous_headings":"","what":"Confidence Intervals","title":"Parameters standardization — standardize_parameters","text":"returned confidence intervals re-scaled versions unstandardized confidence intervals, \"true\" confidence intervals standardized coefficients (cf. Jones & Waller, 2015).","code":""},{"path":"https://easystats.github.io/parameters/reference/standardize_parameters.html","id":"generalized-linear-models","dir":"Reference","previous_headings":"","what":"Generalized Linear Models","title":"Parameters standardization — standardize_parameters","text":"Standardization generalized linear models (GLM, GLMM, etc) done respect predictors (outcome remains -, unstandardized) - maintaining interpretability coefficients (e.g., binomial model: exponent standardized parameter change 1 SD predictor, etc.)","code":""},{"path":"https://easystats.github.io/parameters/reference/standardize_parameters.html","id":"dealing-with-factors","dir":"Reference","previous_headings":"","what":"Dealing with Factors","title":"Parameters standardization — standardize_parameters","text":"standardize(model) standardize_parameters(model, method = \"refit\") standardize categorical predictors (.e. factors) / dummy-variables, may different behaviour compared R packages (lm.beta) software packages (like SPSS). mimic behaviours, either use standardize_parameters(model, method = \"basic\") obtain post-hoc standardized parameters, standardize data datawizard::standardize(data, force = TRUE) fitting model.","code":""},{"path":"https://easystats.github.io/parameters/reference/standardize_parameters.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Parameters standardization — standardize_parameters","text":"Hoffman, L. (2015). Longitudinal analysis: Modeling within-person fluctuation change. Routledge. Jones, J. ., & Waller, N. G. (2015). normal-theory asymptotic distribution-free (ADF) covariance matrix standardized regression coefficients: theoretical extensions finite sample behavior. Psychometrika, 80(2), 365-378. Neter, J., Wasserman, W., & Kutner, M. H. (1989). Applied linear regression models. Gelman, . (2008). Scaling regression inputs dividing two standard deviations. Statistics medicine, 27(15), 2865-2873.","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/standardize_parameters.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parameters standardization — standardize_parameters","text":"","code":"model <- lm(len ~ supp * dose, data = ToothGrowth) standardize_parameters(model, method = \"refit\") #> # Standardization method: refit #>  #> Parameter   | Std. Coef. |         95% CI #> ----------------------------------------- #> (Intercept) |       0.24 | [ 0.05,  0.44] #> suppVC      |      -0.48 | [-0.76, -0.21] #> dose        |       0.64 | [ 0.45,  0.84] #> suppVC:dose |       0.32 | [ 0.04,  0.60] # \\donttest{ standardize_parameters(model, method = \"posthoc\") #> # Standardization method: posthoc #>  #> Parameter   | Std. Coef. |         95% CI #> ----------------------------------------- #> (Intercept) |       0.00 | [ 0.00,  0.00] #> suppVC      |      -1.08 | [-1.66, -0.49] #> dose        |       0.64 | [ 0.45,  0.84] #> suppVC:dose |       0.32 | [ 0.04,  0.60] standardize_parameters(model, method = \"smart\") #> # Standardization method: smart #>  #> Parameter   | Std. Coef. |         95% CI #> ----------------------------------------- #> (Intercept) |       0.00 | [ 0.00,  0.00] #> suppVC      |      -1.00 | [-1.54, -0.46] #> dose        |       0.64 | [ 0.45,  0.84] #> suppVC:dose |       0.55 | [ 0.07,  1.02] standardize_parameters(model, method = \"basic\") #> # Standardization method: basic #>  #> Parameter   | Std. Coef. |         95% CI #> ----------------------------------------- #> (Intercept) |       0.00 | [ 0.00,  0.00] #> suppVC      |      -0.54 | [-0.84, -0.25] #> dose        |       0.64 | [ 0.45,  0.84] #> suppVC:dose |       0.38 | [ 0.05,  0.70]  # Robust and 2 SD standardize_parameters(model, robust = TRUE) #> # Standardization method: refit #>  #> Parameter   | Std. Coef. |         95% CI #> ----------------------------------------- #> (Intercept) |       0.01 | [-0.16,  0.18] #> suppVC      |      -0.48 | [-0.72, -0.24] #> dose        |       0.64 | [ 0.44,  0.84] #> suppVC:dose |       0.32 | [ 0.04,  0.60] #>  #> - Scaled by one MAD from the median. standardize_parameters(model, two_sd = TRUE) #> # Standardization method: refit #>  #> Parameter   | Std. Coef. |         95% CI #> ----------------------------------------- #> (Intercept) |       0.24 | [ 0.05,  0.44] #> suppVC      |      -0.48 | [-0.76, -0.21] #> dose        |       1.28 | [ 0.89,  1.68] #> suppVC:dose |       0.64 | [ 0.09,  1.20] #>  #> - Scaled by two SDs from the mean.  model <- glm(am ~ cyl * mpg, data = mtcars, family = \"binomial\") standardize_parameters(model, method = \"refit\") #> # Standardization method: refit #>  #> Parameter   | Std. Coef. |        95% CI #> ---------------------------------------- #> (Intercept) |      -0.58 | [-1.98, 0.70] #> cyl         |       0.25 | [-1.54, 2.10] #> mpg         |       2.10 | [-0.19, 5.28] #> cyl:mpg     |      -0.36 | [-2.57, 1.54] #>  #> - Response is unstandardized. standardize_parameters(model, method = \"posthoc\") #> # Standardization method: posthoc #>  #> Parameter   | Std. Coef. |         95% CI #> ----------------------------------------- #> (Intercept) |       0.00 | [ 0.00,  0.00] #> cyl         |       1.46 | [-4.63,  9.37] #> mpg         |       3.36 | [-2.31, 12.59] #> cyl:mpg     |      -0.20 | [-1.44,  0.86] #>  #> - Response is unstandardized. standardize_parameters(model, method = \"basic\", exponentiate = TRUE) #> # Standardization method: basic #>  #> Parameter   | Std_Odds_Ratio |           95% CI #> ----------------------------------------------- #> (Intercept) |           1.00 | [1.00,     1.00] #> cyl         |           4.32 | [0.01, 11681.98] #> mpg         |          28.80 | [0.10, 2.92e+05] #> cyl:mpg     |           0.54 | [0.01,    13.94] #>  #> - Response is unstandardized. # }  if (require(\"lme4\")) { # \\donttest{   m <- lme4::lmer(mpg ~ cyl + am + vs + (1 | cyl), mtcars)   standardize_parameters(m, method = \"pseudo\", ci_method = \"satterthwaite\") # } } #> boundary (singular) fit: see help('isSingular') #> Warning: The following within-group terms have between-group variance: #>   am, vs #>   This can inflate standardized within-group parameters associated with #>   these terms. #>   See help(\"demean\", package = \"datawizard\") for modeling between- and #>   within-subject effects. #> # Standardization method: pseudo #>  #> Parameter   | Std. Coef. |         95% CI #> ----------------------------------------- #> (Intercept) |       0.00 | [ 0.00,  0.00] #> cyl         |      -0.74 | [-1.25, -0.23] #> am          |       0.47 | [-0.01,  0.95] #> vs          |       0.20 | [-0.50,  0.90]  if (FALSE) { if (require(\"rstanarm\")) {   model <- rstanarm::stan_glm(rating ~ critical + privileges, data = attitude, refresh = 0)   standardize_posteriors(model, method = \"refit\")   standardize_posteriors(model, method = \"posthoc\")   standardize_posteriors(model, method = \"smart\")   head(standardize_posteriors(model, method = \"basic\")) } }"},{"path":[]},{"path":"https://easystats.github.io/parameters/news/index.html","id":"breaking-0-18-3","dir":"Changelog","previous_headings":"","what":"Breaking","title":"parameters 0.18.3","text":"Removed depricated argument parameters model_parameters().","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"changes-to-functions-0-18-3","dir":"Changelog","previous_headings":"","what":"Changes to functions","title":"parameters 0.18.3","text":"bootstrap_model() models class glmmTMB merMod gains cluster argument specify optional clusters parallel option set \"snow\". P-value adjustment (argument p_adjust model_parameters()) now performed potential parameters removed (using keep drop), adjusted p-values applied parameters interest. Robust standard errors now supported fixest models vcov argument.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"bug-fixes-0-18-3","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"parameters 0.18.3","text":"Fix erroneous warning p-value adjustments differences original adjusted p-values small.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"parameters-0182","dir":"Changelog","previous_headings":"","what":"parameters 0.18.2","title":"parameters 0.18.2","text":"CRAN release: 2022-08-10","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"new-functions-0-18-2","dir":"Changelog","previous_headings":"","what":"New functions","title":"parameters 0.18.2","text":"New function dominance_analysis(), compute dominance analysis statistics designations.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"changes-to-functions-0-18-2","dir":"Changelog","previous_headings":"","what":"Changes to functions","title":"parameters 0.18.2","text":"Argument ci_random model_parameters() defaults NULL. uses heuristic determine random effects confidence intervals likely take long time compute, automatically includes excludes confidence intervals. Set ci_random TRUE FALSE explicitly calculate omit confidence intervals random effects.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"bug-fixes-0-18-2","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"parameters 0.18.2","text":"Fix issues pool_parameters() certain models special components (like MASS::polr()), failed argument component set \"conditional\" (default). Fix issues model_parameters() multiple imputation models package Hmisc.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"parameters-0181","dir":"Changelog","previous_headings":"","what":"parameters 0.18.1","title":"parameters 0.18.1","text":"CRAN release: 2022-05-29","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"general-0-18-1","dir":"Changelog","previous_headings":"","what":"General","title":"parameters 0.18.1","text":"now possible hide messages CI method tables specifying options(\"parameters_cimethod\" = FALSE) (#722). default, messages displayed. model_parameters() now supports objects package marginaleffects objects returned car::linearHypothesis(). Added predict() method cluster_meta objects. Reorganization docs model_parameters().","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"changes-to-functions-0-18-1","dir":"Changelog","previous_headings":"","what":"Changes to functions","title":"parameters 0.18.1","text":"model_parameters() now also includes standard errors confidence intervals slope-slope-correlations random effects variances. model_parameters() mixed models gains ci_random argument, toggle whether confidence intervals random effects parameters also computed. Set FALSE calculation confidence intervals random effects parameters takes long. ci() glmmTMB models method = \"profile\" now robust.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"bug-fixes-0-18-1","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"parameters 0.18.1","text":"Fixed issue glmmTMB models calculating confidence intervals random effects failed due singular fits. display() now correctly includes custom text additional information footer (#722). Fixed issue argument column_names compare_parameters() strings contained characters needed escaped regular expressions. Fixed issues unknown arguments model_parameters() lavaan models standardize = TRUE.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"parameters-0180","dir":"Changelog","previous_headings":"","what":"parameters 0.18.0","title":"parameters 0.18.0","text":"CRAN release: 2022-05-24","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"breaking-changes-0-18-0","dir":"Changelog","previous_headings":"","what":"Breaking Changes","title":"parameters 0.18.0","text":"model_parameters() now longer treats data frame inputs posterior samples. Rather, data frames, now NULL returned. want treat data frame posterior samples, set new argument as_draws = TRUE.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"new-functions-0-18-0","dir":"Changelog","previous_headings":"","what":"New functions","title":"parameters 0.18.0","text":"sort_parameters() sort model parameters coefficient values. standardize_parameters(), standardize_info() standardise_posteriors() standardize model parameters.","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/news/index.html","id":"model_parameters-0-18-0","dir":"Changelog","previous_headings":"Changes to functions","what":"model_parameters()","title":"parameters 0.18.0","text":"model_parameters() mixed models package lme4 now also reports confidence intervals random effect variances default. Formerly, CIs included ci_method \"profile\" \"boot\". merDeriv package required feature. model_parameters() htest objects now also supports models var.test(). Improved support anova.rms models model_parameters(). model_parameters() now supports draws objects package posterior deltaMethods objects package car. model_parameters() now checks arguments informs user specific given arguments supported model class (e.g., \"vcov\" currently supported models class glmmTMB).","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"bug-fixes-0-18-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"parameters 0.18.0","text":"vcov argument, used computing robust standard errors, calculate correct p-values confidence intervals models class lme. pool_parameters() save relevant model information attributes. model_parameters() models package glmmTMB work exponentiate = TRUE model contained dispersion parameter different sigma. Furthermore, exponentiating falsely exponentiated dispersion parameter.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"parameters-0170","dir":"Changelog","previous_headings":"","what":"parameters 0.17.0","title":"parameters 0.17.0","text":"CRAN release: 2022-03-10","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"general-0-17-0","dir":"Changelog","previous_headings":"","what":"General","title":"parameters 0.17.0","text":"Added options set defaults different arguments. Currently supported: options(\"parameters_summary\" = TRUE/FALSE), sets default value summary argument model_parameters() non-mixed models. options(\"parameters_mixed_summary\" = TRUE/FALSE), sets default value summary argument model_parameters() mixed models. Minor improvements print() methods. Robust uncertainty estimates: vcov_estimation, vcov_type, robust arguments deprecated functions: model_parameters(), parameters(), standard_error(), p_value(), ci(). replaced vcov vcov_args arguments. standard_error_robust() p_value_robust() functions superseded vcov vcov_args arguments standard_error() p_value() functions. Vignette: https://easystats.github.io/parameters/articles/model_parameters_robust.html","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"bug-fixes-0-17-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"parameters 0.17.0","text":"Fixed minor issues edge cases n_clusters() related cluster functions. Fixed issue p_value() returned wrong p-values fixest::feols().","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"parameters-0160","dir":"Changelog","previous_headings":"","what":"parameters 0.16.0","title":"parameters 0.16.0","text":"CRAN release: 2022-01-12","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"general-0-16-0","dir":"Changelog","previous_headings":"","what":"General","title":"parameters 0.16.0","text":"Improved speed performance model_parameters(), particular glm’s mixed models random effect variances calculated. Added options printing model_parameters(). See also revised vignette: https://easystats.github.io/parameters/articles/model_parameters_print.html","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/news/index.html","id":"model_parameters-0-16-0","dir":"Changelog","previous_headings":"Changes to functions","what":"model_parameters()","title":"parameters 0.16.0","text":"model_parameters() mixed models gains include_sigma argument. TRUE, adds residual variance, computed random effects variances, attribute returned data frame. Including sigma default behaviour, now defaults FALSE included include_sigma = TRUE, calculation time consuming. model_parameters() merMod models now also computes CIs random SD parameters ci_method=\"boot\" (previously, possible ci_method \"profile\"). model_parameters() glmmTMB models now computes CIs random SD parameters. Note based Wald-z-distribution. Similar model_parameters.htest(), model_parameters.BFBayesFactor() method gains cohens_d cramers_v arguments control need add frequentist effect size estimates returned summary data frame. Previously, done default. Column name coefficients emmeans objects now specific. model_prameters() MixMod objects (package GLMMadaptive) gains robust argument, compute robust standard errors.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"bug-fixes-0-16-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"parameters 0.16.0","text":"Fixed bug ci() class merMod method=\"boot\". Fixed issue correct association components ordinal models classes clm clm2. Fixed issues random_parameters() model_parameters() mixed models without random intercept. Confidence intervals random parameters model_parameters() failed (?) glmer models. Fix issue default ci_type compare_parameters() Bayesian models.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"parameters-0150","dir":"Changelog","previous_headings":"","what":"parameters 0.15.0","title":"parameters 0.15.0","text":"CRAN release: 2021-10-18","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"breaking-changes-0-15-0","dir":"Changelog","previous_headings":"","what":"Breaking changes","title":"parameters 0.15.0","text":"Following functions moved new datawizard package now re-exported parameters package: center() convert_data_to_numeric() data_partition() demean() (aliases degroup() detrend()) kurtosis() rescale_weights() skewness() smoothness() Note functions removed next release parameters package currently re-exported convenience package developers. release provide time make necessary changes breaking change implemented. Following functions moved performance package: check_heterogeneity() check_multimodal()","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"general-0-15-0","dir":"Changelog","previous_headings":"","what":"General","title":"parameters 0.15.0","text":"handling approximate degrees freedom model_parameters(), ci() p_value() revised now consistent. bugs related previous computation confidence intervals p-values fixed. Now possible change method approximate degrees freedom CIs p-values using ci_method, resp. method argument. change documented detail ?model_parameters, online : https://easystats.github.io/parameters/reference/model_parameters.html Minor changes print() glmmTMB dispersion parameter. Added vignette printing options model parameters.","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/news/index.html","id":"model_parameters-0-15-0","dir":"Changelog","previous_headings":"Changes to functions","what":"model_parameters()","title":"parameters 0.15.0","text":"df_method argument model_parameters() deprecated. Please use ci_method now. model_parameters() standardize = \"refit\" now returns random effects standardized model. model_parameters() ci() lmerMod models gain \"residuals\" option ci_method (resp. method) argument, explicitly calculate confidence intervals based residual degrees freedom, present. model_parameters() supports following new objects: trimcibt, wmcpAKP, dep.effect (WRS2 package), systemfit model_parameters() gains new argument table_wide ANOVA tables. can helpful users may wish report ANOVA table wide format (.e., numerator denominator degrees freedom row). model_parameters() gains two new arguments, keep drop. keep new names former parameters argument can used filter parameters. keep selects parameters whose names match regular expression pattern defined keep, drop counterpart excludes matching parameter names. model_parameters() called verbose = TRUE, ci_method default value, printed output includes message indicating approximation-method degrees freedom used. model_parameters() mixed models ci_method = \"profile computes (profiled) confidence intervals fixed random effects. Thus, ci_method = \"profile allows add confidence intervals random effect variances. model_parameters() longer fail supported model classes robust standard errors available.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"other-functions-0-15-0","dir":"Changelog","previous_headings":"Changes to functions","what":"Other functions","title":"parameters 0.15.0","text":"n_factors() methods based fit indices fixed can included separately (package = \"fit\"). Also added n_max argument crop output. compare_parameters() now also accepts list model objects. describe_distribution() gets verbose argument toggle warnings messages. format_parameters() removes dots underscores parameter names, make “human readable”. experimental calculation p-values equivalence_test() replaced proper calculation p-values. argument p_value removed p-values now always included. Minor improvements print(), print_html() print_md().","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"bug-fixes-0-15-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"parameters 0.15.0","text":"random effects returned model_parameters() mistakenly displayed residuals standard deviation square-root residual SD. Fixed issue model_parameters() brmsfit objects model standard errors (.e. meta-analysis). Fixed issue model_parameters lmerMod models , default, returned residual degrees freedom statistic column, confidence intervals based Inf degrees freedom instead. Fixed issue ci_satterthwaite(), used Inf degrees freedom instead Satterthwaite approximation. Fixed issue model_parameters.mlm() model contained interaction terms. Fixed issue model_parameters.rma() model contained interaction terms. Fixed sign error model_parameters.htest() objects created t.test.formula() (issue #552) Fixed issue computing random effect variances model_parameters() mixed models categorical random slopes.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"parameters-0140","dir":"Changelog","previous_headings":"","what":"parameters 0.14.0","title":"parameters 0.14.0","text":"CRAN release: 2021-05-29","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"breaking-changes-0-14-0","dir":"Changelog","previous_headings":"","what":"Breaking changes","title":"parameters 0.14.0","text":"check_sphericity() renamed check_sphericity_bartlett(). Removed deprecated arguments. model_parameters() bootstrapped samples used emmeans now treats bootstrap samples samples posterior distributions (Bayesian models).","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"new-supported-model-classes-0-14-0","dir":"Changelog","previous_headings":"","what":"New supported model classes","title":"parameters 0.14.0","text":"SemiParBIV (GJRM), selection (sampleSelection), htest survey package, pgmm (plm).","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"general-0-14-0","dir":"Changelog","previous_headings":"","what":"General","title":"parameters 0.14.0","text":"Performance improvements models package survey.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"new-functions-0-14-0","dir":"Changelog","previous_headings":"","what":"New functions","title":"parameters 0.14.0","text":"Added summary() method model_parameters(), convenient shortcut print(..., select = \"minimal\").","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/news/index.html","id":"model_parameters-0-14-0","dir":"Changelog","previous_headings":"Changes to functions","what":"model_parameters()","title":"parameters 0.14.0","text":"model_parameters() gains parameters argument, takes regular expression string, select specific parameters returned data frame. print() model_parameters() compare_parameters() gains groups argument, group parameters output. Furthermore, groups can used directly argument model_parameters() compare_parameters() passed print() method. model_parameters() ANOVAs now saves type attribute prints information footer output well. model_parameters() htest-objects now saves alternative hypothesis attribute prints information footer output well. model_parameters() passes arguments type, parallel n_cpus bootstrap_model() bootstrap = TRUE.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"other-0-14-0","dir":"Changelog","previous_headings":"Changes to functions","what":"other","title":"parameters 0.14.0","text":"bootstrap_models() merMod glmmTMB objects gains arguments set type bootstrapping allow parallel computing. bootstrap_parameters() gains ci_method type \"bci\", compute bias-corrected accelerated bootstrapped intervals. ci() svyglm gains method argument.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"bug-fixes-0-14-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"parameters 0.14.0","text":"Fixed issue model_parameters() emmGrid objects Bayesian models. Arguments digits, ci_digits p_digits ignored print() worked used call model_parameters() directly.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"parameters-0130","dir":"Changelog","previous_headings":"","what":"parameters 0.13.0","title":"parameters 0.13.0","text":"CRAN release: 2021-04-08","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"general-0-13-0","dir":"Changelog","previous_headings":"","what":"General","title":"parameters 0.13.0","text":"Revised improved print() method model_parameters().","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"new-supported-model-classes-0-13-0","dir":"Changelog","previous_headings":"","what":"New supported model classes","title":"parameters 0.13.0","text":"blrm (rmsb), AKP, med1way, robtab (WRS2), epi.2by2 (epiR), mjoint (joineRML), mhurdle (mhurdle), sarlm (spatialreg), model_fit (tidymodels), BGGM (BGGM), mvord (mvord)","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/news/index.html","id":"model_parameters-0-13-0","dir":"Changelog","previous_headings":"Changes to functions","what":"model_parameters()","title":"parameters 0.13.0","text":"model_parameters() blavaan models now fully treated Bayesian model thus relies functions bayestestR (.e. ROPE, Rhat ESS reported) . effects-argument model_parameters() mixed models revised now shows random effects variances default (functionality random_parameters(), mimicking behaviour broom.mixed::tidy()). group_level argument set TRUE, conditional modes (BLUPs) random effects shown. model_parameters() mixed models now returns Effects column even just one type “effects”, mimic behaviour broom.mixed::tidy(). conjunction standardize_names() users can get column names tidy() model_parameters() objects. model_parameters() t-tests now uses group values column names. print() model_parameters() gains zap_small argument, avoid scientific notation small numbers. Instead, zap_small forces round specified number digits. internally consistent, degrees freedom column lqm(m) cgam(m) objects (t-statistic) called df_error. model_parameters() gains summary argument add summary information model printed outputs. Minor improvements models quantreg. model_parameters supports rank-biserial, rank epsilon-squared, Kendall’s W effect size measures wilcox.test(), kruskal.test, friedman.test, respectively.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"other-functions-0-13-0","dir":"Changelog","previous_headings":"Changes to functions","what":"Other functions","title":"parameters 0.13.0","text":"describe_distribution() gets quartiles argument include 25th 75th quartiles variable.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"bug-fixes-0-13-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"parameters 0.13.0","text":"Fixed issue non-initialized argument style display() compare_parameters(). Make print() compare_parameters() work objects “simple” column names confidence intervals missing CI-level (.e. column named \"CI\" instead , say, \"95% CI\"). Fixed issue p_adjust model_parameters(), work adjustment-methods \"\" \"BH\". Fixed issue show_sigma print() model_parameters(). Fixed issue model_parameters() incorrect order degrees freedom.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"parameters-0120","dir":"Changelog","previous_headings":"","what":"parameters 0.12.0","title":"parameters 0.12.0","text":"CRAN release: 2021-02-21","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"general-0-12-0","dir":"Changelog","previous_headings":"","what":"General","title":"parameters 0.12.0","text":"Roll-back R dependency R >= 3.4. Bootstrapped estimates (bootstrap_model() bootstrap_parameters()) can passed emmeans obtain bootstrapped estimates, contrasts, simple slopes (etc) CIs. can passed model_parameters() related functions obtain standard errors, p-values, etc.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"breaking-changes-0-12-0","dir":"Changelog","previous_headings":"","what":"Breaking changes","title":"parameters 0.12.0","text":"model_parameters() now always returns confidence level additional CI column. rule argument equivalenct_test() defaults \"classic\".","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"new-supported-model-classes-0-12-0","dir":"Changelog","previous_headings":"","what":"New supported model classes","title":"parameters 0.12.0","text":"crr (cmprsk), leveneTest() (car), varest (vars), ergm (ergm), btergm (btergm), Rchoice (Rchoice), garch (tseries)","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"new-functions-0-12-0","dir":"Changelog","previous_headings":"","what":"New functions","title":"parameters 0.12.0","text":"compare_parameters() (alias compare_models()) show / print parameters multiple models one table.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"changes-to-functions-0-12-0","dir":"Changelog","previous_headings":"","what":"Changes to functions","title":"parameters 0.12.0","text":"Estimation bootstrapped p-values re-written accurate. model_parameters() mixed models gains effects-argument, return fixed, random fixed random effects parameters. Revised printing model_parameters() metafor models. model_parameters() metafor models now recognized confidence levels specified function call (via argument level). Improved support effect sizes model_parameters() anova objects.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"bug-fixes-0-12-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"parameters 0.12.0","text":"Fixed edge case formatting parameters polynomial terms many degrees. Fixed issue random sampling dropped factor levels bootstrap_model().","code":""}]
