[{"path":[]},{"path":"https://easystats.github.io/parameters/CODE_OF_CONDUCT.html","id":"our-pledge","dir":"","previous_headings":"","what":"Our Pledge","title":"Contributor Covenant Code of Conduct","text":"members, contributors, leaders pledge make participation community harassment-free experience everyone, regardless age, body size, visible invisible disability, ethnicity, sex characteristics, gender identity expression, level experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, sexual identity orientation. pledge act interact ways contribute open, welcoming, diverse, inclusive, healthy community.","code":""},{"path":"https://easystats.github.io/parameters/CODE_OF_CONDUCT.html","id":"our-standards","dir":"","previous_headings":"","what":"Our Standards","title":"Contributor Covenant Code of Conduct","text":"Examples behavior contributes positive environment community include: Demonstrating empathy kindness toward people respectful differing opinions, viewpoints, experiences Giving gracefully accepting constructive feedback Accepting responsibility apologizing affected mistakes, learning experience Focusing best just us individuals, overall community Examples unacceptable behavior include: use sexualized language imagery, sexual attention advances kind Trolling, insulting derogatory comments, personal political attacks Public private harassment Publishing others’ private information, physical email address, without explicit permission conduct reasonably considered inappropriate professional setting","code":""},{"path":"https://easystats.github.io/parameters/CODE_OF_CONDUCT.html","id":"enforcement-responsibilities","dir":"","previous_headings":"","what":"Enforcement Responsibilities","title":"Contributor Covenant Code of Conduct","text":"Community leaders responsible clarifying enforcing standards acceptable behavior take appropriate fair corrective action response behavior deem inappropriate, threatening, offensive, harmful. Community leaders right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct, communicate reasons moderation decisions appropriate.","code":""},{"path":"https://easystats.github.io/parameters/CODE_OF_CONDUCT.html","id":"scope","dir":"","previous_headings":"","what":"Scope","title":"Contributor Covenant Code of Conduct","text":"Code Conduct applies within community spaces, also applies individual officially representing community public spaces. Examples representing community include using official e-mail address, posting via official social media account, acting appointed representative online offline event.","code":""},{"path":"https://easystats.github.io/parameters/CODE_OF_CONDUCT.html","id":"enforcement","dir":"","previous_headings":"","what":"Enforcement","title":"Contributor Covenant Code of Conduct","text":"Instances abusive, harassing, otherwise unacceptable behavior may reported community leaders responsible enforcement d.luedecke@uke.de. complaints reviewed investigated promptly fairly. community leaders obligated respect privacy security reporter incident.","code":""},{"path":"https://easystats.github.io/parameters/CODE_OF_CONDUCT.html","id":"enforcement-guidelines","dir":"","previous_headings":"","what":"Enforcement Guidelines","title":"Contributor Covenant Code of Conduct","text":"Community leaders follow Community Impact Guidelines determining consequences action deem violation Code Conduct:","code":""},{"path":"https://easystats.github.io/parameters/CODE_OF_CONDUCT.html","id":"id_1-correction","dir":"","previous_headings":"Enforcement Guidelines","what":"1. Correction","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Use inappropriate language behavior deemed unprofessional unwelcome community. Consequence: private, written warning community leaders, providing clarity around nature violation explanation behavior inappropriate. public apology may requested.","code":""},{"path":"https://easystats.github.io/parameters/CODE_OF_CONDUCT.html","id":"id_2-warning","dir":"","previous_headings":"Enforcement Guidelines","what":"2. Warning","title":"Contributor Covenant Code of Conduct","text":"Community Impact: violation single incident series actions. Consequence: warning consequences continued behavior. interaction people involved, including unsolicited interaction enforcing Code Conduct, specified period time. includes avoiding interactions community spaces well external channels like social media. Violating terms may lead temporary permanent ban.","code":""},{"path":"https://easystats.github.io/parameters/CODE_OF_CONDUCT.html","id":"id_3-temporary-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"3. Temporary Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: serious violation community standards, including sustained inappropriate behavior. Consequence: temporary ban sort interaction public communication community specified period time. public private interaction people involved, including unsolicited interaction enforcing Code Conduct, allowed period. Violating terms may lead permanent ban.","code":""},{"path":"https://easystats.github.io/parameters/CODE_OF_CONDUCT.html","id":"id_4-permanent-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"4. Permanent Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Demonstrating pattern violation community standards, including sustained inappropriate behavior, harassment individual, aggression toward disparagement classes individuals. Consequence: permanent ban sort public interaction within community.","code":""},{"path":"https://easystats.github.io/parameters/CODE_OF_CONDUCT.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Contributor Covenant Code of Conduct","text":"Code Conduct adapted Contributor Covenant, version 2.1, available https://www.contributor-covenant.org/version/2/1/code_of_conduct.html. Community Impact Guidelines inspired [Mozilla’s code conduct enforcement ladder][https://github.com/mozilla/inclusion]. answers common questions code conduct, see FAQ https://www.contributor-covenant.org/faq. Translations available https://www.contributor-covenant.org/translations.","code":""},{"path":"https://easystats.github.io/parameters/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contributing to parameters","title":"Contributing to parameters","text":"outlines propose change parameters.","code":""},{"path":"https://easystats.github.io/parameters/CONTRIBUTING.html","id":"fixing-typos","dir":"","previous_headings":"","what":"Fixing typos","title":"Contributing to parameters","text":"Small typos grammatical errors documentation may edited directly using GitHub web interface, long changes made source file. want fix typos documentation, please edit related .R file R/ folder. edit .Rd file man/.","code":""},{"path":"https://easystats.github.io/parameters/CONTRIBUTING.html","id":"filing-an-issue","dir":"","previous_headings":"","what":"Filing an issue","title":"Contributing to parameters","text":"easiest way propose change new feature file issue. ’ve found bug, may also create associated issue. possible, try illustrate proposal bug minimal reproducible example.","code":""},{"path":"https://easystats.github.io/parameters/CONTRIBUTING.html","id":"pull-requests","dir":"","previous_headings":"","what":"Pull requests","title":"Contributing to parameters","text":"Please create Git branch pull request (PR). contributed code roughly follow R style guide, particular easystats convention code-style. parameters uses roxygen2, Markdown syntax, documentation. parameters uses testthat. Adding tests PR makes easier merge PR code base. PR user-visible change, may add bullet top NEWS.md describing changes made. may optionally add GitHub username, links relevant issue(s)/PR(s).","code":""},{"path":"https://easystats.github.io/parameters/CONTRIBUTING.html","id":"code-of-conduct","dir":"","previous_headings":"","what":"Code of Conduct","title":"Contributing to parameters","text":"Please note project released Contributor Code Conduct. participating project agree abide terms.","code":""},{"path":"https://easystats.github.io/parameters/SUPPORT.html","id":null,"dir":"","previous_headings":"","what":"Getting help with {parameters}","title":"Getting help with {parameters}","text":"Thanks using parameters. filing issue, places explore pieces put together make process smooth possible. Start making minimal reproducible example using reprex package. haven’t heard used reprex , ’re treat! Seriously, reprex make R-question-asking endeavors easier (pretty insane ROI five ten minutes ’ll take learn ’s ). additional reprex pointers, check Get help! resource used tidyverse team. Armed reprex, next step figure ask: ’s question: start StackOverflow. people answer questions. ’s bug: ’re right place, file issue. ’re sure: let’s discuss try figure ! problem bug feature request, can easily return report . opening new issue, sure search issues pull requests make sure bug hasn’t reported /already fixed development version. default, search pre-populated :issue :open. can edit qualifiers (e.g. :pr, :closed) needed. example, ’d simply remove :open search issues repo, open closed. Thanks help!","code":""},{"path":"https://easystats.github.io/parameters/articles/clustering.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Clustering with easystats","text":"Clustering traditionally refers identification groups observations (.e., data rows). differs methods like PCA Factor Analysis, usually applied variables (.e., columns). said, possible transpose data (columns become rows) apply clustering variables. many clustering algorithms (see overview), can grouped two categories: supervised unsupervised techniques. supervised techniques, explicitly specify many clusters want extract. Unsupervised techniques, hand, estimate number part algorithm. Note inherently superior inferior clustering methods, come sets limitations benefits. example tutorial , use iris dataset, know 3 “real” clusters (3 Species flowers). Let’s first start visualizing 3 “real” clusters 2D space variables created PCA.  setosa species stands quite clearly PCA space, separation two species appear less clear cut. Let’s see data-driven clustering performs, manage retrieve 3 clusters.","code":"library(ggplot2) library(parameters) library(see)  set.seed(33) # Set random seed  # Select the first 4 numeric columns (drop the Species fator) data <- iris[1:4] head(data) # Print the 6 first rows #>   Sepal.Length Sepal.Width Petal.Length Petal.Width #> 1          5.1         3.5          1.4         0.2 #> 2          4.9         3.0          1.4         0.2 #> 3          4.7         3.2          1.3         0.2 #> 4          4.6         3.1          1.5         0.2 #> 5          5.0         3.6          1.4         0.2 #> 6          5.4         3.9          1.7         0.4  # Run PCA pca <- principal_components(data, n = 2) pca_scores <- predict(pca, names = c(\"PCA_1\", \"PCA_2\")) pca_scores$True_Clusters <- iris$Species # Add real clusters  # Visualize ggplot(pca_scores, aes(x = PCA_1, y = PCA_2, color = True_Clusters)) +   geom_point() +   theme_modern()"},{"path":[]},{"path":"https://easystats.github.io/parameters/articles/clustering.html","id":"how-many-clusters-to-extract","dir":"Articles","previous_headings":"Supervised Clustering Methods","what":"How Many Clusters to Extract?","title":"Clustering with easystats","text":"easy answer important question. best way strong expectations hypotheses. don’t, well, researchers came data-driven solutions estimate optimal number clusters. problem now lot numerical methods, don’t always agree… clearly better method, implemented easystats consensus-based algorithm runs many methods, returns number clusters agreed upon.  can see, methods suggest existence 2 clusters, followed 3-clusters solution. seems like data clearly discriminate 3 species flowers. discrepancy , can recover real-world data, fundamental issue data science.","code":"n <- n_clusters(data, package = c(\"easystats\", \"NbClust\", \"mclust\")) n #> # Method Agreement Procedure: #>  #> The choice of 2 clusters is supported by 15 (51.72%) methods out of 29 (Elbow, Silhouette, Gap_Maechler2012, Gap_Dudoit2002, Ch, DB, Duda, Pseudot2, Beale, Ratkowsky, PtBiserial, Mcclain, Dunn, SDindex, Mixture (VVV)). plot(n)"},{"path":"https://easystats.github.io/parameters/articles/clustering.html","id":"k-means","dir":"Articles","previous_headings":"Supervised Clustering Methods","what":"K-Means","title":"Clustering with easystats","text":"won’t go much details mathematics intuition behind clustering methods, good resources available internet. Instead, ’ll focus apply . K-means one basic clustering algorithm, available base R kmeans() function. However, provide easystats unified function run different clustering algorithms: cluster_analysis(). (Note k-means non-deterministic algorithm; running multiple times result different results!) Now know many clusters want extract (let’s say strong hypothesis 3, partially supported consensus method estimating optimal number clusters). Note can also visualize centers (.e., “average” variable cluster):  One can extract cluster assignments use new variable using predict().","code":"rez_kmeans <- cluster_analysis(data, n = 3, method = \"kmeans\")  rez_kmeans # Show results #> # Clustering Solution #>  #> The 3 clusters accounted for 76.70% of the total variance of the original data. #>  #> Cluster | n_Obs | Sum_Squares | Sepal.Length | Sepal.Width | Petal.Length | Petal.Width #> --------------------------------------------------------------------------------------- #> 1       |    53 |       44.09 |        -0.05 |       -0.88 |         0.35 |        0.28 #> 2       |    47 |       47.45 |         1.13 |        0.09 |         0.99 |        1.01 #> 3       |    50 |       47.35 |        -1.01 |        0.85 |        -1.30 |       -1.25 #>  #> # Indices of model performance #>  #> Sum_Squares_Total | Sum_Squares_Between | Sum_Squares_Within |    R2 #> -------------------------------------------------------------------- #> 596.000           |             457.112 |            138.888 | 0.767 #>  #> # You can access the predicted clusters via `predict()`. plot(summary(rez_kmeans)) # Visualize cluster centers predict(rez_kmeans) # Get clusters #>   [1] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 #>  [38] 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 1 1 1 2 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 #>  [75] 1 2 2 2 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 2 2 2 1 2 2 2 2 #> [112] 2 2 1 1 2 2 2 2 1 2 1 2 1 2 2 1 2 2 2 2 2 2 1 1 2 2 2 1 2 2 2 1 2 2 2 1 2 #> [149] 2 1"},{"path":"https://easystats.github.io/parameters/articles/clustering.html","id":"hierarchical-clustering","dir":"Articles","previous_headings":"Supervised Clustering Methods","what":"Hierarchical Clustering","title":"Clustering with easystats","text":"Hierarchical clustering also common clustering algorithm, available base R hclust() function. method bit different sense straight return clusters. Instead, creates hierarchical structure (dendrogram), tree can cut branches get given number clusters. Note “tree” cutting can done unsupervised fashion using bootstrapping (apply next section).","code":"rez_hclust <- cluster_analysis(data, n = 3, method = \"hclust\")  rez_hclust # Show results #> # Clustering Solution #>  #> The 3 clusters accounted for 74.35% of the total variance of the original data. #>  #> Cluster | n_Obs | Sum_Squares | Sepal.Length | Sepal.Width | Petal.Length | Petal.Width #> --------------------------------------------------------------------------------------- #> 1       |    49 |       40.12 |        -1.00 |        0.90 |        -1.30 |       -1.25 #> 2       |    24 |       18.65 |        -0.40 |       -1.36 |         0.06 |       -0.04 #> 3       |    77 |       94.08 |         0.76 |       -0.15 |         0.81 |        0.81 #>  #> # Indices of model performance #>  #> Sum_Squares_Total | Sum_Squares_Between | Sum_Squares_Within |    R2 #> -------------------------------------------------------------------- #> 596.000           |             443.143 |            152.857 | 0.744 #>  #> # You can access the predicted clusters via `predict()`.  # Visualize plot(rez_hclust) + theme_modern() # Visualize"},{"path":"https://easystats.github.io/parameters/articles/clustering.html","id":"hierarchical-k-means","dir":"Articles","previous_headings":"Supervised Clustering Methods","what":"Hierarchical K-Means","title":"Clustering with easystats","text":"Hierarchical K-Means, name suggest, essentially combination K-Means hierarchical clustering aims improving stability robustness results.","code":"rez_hkmeans <- cluster_analysis(data, n = 3, method = \"hkmeans\")  rez_hkmeans # Show results #> # Clustering Solution #>  #> The 3 clusters accounted for 76.70% of the total variance of the original data. #>  #> Cluster | n_Obs | Sum_Squares | Sepal.Length | Sepal.Width | Petal.Length | Petal.Width #> --------------------------------------------------------------------------------------- #> 1       |    50 |       47.35 |        -1.01 |        0.85 |        -1.30 |       -1.25 #> 2       |    53 |       44.09 |        -0.05 |       -0.88 |         0.35 |        0.28 #> 3       |    47 |       47.45 |         1.13 |        0.09 |         0.99 |        1.01 #>  #> # Indices of model performance #>  #> Sum_Squares_Total | Sum_Squares_Between | Sum_Squares_Within |    R2 #> -------------------------------------------------------------------- #> 596.000           |             457.112 |            138.888 | 0.767 #>  #> # You can access the predicted clusters via `predict()`.  # Visualize plot(rez_hkmeans) + theme_modern() # Visualize"},{"path":"https://easystats.github.io/parameters/articles/clustering.html","id":"k-medoids-pam","dir":"Articles","previous_headings":"Supervised Clustering Methods","what":"K-Medoids (PAM)","title":"Clustering with easystats","text":"Clustering around “medoids”, instead “centroid”, considered robust version K-means. See cluster::pam() information.","code":"rez_pam <- cluster_analysis(data, n = 3, method = \"pam\")  rez_pam # Show results #> # Clustering Solution #>  #> The 3 clusters accounted for 76.46% of the total variance of the original data. #>  #> Cluster | n_Obs | Sum_Squares | Sepal.Length | Sepal.Width | Petal.Length | Petal.Width #> --------------------------------------------------------------------------------------- #> 1       |    50 |       47.35 |        -1.01 |        0.85 |        -1.30 |       -1.25 #> 2       |    45 |       45.26 |         1.17 |        0.06 |         1.02 |        1.05 #> 3       |    55 |       47.67 |        -0.04 |       -0.82 |         0.35 |        0.28 #>  #> # Indices of model performance #>  #> Sum_Squares_Total | Sum_Squares_Between | Sum_Squares_Within |    R2 #> -------------------------------------------------------------------- #> 596.000           |             455.714 |            140.286 | 0.765 #>  #> # You can access the predicted clusters via `predict()`.  # Visualize plot(rez_pam) + theme_modern() # Visualize"},{"path":"https://easystats.github.io/parameters/articles/clustering.html","id":"unsupervised-clustering-methods","dir":"Articles","previous_headings":"","what":"Unsupervised Clustering Methods","title":"Clustering with easystats","text":"Unsupervised clustering methods estimate optimal number clusters (hence, n = NULL don’t pre-specify given number clusters). Note unsupervised methods can sometimes identify observations fit clusters (.e., “outliers”). classified belonging cluster “0” (real cluster, rather groups outliers).","code":""},{"path":"https://easystats.github.io/parameters/articles/clustering.html","id":"bootstrapped-hierarchical-clustering","dir":"Articles","previous_headings":"Unsupervised Clustering Methods","what":"Bootstrapped Hierarchical Clustering","title":"Clustering with easystats","text":"method computes p-values cluster hierarchical cluster structure, returns significant clusters. method can return larger number smaller clusters , ’s based bootstrapping, quite slow.","code":"rez_hclust2 <- cluster_analysis(data,   n = NULL,   method = \"hclust\",   iterations = 500,   ci = 0.90 )  rez_hclust2 # Show results #> # Clustering Solution #>  #> The 25 clusters accounted for 48.37% of the total variance of the original data. #>  #> Cluster | n_Obs | Sum_Squares | Sepal.Length | Sepal.Width | Petal.Length | Petal.Width #> --------------------------------------------------------------------------------------- #> 0       |    89 |      304.31 |         0.11 |       -0.19 |         0.12 |        0.12 #> 1       |     2 |    7.29e-03 |        -0.96 |        0.79 |        -1.28 |       -1.31 #> 10      |     2 |        0.02 |        -0.23 |       -0.13 |         0.22 |        0.07 #> 11      |     2 |        0.02 |         0.49 |        0.79 |         0.99 |        1.51 #> 12      |     2 |        0.03 |        -0.41 |       -0.13 |         0.42 |        0.39 #> 13      |     2 |        0.03 |        -1.02 |        0.44 |        -1.39 |       -1.31 #> 14      |     2 |        0.03 |        -1.08 |       -1.62 |        -0.26 |       -0.26 #> 15      |     3 |        0.07 |        -1.78 |       -0.21 |        -1.41 |       -1.35 #> 16      |     3 |        0.09 |        -0.13 |       -0.74 |         0.72 |        0.96 #> 17      |     3 |        0.12 |        -0.50 |        0.86 |        -1.28 |       -1.22 #> 18      |     3 |        0.09 |        -1.34 |        0.79 |        -1.20 |       -1.27 #> 19      |     2 |        0.08 |         2.18 |       -0.13 |         1.47 |        1.31 #> 2       |     2 |    7.29e-03 |        -0.60 |        1.47 |        -1.28 |       -1.31 #> 20      |     2 |        0.10 |        -0.60 |        2.51 |        -1.31 |       -1.38 #> 21      |     2 |        0.15 |         1.64 |        0.10 |         1.21 |        0.66 #> 22      |     3 |        0.22 |         0.39 |       -1.89 |         0.50 |        0.31 #> 23      |     7 |        1.42 |         0.29 |        0.23 |         0.57 |        0.66 #> 24      |     3 |        0.80 |         2.12 |        1.55 |         1.50 |        1.36 #> 3       |     2 |    8.61e-03 |         0.67 |       -0.59 |         1.04 |        1.25 #> 4       |     2 |        0.01 |        -0.41 |       -1.51 |    -4.53e-03 |       -0.20 #> 5       |     2 |        0.01 |        -0.90 |        1.70 |        -1.25 |       -1.25 #> 6       |     2 |        0.01 |         1.22 |        0.33 |         1.16 |        1.44 #> 7       |     2 |        0.02 |        -1.08 |        1.25 |        -1.34 |       -1.38 #> 8       |     3 |        0.02 |        -0.94 |        1.02 |        -1.35 |       -1.22 #> 9       |     3 |        0.02 |        -1.18 |        0.10 |        -1.26 |       -1.35 #>  #> # Indices of model performance #>  #> Sum_Squares_Total | Sum_Squares_Between | Sum_Squares_Within |    R2 #> -------------------------------------------------------------------- #> 596.000           |             288.295 |              3.390 | 0.484 #>  #> # You can access the predicted clusters via `predict()`. plot(rez_hclust2) + theme_modern() # Visualize"},{"path":"https://easystats.github.io/parameters/articles/clustering.html","id":"dbscan","dir":"Articles","previous_headings":"Unsupervised Clustering Methods","what":"DBSCAN","title":"Clustering with easystats","text":"Although DBSCAN method quite powerful identify clusters, highly dependent parameters, namely, eps min_size. Regarding latter, minimum size cluster set default 0.1 (.e., 10% rows), appropriate avoid small clusters. “optimal” eps value can estimated using n_clusters_dbscan() function:  seems like numeric method find elbow curve doesn’t work well, returns value high. Based visual assessment, elbow seems located around eps = 1.45.","code":"eps <- n_clusters_dbscan(data, min_size = 0.1) eps #> The DBSCAN method, based on the total clusters sum of squares, suggests that the optimal eps = 2.11193281281293 (with min. cluster size set to 15), which corresponds to 1 clusters. plot(eps) rez_dbscan <- cluster_analysis(data, method = \"dbscan\", dbscan_eps = 1.45)  rez_dbscan # Show results #> # Clustering Solution #>  #> The 3 clusters accounted for 61.14% of the total variance of the original data. #>  #> Cluster | n_Obs | Sum_Squares | Sepal.Length | Sepal.Width | Petal.Length | Petal.Width #> --------------------------------------------------------------------------------------- #> 0       |     5 |       47.84 |         1.03 |        0.74 |         0.45 |        0.32 #> 1       |    48 |       34.54 |        -1.02 |        0.86 |        -1.30 |       -1.26 #> 2       |    97 |      149.21 |         0.45 |       -0.46 |         0.62 |        0.61 #>  #> # Indices of model performance #>  #> Sum_Squares_Total | Sum_Squares_Between | Sum_Squares_Within |    R2 #> -------------------------------------------------------------------- #> 596.000           |             364.406 |            183.751 | 0.611 #>  #> # You can access the predicted clusters via `predict()`. plot(rez_dbscan) + theme_modern() # Visualize"},{"path":"https://easystats.github.io/parameters/articles/clustering.html","id":"hierarchical-k-means-1","dir":"Articles","previous_headings":"Unsupervised Clustering Methods","what":"Hierarchical K-Means","title":"Clustering with easystats","text":"Hierarchical DBSCAN variant require critical EPS argument. computes hierarchy DBSCAN solutions, finds optimal cuts hierarchy using stability-based extraction method.","code":"rez_hdbscan <- cluster_analysis(data, method = \"hdbscan\")  rez_hdbscan # Show results #> # Clustering Solution #>  #> The 3 clusters accounted for 66.08% of the total variance of the original data. #>  #> Cluster | n_Obs | Sum_Squares | Sepal.Length | Sepal.Width | Petal.Length | Petal.Width #> --------------------------------------------------------------------------------------- #> 0       |     2 |        0.08 |         2.36 |        1.70 |         1.58 |        1.18 #> 1       |    98 |      154.76 |         0.47 |       -0.47 |         0.63 |        0.61 #> 2       |    50 |       47.35 |        -1.01 |        0.85 |        -1.30 |       -1.25 #>  #> # Indices of model performance #>  #> Sum_Squares_Total | Sum_Squares_Between | Sum_Squares_Within |    R2 #> -------------------------------------------------------------------- #> 596.000           |             393.813 |            202.108 | 0.661 #>  #> # You can access the predicted clusters via `predict()`.  # Visualize plot(rez_hdbscan) + theme_modern() # Visualize"},{"path":"https://easystats.github.io/parameters/articles/clustering.html","id":"k-medoids-with-estimation-of-number-of-clusters-pamk","dir":"Articles","previous_headings":"Unsupervised Clustering Methods","what":"K-Medoids with estimation of number of clusters (pamk)","title":"Clustering with easystats","text":"K-Medoids integrated estimation number clusters. See fpc::pamk details.","code":"rez_pamk <- cluster_analysis(data, method = \"pamk\")  rez_pamk # Show results #> # Clustering Solution #>  #> The 2 clusters accounted for 62.94% of the total variance of the original data. #>  #> Cluster | n_Obs | Sum_Squares | Sepal.Length | Sepal.Width | Petal.Length | Petal.Width #> --------------------------------------------------------------------------------------- #> 1       |    50 |       47.35 |        -1.01 |        0.85 |        -1.30 |       -1.25 #> 2       |   100 |      173.53 |         0.51 |       -0.43 |         0.65 |        0.63 #>  #> # Indices of model performance #>  #> Sum_Squares_Total | Sum_Squares_Between | Sum_Squares_Within |    R2 #> -------------------------------------------------------------------- #> 596.000           |             375.121 |            220.879 | 0.629 #>  #> # You can access the predicted clusters via `predict()`.  # Visualize plot(rez_pamk) + theme_modern() # Visualize"},{"path":"https://easystats.github.io/parameters/articles/clustering.html","id":"mixture","dir":"Articles","previous_headings":"Unsupervised Clustering Methods","what":"Mixture","title":"Clustering with easystats","text":"Model-based clustering based finite Gaussian mixture models. Models estimated EM algorithm initialized hierarchical model-based agglomerative clustering. optimal model selected according BIC.","code":"library(mclust)  rez_mixture <- cluster_analysis(data, method = \"mixture\")  rez_mixture # Show results #> # Clustering Solution #>  #> The 2 clusters accounted for 62.94% of the total variance of the original data. #>  #> Cluster | n_Obs | Sum_Squares | Sepal.Length | Sepal.Width | Petal.Length | Petal.Width #> --------------------------------------------------------------------------------------- #> 1       |    50 |       47.35 |        -1.01 |        0.85 |        -1.30 |       -1.25 #> 2       |   100 |      173.53 |         0.51 |       -0.43 |         0.65 |        0.63 #>  #> # Indices of model performance #>  #> Sum_Squares_Total | Sum_Squares_Between | Sum_Squares_Within |    R2 #> -------------------------------------------------------------------- #> 596.000           |             375.121 |            220.879 | 0.629 #>  #> # You can access the predicted clusters via `predict()`.  # Visualize plot(rez_mixture) + theme_modern() # Visualize"},{"path":"https://easystats.github.io/parameters/articles/clustering.html","id":"metaclustering","dir":"Articles","previous_headings":"","what":"Metaclustering","title":"Clustering with easystats","text":"One core “issue” statistical clustering , many cases, different methods give different results. metaclustering approach proposed easystats (finds echoes consensus clustering; see Monti et al., 2003) consists treating unique clustering solutions ensemble, can derive probability matrix. matrix contains, pair observations, probability cluster. instance, 6th 9th row dataframe assigned similar cluster 5 10 clustering methods, probability grouped together 0.5. Metaclustering based hypothesis , clustering algorithm embodies different prism sees data, running infinite amount algorithms result emergence “true” clusters. number algorithms parameters finite, probabilistic perspective useful proxy. method interesting obvious reasons prefer one another clustering method, well investigate robust clusters different algorithms.  dendrogram (hierarchical clustering clustering solution, hence name metaclustering), well heatmap (darker squares represent higher probability belonging cluster) shows one metacluster consisting 1-50 first rows (bottom left), rest observations closer one another. However, two subclusters still visible, corresponding “true” species. metaclustering approach confirms initial hypothesis, setosa species stands quite clearly, separation two species less clear cut.","code":"list_of_results <- list(   rez_kmeans, rez_hclust, rez_hkmeans, rez_pam,   rez_hclust2, rez_dbscan, rez_hdbscan, rez_mixture )  probability_matrix <- cluster_meta(list_of_results)  # Plot the matrix as a reordered heatmap heatmap(probability_matrix,   scale = \"none\",   col = grDevices::hcl.colors(256, palette = \"inferno\") )"},{"path":"https://easystats.github.io/parameters/articles/clustering.html","id":"resources","dir":"Articles","previous_headings":"","what":"Resources","title":"Clustering with easystats","text":"Clustering algorithms overview Density-based Clustering","code":""},{"path":"https://easystats.github.io/parameters/articles/demean.html","id":"sample-data-used-in-this-vignette","dir":"Articles","previous_headings":"","what":"Sample data used in this vignette","title":"Analysing Longitudinal or Panel Data","text":"Variables: QoL : Response (quality life patient) phq4 : Patient Health Questionnaire, time-varying variable hospital : Location treatment, time-invariant variable, co-variate education: Educational level, time-invariant variable, co-variate ID : patient ID time : time-point measurement","code":"library(parameters) data(\"qol_cancer\")"},{"path":"https://easystats.github.io/parameters/articles/demean.html","id":"heterogeneity-bias","dir":"Articles","previous_headings":"","what":"Heterogeneity bias","title":"Analysing Longitudinal or Panel Data","text":"Heterogeneity bias occurs group-level predictors vary within across groups, hence fixed effects may correlate group (random) effects. typical situation analyzing longitudinal panel data: Due repeated measurements persons, “person” (subject-ID) now level-2 variable. Predictors level-1 (“fixed effects”), e.g. self-rated health income, now effect level-1 (“within”-effect) higher-level units (level-2, subject-level, “”-effect) (see also posting). inevitably leads correlating fixed effects error terms - , turn, results biased estimates, within- -effect captured one estimate. can check model may suffer heterogeneity bias using check_heterogeneity_bias() function:","code":"library(performance) check_heterogeneity_bias(qol_cancer, select = c(\"phq4\", \"education\"), by = \"ID\") #> Possible heterogeneity bias due to following predictors: phq4"},{"path":"https://easystats.github.io/parameters/articles/demean.html","id":"adressing-heterogeneity-bias-the-fixed-effects-regression-fe-approach","dir":"Articles","previous_headings":"","what":"Adressing heterogeneity bias: the Fixed Effects Regression (FE) approach","title":"Analysing Longitudinal or Panel Data","text":"Fixed effects regression models (FE) popular approach panel data analysis particular econometrics considered gold standard. avoid problem heterogeneity bias, FE higher-level variance (thus, -effects), “controlled using higher-level entities , included model dummy variables” (Bell Jones 2015). consequence, FE models able estimate within-effects. remove -effects model within-effects, data needs preparation: de-meaning. De-meaning, person-mean centering, centering within clusters, takes away higher-level mean regression equation, , FE avoids estimating parameter higher-level unit.","code":""},{"path":"https://easystats.github.io/parameters/articles/demean.html","id":"computing-the-de-meaned-and-group-meaned-variables","dir":"Articles","previous_headings":"Adressing heterogeneity bias: the Fixed Effects Regression (FE) approach","what":"Computing the de-meaned and group-meaned variables","title":"Analysing Longitudinal or Panel Data","text":"Now : phq4_between: time-varying variable mean phq4 across time-points, patient (ID). phq4_within: de-meaned time-varying variable phq4. FE model classical linear model, Intercept removed time-invariant predictors allowed included group-level factor included predictor time-varying predictors de-meaned (“person-mean centered”, indicating “within-subject” effect) can see, within-effect PHQ-4 -3.66, hence mean change average individual case sample (, “net” effect), -3.66. -effect? people higher PHQ-4 score differ people lower PHQ-4 score? educational inequalities? higher educated people higher PHQ-4 score lower educated people? question answered FE regression. : “Can one fit multilevel model varying intercepts (coefficients) units predictors correlate? answer yes. solution simple.” (Bafumi Gelman 2006)","code":"qol_cancer <- cbind(   qol_cancer,   datawizard::demean(qol_cancer, select = c(\"phq4\", \"QoL\"), by = \"ID\") ) fe_model1 <- lm(   QoL ~ 0 + time + phq4_within + ID,   data = qol_cancer ) # we use only the first two rows, because the remaining rows are # the estimates for \"ID\", which is not of interest here... model_parameters(fe_model1)[1:2, ] #> Parameter   | Coefficient |   SE |         95% CI | t(374) |      p #> ------------------------------------------------------------------- #> time        |        1.09 | 0.64 | [-0.17,  2.34] |   1.70 | 0.089  #> phq4 within |       -3.66 | 0.41 | [-4.46, -2.86] |  -8.95 | < .001   # instead of removing the intercept, we could also use the # de-meaned response... fe_model2 <- lm(   QoL_within ~ time + phq4_within + ID,   data = qol_cancer ) model_parameters(fe_model2)[2:3, ] #> Parameter   | Coefficient |   SE |         95% CI | t(374) |      p #> ------------------------------------------------------------------- #> time        |        1.09 | 0.64 | [-0.17,  2.34] |   1.70 | 0.089  #> phq4 within |       -3.66 | 0.41 | [-4.46, -2.86] |  -8.95 | < .001  # we compare the results with those from the \"lfe\"-package for panel data library(lfe) fe_model3 <- felm(   QoL ~ time + phq4 | ID,   data = qol_cancer ) model_parameters(fe_model3) #> # Fixed Effects #>  #> Parameter | Coefficient |   SE |         95% CI | t(374) |      p #> ----------------------------------------------------------------- #> time      |        1.09 | 0.64 | [-0.17,  2.34] |   1.70 | 0.089  #> phq4      |       -3.66 | 0.41 | [-4.46, -2.86] |  -8.95 | < .001"},{"path":"https://easystats.github.io/parameters/articles/demean.html","id":"adressing-heterogeneity-bias-the-mixed-model-approach","dir":"Articles","previous_headings":"","what":"Adressing heterogeneity bias: the Mixed Model approach","title":"Analysing Longitudinal or Panel Data","text":"Mixed models include different levels sources variability (.e. error terms level). Predictors used level-1 varying across higher-level units thus residual errors level-1 higher-level units. “covariates contain two parts: one specific higher-level entity vary occasions, one represents difference occasions, within higher-level entities” (Bell Jones 2015). Hence, error terms correlated covariate, violates one assumptions mixed models (iid, independent identically distributed error terms) - also known described heterogeneity bias. can issue addressed outside FE framework? several ways address using mixed models approach: Correlated group factors predictors problem anyway, partial pooling allows estimates units o borrow strength whole sample shrink toward common mean (Shor et al. (2007)). predictor group factors correlate, one can remove correlation group-meaning (“mean within clusters,” Bafumi Gelman 2006; Gelman Hill 2007, chap. 12.6.). time-varying predictors “decomposed” time-varying time-invariant components (de-meaning), mixed models can model within- -subject effects (Bell, Fairbrother, Jones 2019) - approach essentially development long-known recommendation Mundlak (Mundlak 1978). now, follow last recommendation use within- -version phq4. can see, estimates standard errors identical. argument use mixed models, .e. using mixed models panel data yield biased estimates standard errors, based incorrect model specification (Mundlak 1978). , (mixed) model properly specified, estimator mixed model identical ‘within’ (.e. FE) estimator. consequence, use specified mixed model panel data, can even specify complex models including within-effects, -effects random effects variation. mixed models approach can model causes endogeneity explicitly including (separated) within- -effects time-varying fixed effects including time-constant fixed effects. complex models, within-effects naturally change slightly longer identical simpler FE models. “bias”, rather result building complex models: FE models lack information variation group-effects -subject effects. Furthermore, FE models include random slopes, means fixed effects regressions neglecting “cross-cluster differences effects lower-level controls () reduces precision estimated context effects, resulting (…) low statistical power” (Heisig, Schaeffer, Giesecke 2017).","code":"library(lme4) mixed_1 <- lmer(   QoL ~ time + phq4_within + phq4_between + (1 | ID),   data = qol_cancer ) model_parameters(mixed_1) #> # Fixed Effects #>  #> Parameter    | Coefficient |   SE |         95% CI | t(558) |      p #> -------------------------------------------------------------------- #> (Intercept)  |       71.53 | 1.56 | [68.48, 74.59] |  45.98 | < .001 #> time         |        1.09 | 0.64 | [-0.17,  2.34] |   1.70 | 0.089  #> phq4 within  |       -3.66 | 0.41 | [-4.46, -2.86] |  -8.95 | < .001 #> phq4 between |       -6.28 | 0.50 | [-7.27, -5.30] | -12.53 | < .001 #>  #> # Random Effects #>  #> Parameter          | Coefficient |   SE |         95% CI #> -------------------------------------------------------- #> SD (Intercept: ID) |        9.88 | 0.80 | [ 8.43, 11.58] #> SD (Residual)      |       12.37 | 0.45 | [11.51, 13.28]  # compare to FE-model model_parameters(fe_model1)[1:2, ] #> Parameter   | Coefficient |   SE |         95% CI | t(374) |      p #> ------------------------------------------------------------------- #> time        |        1.09 | 0.64 | [-0.17,  2.34] |   1.70 | 0.089  #> phq4 within |       -3.66 | 0.41 | [-4.46, -2.86] |  -8.95 | < .001 mixed_2 <- lmer(   QoL ~ time + phq4_within + phq4_between + education + (1 + time | ID),   data = qol_cancer ) # effects = \"fixed\" will not display random effects, but split the # fixed effects into its between- and within-effects components. model_parameters(mixed_2, effects = \"fixed\") #> Parameter        | Coefficient |   SE |         95% CI | t(554) |      p #> ------------------------------------------------------------------------ #> (Intercept)      |       67.36 | 2.48 | [62.48, 72.23] |  27.15 | < .001 #> time             |        1.09 | 0.66 | [-0.21,  2.39] |   1.65 | 0.099  #> education [mid]  |        5.01 | 2.35 | [ 0.40,  9.62] |   2.14 | 0.033  #> education [high] |        5.52 | 2.75 | [ 0.11, 10.93] |   2.00 | 0.046  #>  #> # Within-Effects #>  #> Parameter   | Coefficient |   SE |         95% CI | t(554) |      p #> ------------------------------------------------------------------- #> phq4 within |       -3.72 | 0.41 | [-4.52, -2.92] |  -9.10 | < .001 #>  #> # Between-Effects #>  #> Parameter    | Coefficient |   SE |         95% CI | t(554) |      p #> -------------------------------------------------------------------- #> phq4 between |       -6.13 | 0.52 | [-7.14, -5.11] | -11.84 | < .001"},{"path":"https://easystats.github.io/parameters/articles/demean.html","id":"conclusion-complex-random-effects-within-between-models","dir":"Articles","previous_headings":"","what":"Conclusion: Complex Random Effects Within-Between Models","title":"Analysing Longitudinal or Panel Data","text":"Depending structure data, best approach analyzing panel data called “complex random effects within-” model (Bell, Fairbrother, Jones 2019): yit = β0 + β1W (xit - ͞xi) + β2B ͞xi + β3 zi + υi0 + υi1 (xit - ͞xi) + εit xit - ͞xi de-meaned predictor, phq4_within ͞xi group-meaned predictor, phq4_between β1W coefficient phq4_within (within-subject) β2B coefficient phq4_between (bewteen-subject) β3 coefficient time-constant predictors, hospital education (bewteen-subject) R-code, model written like : time-constant predictors? de-meaning time-varying predictors, “higher level, mean term longer constrained Level 1 effects, free account higher-level variance associated variable” (Bell Jones 2015). Thus, time-constant categorical predictors, -effect, can simply included fixed effects predictor (since ’re constrained level-1 effects). Time-constant continuous group-level predictors (instance, GDP countries) group-meaned, proper “”-effect (Gelman Hill 2007, chap. 12.6.). benefit kind model information within-, - time-constant (.e. ) effects group-level predictors… … can also model variation (group) effects across time (probably space), can even include higher-level units (e.g. nested design cross-classified design two levels): imbalanced groups, .e. large differences N per group? See little example visual example…","code":"# We ignore the convergence warnings for now... rewb <- suppressWarnings(lmer(   QoL ~ time + phq4_within + phq4_between + education +     (1 + time | ID) + (1 + phq4_within | ID),   data = qol_cancer )) model_parameters(rewb, effects = \"fixed\") #> Parameter        | Coefficient |   SE |         95% CI | t(551) |      p #> ------------------------------------------------------------------------ #> (Intercept)      |       67.18 | 2.39 | [62.49, 71.87] |  28.13 | < .001 #> time             |        1.18 | 0.60 | [-0.01,  2.37] |   1.95 | 0.051  #> education [mid]  |        4.95 | 2.35 | [ 0.34,  9.56] |   2.11 | 0.035  #> education [high] |        5.62 | 2.76 | [ 0.20, 11.04] |   2.04 | 0.042  #>  #> # Within-Effects #>  #> Parameter   | Coefficient |   SE |         95% CI | t(551) |      p #> ------------------------------------------------------------------- #> phq4 within |       -4.50 | 0.58 | [-5.64, -3.36] |  -7.78 | < .001 #>  #> # Between-Effects #>  #> Parameter    | Coefficient |   SE |         95% CI | t(551) |      p #> -------------------------------------------------------------------- #> phq4 between |       -6.11 | 0.52 | [-7.13, -5.10] | -11.81 | < .001 random_parameters(rewb) #> # Random Effects #>  #> Within-Group Variance              119.51 (10.93) #> Between-Group Variance #>   Random Intercept (ID)            111.26 (10.55) #>   Random Intercept (ID.1)           21.86  (4.68) #>   Random Slope (ID.time)             0.46  (0.68) #>   Random Slope (ID.1.phq4_within)   14.37  (3.79) #> Correlations #>   ID.time                              -1 #>   ID.phq4_within                     0.48 #> N (groups per factor) #>   ID                                  188 #> Observations                          564"},{"path":"https://easystats.github.io/parameters/articles/demean.html","id":"a-visual-example","dir":"Articles","previous_headings":"","what":"A visual example","title":"Analysing Longitudinal or Panel Data","text":"First, generate fake data implies linear relationship outcome independent variable. objective amount typing errors depends fast (typing speed) can type, however, typing experience , faster can type. Thus, outcome measure “amount typing errors”, predictor “typing speed”. Furthermore, repeated measurements people different “typing experience levels”. results show two sources variation: Overall, experienced typists make less mistakes (group-level pattern). typing faster, typists make mistakes (individual-level pattern). Let’s look raw data…","code":"library(ggplot2) library(poorman) library(see)  set.seed(123) n <- 5 b <- seq(1, 1.5, length.out = 5) x <- seq(2, 2 * n, 2)  d <- do.call(rbind, lapply(1:n, function(i) {   data.frame(     x = seq(1, n, by = 0.2),     y = 2 * x[i] + b[i] * seq(1, n, by = 0.2) + rnorm(21),     grp = as.factor(2 * i)   ) }))  d <- d %>%   group_by(grp) %>%   mutate(x = rev(15 - (x + 1.5 * as.numeric(grp)))) %>%   ungroup()  labs <- c(\"very slow\", \"slow\", \"average\", \"fast\", \"very fast\") levels(d$grp) <- rev(labs)  d <- cbind(d, datawizard::demean(d, c(\"x\", \"y\"), by = \"grp\"))"},{"path":"https://easystats.github.io/parameters/articles/demean.html","id":"model-1-linear-relationship-between-typing-errors-and-typing-speed","dir":"Articles","previous_headings":"A visual example","what":"Model 1: Linear relationship between typing errors and typing speed","title":"Analysing Longitudinal or Panel Data","text":"can now assume (linear) relationship typing errors typing speed.  Looking coefficients, following model coefficient -1.92. However, ignored clustered structure data, example due repeated measurements.","code":"m1 <- lm(y ~ x, data = d) model_parameters(m1) #> Parameter   | Coefficient |   SE |         95% CI | t(103) |      p #> ------------------------------------------------------------------- #> (Intercept) |       30.20 | 1.42 | [27.39, 33.00] |  21.34 | < .001 #> x           |       -1.92 | 0.18 | [-2.27, -1.56] | -10.69 | < .001"},{"path":"https://easystats.github.io/parameters/articles/demean.html","id":"model-2-within-subject-effect-of-typing-speed","dir":"Articles","previous_headings":"A visual example","what":"Model 2: Within-subject effect of typing speed","title":"Analysing Longitudinal or Panel Data","text":"fixed effects regression (FE-regression) now remove -effects include within-effects well group-level indicator.  returns coefficient “within”-effect, 1.2, standard error 0.07. Note FE-model take variation subjects account, thus resulting (possibly) biased estimates, biased standard errors.","code":"m2 <- lm(y ~ 0 + x_within + grp, data = d) model_parameters(m2)[1, ] #> Parameter | Coefficient |   SE |       95% CI | t(99) |      p #> -------------------------------------------------------------- #> x within  |        1.20 | 0.07 | [1.06, 1.35] | 16.08 | < .001"},{"path":"https://easystats.github.io/parameters/articles/demean.html","id":"model-3-between-subject-effect-of-typing-speed","dir":"Articles","previous_headings":"A visual example","what":"Model 3: Between-subject effect of typing speed","title":"Analysing Longitudinal or Panel Data","text":"understand, model 1 (m1) returns biased estimate, “weighted average” within- -effects, let us look -effect now.  can see, -effect -2.93, different -1.92 estimated model m1.","code":"m3 <- lm(y ~ x_between, data = d) model_parameters(m3) #> Parameter   | Coefficient |   SE |         95% CI | t(103) |      p #> ------------------------------------------------------------------- #> (Intercept) |       37.83 | 0.62 | [36.59, 39.06] |  60.79 | < .001 #> x between   |       -2.93 | 0.08 | [-3.09, -2.78] | -36.76 | < .001"},{"path":"https://easystats.github.io/parameters/articles/demean.html","id":"model-4-mixed-model-with-within--and-between-subjects","dir":"Articles","previous_headings":"A visual example","what":"Model 4: Mixed model with within- and between-subjects","title":"Analysing Longitudinal or Panel Data","text":"Since FE-models can model within-effects, now use mixed model within- -effects.  see, estimate within-effects biased. Furthermore, get correct -effect well (standard errors differ, variance grouping structure accurately taken account).","code":"m4 <- lmer(y ~ x_between + x_within + (1 | grp), data = d) model_parameters(m4) #> # Fixed Effects #>  #> Parameter   | Coefficient |   SE |         95% CI | t(100) |      p #> ------------------------------------------------------------------- #> (Intercept) |       37.83 | 0.33 | [37.17, 38.48] | 114.46 | < .001 #> x between   |       -2.93 | 0.04 | [-3.02, -2.85] | -69.22 | < .001 #> x within    |        1.20 | 0.07 | [ 1.06,  1.35] |  16.22 | < .001 #>  #> # Random Effects #>  #> Parameter           | Coefficient #> --------------------------------- #> SD (Intercept: grp) |        0.00 #> SD (Residual)       |        0.92"},{"path":"https://easystats.github.io/parameters/articles/demean.html","id":"model-5-complex-random-effects-within-between-model","dir":"Articles","previous_headings":"A visual example","what":"Model 5: Complex Random-Effects Within-Between Model","title":"Analysing Longitudinal or Panel Data","text":"Finally, can also take variation subjects account adding random slope. model can called complex “REWB” (random-effects within-) model. Due variation subjects, get larger standard errors within-effect.","code":"m5 <- lmer(y ~ x_between + x_within + (1 + x_within | grp), data = d) model_parameters(m5) #> # Fixed Effects #>  #> Parameter   | Coefficient |   SE |         95% CI |  t(98) |      p #> ------------------------------------------------------------------- #> (Intercept) |       37.95 | 0.34 | [37.28, 38.63] | 111.15 | < .001 #> x between   |       -2.95 | 0.04 | [-3.04, -2.87] | -67.57 | < .001 #> x within    |        1.20 | 0.10 | [ 1.01,  1.40] |  12.16 | < .001 #>  #> # Random Effects #>  #> Parameter                     | Coefficient |   SE |         95% CI #> ------------------------------------------------------------------- #> SD (Intercept: grp)           |        0.09 | 0.22 | [ 0.00, 14.20] #> SD (x_within: grp)            |        0.15 | 0.12 | [ 0.03,  0.69] #> Cor (Intercept~x_within: grp) |       -1.00 | 2.18 | [-1.00,      ] #> SD (Residual)                 |        0.90 | 0.07 | [ 0.78,  1.04]"},{"path":"https://easystats.github.io/parameters/articles/demean.html","id":"balanced-versus-imbalanced-groups","dir":"Articles","previous_headings":"","what":"Balanced versus imbalanced groups","title":"Analysing Longitudinal or Panel Data","text":"“simple” linear slope -effect (also within-effect) (almost) identical “classical” linear regression compared linear mixed models groups balanced, .e. number observation per group similar . Whenever group size imbalanced, “simple” linear slope adjusted. leads different estimates -effects classical mixed models regressions due shrinkage - .e. larger variation group sizes find stronger regularization estimates. Hence, mixed models larger differences number observation per random effects group, -effect differ -effect calculated “classical” regression models. However, shrinkage desired property mixed models usually improves estimates.","code":"set.seed(123) n <- 5 b <- seq(1, 1.5, length.out = 5) x <- seq(2, 2 * n, 2)  d <- do.call(rbind, lapply(1:n, function(i) {   data.frame(     x = seq(1, n, by = 0.2),     y = 2 * x[i] + b[i] * seq(1, n, by = 0.2) + rnorm(21),     grp = as.factor(2 * i)   ) }))  # create imbalanced groups d$grp[sample(which(d$grp == 8), 10)] <- 6 d$grp[sample(which(d$grp == 4), 8)] <- 2 d$grp[sample(which(d$grp == 10), 9)] <- 6  d <- d %>%   group_by(grp) %>%   mutate(x = rev(15 - (x + 1.5 * as.numeric(grp)))) %>%   ungroup()  labs <- c(\"very slow\", \"slow\", \"average\", \"fast\", \"very fast\") levels(d$grp) <- rev(labs)  d <- cbind(d, datawizard::demean(d, c(\"x\", \"y\"), by = \"grp\"))  # Between-subject effect of typing speed m1 <- lm(y ~ x_between, data = d) model_parameters(m1) #> Parameter   | Coefficient |   SE |         95% CI | t(103) |      p #> ------------------------------------------------------------------- #> (Intercept) |       38.32 | 1.33 | [35.69, 40.95] |  28.87 | < .001 #> x between   |       -2.81 | 0.16 | [-3.13, -2.49] | -17.47 | < .001  # Between-subject effect of typing speed, accounting for group structure m2 <- lmer(y ~ x_between + (1 | grp), data = d) model_parameters(m2) #> # Fixed Effects #>  #> Parameter   | Coefficient |   SE |         95% CI | t(101) |      p #> ------------------------------------------------------------------- #> (Intercept) |       37.02 | 2.73 | [31.59, 42.44] |  13.54 | < .001 #> x between   |       -2.71 | 0.35 | [-3.40, -2.02] |  -7.81 | < .001 #>  #> # Random Effects #>  #> Parameter           | Coefficient |   SE |       95% CI #> ------------------------------------------------------- #> SD (Intercept: grp) |        1.54 | 0.77 | [0.58, 4.09] #> SD (Residual)       |        2.98 | 0.21 | [2.60, 3.42]"},{"path":"https://easystats.github.io/parameters/articles/demean.html","id":"a-final-note---latent-mean-centering","dir":"Articles","previous_headings":"","what":"A final note - latent mean centering","title":"Analysing Longitudinal or Panel Data","text":"can even complicated. person-mean observed, true value known. Thus, certain situations, coefficients de-meaning still might (less) biased, doesn’t appropriately account uncertainty person-means. case, latent mean centering recommended, however, options . One way using great brms package, approach described .","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/articles/efa_cfa.html","id":"how-to-perform-a-factor-analysis-fa","dir":"Articles","previous_headings":"","what":"How to perform a Factor Analysis (FA)","title":"Structural Models (EFA, CFA, SEM, ...)","text":"difference PCA EFA can quite hard intuitively grasp output familiar. idea PCA aims extracting variance possible variables dataset, whereas EFA aims creating consistent factors dataset without desperately trying represent variables. PCA popular feature reduction, try best represent variance contained original data, minimizing loss information. hand, EFA usually context exploring latent dimensions might hidden observed variables, without necessarily striving represent whole dataset. illustrate EFA, let us use International Personality Item Pool data available psych package. includes 25 personality self report items. authors built items following big 5 personality structure.","code":""},{"path":"https://easystats.github.io/parameters/articles/efa_cfa.html","id":"factor-structure-sphericity-and-kmo","dir":"Articles","previous_headings":"How to perform a Factor Analysis (FA)","what":"Factor Structure (Sphericity and KMO)","title":"Structural Models (EFA, CFA, SEM, ...)","text":"first step test dataset suitable carrying factor analysis. two Bartlett’s Test Sphericity: tests whether matrix (correlations) significantly different identity matrix. test provides probability correlation matrix significant correlations among least variables dataset, prerequisite factor analysis work. words, starting factor analysis, one needs check whether Bartlett’s test sphericity significant. Kaiser, Meyer, Olkin (KMO) Measure Sampling Adequacy (MSA): test introduced Kaiser (1970) Measure Sampling Adequacy (MSA), later modified Kaiser Rice (1974). Kaiser-Meyer-Olkin (KMO) statistic, can vary 0 1, indicates degree variable set predicted without error variables. value 0 indicates sum partial correlations large relative sum correlations, indicating factor analysis likely inappropriate. KMO value close 1 indicates sum partial correlations large relative sum correlations factor analysis yield distinct reliable factors. tests can performed using performance::check_factorstructure() function. First, set data. Next, check test dataset suitable carrying factor analysis.","code":"library(parameters) library(psych)  # Load the data data <- psych::bfi[, 1:25] # Select only the 25 first columns corresponding to the items data <- na.omit(data) # remove missing values library(performance) # Check factor structure performance::check_factorstructure(data) #> # Is the data suitable for Factor Analysis? #>  #>  #>   - Sphericity: Bartlett's test of sphericity suggests that there is sufficient significant correlation in the data for factor analysis (Chisq(300) = 18146.07, p < .001). #>   - KMO: The Kaiser, Meyer, Olkin (KMO) overall measure of sampling adequacy suggests that data seems appropriate for factor analysis (KMO = 0.85). The individual KMO scores are: A1 (0.75), A2 (0.84), A3 (0.87), A4 (0.88), A5 (0.90), C1 (0.84), C2 (0.80), C3 (0.85), C4 (0.83), C5 (0.86), E1 (0.84), E2 (0.88), E3 (0.90), E4 (0.88), E5 (0.89), N1 (0.78), N2 (0.78), N3 (0.86), N4 (0.89), N5 (0.86), O1 (0.86), O2 (0.78), O3 (0.84), O4 (0.77), O5 (0.76)."},{"path":"https://easystats.github.io/parameters/articles/efa_cfa.html","id":"exploratory-factor-analysis-efa","dir":"Articles","previous_headings":"How to perform a Factor Analysis (FA)","what":"Exploratory Factor Analysis (EFA)","title":"Structural Models (EFA, CFA, SEM, ...)","text":"Now confident dataset appropriate, explore factor structure made 5 latent variables, corresponding items’ authors theory personality. can see, 25 items nicely spread 5 latent factors, famous big 5. Based model, can now predict back scores individual new variables:","code":"# Fit an EFA efa <- psych::fa(data, nfactors = 5) %>%   model_parameters(sort = TRUE, threshold = \"max\")  efa #> # Rotated loadings from Factor Analysis (oblimin-rotation) #>  #> Variable |  MR2 |   MR1 |   MR3 |   MR5 |   MR4 | Complexity | Uniqueness #> ------------------------------------------------------------------------- #> N1       | 0.83 |       |       |       |       |       1.07 |       0.32 #> N2       | 0.78 |       |       |       |       |       1.03 |       0.39 #> N3       | 0.70 |       |       |       |       |       1.08 |       0.46 #> N5       | 0.48 |       |       |       |       |       2.00 |       0.65 #> N4       | 0.47 |       |       |       |       |       2.33 |       0.49 #> E2       |      |  0.67 |       |       |       |       1.08 |       0.45 #> E4       |      | -0.59 |       |       |       |       1.52 |       0.46 #> E1       |      |  0.55 |       |       |       |       1.22 |       0.65 #> E5       |      | -0.42 |       |       |       |       2.68 |       0.59 #> E3       |      | -0.41 |       |       |       |       2.65 |       0.56 #> C2       |      |       |  0.67 |       |       |       1.18 |       0.55 #> C4       |      |       | -0.64 |       |       |       1.13 |       0.52 #> C3       |      |       |  0.57 |       |       |       1.10 |       0.68 #> C5       |      |       | -0.56 |       |       |       1.41 |       0.56 #> C1       |      |       |  0.55 |       |       |       1.20 |       0.65 #> A3       |      |       |       |  0.68 |       |       1.06 |       0.46 #> A2       |      |       |       |  0.66 |       |       1.03 |       0.54 #> A5       |      |       |       |  0.54 |       |       1.48 |       0.53 #> A4       |      |       |       |  0.45 |       |       1.74 |       0.70 #> A1       |      |       |       | -0.44 |       |       1.88 |       0.80 #> O3       |      |       |       |       |  0.62 |       1.16 |       0.53 #> O5       |      |       |       |       | -0.54 |       1.21 |       0.70 #> O1       |      |       |       |       |  0.52 |       1.10 |       0.68 #> O2       |      |       |       |       | -0.47 |       1.68 |       0.73 #> O4       |      |       |       |       |  0.36 |       2.65 |       0.75 #>  #> The 5 latent factors (oblimin rotation) accounted for 42.36% of the total variance of the original data (MR2 = 10.31%, MR1 = 8.83%, MR3 = 8.39%, MR5 = 8.29%, MR4 = 6.55%). predictions <- predict(   efa,   names = c(\"Neuroticism\", \"Conscientiousness\", \"Extraversion\", \"Agreeableness\", \"Opennness\"),   verbose = FALSE ) # let's look only at the first five individuals head(predictions, 5) #>   Neuroticism Conscientiousness Extraversion Agreeableness Opennness #> 1       -0.22            -0.128       -1.327        -0.855     -1.61 #> 2        0.16            -0.466       -0.572        -0.072     -0.17 #> 3        0.62            -0.141       -0.043        -0.552      0.23 #> 4       -0.12            -0.058       -1.063        -0.091     -1.06 #> 5       -0.17            -0.460       -0.099        -0.712     -0.66"},{"path":"https://easystats.github.io/parameters/articles/efa_cfa.html","id":"how-many-factors-to-retain-in-factor-analysis-fa","dir":"Articles","previous_headings":"How to perform a Factor Analysis (FA)","what":"How many factors to retain in Factor Analysis (FA)","title":"Structural Models (EFA, CFA, SEM, ...)","text":"running factor analysis (FA), one often needs specify many components (latent variables) retain extract. decision often motivated supported statistical indices procedures aiming finding optimal number factors. huge number methods exist statistically address issue, can sometimes give different results. Unfortunately, consensus method use, best.","code":""},{"path":"https://easystats.github.io/parameters/articles/efa_cfa.html","id":"the-method-agreement-procedure","dir":"Articles","previous_headings":"How to perform a Factor Analysis (FA) > How many factors to retain in Factor Analysis (FA)","what":"The Method Agreement procedure","title":"Structural Models (EFA, CFA, SEM, ...)","text":"Method Agreement procedure, first implemented psycho package (Makowski 2018), proposes rely consensus methods, rather one method particular. procedure can easily used via n_factors() function, re-implemented improved parameters package. One can provide dataframe, function run large number routines return optimal number factors based higher consensus. Interestingly, smallest nubmer factors methods suggest 6, consistent newer models personality (e.g., HEXACO). details, well summary table can obtained follows: plot can also obtained (see package must loaded):","code":"n <- n_factors(data) n #> # Method Agreement Procedure: #>  #> The choice of 6 dimensions is supported by 3 (15.79%) methods out of 19 (Optimal coordinates, Parallel analysis, Kaiser criterion). as.data.frame(n) #>    n_Factors              Method              Family #> 1          1 Acceleration factor               Scree #> 2          3                 CNG                 CNG #> 3          4                beta Multiple_regression #> 4          4    VSS complexity 1                 VSS #> 5          5    VSS complexity 2                 VSS #> 6          5       Velicer's MAP        Velicers_MAP #> 7          6 Optimal coordinates               Scree #> 8          6   Parallel analysis               Scree #> 9          6    Kaiser criterion               Scree #> 10         7                   t Multiple_regression #> 11         7                   p Multiple_regression #> 12         7          Scree (R2)            Scree_SE #> 13         8          Scree (SE)            Scree_SE #> 14         8                 BIC                 BIC #> 15        11      BIC (adjusted)                 BIC #> 16        22             Bentler             Bentler #> 17        24            Bartlett             Barlett #> 18        24            Anderson             Barlett #> 19        24              Lawley             Barlett summary(n) #>    n_Factors n_Methods Variance_Cumulative #> 1          1         1                0.19 #> 2          3         1                0.35 #> 3          4         2                0.41 #> 4          5         2                0.45 #> 5          6         3                0.48 #> 6          7         3                0.49 #> 7          8         2                0.51 #> 8         11         1                0.53 #> 9         22         1                0.57 #> 10        24         3                0.57 library(see)  plot(n) + theme_modern()"},{"path":"https://easystats.github.io/parameters/articles/efa_cfa.html","id":"confirmatory-factor-analysis-cfa","dir":"Articles","previous_headings":"How to perform a Factor Analysis (FA)","what":"Confirmatory Factor Analysis (CFA)","title":"Structural Models (EFA, CFA, SEM, ...)","text":"’ve seen EFA 5 latent variables works great dataset, structure 6 latent factors might fact appropriate. can statistically test actually case? can done using Confirmatory Factor Analysis (CFA) (opposed Exploratory FA), bridges factor analysis Structural Equation Modeling (SEM). However, order cleanly, EFA independent CFA: factor structure explored “training” set, tested (“confirmed”) “testing” set. words, dataset used exploration confirmation , standard widely adopted field machine learning.","code":""},{"path":"https://easystats.github.io/parameters/articles/efa_cfa.html","id":"partition-the-data","dir":"Articles","previous_headings":"How to perform a Factor Analysis (FA) > Confirmatory Factor Analysis (CFA)","what":"Partition the data","title":"Structural Models (EFA, CFA, SEM, ...)","text":"data can easily split two sets data_partition() function, use 70% sample training rest test.","code":"# to have reproducible result, we will also set seed here so that similar # portions of the data are used each time we run the following code partitions <- datawizard::data_partition(data, training_proportion = 0.7, seed = 111) training <- partitions$p_0.7 test <- partitions$test"},{"path":"https://easystats.github.io/parameters/articles/efa_cfa.html","id":"create-cfa-structures-out-of-efa-models","dir":"Articles","previous_headings":"How to perform a Factor Analysis (FA) > Confirmatory Factor Analysis (CFA)","what":"Create CFA structures out of EFA models","title":"Structural Models (EFA, CFA, SEM, ...)","text":"next step, run two EFA models training set, specifying 5 6 latent factors respectively, transform CFA structures. can see, structure just string encoding manifest variables (observed variables) integrated latent variables.","code":"structure_big5 <- psych::fa(training, nfactors = 5) %>%   efa_to_cfa() structure_big6 <- psych::fa(training, nfactors = 6) %>%   efa_to_cfa()  # Investigate how the models look structure_big5 #> # Latent variables #> MR2 =~ N1 + N2 + N3 + N4 + N5 + .row_id #> MR1 =~ E1 + E2 + E3 + E4 + E5 #> MR3 =~ C1 + C2 + C3 + C4 + C5 #> MR5 =~ A1 + A2 + A3 + A4 + A5 #> MR4 =~ O1 + O2 + O3 + O4 + O5  structure_big6 #> # Latent variables #> MR2 =~ N1 + N2 + N3 + N5 + .row_id #> MR3 =~ C1 + C2 + C3 + C4 + C5 #> MR1 =~ E1 + E2 + E4 + E5 + N4 + O4 #> MR5 =~ A1 + A2 + A3 + A4 + A5 #> MR4 =~ E3 + O1 + O2 + O3 #> MR6 =~ O5"},{"path":"https://easystats.github.io/parameters/articles/efa_cfa.html","id":"fit-and-compare-models","dir":"Articles","previous_headings":"How to perform a Factor Analysis (FA) > Confirmatory Factor Analysis (CFA)","what":"Fit and Compare models","title":"Structural Models (EFA, CFA, SEM, ...)","text":"can finally apply structure testing dataset using lavaan package, compare models : , seems Big-5 structure remains quite reliable.","code":"library(lavaan) library(performance)  big5 <- suppressWarnings(lavaan::cfa(structure_big5, data = test)) big6 <- suppressWarnings(lavaan::cfa(structure_big6, data = test))  performance::compare_performance(big5, big6, verbose = FALSE) #> # Comparison of Model Performance Indices #>  #> Name |  Model |     Chi2 | Chi2_df | p (Chi2) | Baseline(325) | p (Baseline) #> ---------------------------------------------------------------------------- #> big5 | lavaan | 1366.793 | 289.000 |   < .001 |      5413.276 |       < .001 #> big6 | lavaan | 1504.653 | 285.000 |   < .001 |      5413.276 |       < .001 #>  #> Name |   GFI |  AGFI |   NFI |  NNFI |   CFI | RMSEA |    RMSEA  CI | p (RMSEA) #> ------------------------------------------------------------------------------- #> big5 | 0.861 | 0.831 | 0.748 | 0.762 | 0.788 | 0.071 | [0.07, 0.08] |    < .001 #> big6 | 0.854 | 0.820 | 0.722 | 0.727 | 0.760 | 0.077 | [0.07, 0.08] |    < .001 #>  #> Name |    RMR |  SRMR |   RFI |  PNFI |   IFI |   RNI | Loglikelihood #> --------------------------------------------------------------------- #> big5 | 12.332 | 0.076 | 0.716 | 0.665 | 0.790 | 0.788 |    -35860.601 #> big6 | 12.595 | 0.083 | 0.683 | 0.633 | 0.762 | 0.760 |    -35929.531 #>  #> Name |   AIC (weights) |   BIC (weights) | BIC_adjusted #> ------------------------------------------------------- #> big5 | 71845.2 (>.999) | 72130.1 (>.999) |    71933.186 #> big6 | 71991.1 (<.001) | 72294.3 (<.001) |    72084.722"},{"path":"https://easystats.github.io/parameters/articles/efa_cfa.html","id":"structural-equation-modeling","dir":"Articles","previous_headings":"","what":"Structural Equation Modeling","title":"Structural Models (EFA, CFA, SEM, ...)","text":"previous example shows one enormous amount modeling possibilities structural equation models, particular example mediation analysis, .e. model estimates indirect effects partial mediation structures.","code":"set.seed(1234) X <- rnorm(100) M <- 0.5 * X + rnorm(100) Y <- 0.7 * M + rnorm(100) df <- data.frame(X = X, Y = Y, M = M)  model <- \" # direct effect              Y ~ c*X            # mediator              M ~ a*X              Y ~ b*M            # indirect effect (a*b)              ab := a*b            # total effect              total := c + (a*b)          \" fit <- lavaan::sem(model, data = df, test = \"Satorra-Bentler\") model_parameters(fit) #> # Regression #>  #> Link      | Coefficient |   SE |        95% CI |    z |      p #> -------------------------------------------------------------- #> Y ~ X (c) |        0.04 | 0.10 | [-0.17, 0.24] | 0.35 | 0.728  #> M ~ X (a) |        0.47 | 0.10 | [ 0.27, 0.68] | 4.61 | < .001 #> Y ~ M (b) |        0.79 | 0.09 | [ 0.61, 0.97] | 8.54 | < .001 #>  #> # Defined #>  #> To      | Coefficient |   SE |       95% CI |    z |      p #> ----------------------------------------------------------- #> (ab)    |        0.37 | 0.09 | [0.19, 0.55] | 4.06 | < .001 #> (total) |        0.41 | 0.12 | [0.17, 0.65] | 3.29 | 0.001"},{"path":[]},{"path":[]},{"path":"https://easystats.github.io/parameters/articles/model_parameters.html","id":"frequentist","dir":"Articles","previous_headings":"Correlations and t-tests","what":"Frequentist","title":"Summary of Model Parameters","text":"","code":"library(parameters) cor.test(iris$Sepal.Length, iris$Sepal.Width) |>   parameters() #> Pearson's product-moment correlation #>  #> Parameter1        |       Parameter2 |     r |        95% CI | t(148) |     p #> ----------------------------------------------------------------------------- #> iris$Sepal.Length | iris$Sepal.Width | -0.12 | [-0.27, 0.04] |  -1.44 | 0.152 #>  #> Alternative hypothesis: true correlation is not equal to 0 t.test(mpg ~ vs, data = mtcars) |>   parameters() #> Welch Two Sample t-test #>  #> Parameter | Group | vs = 0 | vs = 1 | Difference |          95% CI | t(22.72) |      p #> -------------------------------------------------------------------------------------- #> mpg       |    vs |  16.62 |  24.56 |      -7.94 | [-11.46, -4.42] |    -4.67 | < .001 #>  #> Alternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0"},{"path":"https://easystats.github.io/parameters/articles/model_parameters.html","id":"bayesian","dir":"Articles","previous_headings":"Correlations and t-tests","what":"Bayesian","title":"Summary of Model Parameters","text":"","code":"BayesFactor::correlationBF(iris$Sepal.Length, iris$Sepal.Width) |>   parameters() #> Bayesian correlation analysis #>  #> Parameter | Median |        95% CI |     pd |         Prior |    BF #> ------------------------------------------------------------------- #> rho       |  -0.11 | [-0.27, 0.04] | 92.25% | Beta (3 +- 3) | 0.509 BayesFactor::ttestBF(formula = mpg ~ vs, data = mtcars) |>   parameters() #> Bayesian t-test #>  #> Parameter  | Median |          95% CI |     pd |              Prior |     BF #> ---------------------------------------------------------------------------- #> Difference |  -7.31 | [-10.81, -3.79] | 99.98% | Cauchy (0 +- 0.71) | 529.27"},{"path":"https://easystats.github.io/parameters/articles/model_parameters.html","id":"anovas","dir":"Articles","previous_headings":"","what":"ANOVAs","title":"Summary of Model Parameters","text":"Indices effect size ANOVAs, partial non-partial versions eta_squared(), epsilon_sqared() omega_squared() powered effectsize-package. However, parameters uses function compute indices parameters summaries, including confidence intervals","code":""},{"path":"https://easystats.github.io/parameters/articles/model_parameters.html","id":"simple","dir":"Articles","previous_headings":"ANOVAs","what":"Simple","title":"Summary of Model Parameters","text":"Let’s complicate things interaction term:","code":"aov(Sepal.Length ~ Species, data = iris) |>   parameters(es_type = c(\"omega\", \"eta\", \"epsilon\")) #> Parameter | Sum_Squares |  df | Mean_Square |      F |      p | Omega2 | Eta2 | Epsilon2 #> ---------------------------------------------------------------------------------------- #> Species   |       63.21 |   2 |       31.61 | 119.26 | < .001 |   0.61 | 0.62 |     0.61 #> Residuals |       38.96 | 147 |        0.27 |        |        |        |      |          #>  #> Anova Table (Type 1 tests) aov(Sepal.Length ~ Species * Sepal.Width, data = iris) |>   parameters(     es_type = c(\"omega\", \"eta\"),     ci = 0.8   ) #> Parameter           | Sum_Squares |  df | Mean_Square |      F |      p #> ----------------------------------------------------------------------- #> Species             |       63.21 |   2 |       31.61 | 163.44 | < .001 #> Sepal.Width         |       10.95 |   1 |       10.95 |  56.64 | < .001 #> Species:Sepal.Width |        0.16 |   2 |        0.08 |   0.41 | 0.667  #> Residuals           |       27.85 | 144 |        0.19 |        |        #>  #> Parameter           | Omega2 (partial) | Omega2 80% CI | Eta2 (partial) |  Eta2 80% CI #> -------------------------------------------------------------------------------------- #> Species             |             0.68 |  [0.65, 1.00] |           0.69 | [0.66, 1.00] #> Sepal.Width         |             0.27 |  [0.22, 1.00] |           0.28 | [0.23, 1.00] #> Species:Sepal.Width |             0.00 |  [0.00, 1.00] |       5.61e-03 | [0.00, 1.00] #> Residuals           |                  |               |                |              #>  #> Anova Table (Type 1 tests)"},{"path":"https://easystats.github.io/parameters/articles/model_parameters.html","id":"repeated-measures","dir":"Articles","previous_headings":"ANOVAs","what":"Repeated measures","title":"Summary of Model Parameters","text":"parameters() (resp. alias model_parameters()) also works repeated measures ANOVAs, whether computed aov() mixed model.","code":"aov(mpg ~ am + Error(gear), data = mtcars) |>   parameters() #> # gear #>  #> Parameter | Sum_Squares | df | Mean_Square #> ------------------------------------------ #> am        |      259.75 |  1 |      259.75 #>  #> # Within #>  #> Parameter | Sum_Squares | df | Mean_Square |    F |     p #> --------------------------------------------------------- #> am        |      145.45 |  1 |      145.45 | 5.85 | 0.022 #> Residuals |      720.85 | 29 |       24.86 |      |       #>  #> Anova Table (Type 1 tests)"},{"path":"https://easystats.github.io/parameters/articles/model_parameters.html","id":"regressions-glms-mixed-models-gams","dir":"Articles","previous_headings":"","what":"Regressions (GLMs, Mixed Models, GAMs, …)","title":"Summary of Model Parameters","text":"parameters() (resp. alias model_parameters()) mainly built regression models mind. works many types models packages, including mixed models Bayesian models.","code":""},{"path":"https://easystats.github.io/parameters/articles/model_parameters.html","id":"glms","dir":"Articles","previous_headings":"Regressions (GLMs, Mixed Models, GAMs, …)","what":"GLMs","title":"Summary of Model Parameters","text":"","code":"glm(vs ~ poly(mpg, 2) + cyl, data = mtcars, family = binomial()) |>   parameters() #> Parameter        | Log-Odds |   SE |          95% CI |     z |     p #> -------------------------------------------------------------------- #> (Intercept)      |    13.51 | 7.20 | [  2.56, 33.42] |  1.88 | 0.060 #> mpg [1st degree] |    -6.64 | 8.99 | [-27.81, 11.13] | -0.74 | 0.461 #> mpg [2nd degree] |     1.16 | 3.59 | [ -7.91,  8.56] |  0.32 | 0.746 #> cyl              |    -2.28 | 1.18 | [ -5.58, -0.51] | -1.92 | 0.055 # show Odds Ratios and Wald-method for degrees of freedom glm(vs ~ poly(mpg, 2) + cyl, data = mtcars, family = binomial()) |>   parameters(exponentiate = TRUE, ci_method = \"wald\") #> Parameter        | Odds Ratio |       SE |           95% CI |     z |     p #> --------------------------------------------------------------------------- #> (Intercept)      |   7.38e+05 | 5.31e+06 | [0.55, 9.87e+11] |  1.88 | 0.060 #> mpg [1st degree] |   1.31e-03 |     0.01 | [0.00, 59497.56] | -0.74 | 0.461 #> mpg [2nd degree] |       3.20 |    11.49 | [0.00,  3637.30] |  0.32 | 0.746 #> cyl              |       0.10 |     0.12 | [0.01,     1.05] | -1.92 | 0.055 # show Odds Ratios and include model info glm(vs ~ poly(mpg, 2) + cyl, data = mtcars, family = binomial()) |>   parameters(exponentiate = TRUE, include_info = TRUE) #> Parameter        | Odds Ratio |       SE |            95% CI |     z |     p #> ---------------------------------------------------------------------------- #> (Intercept)      |   7.38e+05 | 5.31e+06 | [12.95, 3.26e+14] |  1.88 | 0.060 #> mpg [1st degree] |   1.31e-03 |     0.01 | [ 0.00, 68459.83] | -0.74 | 0.461 #> mpg [2nd degree] |       3.20 |    11.49 | [ 0.00,  5212.21] |  0.32 | 0.746 #> cyl              |       0.10 |     0.12 | [ 0.00,     0.60] | -1.92 | 0.055 #>  #> Model: vs ~ poly(mpg, 2) + cyl (32 Observations) #> Sigma: 1.000 (df = 28) #> RMSE : 0.283 #> Tjur's R2: 0.670"},{"path":"https://easystats.github.io/parameters/articles/model_parameters.html","id":"mixed-models","dir":"Articles","previous_headings":"Regressions (GLMs, Mixed Models, GAMs, …)","what":"Mixed Models","title":"Summary of Model Parameters","text":"","code":"library(lme4)  lmer(Sepal.Width ~ Petal.Length + (1 | Species), data = iris) |>   parameters() #> # Fixed Effects #>  #> Parameter    | Coefficient |   SE |       95% CI | t(146) |      p #> ------------------------------------------------------------------ #> (Intercept)  |        2.00 | 0.56 | [0.89, 3.11] |   3.56 | < .001 #> Petal Length |        0.28 | 0.06 | [0.16, 0.40] |   4.75 | < .001 #>  #> # Random Effects #>  #> Parameter               | Coefficient |   SE |       95% CI #> ----------------------------------------------------------- #> SD (Intercept: Species) |        0.89 | 0.46 | [0.33, 2.43] #> SD (Residual)           |        0.32 | 0.02 | [0.28, 0.35]"},{"path":"https://easystats.github.io/parameters/articles/model_parameters.html","id":"mixed-models-without-random-effects-variances","dir":"Articles","previous_headings":"Regressions (GLMs, Mixed Models, GAMs, …)","what":"Mixed Models, without Random Effects Variances","title":"Summary of Model Parameters","text":"","code":"lmer(Sepal.Width ~ Petal.Length + (1 | Species), data = iris) |>   parameters(effects = \"fixed\") #> # Fixed Effects #>  #> Parameter    | Coefficient |   SE |       95% CI | t(146) |      p #> ------------------------------------------------------------------ #> (Intercept)  |        2.00 | 0.56 | [0.89, 3.11] |   3.56 | < .001 #> Petal Length |        0.28 | 0.06 | [0.16, 0.40] |   4.75 | < .001"},{"path":"https://easystats.github.io/parameters/articles/model_parameters.html","id":"mixed-model-with-zero-inflation-model","dir":"Articles","previous_headings":"Regressions (GLMs, Mixed Models, GAMs, …)","what":"Mixed Model with Zero-Inflation Model","title":"Summary of Model Parameters","text":"","code":"library(GLMMadaptive) library(glmmTMB) data(\"Salamanders\") model <- mixed_model(   count ~ spp + mined,   random = ~ 1 | site,   zi_fixed = ~ spp + mined,   family = zi.negative.binomial(),   data = Salamanders ) parameters(model) #> # Fixed Effects (Count Model) #>  #> Parameter   | Log-Mean |   SE |        95% CI |     z |      p #> -------------------------------------------------------------- #> (Intercept) |    -0.63 | 0.40 | [-1.42, 0.16] | -1.56 | 0.118  #> spp [PR]    |    -0.99 | 0.70 | [-2.35, 0.38] | -1.41 | 0.157  #> spp [DM]    |     0.17 | 0.24 | [-0.29, 0.63] |  0.72 | 0.469  #> spp [EC-A]  |    -0.39 | 0.35 | [-1.07, 0.29] | -1.13 | 0.258  #> spp [EC-L]  |     0.49 | 0.24 | [ 0.02, 0.96] |  2.03 | 0.043  #> spp [DES-L] |     0.59 | 0.23 | [ 0.14, 1.04] |  2.57 | 0.010  #> spp [DF]    |    -0.11 | 0.24 | [-0.59, 0.37] | -0.46 | 0.642  #> mined [no]  |     1.45 | 0.37 | [ 0.73, 2.17] |  3.95 | < .001 #>  #> # Fixed Effects (Zero-Inflation Component) #>  #> Parameter   | Log-Odds |   SE |         95% CI |     z |      p #> --------------------------------------------------------------- #> (Intercept) |     0.90 | 0.64 | [-0.35,  2.15] |  1.41 | 0.159  #> spp [PR]    |     1.12 | 1.50 | [-1.82,  4.06] |  0.74 | 0.456  #> spp [DM]    |    -0.95 | 0.82 | [-2.56,  0.65] | -1.17 | 0.244  #> spp [EC-A]  |     1.04 | 0.72 | [-0.38,  2.46] |  1.44 | 0.150  #> spp [EC-L]  |    -0.58 | 0.74 | [-2.03,  0.88] | -0.77 | 0.439  #> spp [DES-L] |    -0.91 | 0.78 | [-2.43,  0.61] | -1.18 | 0.239  #> spp [DF]    |    -2.63 | 2.37 | [-7.27,  2.02] | -1.11 | 0.268  #> mined [no]  |    -2.56 | 0.63 | [-3.80, -1.32] | -4.06 | < .001 #>  #> # Random Effects Variances #>  #> Parameter            | Coefficient #> ---------------------------------- #> SD (Intercept: site) |        0.39 #> SD (Residual)        |        1.62"},{"path":"https://easystats.github.io/parameters/articles/model_parameters.html","id":"mixed-models-with-dispersion-model","dir":"Articles","previous_headings":"Regressions (GLMs, Mixed Models, GAMs, …)","what":"Mixed Models with Dispersion Model","title":"Summary of Model Parameters","text":"","code":"library(glmmTMB)  sim1 <- function(nfac = 40, nt = 100, facsd = 0.1, tsd = 0.15, mu = 0, residsd = 1) {   dat <- expand.grid(fac = factor(letters[1:nfac]), t = 1:nt)   n <- nrow(dat)   dat$REfac <- rnorm(nfac, sd = facsd)[dat$fac]   dat$REt <- rnorm(nt, sd = tsd)[dat$t]   dat$x <- rnorm(n, mean = mu, sd = residsd) + dat$REfac + dat$REt   dat }  set.seed(101) d1 <- sim1(mu = 100, residsd = 10) d2 <- sim1(mu = 200, residsd = 5) d1$sd <- \"ten\" d2$sd <- \"five\" dat <- rbind(d1, d2) model <- glmmTMB(x ~ sd + (1 | t), dispformula = ~sd, data = dat)  parameters(model) #> # Fixed Effects #>  #> Parameter   | Coefficient |   SE |            95% CI |       z |      p #> ----------------------------------------------------------------------- #> (Intercept) |      200.03 | 0.10 | [ 199.84, 200.22] | 2056.35 | < .001 #> sd [ten]    |      -99.71 | 0.22 | [-100.14, -99.29] | -458.39 | < .001 #>  #> # Dispersion #>  #> Parameter   | Coefficient |   SE |       95% CI |      z |      p #> ----------------------------------------------------------------- #> (Intercept) |        1.60 | 0.01 | [1.57, 1.63] | 115.48 | < .001 #> sd [ten]    |        0.69 | 0.02 | [0.65, 0.73] |  35.35 | < .001 #>  #> # Random Effects Variances #>  #> Parameter         | Coefficient #> ------------------------------- #> SD (Intercept: t) |    4.61e-04 #> SD (Residual)     |"},{"path":"https://easystats.github.io/parameters/articles/model_parameters.html","id":"bayesian-models","dir":"Articles","previous_headings":"Regressions (GLMs, Mixed Models, GAMs, …)","what":"Bayesian Models","title":"Summary of Model Parameters","text":"model_parameters() also works Bayesian models rstanarm package: Additionally, also works models brms package. complex models, specific model components can printed using arguments effects component arguments. include information random effect parameters (group levels), set group_level = TRUE:","code":"library(rstanarm)  # if you are unfamiliar with the `refresh` argument here, it just avoids # printing few messages to the console stan_glm(mpg ~ wt * cyl, data = mtcars, refresh = 0) |>   parameters() #> Parameter   | Median |          95% CI |     pd |  Rhat |     ESS |                   Prior #> ------------------------------------------------------------------------------------------- #> (Intercept) |  52.86 | [ 40.98, 63.96] |   100% | 1.003 | 1048.00 | Normal (20.09 +- 15.07) #> wt          |  -8.09 | [-12.44, -3.72] | 99.88% | 1.002 | 1256.00 |  Normal (0.00 +- 15.40) #> cyl         |  -3.58 | [ -5.47, -1.63] | 99.98% | 1.002 | 1120.00 |   Normal (0.00 +- 8.44) #> wt:cyl      |   0.73 | [  0.11,  1.33] | 98.58% | 1.003 | 1068.00 |   Normal (0.00 +- 1.36) library(brms) data(fish) set.seed(123)  # fitting a model using `brms` model <- suppressWarnings(brm(   bf(     count ~ persons + child + camper + (1 | persons),     zi ~ child + camper + (1 | persons)   ),   data = fish,   family = zero_inflated_poisson(),   refresh = 0 ))  parameters(model, component = \"conditional\", verbose = FALSE) #> # Fixed Effects #>  #> Parameter   | Median |         95% CI |     pd |  Rhat |     ESS #> ---------------------------------------------------------------- #> (Intercept) |  -0.87 | [-1.47, -0.29] | 99.50% | 1.013 |  319.00 #> persons     |   0.84 | [ 0.65,  1.08] |   100% | 1.022 |  166.00 #> child       |  -1.15 | [-1.34, -0.97] |   100% | 1.001 | 2287.00 #> camper1     |   0.73 | [ 0.56,  0.92] |   100% | 1.006 |  774.00  parameters(model, effects = \"all\", component = \"all\", verbose = FALSE) #> # Fixed Effects (Count Model) #>  #> Parameter   | Median |         95% CI |     pd |  Rhat |     ESS #> ---------------------------------------------------------------- #> (Intercept) |  -0.87 | [-1.47, -0.29] | 99.50% | 1.013 |  319.00 #> persons     |   0.84 | [ 0.65,  1.08] |   100% | 1.022 |  166.00 #> child       |  -1.15 | [-1.34, -0.97] |   100% | 1.001 | 2287.00 #> camper1     |   0.73 | [ 0.56,  0.92] |   100% | 1.006 |  774.00 #>  #> # Fixed Effects (Zero-Inflation Component) #>  #> Parameter   | Median |         95% CI |     pd |  Rhat |     ESS #> ---------------------------------------------------------------- #> (Intercept) |  -0.65 | [-2.17,  0.73] | 84.92% | 1.003 | 1012.00 #> child       |   1.88 | [ 1.23,  2.51] |   100% | 1.003 | 1680.00 #> camper1     |  -0.84 | [-1.52, -0.12] | 99.05% | 1.008 |  900.00 #>  #> # Random Effects Variances #>  #> Parameter               | Median |       95% CI |   pd |  Rhat |   ESS #> ---------------------------------------------------------------------- #> SD (Intercept: persons) |   0.11 | [0.00, 1.12] | 100% | 1.056 | 56.00 #>  #> # Random Effects (Zero-Inflation Component) #>  #> Parameter               | Median |       95% CI |   pd |  Rhat |     ESS #> ------------------------------------------------------------------------ #> SD (Intercept: persons) |   1.28 | [0.52, 3.43] | 100% | 1.005 | 1039.00 parameters(   model,   effects = \"all\",   component = \"conditional\",   group_level = TRUE,   verbose = FALSE ) #> # Fixed Effects #>  #> Parameter   | Median |         95% CI |     pd |  Rhat |     ESS #> ---------------------------------------------------------------- #> (Intercept) |  -0.87 | [-1.47, -0.29] | 99.50% | 1.013 |  319.00 #> persons     |   0.84 | [ 0.65,  1.08] |   100% | 1.022 |  166.00 #> child       |  -1.15 | [-1.34, -0.97] |   100% | 1.001 | 2287.00 #> camper1     |   0.73 | [ 0.56,  0.92] |   100% | 1.006 |  774.00 #>  #> # Random Effects: persons #>  #> Parameter   |    Median |        95% CI |     pd |  Rhat |    ESS #> ----------------------------------------------------------------- #> persons.1   | -5.37e-03 | [-0.41, 0.30] | 55.27% | 1.010 | 596.00 #> persons.2   |      0.02 | [-0.19, 0.37] | 64.65% | 1.005 | 595.00 #> persons.3   |     -0.01 | [-0.33, 0.22] | 60.12% | 1.021 | 209.00 #> persons.4   |  2.47e-03 | [-0.44, 0.34] | 53.17% | 1.039 |  95.00 #> (Intercept) |      0.11 | [ 0.00, 1.12] |   100% | 1.056 |  56.00"},{"path":"https://easystats.github.io/parameters/articles/model_parameters.html","id":"structural-models-pca-efa-cfa-sem","dir":"Articles","previous_headings":"","what":"Structural Models (PCA, EFA, CFA, SEM…)","title":"Summary of Model Parameters","text":"parameters package extends support structural models.","code":""},{"path":"https://easystats.github.io/parameters/articles/model_parameters.html","id":"principal-component-analysis-pca-and-exploratory-factor-analysis-efa","dir":"Articles","previous_headings":"Structural Models (PCA, EFA, CFA, SEM…)","what":"Principal Component Analysis (PCA) and Exploratory Factor Analysis (EFA)","title":"Summary of Model Parameters","text":"avoid displaying graph carrying factor analysis:","code":"psych::pca(mtcars, nfactors = 3) |>   parameters() #> # Rotated loadings from Principal Component Analysis (varimax-rotation) #>  #> Variable |   RC2 |   RC3 |   RC1 | Complexity | Uniqueness #> ---------------------------------------------------------- #> mpg      |  0.66 | -0.41 | -0.54 |       2.63 |       0.10 #> cyl      | -0.62 |  0.67 |  0.34 |       2.49 |       0.05 #> disp     | -0.72 |  0.52 |  0.35 |       2.33 |       0.10 #> hp       | -0.30 |  0.64 |  0.63 |       2.40 |       0.10 #> drat     |  0.85 | -0.26 | -0.05 |       1.19 |       0.21 #> wt       | -0.78 |  0.21 |  0.51 |       1.90 |       0.08 #> qsec     | -0.18 | -0.91 | -0.28 |       1.28 |       0.06 #> vs       |  0.28 | -0.86 | -0.23 |       1.36 |       0.12 #> am       |  0.92 |  0.14 | -0.11 |       1.08 |       0.12 #> gear     |  0.91 | -0.02 |  0.26 |       1.16 |       0.10 #> carb     |  0.11 |  0.44 |  0.85 |       1.53 |       0.07 #>  #> The 3 principal components (varimax rotation) accounted for 89.87% of the total variance of the original data (RC2 = 41.43%, RC3 = 29.06%, RC1 = 19.39%). FactoMineR::FAMD(iris, ncp = 3, graph = FALSE) |>   parameters() #> # Loadings from Factor Analysis (no rotation) #>  #> Variable     | Dim.1 |    Dim.2 |    Dim.3 | Complexity #> ------------------------------------------------------- #> Sepal.Length |  0.75 |     0.07 |     0.10 |       1.05 #> Sepal.Width  |  0.23 |     0.51 |     0.23 |       1.86 #> Petal.Length |  0.98 | 1.32e-03 | 1.99e-03 |       1.00 #> Petal.Width  |  0.94 |     0.01 | 2.82e-05 |       1.00 #> Species      |  0.96 |     0.75 |     0.26 |       2.05 #>  #> The 3 latent factors accounted for 96.73% of the total variance of the original data (Dim.1 = 64.50%, Dim.2 = 22.37%, Dim.3 = 9.86%)."},{"path":[]},{"path":"https://easystats.github.io/parameters/articles/model_parameters.html","id":"frequentist-1","dir":"Articles","previous_headings":"Structural Models (PCA, EFA, CFA, SEM…) > Confirmatory Factor Analysis (CFA) and Structural Equation Models (SEM)","what":"Frequentist","title":"Summary of Model Parameters","text":"","code":"library(lavaan)  model <- lavaan::cfa(\" visual  =~ x1 + x2 + x3                        textual =~ x4 + x5 + x6                        speed   =~ x7 + x8 + x9 \",   data = HolzingerSwineford1939 )  model_parameters(model) #> # Loading #>  #> Link          | Coefficient |   SE |       95% CI |     z |      p #> ------------------------------------------------------------------ #> visual =~ x1  |        1.00 | 0.00 | [1.00, 1.00] |       | < .001 #> visual =~ x2  |        0.55 | 0.10 | [0.36, 0.75] |  5.55 | < .001 #> visual =~ x3  |        0.73 | 0.11 | [0.52, 0.94] |  6.68 | < .001 #> textual =~ x4 |        1.00 | 0.00 | [1.00, 1.00] |       | < .001 #> textual =~ x5 |        1.11 | 0.07 | [0.98, 1.24] | 17.01 | < .001 #> textual =~ x6 |        0.93 | 0.06 | [0.82, 1.03] | 16.70 | < .001 #> speed =~ x7   |        1.00 | 0.00 | [1.00, 1.00] |       | < .001 #> speed =~ x8   |        1.18 | 0.16 | [0.86, 1.50] |  7.15 | < .001 #> speed =~ x9   |        1.08 | 0.15 | [0.79, 1.38] |  7.15 | < .001 #>  #> # Correlation #>  #> Link              | Coefficient |   SE |       95% CI |    z |      p #> --------------------------------------------------------------------- #> visual ~~ textual |        0.41 | 0.07 | [0.26, 0.55] | 5.55 | < .001 #> visual ~~ speed   |        0.26 | 0.06 | [0.15, 0.37] | 4.66 | < .001 #> textual ~~ speed  |        0.17 | 0.05 | [0.08, 0.27] | 3.52 | < .001"},{"path":"https://easystats.github.io/parameters/articles/model_parameters.html","id":"bayesian-1","dir":"Articles","previous_headings":"Structural Models (PCA, EFA, CFA, SEM…) > Confirmatory Factor Analysis (CFA) and Structural Equation Models (SEM)","what":"Bayesian","title":"Summary of Model Parameters","text":"blavaan done.","code":""},{"path":"https://easystats.github.io/parameters/articles/model_parameters.html","id":"meta-analysis","dir":"Articles","previous_headings":"","what":"Meta-Analysis","title":"Summary of Model Parameters","text":"parameters() also works rma-objects metafor package.","code":"library(metafor)  mydat <<- data.frame(   effectsize = c(-0.393, 0.675, 0.282, -1.398),   standarderror = c(0.317, 0.317, 0.13, 0.36) )  rma(yi = effectsize, sei = standarderror, method = \"REML\", data = mydat) |>   model_parameters() #> Meta-analysis using 'metafor' #>  #> Parameter | Coefficient |   SE |         95% CI |     z |      p | Weight #> ------------------------------------------------------------------------- #> Study 1   |       -0.39 | 0.32 | [-1.01,  0.23] | -1.24 | 0.215  |   9.95 #> Study 2   |        0.68 | 0.32 | [ 0.05,  1.30] |  2.13 | 0.033  |   9.95 #> Study 3   |        0.28 | 0.13 | [ 0.03,  0.54] |  2.17 | 0.030  |  59.17 #> Study 4   |       -1.40 | 0.36 | [-2.10, -0.69] | -3.88 | < .001 |   7.72 #> Overall   |       -0.18 | 0.44 | [-1.05,  0.68] | -0.42 | 0.676  |"},{"path":"https://easystats.github.io/parameters/articles/model_parameters.html","id":"plotting-model-parameters","dir":"Articles","previous_headings":"","what":"Plotting Model Parameters","title":"Summary of Model Parameters","text":"plot()-method implemented see-package. Several examples shown vignette.","code":""},{"path":"https://easystats.github.io/parameters/articles/model_parameters_formatting.html","id":"an-example-model","dir":"Articles","previous_headings":"","what":"An Example Model","title":"Formatting Model Parameters","text":"start model make much sense, useful demonstrating formatting functions.","code":"data(iris) iris$Petlen <- cut(iris$Petal.Length, breaks = c(0, 3, 7)) model <- lm(Sepal.Width ~ poly(Sepal.Length, 2) + Species + Petlen, data = iris)  summary(model) #>  #> Call: #> lm(formula = Sepal.Width ~ poly(Sepal.Length, 2) + Species +  #>     Petlen, data = iris) #>  #> Residuals: #>     Min      1Q  Median      3Q     Max  #> -0.7742 -0.1490 -0.0056  0.1666  0.6973  #>  #> Coefficients: #>                        Estimate Std. Error t value Pr(>|t|)     #> (Intercept)              3.8127     0.0582   65.50  < 2e-16 *** #> poly(Sepal.Length, 2)1   4.0602     0.4668    8.70    7e-15 *** #> poly(Sepal.Length, 2)2  -1.3024     0.3149   -4.14    6e-05 *** #> Speciesversicolor       -1.0056     0.2781   -3.62  0.00041 *** #> Speciesvirginica        -0.9913     0.2851   -3.48  0.00067 *** #> Petlen(3,7]             -0.1360     0.2818   -0.48  0.63019     #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: 0.28 on 144 degrees of freedom #> Multiple R-squared:  0.615,  Adjusted R-squared:  0.602  #> F-statistic:   46 on 5 and 144 DF,  p-value: <2e-16"},{"path":"https://easystats.github.io/parameters/articles/model_parameters_formatting.html","id":"formatting-parameter-names","dir":"Articles","previous_headings":"","what":"Formatting Parameter Names","title":"Formatting Model Parameters","text":"can see, cases, standard R output looks bit cryptic, although necessary important information included summary. formatting coefficients polynomial transformation difficult read, factors grouped cut() always require short time thinking find bound (case, Petlen(3,7], 3 7) included range, names factor levels directly concatenated name factor variable. Thus, first step format parameter names, can done format_parameters() parameters package: format_parameters() returns (named) character vector original coefficients names character element, formatted names coefficients values character vector. Let’s look results : Now variable names factor levels, also polynomial terms even factors grouped cut() much readable. Factor levels separated variable name, inside brackets. coefficients different polynomial degrees. exact range cut()-factors also clearer now.","code":"library(parameters) format_parameters(model) #>                 (Intercept)      poly(Sepal.Length, 2)1  #>               \"(Intercept)\" \"Sepal Length [1st degree]\"  #>      poly(Sepal.Length, 2)2           Speciesversicolor  #> \"Sepal Length [2nd degree]\"      \"Species [versicolor]\"  #>            Speciesvirginica                 Petlen(3,7]  #>       \"Species [virginica]\"             \"Petlen [>3-7]\" cat(format_parameters(model), sep = \"\\n\") #> (Intercept) #> Sepal Length [1st degree] #> Sepal Length [2nd degree] #> Species [versicolor] #> Species [virginica] #> Petlen [>3-7]"},{"path":"https://easystats.github.io/parameters/articles/model_parameters_formatting.html","id":"standardizing-column-names-of-parameter-tables","dir":"Articles","previous_headings":"","what":"Standardizing Column Names of Parameter Tables","title":"Formatting Model Parameters","text":"seen , summary() returns columns named Estimate, t value Pr(>|t|). Estimate specific certain models, t value . logistic regression models, get z value. packages alter names, get just t t-value etc. model_parameters() also uses context-specific column names, applicable: Bayesian models, Coefficient usually named Median etc. makes sense user perspective, instantly know type statistic coefficient , becomes difficult need generic naming scheme access model parameters input model unknown. typical approach broom package, get “standardized” column names: deal situations, insight package provides standardize_names() function, exactly : standardizing column names input. following example, see statistic-column longer named t, statistic. df_error df_residuals renamed df. Furthermore, can request “broom”-style column names:","code":"colnames(model_parameters(model)) #> [1] \"Parameter\"   \"Coefficient\" \"SE\"          \"CI\"          \"CI_low\"      #> [6] \"CI_high\"     \"t\"           \"df_error\"    \"p\" library(broom) colnames(tidy(model)) #> [1] \"term\"      \"estimate\"  \"std.error\" \"statistic\" \"p.value\" library(insight) model |>   model_parameters() |>   standardize_names() |>   colnames() #> [1] \"Parameter\"   \"Coefficient\" \"SE\"          \"CI\"          \"CI_low\"      #> [6] \"CI_high\"     \"Statistic\"   \"df\"          \"p\" model |>   model_parameters() |>   standardize_names(style = \"broom\") |>   colnames() #> [1] \"term\"       \"estimate\"   \"std.error\"  \"conf.level\" \"conf.low\"   #> [6] \"conf.high\"  \"statistic\"  \"df.error\"   \"p.value\""},{"path":"https://easystats.github.io/parameters/articles/model_parameters_formatting.html","id":"formatting-column-names-and-columns","dir":"Articles","previous_headings":"","what":"Formatting Column Names and Columns","title":"Formatting Model Parameters","text":"Beside formatting parameter names (coefficient names) using format_parameters(), can even make output readable. Let’s look example includes confidence intervals. can get similar tabular output using broom. improvements according readability collapsing formatting confidence intervals, maybe p-values. require effort, instance, format values lower upper confidence intervals collapsing one column. However, format_table() function convenient function work . format_table() requires data frame model parameters input, however, requirements make format_table() work. particular, column names must follow certain pattern recognized, pattern may either naming convention broom easystats packages. parameters table also includes degrees freedom, degrees freedom parameter, information included statistic-column. usually default model_parameters():","code":"cbind(summary(model)$coefficients, confint(model)) #>                        Estimate Std. Error t value Pr(>|t|) 2.5 % 97.5 % #> (Intercept)                3.81      0.058   65.50 4.6e-109  3.70   3.93 #> poly(Sepal.Length, 2)1     4.06      0.467    8.70  7.0e-15  3.14   4.98 #> poly(Sepal.Length, 2)2    -1.30      0.315   -4.14  6.0e-05 -1.92  -0.68 #> Speciesversicolor         -1.01      0.278   -3.62  4.1e-04 -1.56  -0.46 #> Speciesvirginica          -0.99      0.285   -3.48  6.7e-04 -1.55  -0.43 #> Petlen(3,7]               -0.14      0.282   -0.48  6.3e-01 -0.69   0.42 tidy(model, conf.int = TRUE) #> # A tibble: 6 × 7 #>   term                 estimate std.error statistic   p.value conf.low conf.high #>   <chr>                   <dbl>     <dbl>     <dbl>     <dbl>    <dbl>     <dbl> #> 1 (Intercept)             3.81     0.0582    65.5   4.61e-109    3.70      3.93  #> 2 poly(Sepal.Length, …    4.06     0.467      8.70  7.00e- 15    3.14      4.98  #> 3 poly(Sepal.Length, …   -1.30     0.315     -4.14  5.98e-  5   -1.92     -0.680 #> 4 Speciesversicolor      -1.01     0.278     -3.62  4.12e-  4   -1.56     -0.456 #> 5 Speciesvirginica       -0.991    0.285     -3.48  6.72e-  4   -1.55     -0.428 #> 6 Petlen(3,7]            -0.136    0.282     -0.482 6.30e-  1   -0.693     0.421 model |>   tidy(conf.int = TRUE) |>   format_table() #>                     term estimate std.error statistic p.value       conf.int #> 1            (Intercept)     3.81      0.06     65.50  < .001 [ 3.70,  3.93] #> 2 poly(Sepal.Length, 2)1     4.06      0.47      8.70  < .001 [ 3.14,  4.98] #> 3 poly(Sepal.Length, 2)2    -1.30      0.31     -4.14  < .001 [-1.92, -0.68] #> 4      Speciesversicolor    -1.01      0.28     -3.62  < .001 [-1.56, -0.46] #> 5       Speciesvirginica    -0.99      0.29     -3.48  < .001 [-1.55, -0.43] #> 6            Petlen(3,7]    -0.14      0.28     -0.48  0.630  [-0.69,  0.42] model |>   model_parameters() |>   format_table() #>                   Parameter Coefficient   SE         95% CI t(144)      p #> 1               (Intercept)        3.81 0.06 [ 3.70,  3.93]  65.50 < .001 #> 2 Sepal Length [1st degree]        4.06 0.47 [ 3.14,  4.98]   8.70 < .001 #> 3 Sepal Length [2nd degree]       -1.30 0.31 [-1.92, -0.68]  -4.14 < .001 #> 4      Species [versicolor]       -1.01 0.28 [-1.56, -0.46]  -3.62 < .001 #> 5       Species [virginica]       -0.99 0.29 [-1.55, -0.43]  -3.48 < .001 #> 6             Petlen [>3-7]       -0.14 0.28 [-0.69,  0.42]  -0.48 0.630"},{"path":"https://easystats.github.io/parameters/articles/model_parameters_formatting.html","id":"exporting-the-parameters-table","dir":"Articles","previous_headings":"","what":"Exporting the Parameters Table","title":"Formatting Model Parameters","text":"Finally, export_table() insight formats data frame returns character vector can printed console inside rmarkdown documents. data frame looks “table-like”. Putting together allows us create nice tabular outputs parameters tables. can done using broom: , simpler way much options (like standardizing, robust standard errors, bootstrapping, …) using model_parameters(), print()-method steps automatically:","code":"data(mtcars) export_table(mtcars[1:8, 1:5]) #>   mpg | cyl |   disp |  hp | drat #> --------------------------------- #> 21.00 |   6 | 160.00 | 110 | 3.90 #> 21.00 |   6 | 160.00 | 110 | 3.90 #> 22.80 |   4 | 108.00 |  93 | 3.85 #> 21.40 |   6 | 258.00 | 110 | 3.08 #> 18.70 |   8 | 360.00 | 175 | 3.15 #> 18.10 |   6 | 225.00 | 105 | 2.76 #> 14.30 |   8 | 360.00 | 245 | 3.21 #> 24.40 |   4 | 146.70 |  62 | 3.69 model |>   tidy(conf.int = TRUE) |>   format_table() |>   export_table() #> term                   | estimate | std.error | statistic | p.value |       conf.int #> ------------------------------------------------------------------------------------ #> (Intercept)            |     3.81 |      0.06 |     65.50 |  < .001 | [ 3.70,  3.93] #> poly(Sepal.Length, 2)1 |     4.06 |      0.47 |      8.70 |  < .001 | [ 3.14,  4.98] #> poly(Sepal.Length, 2)2 |    -1.30 |      0.31 |     -4.14 |  < .001 | [-1.92, -0.68] #> Speciesversicolor      |    -1.01 |      0.28 |     -3.62 |  < .001 | [-1.56, -0.46] #> Speciesvirginica       |    -0.99 |      0.29 |     -3.48 |  < .001 | [-1.55, -0.43] #> Petlen(3,7]            |    -0.14 |      0.28 |     -0.48 |  0.630  | [-0.69,  0.42] model_parameters(model) #> Parameter                 | Coefficient |   SE |         95% CI | t(144) |      p #> --------------------------------------------------------------------------------- #> (Intercept)               |        3.81 | 0.06 | [ 3.70,  3.93] |  65.50 | < .001 #> Sepal Length [1st degree] |        4.06 | 0.47 | [ 3.14,  4.98] |   8.70 | < .001 #> Sepal Length [2nd degree] |       -1.30 | 0.31 | [-1.92, -0.68] |  -4.14 | < .001 #> Species [versicolor]      |       -1.01 | 0.28 | [-1.56, -0.46] |  -3.62 | < .001 #> Species [virginica]       |       -0.99 | 0.29 | [-1.55, -0.43] |  -3.48 | < .001 #> Petlen [>3-7]             |       -0.14 | 0.28 | [-0.69,  0.42] |  -0.48 | 0.630"},{"path":"https://easystats.github.io/parameters/articles/model_parameters_formatting.html","id":"formatting-the-parameters-table-in-markdown","dir":"Articles","previous_headings":"","what":"Formatting the Parameters Table in Markdown","title":"Formatting Model Parameters","text":"export_table() provides options generate tables markdown-format. allows easily render nice-looking tables inside markdown-documents. First , use format = \"markdown\" activate markdown-formatting. caption can used add table caption. Furthermore, align allows choose alignment table columns, specify alignment column individually. following table six columns. Using align = \"lcccrr\" left-align first column, center columns two four, right-align last two columns. Table print_md() convenient wrapper around format_table() export_table(format = \"markdown\"), allows directly format output functions like model_parameters(), simulate_parameters() parameters functions markdown-format. tables also nicely formatted knitting markdown-documents Word PDF. print_md() applies default settings proven work well markdown, PDF Word tables. similar option print_html(), convenient wrapper format_table() export_table(format = \"html\"). Using HTML markdown advantage properly rendered exporting PDF. print_md() print_html() considered main functions users want generate nicely rendered tables inside markdown-documents. wrapper around display(), either calls print_md() print_html().","code":"model |>   tidy(conf.int = TRUE) |>   # parenthesis look better in markdown-tables, so we use \"brackets\" here   format_table(ci_brackets = c(\"(\", \")\")) |>   export_table(format = \"markdown\", caption = \"My Table\", align = \"lcccrr\") model_parameters(model) |> print_md() model_parameters(model) |> print_html() model_parameters(model) |> display(format = \"html\")"},{"path":"https://easystats.github.io/parameters/articles/model_parameters_mice.html","id":"model-parameters-from-mira-objects","dir":"Articles","previous_headings":"","what":"Model Parameters from mira objects","title":"Model Parameters for Multiply Imputed Repeated Analyses","text":"model_parameters() can used combination mice package deal missing data, particular summaries regression models used multiple imputed datasets. computes pooled summaries multiple imputed repeated regression analyses, .e. objects class mira. Thus, model_parameters() mira-objects comparable pool()-function mice, focuses final summary parameters include diagnostic statistic per estimate. packages work .mids() package mice. Thus, modeling packages, ’s possible perform multiply imputed repeated analyses, .e. work imputed data models. give example GLMMadaptive package . First, generate dataset missing values. take data cbpp lme4 randomly assign missing values one predictors. impute data, using mice() package mice. Using compute multiple regression analyses imputed dataset fails. However, can use workaround using pool_parameters(), works list model objects. whenever model-object yet supported mice::(), can instead fit multiple models imputed datasets pool parameters pool_parameters(): steps : Calculate regression models imputed dataset manually (either using complete() package mice get imputed datasets, accessing datasets directly mids object) Save model objects list. Pass list pool_parameters(). comparison show results mice:pool() pool_parameters() identical, take example also works mice package:","code":"library(mice) library(parameters)  data(\"nhanes2\") imp <- mice(nhanes2, printFlag = FALSE) fit <- with(data = imp, exp = lm(bmi ~ age + hyp + chl))  model_parameters(fit) #> # Fixed Effects #>  #> Parameter   | Coefficient |   SE |          95% CI | Statistic |    df |      p #> ------------------------------------------------------------------------------- #> (Intercept) |       18.93 | 2.89 | [ 12.82, 25.03] |      6.54 | 16.91 | < .001 #> age40-59    |       -6.16 | 1.65 | [ -9.74, -2.58] |     -3.73 | 12.59 | 0.003  #> age60-99    |       -7.87 | 2.17 | [-12.99, -2.76] |     -3.63 |  7.05 | 0.008  #> hypyes      |        2.23 | 1.68 | [ -1.40,  5.86] |      1.33 | 12.84 | 0.208  #> chl         |        0.06 | 0.02 | [  0.02,  0.09] |      3.51 | 17.27 | 0.003 library(lme4) library(GLMMadaptive)  data(cbpp) cbpp$period[sample(seq_len(nrow(cbpp)), size = 10)] <- NA  imputed_data <- mice(cbpp, printFlag = FALSE) fit <- with(data = imputed_data, expr = GLMMadaptive::mixed_model(   cbind(incidence, size - incidence) ~ period,   random = ~ 1 | herd,   family = binomial )) # > Error in as.data.frame(data) : # >   argument \"data\" is missing, with no default models <- lapply(1:imputed_data$m, function(i) {   mixed_model(     cbind(incidence, size - incidence) ~ period,     random = ~ 1 | herd,     data = complete(imputed_data, action = i),     family = binomial   ) }) pool_parameters(models) #> # Fixed Effects #>  #> Parameter   | Log-Odds |   SE |         95% CI | Statistic |      p #> ------------------------------------------------------------------- #> (Intercept) |    -1.45 | 0.24 | [-1.93, -0.97] |     -5.93 | < .001 #> period [2]  |    -0.88 | 0.34 | [-1.55, -0.20] |     -2.55 | 0.011  #> period [3]  |    -1.41 | 0.38 | [-2.16, -0.66] |     -3.70 | < .001 #> period [4]  |    -1.65 | 0.62 | [-2.87, -0.43] |     -2.66 | 0.008 library(mice) library(parameters)  data(\"nhanes2\") imp <- mice(nhanes2, printFlag = FALSE)  # approach when model is supported by \"mice\" fit <- with(data = imp, exp = lm(bmi ~ age + hyp + chl)) summary(pool(fit)) #>          term estimate std.error statistic df p.value #> 1 (Intercept)   19.667     3.373       5.8 11 0.00013 #> 2    age40-59   -5.705     1.711      -3.3 14 0.00475 #> 3    age60-99   -7.007     1.783      -3.9 18 0.00099 #> 4      hypyes    2.713     1.829       1.5 11 0.16544 #> 5         chl    0.051     0.017       2.9 12 0.01290 # approach when model is *not* supported by \"mice\" models <- lapply(1:5, function(i) {   lm(bmi ~ age + hyp + chl, data = complete(imp, action = i)) }) pool_parameters(models) #> # Fixed Effects #>  #> Parameter   | Coefficient |   SE |          95% CI | Statistic |    df |      p #> ------------------------------------------------------------------------------- #> (Intercept) |       19.67 | 3.37 | [ 12.21, 27.13] |      5.83 | 10.62 | < .001 #> age [40-59] |       -5.71 | 1.71 | [ -9.37, -2.04] |     -3.33 | 14.41 | 0.005  #> age [60-99] |       -7.01 | 1.78 | [-10.76, -3.26] |     -3.93 | 17.88 | < .001 #> hyp [yes]   |        2.71 | 1.83 | [ -1.30,  6.73] |      1.48 | 11.24 | 0.165  #> chl         |        0.05 | 0.02 | [  0.01,  0.09] |      2.90 | 12.34 | 0.013"},{"path":"https://easystats.github.io/parameters/articles/model_parameters_mice.html","id":"model-parameters-from-mipo-objects","dir":"Articles","previous_headings":"","what":"Model Parameters from mipo objects","title":"Model Parameters for Multiply Imputed Repeated Analyses","text":"also possible compute summaries pooled objects class mipo.","code":"data(\"nhanes2\") imp <- mice(nhanes2, printFlag = FALSE) fit <- with(data = imp, exp = lm(bmi ~ age + hyp + chl)) pooled <- pool(fit)  model_parameters(pooled) #> # Fixed Effects #>  #> Parameter   | Coefficient |   SE |          95% CI |     t |    df |      p #> --------------------------------------------------------------------------- #> (Intercept) |       17.10 | 3.87 | [  8.63, 25.58] |  4.42 | 11.51 | < .001 #> age [40-59] |       -5.03 | 2.55 | [-11.44,  1.38] | -1.97 |  5.42 | 0.101  #> age [60-99] |       -7.39 | 2.70 | [-13.87, -0.92] | -2.73 |  6.59 | 0.031  #> hyp [yes]   |        1.36 | 2.44 | [ -4.27,  6.99] |  0.56 |  8.03 | 0.593  #> chl         |        0.06 | 0.02 | [  0.01,  0.12] |  2.68 |  8.34 | 0.027"},{"path":"https://easystats.github.io/parameters/articles/model_parameters_print.html","id":"summaries-for-a-single-model","dir":"Articles","previous_headings":"","what":"Summaries for a single model","title":"Printing Model Parameters","text":"following examples model_parameters(), returns tabular output single models, shown.","code":""},{"path":"https://easystats.github.io/parameters/articles/model_parameters_print.html","id":"pretty-parameter-names-formatting","dir":"Articles","previous_headings":"Summaries for a single model","what":"Pretty parameter names formatting","title":"Printing Model Parameters","text":"default, argument pretty_names TRUE, meaning parameter names formatted make “human readable”, .e. factor levels separated variable names, interactions denoted * etc. data labelled, pretty_names = \"labels\" use variable value labels pretty names. data labelled, default pretty names used.","code":"library(parameters) data(iris) model <- lm(Sepal.Length ~ Species * Petal.Length, data = iris) model_parameters(model) #> Parameter                           | Coefficient |   SE |         95% CI #> ------------------------------------------------------------------------- #> (Intercept)                         |        4.21 | 0.41 | [ 3.41,  5.02] #> Species [versicolor]                |       -1.81 | 0.60 | [-2.99, -0.62] #> Species [virginica]                 |       -3.15 | 0.63 | [-4.41, -1.90] #> Petal Length                        |        0.54 | 0.28 | [ 0.00,  1.09] #> Species [versicolor] × Petal Length |        0.29 | 0.30 | [-0.30,  0.87] #> Species [virginica] × Petal Length  |        0.45 | 0.29 | [-0.12,  1.03] #>  #> Parameter                           | t(144) |      p #> ----------------------------------------------------- #> (Intercept)                         |  10.34 | < .001 #> Species [versicolor]                |  -3.02 | 0.003  #> Species [virginica]                 |  -4.97 | < .001 #> Petal Length                        |   1.96 | 0.052  #> Species [versicolor] × Petal Length |   0.97 | 0.334  #> Species [virginica] × Petal Length  |   1.56 | 0.120  mp <- model_parameters(model) print(mp, pretty_names = FALSE) #> Parameter                      | Coefficient |   SE |         95% CI | t(144) |      p #> -------------------------------------------------------------------------------------- #> (Intercept)                    |        4.21 | 0.41 | [ 3.41,  5.02] |  10.34 | < .001 #> Speciesversicolor              |       -1.81 | 0.60 | [-2.99, -0.62] |  -3.02 | 0.003  #> Speciesvirginica               |       -3.15 | 0.63 | [-4.41, -1.90] |  -4.97 | < .001 #> Petal.Length                   |        0.54 | 0.28 | [ 0.00,  1.09] |   1.96 | 0.052  #> Speciesversicolor:Petal.Length |        0.29 | 0.30 | [-0.30,  0.87] |   0.97 | 0.334  #> Speciesvirginica:Petal.Length  |        0.45 | 0.29 | [-0.12,  1.03] |   1.56 | 0.120 data(efc, package = \"datawizard\") model <- lm(neg_c_7 ~ e42dep + c172code, data = efc)  # default printing model_parameters(model) #> Parameter   | Coefficient |   SE |         95% CI | t(80) |     p #> ----------------------------------------------------------------- #> (Intercept) |        8.72 | 3.56 | [ 1.63, 15.80] |  2.45 | 0.017 #> e42dep [2]  |       -1.00 | 3.72 | [-8.41,  6.41] | -0.27 | 0.789 #> e42dep [3]  |        2.68 | 3.16 | [-3.60,  8.96] |  0.85 | 0.398 #> e42dep [4]  |        3.88 | 3.10 | [-2.29, 10.04] |  1.25 | 0.214 #> c172code    |        1.14 | 0.93 | [-0.70,  2.99] |  1.23 | 0.221  # using value and variable labels mp <- model_parameters(model) print(mp, pretty_names = \"labels\") #> Parameter                                 | Coefficient |   SE |         95% CI #> ------------------------------------------------------------------------------- #> (Intercept)                               |        8.72 | 3.56 | [ 1.63, 15.80] #> elder's dependency [slightly dependent]   |       -1.00 | 3.72 | [-8.41,  6.41] #> elder's dependency [moderately dependent] |        2.68 | 3.16 | [-3.60,  8.96] #> elder's dependency [severely dependent]   |        3.88 | 3.10 | [-2.29, 10.04] #> carer's level of education                |        1.14 | 0.93 | [-0.70,  2.99] #>  #> Parameter                                 | t(80) |     p #> --------------------------------------------------------- #> (Intercept)                               |  2.45 | 0.017 #> elder's dependency [slightly dependent]   | -0.27 | 0.789 #> elder's dependency [moderately dependent] |  0.85 | 0.398 #> elder's dependency [severely dependent]   |  1.25 | 0.214 #> carer's level of education                |  1.23 | 0.221"},{"path":"https://easystats.github.io/parameters/articles/model_parameters_print.html","id":"more-compact-output","dir":"Articles","previous_headings":"Summaries for a single model","what":"More compact output","title":"Printing Model Parameters","text":"Using summary, select argument via print() method allows compact table, case information required. summary() return coefficient, confidence intervals p-values. select allows select specific columns . select argument can also used customized output. See examples compare_parameters().","code":"data(iris) model <- lm(Sepal.Length ~ Species * Petal.Length, data = iris)  result <- model_parameters(model)  # Coefficients, CI and p summary(result) #> Parameter                           | Coefficient |         95% CI |      p #> --------------------------------------------------------------------------- #> (Intercept)                         |        4.21 | [ 3.41,  5.02] | < .001 #> Species [versicolor]                |       -1.81 | [-2.99, -0.62] | 0.003  #> Species [virginica]                 |       -3.15 | [-4.41, -1.90] | < .001 #> Petal Length                        |        0.54 | [ 0.00,  1.09] | 0.052  #> Species [versicolor] × Petal Length |        0.29 | [-0.30,  0.87] | 0.334  #> Species [virginica] × Petal Length  |        0.45 | [-0.12,  1.03] | 0.120  #>  #> Model: Sepal.Length ~ Species * Petal.Length (150 Observations) #> Sigma: 0.336 (df = 144)  # Parameter name, SE and p print(result, select = c(\"Parameter\", \"SE\", \"p\")) #> Parameter                           |   SE |      p #> --------------------------------------------------- #> (Intercept)                         | 0.41 | < .001 #> Species [versicolor]                | 0.60 | 0.003  #> Species [virginica]                 | 0.63 | < .001 #> Petal Length                        | 0.28 | 0.052  #> Species [versicolor] × Petal Length | 0.30 | 0.334  #> Species [virginica] × Petal Length  | 0.29 | 0.120"},{"path":"https://easystats.github.io/parameters/articles/model_parameters_print.html","id":"splitting-model-components","dir":"Articles","previous_headings":"Summaries for a single model","what":"Splitting model components","title":"Printing Model Parameters","text":"default, argument split_components TRUE, means models multiple components like fixed random effects, count zero-inflated part etc. split separate tables output. Redundant columns removed. related model component shown table header. However, can also return single table:","code":"library(glmmTMB) data(\"Salamanders\") model <- glmmTMB(count ~ spp + mined + (1 | site),   ziformula = ~ spp + mined,   family = nbinom2(),   data = Salamanders ) model_parameters(model) #> # Fixed Effects (Count Model) #>  #> Parameter   | Log-Mean |   SE |        95% CI |     z |      p #> -------------------------------------------------------------- #> (Intercept) |    -0.61 | 0.41 | [-1.40, 0.18] | -1.51 | 0.132  #> spp [PR]    |    -0.96 | 0.64 | [-2.23, 0.30] | -1.50 | 0.134  #> spp [DM]    |     0.17 | 0.24 | [-0.29, 0.63] |  0.73 | 0.468  #> spp [EC-A]  |    -0.39 | 0.34 | [-1.06, 0.28] | -1.13 | 0.258  #> spp [EC-L]  |     0.49 | 0.24 | [ 0.02, 0.96] |  2.05 | 0.041  #> spp [DES-L] |     0.59 | 0.23 | [ 0.14, 1.04] |  2.59 | 0.010  #> spp [DF]    |    -0.11 | 0.24 | [-0.59, 0.36] | -0.46 | 0.642  #> mined [no]  |     1.43 | 0.37 | [ 0.71, 2.15] |  3.90 | < .001 #>  #> # Fixed Effects (Zero-Inflation Component) #>  #> Parameter   | Log-Odds |   SE |         95% CI |     z |      p #> --------------------------------------------------------------- #> (Intercept) |     0.91 | 0.63 | [-0.32,  2.14] |  1.45 | 0.147  #> spp [PR]    |     1.16 | 1.33 | [-1.45,  3.78] |  0.87 | 0.384  #> spp [DM]    |    -0.94 | 0.80 | [-2.51,  0.63] | -1.17 | 0.241  #> spp [EC-A]  |     1.04 | 0.71 | [-0.36,  2.44] |  1.46 | 0.144  #> spp [EC-L]  |    -0.56 | 0.73 | [-1.99,  0.86] | -0.77 | 0.439  #> spp [DES-L] |    -0.89 | 0.75 | [-2.37,  0.58] | -1.19 | 0.236  #> spp [DF]    |    -2.54 | 2.18 | [-6.82,  1.74] | -1.16 | 0.244  #> mined [no]  |    -2.56 | 0.60 | [-3.75, -1.38] | -4.24 | < .001 #>  #> # Dispersion #>  #> Parameter   | Coefficient |       95% CI #> ---------------------------------------- #> (Intercept) |        1.51 | [0.93, 2.46] #>  #> # Random Effects Variances #>  #> Parameter            | Coefficient |       95% CI #> ------------------------------------------------- #> SD (Intercept: site) |        0.38 | [0.17, 0.87] mp <- model_parameters(model) # We use `table_width` here to print a wider table, # which is not split into multiple tables print(mp, split_component = FALSE, table_width = Inf) #> # Fixed Effects #>  #> Parameter            | Coefficient |   SE |         95% CI |     z |      p | Effects |     Component #> ----------------------------------------------------------------------------------------------------- #> (Intercept)          |       -0.61 | 0.41 | [-1.40,  0.18] | -1.51 | 0.132  |   fixed |   conditional #> spp [PR]             |       -0.96 | 0.64 | [-2.23,  0.30] | -1.50 | 0.134  |   fixed |   conditional #> spp [DM]             |        0.17 | 0.24 | [-0.29,  0.63] |  0.73 | 0.468  |   fixed |   conditional #> spp [EC-A]           |       -0.39 | 0.34 | [-1.06,  0.28] | -1.13 | 0.258  |   fixed |   conditional #> spp [EC-L]           |        0.49 | 0.24 | [ 0.02,  0.96] |  2.05 | 0.041  |   fixed |   conditional #> spp [DES-L]          |        0.59 | 0.23 | [ 0.14,  1.04] |  2.59 | 0.010  |   fixed |   conditional #> spp [DF]             |       -0.11 | 0.24 | [-0.59,  0.36] | -0.46 | 0.642  |   fixed |   conditional #> mined [no]           |        1.43 | 0.37 | [ 0.71,  2.15] |  3.90 | < .001 |   fixed |   conditional #> (Intercept)          |        0.91 | 0.63 | [-0.32,  2.14] |  1.45 | 0.147  |   fixed | zero_inflated #> sppPR                |        1.16 | 1.33 | [-1.45,  3.78] |  0.87 | 0.384  |   fixed | zero_inflated #> sppDM                |       -0.94 | 0.80 | [-2.51,  0.63] | -1.17 | 0.241  |   fixed | zero_inflated #> sppEC-A              |        1.04 | 0.71 | [-0.36,  2.44] |  1.46 | 0.144  |   fixed | zero_inflated #> sppEC-L              |       -0.56 | 0.73 | [-1.99,  0.86] | -0.77 | 0.439  |   fixed | zero_inflated #> sppDES-L             |       -0.89 | 0.75 | [-2.37,  0.58] | -1.19 | 0.236  |   fixed | zero_inflated #> sppDF                |       -2.54 | 2.18 | [-6.82,  1.74] | -1.16 | 0.244  |   fixed | zero_inflated #> minedno              |       -2.56 | 0.60 | [-3.75, -1.38] | -4.24 | < .001 |   fixed | zero_inflated #> (Intercept)          |        1.51 |      | [ 0.93,  2.46] |       |        |   fixed |    dispersion #> SD (Intercept: site) |        0.38 |      | [ 0.17,  0.87] |       |        |  random |   conditional"},{"path":"https://easystats.github.io/parameters/articles/model_parameters_print.html","id":"adding-model-information","dir":"Articles","previous_headings":"Summaries for a single model","what":"Adding model information","title":"Printing Model Parameters","text":"model summary can added table include_info = TRUE call model_parameters():","code":"model <- lm(Sepal.Length ~ Species * Petal.Length, data = iris) model_parameters(model, include_info = TRUE) #> Parameter                           | Coefficient |   SE |         95% CI #> ------------------------------------------------------------------------- #> (Intercept)                         |        4.21 | 0.41 | [ 3.41,  5.02] #> Species [versicolor]                |       -1.81 | 0.60 | [-2.99, -0.62] #> Species [virginica]                 |       -3.15 | 0.63 | [-4.41, -1.90] #> Petal Length                        |        0.54 | 0.28 | [ 0.00,  1.09] #> Species [versicolor] × Petal Length |        0.29 | 0.30 | [-0.30,  0.87] #> Species [virginica] × Petal Length  |        0.45 | 0.29 | [-0.12,  1.03] #>  #> Parameter                           | t(144) |      p #> ----------------------------------------------------- #> (Intercept)                         |  10.34 | < .001 #> Species [versicolor]                |  -3.02 | 0.003  #> Species [virginica]                 |  -4.97 | < .001 #> Petal Length                        |   1.96 | 0.052  #> Species [versicolor] × Petal Length |   0.97 | 0.334  #> Species [virginica] × Petal Length  |   1.56 | 0.120  #>  #> Model: Sepal.Length ~ Species * Petal.Length (150 Observations) #> Sigma: 0.336 (df = 144) #> RMSE : 0.330 #> R2: 0.840; adjusted R2: 0.835"},{"path":"https://easystats.github.io/parameters/articles/model_parameters_print.html","id":"including-the-reference-level-of-categorical-variables","dir":"Articles","previous_headings":"Summaries for a single model","what":"Including the reference level of categorical variables","title":"Printing Model Parameters","text":"Sometimes, can helpful include reference level categorical predictors table. can done setting include_reference = TRUE (either directly model_parameters() print() method). Since reference level parameter, shown separate row, 0 coefficient blank cells remaining columns.","code":"model <- lm(Sepal.Length ~ Petal.Length + Species, data = iris) model_parameters(model, include_reference = TRUE) #> Parameter            | Coefficient |   SE |         95% CI | t(146) |      p #> ---------------------------------------------------------------------------- #> (Intercept)          |        3.68 | 0.11 | [ 3.47,  3.89] |  34.72 | < .001 #> Petal Length         |        0.90 | 0.06 | [ 0.78,  1.03] |  13.96 | < .001 #> Species [setosa]     |        0.00 |      |                |        |        #> Species [versicolor] |       -1.60 | 0.19 | [-1.98, -1.22] |  -8.28 | < .001 #> Species [virginica]  |       -2.12 | 0.27 | [-2.66, -1.58] |  -7.74 | < .001"},{"path":"https://easystats.github.io/parameters/articles/model_parameters_print.html","id":"changing-number-of-digits","dir":"Articles","previous_headings":"Summaries for a single model","what":"Changing number of digits","title":"Printing Model Parameters","text":"digits changes digits coefficients, standard errors statistics. ci_digits p_digits especially confidence intervals p-values. p-values can displayed exact, scientific notation required.","code":"model <- lm(Sepal.Length ~ Species, data = iris) model_parameters(model, digits = 4) #> Parameter            | Coefficient |     SE |           95% CI |  t(147) |      p #> --------------------------------------------------------------------------------- #> (Intercept)          |      5.0060 | 0.0728 | [4.8621, 5.1499] | 68.7616 | < .001 #> Species [versicolor] |      0.9300 | 0.1030 | [0.7265, 1.1335] |  9.0328 | < .001 #> Species [virginica]  |      1.5820 | 0.1030 | [1.3785, 1.7855] | 15.3655 | < .001 model_parameters(model, p_digits = \"scientific\") #> Parameter            | Coefficient |   SE |       95% CI | t(147) |            p #> -------------------------------------------------------------------------------- #> (Intercept)          |        5.01 | 0.07 | [4.86, 5.15] |  68.76 | 1.13429e-113 #> Species [versicolor] |        0.93 | 0.10 | [0.73, 1.13] |   9.03 | 8.77019e-16  #> Species [virginica]  |        1.58 | 0.10 | [1.38, 1.79] |  15.37 | 2.21482e-32"},{"path":"https://easystats.github.io/parameters/articles/model_parameters_print.html","id":"fixing-column-widths","dir":"Articles","previous_headings":"Summaries for a single model","what":"Fixing column widths","title":"Printing Model Parameters","text":"default, width table columns set minimum required width. works well models produce just one table. However, models multiple components, component shown separate table, columns possibly longer aligned across tables. See following example zero-inflated mixed model three components (fixed count, fixed zero-inflated, random effects): column_width argument can used either define width specific columns, fix column widths columns across tables width. latter case, use column_width = \"fixed\" print() method. column_width named vector, names matched column names, columns gain specified minimum width.","code":"data(\"Salamanders\") # we create very long parameter names for this predictor here levels(Salamanders$spp) <- paste(\"long\", levels(Salamanders$spp))  model <- glmmTMB(   count ~ spp + mined + (1 | site),   ziformula = ~mined,   family = poisson(),   data = Salamanders )  # default printing model_parameters(model) #> # Fixed Effects (Count Model) #>  #> Parameter        | Log-Mean |   SE |         95% CI |     z |      p #> -------------------------------------------------------------------- #> (Intercept)      |    -0.36 | 0.28 | [-0.90,  0.18] | -1.30 | 0.194  #> spp [long PR]    |    -1.27 | 0.24 | [-1.74, -0.80] | -5.27 | < .001 #> spp [long DM]    |     0.27 | 0.14 | [ 0.00,  0.54] |  1.95 | 0.051  #> spp [long EC-A]  |    -0.57 | 0.21 | [-0.97, -0.16] | -2.75 | 0.006  #> spp [long EC-L]  |     0.67 | 0.13 | [ 0.41,  0.92] |  5.20 | < .001 #> spp [long DES-L] |     0.63 | 0.13 | [ 0.38,  0.87] |  4.96 | < .001 #> spp [long DF]    |     0.12 | 0.15 | [-0.17,  0.40] |  0.78 | 0.435  #> mined [no]       |     1.27 | 0.27 | [ 0.74,  1.80] |  4.72 | < .001 #>  #> # Fixed Effects (Zero-Inflation Component) #>  #> Parameter   | Log-Odds |   SE |         95% CI |     z |      p #> --------------------------------------------------------------- #> (Intercept) |     0.79 | 0.27 | [ 0.26,  1.32] |  2.90 | 0.004  #> mined [no]  |    -1.84 | 0.31 | [-2.46, -1.23] | -5.87 | < .001 #>  #> # Random Effects Variances #>  #> Parameter            | Coefficient |       95% CI #> ------------------------------------------------- #> SD (Intercept: site) |        0.33 | [0.18, 0.63] mp <- model_parameters(model) print(mp, column_width = \"fixed\") #> # Fixed Effects (Count Model) #>  #> Parameter            | Log-Mean |   SE |         95% CI |     z |      p #> ------------------------------------------------------------------------ #> (Intercept)          |    -0.36 | 0.28 | [-0.90,  0.18] | -1.30 | 0.194  #> spp [long PR]        |    -1.27 | 0.24 | [-1.74, -0.80] | -5.27 | < .001 #> spp [long DM]        |     0.27 | 0.14 | [ 0.00,  0.54] |  1.95 | 0.051  #> spp [long EC-A]      |    -0.57 | 0.21 | [-0.97, -0.16] | -2.75 | 0.006  #> spp [long EC-L]      |     0.67 | 0.13 | [ 0.41,  0.92] |  5.20 | < .001 #> spp [long DES-L]     |     0.63 | 0.13 | [ 0.38,  0.87] |  4.96 | < .001 #> spp [long DF]        |     0.12 | 0.15 | [-0.17,  0.40] |  0.78 | 0.435  #> mined [no]           |     1.27 | 0.27 | [ 0.74,  1.80] |  4.72 | < .001 #>  #> # Fixed Effects (Zero-Inflation Component) #>  #> Parameter            | Log-Odds |   SE |         95% CI |     z |      p #> ------------------------------------------------------------------------ #> (Intercept)          |     0.79 | 0.27 | [ 0.26,  1.32] |  2.90 | 0.004  #> mined [no]           |    -1.84 | 0.31 | [-2.46, -1.23] | -5.87 | < .001 #>  #> # Random Effects Variances #>  #> Parameter            | Coefficient |         95% CI #> --------------------------------------------------- #> SD (Intercept: site) |        0.33 |   [0.18, 0.63] print(mp, column_width = c(SE = 8, `95% CI` = 12, p = 7)) #> # Fixed Effects (Count Model) #>  #> Parameter        | Log-Mean |       SE |         95% CI |     z |       p #> ------------------------------------------------------------------------- #> (Intercept)      |    -0.36 |     0.28 | [-0.90,  0.18] | -1.30 |   0.194 #> spp [long PR]    |    -1.27 |     0.24 | [-1.74, -0.80] | -5.27 |  < .001 #> spp [long DM]    |     0.27 |     0.14 | [ 0.00,  0.54] |  1.95 |   0.051 #> spp [long EC-A]  |    -0.57 |     0.21 | [-0.97, -0.16] | -2.75 |   0.006 #> spp [long EC-L]  |     0.67 |     0.13 | [ 0.41,  0.92] |  5.20 |  < .001 #> spp [long DES-L] |     0.63 |     0.13 | [ 0.38,  0.87] |  4.96 |  < .001 #> spp [long DF]    |     0.12 |     0.15 | [-0.17,  0.40] |  0.78 |   0.435 #> mined [no]       |     1.27 |     0.27 | [ 0.74,  1.80] |  4.72 |  < .001 #>  #> # Fixed Effects (Zero-Inflation Component) #>  #> Parameter   | Log-Odds |       SE |         95% CI |     z |       p #> -------------------------------------------------------------------- #> (Intercept) |     0.79 |     0.27 | [ 0.26,  1.32] |  2.90 |   0.004 #> mined [no]  |    -1.84 |     0.31 | [-2.46, -1.23] | -5.87 |  < .001 #>  #> # Random Effects Variances #>  #> Parameter            | Coefficient |       95% CI #> ------------------------------------------------- #> SD (Intercept: site) |        0.33 | [0.18, 0.63]"},{"path":"https://easystats.github.io/parameters/articles/model_parameters_print.html","id":"group-parameters","dir":"Articles","previous_headings":"Summaries for a single model","what":"Group parameters","title":"Printing Model Parameters","text":"groups argument can used group parameters table. groups must named list, names list elements equal header group, values list elements equal parameter names, position parameters table (data frame). following example, see names parameters Parameter column, rownumbers indicate position. Now create group named \"Engine\", encompasses parameters \"cyl6\", \"cyl8\", \"vs\" \"hp\". \"Interactions\" group includes \"gear4:vs\" \"gear5:vs\". group \"controls\" parameters rows 2, 3 7. Note parameters table summary re-ordered according order specified groups. prefer tables without vertical borders, use sep argument define string used border-separator. argument passed insight::export_table().","code":"data(mtcars) mtcars$cyl <- as.factor(mtcars$cyl) mtcars$gear <- as.factor(mtcars$gear) model <- lm(mpg ~ hp + gear * vs + cyl + drat, data = mtcars)  # don't select \"Intercept\" parameter mp <- model_parameters(model, drop = \"^\\\\(Intercept\")  # inspect data frame as.data.frame(mp) #>   Parameter Coefficient    SE   CI CI_low CI_high     t df_error      p #> 1        hp      -0.062 0.021 0.95  -0.11  -0.018 -2.91       22 0.0081 #> 2     gear4       3.100 4.339 0.95  -5.90  12.098  0.71       22 0.4825 #> 3     gear5       4.798 3.478 0.95  -2.42  12.011  1.38       22 0.1816 #> 4        vs       3.183 3.790 0.95  -4.68  11.042  0.84       22 0.4100 #> 5      cyl6      -2.466 2.210 0.95  -7.05   2.116 -1.12       22 0.2764 #> 6      cyl8       1.975 5.111 0.95  -8.63  12.575  0.39       22 0.7029 #> 7      drat       2.697 2.033 0.95  -1.52   6.913  1.33       22 0.1983 #> 8  gear4:vs      -2.897 4.665 0.95 -12.57   6.778 -0.62       22 0.5410 #> 9  gear5:vs       2.588 4.537 0.95  -6.82  11.998  0.57       22 0.5741 # group parameters, either by parameter name or position print(mp, groups = list(   Engine = c(\"cyl6\", \"cyl8\", \"vs\", \"hp\"),   Interactions = c(\"gear4:vs\", \"gear5:vs\"),   Controls = c(2, 3, 7) )) # gear 4 and 5, drat #> Parameter        | Coefficient |   SE |          95% CI | t(22) |     p #> ----------------------------------------------------------------------- #> Engine           |             |      |                 |       |       #>   cyl [6]        |       -2.47 | 2.21 | [ -7.05,  2.12] | -1.12 | 0.276 #>   cyl [8]        |        1.97 | 5.11 | [ -8.63, 12.58] |  0.39 | 0.703 #>   vs             |        3.18 | 3.79 | [ -4.68, 11.04] |  0.84 | 0.410 #>   hp             |       -0.06 | 0.02 | [ -0.11, -0.02] | -2.91 | 0.008 #> Interactions     |             |      |                 |       |       #>   gear [4] × vs  |       -2.90 | 4.67 | [-12.57,  6.78] | -0.62 | 0.541 #>   gear [5] × vs  |        2.59 | 4.54 | [ -6.82, 12.00] |  0.57 | 0.574 #> Controls         |             |      |                 |       |       #>   gear [4]       |        3.10 | 4.34 | [ -5.90, 12.10] |  0.71 | 0.482 #>   gear [5]       |        4.80 | 3.48 | [ -2.42, 12.01] |  1.38 | 0.182 #>   drat           |        2.70 | 2.03 | [ -1.52,  6.91] |  1.33 | 0.198 # group parameters, either by parameter name or position print(mp,   sep = \"  \",   groups = list(     Engine = c(\"cyl6\", \"cyl8\", \"vs\", \"hp\"),     Interactions = c(\"gear4:vs\", \"gear5:vs\"),     Controls = c(2, 3, 7)   ) ) #> Parameter         Coefficient    SE           95% CI  t(22)      p #> ------------------------------------------------------------------ #> Engine                                                             #>   cyl [6]               -2.47  2.21  [ -7.05,  2.12]  -1.12  0.276 #>   cyl [8]                1.97  5.11  [ -8.63, 12.58]   0.39  0.703 #>   vs                     3.18  3.79  [ -4.68, 11.04]   0.84  0.410 #>   hp                    -0.06  0.02  [ -0.11, -0.02]  -2.91  0.008 #> Interactions                                                       #>   gear [4] × vs         -2.90  4.67  [-12.57,  6.78]  -0.62  0.541 #>   gear [5] × vs          2.59  4.54  [ -6.82, 12.00]   0.57  0.574 #> Controls                                                           #>   gear [4]               3.10  4.34  [ -5.90, 12.10]   0.71  0.482 #>   gear [5]               4.80  3.48  [ -2.42, 12.01]   1.38  0.182 #>   drat                   2.70  2.03  [ -1.52,  6.91]   1.33  0.198"},{"path":"https://easystats.github.io/parameters/articles/model_parameters_print.html","id":"summaries-for-multiple-models","dir":"Articles","previous_headings":"","what":"Summaries for multiple models","title":"Printing Model Parameters","text":"compare_parameters() (alias compare_models()) allows create tables multiple models, aligned side side. default, estimates confidence intervals shown.","code":"data(iris) lm1 <- lm(Sepal.Length ~ Species, data = iris) lm2 <- lm(Sepal.Length ~ Species + Petal.Length, data = iris) lm3 <- lm(Sepal.Length ~ Species * Petal.Length, data = iris) compare_parameters(lm1, lm2, lm3) #> Parameter                           |               lm1 |                  lm2 |                  lm3 #> ----------------------------------------------------------------------------------------------------- #> (Intercept)                         | 5.01 (4.86, 5.15) |  3.68 ( 3.47,  3.89) |  4.21 ( 3.41,  5.02) #> Species [versicolor]                | 0.93 (0.73, 1.13) | -1.60 (-1.98, -1.22) | -1.81 (-2.99, -0.62) #> Species [virginica]                 | 1.58 (1.38, 1.79) | -2.12 (-2.66, -1.58) | -3.15 (-4.41, -1.90) #> Petal Length                        |                   |  0.90 ( 0.78,  1.03) |  0.54 ( 0.00,  1.09) #> Species [versicolor] × Petal Length |                   |                      |  0.29 (-0.30,  0.87) #> Species [virginica] × Petal Length  |                   |                      |  0.45 (-0.12,  1.03) #> ----------------------------------------------------------------------------------------------------- #> Observations                        |               150 |                  150 |                  150"},{"path":"https://easystats.github.io/parameters/articles/model_parameters_print.html","id":"changing-style-of-column-output","dir":"Articles","previous_headings":"Summaries for multiple models","what":"Changing style of column output","title":"Printing Model Parameters","text":"default, estimates confidence intervals shown. Using select allows us create different output, e.g. standard errors instead confidence intervals, including p-values. select argument also basic support glue-like syntax, lets layout model elements flexible way. Following tokens replaced related summary coefficients statistics: {estimate} ({coefficient} {coef}): coefficient {se} ({std.error} {standard error}): standard error {ci_low} {ci_high}: lower/upper confidence interval limits {p} ({pval} {p.value}): p-values stars: significant stars p-values Note add parentheses manually, e.g. around confidence intervals. select also works model_parameters(), however, ’s necessary call argument via print() method:","code":"compare_parameters(lm1, lm2, lm3, select = \"se_p\") #> Parameter                           |            lm1 |             lm2 |             lm3 #> ---------------------------------------------------------------------------------------- #> (Intercept)                         | 5.01*** (0.07) |  3.68*** (0.11) |  4.21*** (0.41) #> Species [versicolor]                | 0.93*** (0.10) | -1.60*** (0.19) | -1.81 ** (0.60) #> Species [virginica]                 | 1.58*** (0.10) | -2.12*** (0.27) | -3.15*** (0.63) #> Petal Length                        |                |  0.90*** (0.06) |     0.54 (0.28) #> Species [versicolor] × Petal Length |                |                 |     0.29 (0.30) #> Species [virginica] × Petal Length  |                |                 |     0.45 (0.29) #> ---------------------------------------------------------------------------------------- #> Observations                        |            150 |             150 |             150 # estimates, p-stars and standard error in parentheses compare_parameters(lm1, lm2, lm3, select = \"{estimate}{stars} ({se})\") #> Parameter                           |            lm1 |             lm2 |             lm3 #> ---------------------------------------------------------------------------------------- #> (Intercept)                         | 5.01*** (0.07) |  3.68*** (0.11) |  4.21*** (0.41) #> Species [versicolor]                | 0.93*** (0.10) | -1.60*** (0.19) | -1.81 ** (0.60) #> Species [virginica]                 | 1.58*** (0.10) | -2.12*** (0.27) | -3.15*** (0.63) #> Petal Length                        |                |  0.90*** (0.06) |     0.54 (0.28) #> Species [versicolor] × Petal Length |                |                 |     0.29 (0.30) #> Species [virginica] × Petal Length  |                |                 |     0.45 (0.29) #> ---------------------------------------------------------------------------------------- #> Observations                        |            150 |             150 |             150  # estimates, CI, p and stars compare_parameters(lm1, lm2, lm3, select = \"{estimate} ({ci_low}, {ci_high}), p={p}{stars}\") #> Parameter                           |                           lm1 #> ------------------------------------------------------------------- #> (Intercept)                         | 5.01 (4.86, 5.15), p<0.001*** #> Species [versicolor]                | 0.93 (0.73, 1.13), p<0.001*** #> Species [virginica]                 | 1.58 (1.38, 1.79), p<0.001*** #> Petal Length                        |                               #> Species [versicolor] × Petal Length |                               #> Species [virginica] × Petal Length  |                               #> ------------------------------------------------------------------- #> Observations                        |                           150 #>  #> Parameter                           |                              lm2 |                              lm3 #> --------------------------------------------------------------------------------------------------------- #> (Intercept)                         |  3.68 ( 3.47,  3.89), p<0.001*** |  4.21 ( 3.41,  5.02), p<0.001*** #> Species [versicolor]                | -1.60 (-1.98, -1.22), p<0.001*** | -1.81 (-2.99, -0.62), p=0.003 ** #> Species [virginica]                 | -2.12 (-2.66, -1.58), p<0.001*** | -3.15 (-4.41, -1.90), p<0.001*** #> Petal Length                        |  0.90 ( 0.78,  1.03), p<0.001*** |     0.54 ( 0.00,  1.09), p=0.052 #> Species [versicolor] × Petal Length |                                  |     0.29 (-0.30,  0.87), p=0.334 #> Species [virginica] × Petal Length  |                                  |     0.45 (-0.12,  1.03), p=0.120 #> --------------------------------------------------------------------------------------------------------- #> Observations                        |                              150 |                              150 # estimates, p-stars and CI in parentheses result <- model_parameters(lm3) print(result, select = \"{estimate}{stars} ({ci})\") #> Parameter                           |           Estimate (ci) #> ------------------------------------------------------------- #> (Intercept)                         |  4.21*** ( 3.41,  5.02) #> Species [versicolor]                | -1.81 ** (-2.99, -0.62) #> Species [virginica]                 | -3.15*** (-4.41, -1.90) #> Petal Length                        |     0.54 ( 0.00,  1.09) #> Species [versicolor] × Petal Length |     0.29 (-0.30,  0.87) #> Species [virginica] × Petal Length  |     0.45 (-0.12,  1.03)"},{"path":"https://easystats.github.io/parameters/articles/model_parameters_print.html","id":"defining-column-names","dir":"Articles","previous_headings":"Summaries for multiple models","what":"Defining column names","title":"Printing Model Parameters","text":"column names models default objects’ names. can define names using column_names argument.","code":"compare_parameters(   lm1, lm2, lm3,   column_names = c(\"First Model\", \"Second Model\", \"Third Model\") ) #> Parameter                           |       First Model |         Second Model |          Third Model #> ----------------------------------------------------------------------------------------------------- #> (Intercept)                         | 5.01 (4.86, 5.15) |  3.68 ( 3.47,  3.89) |  4.21 ( 3.41,  5.02) #> Species [versicolor]                | 0.93 (0.73, 1.13) | -1.60 (-1.98, -1.22) | -1.81 (-2.99, -0.62) #> Species [virginica]                 | 1.58 (1.38, 1.79) | -2.12 (-2.66, -1.58) | -3.15 (-4.41, -1.90) #> Petal Length                        |                   |  0.90 ( 0.78,  1.03) |  0.54 ( 0.00,  1.09) #> Species [versicolor] × Petal Length |                   |                      |  0.29 (-0.30,  0.87) #> Species [virginica] × Petal Length  |                   |                      |  0.45 (-0.12,  1.03) #> ----------------------------------------------------------------------------------------------------- #> Observations                        |               150 |                  150 |                  150"},{"path":"https://easystats.github.io/parameters/articles/model_parameters_print.html","id":"models-with-multiple-components","dir":"Articles","previous_headings":"Summaries for multiple models","what":"Models with multiple components","title":"Printing Model Parameters","text":"models multiple components, like mixed models fixed random effects, models count- zero-inflation parts, using arguments effects = \"\" /component = \"\" prints separate tables model component. tables, usually become clearer columns per model aligned fixed width. can using column_width = \"fixed\".","code":"library(glmmTMB) data(\"fish\")  m0 <- glm(count ~ child + camper, data = fish, family = poisson())  m1 <- glmmTMB(   count ~ child + camper + (1 | persons) + (1 | ID),   data = fish,   family = poisson() )  m2 <- glmmTMB(   count ~ child + camper + zg + (1 | ID),   ziformula = ~ child + (1 | persons),   data = fish,   family = truncated_poisson() )  compare_parameters(m0, m1, m2, effects = \"all\", component = \"all\") #> # Fixed Effects #>  #> Parameter   |                   m0 |                   m1 |                   m2 #> -------------------------------------------------------------------------------- #> (Intercept) |  0.91 ( 0.75,  1.07) |  0.68 (-0.54,  1.91) |  1.41 ( 1.06,  1.75) #> child       | -1.23 (-1.39, -1.08) | -1.67 (-1.84, -1.51) | -0.53 (-0.77, -0.29) #> camper [1]  |  1.05 ( 0.88,  1.23) |  0.94 ( 0.77,  1.12) |  0.58 ( 0.39,  0.78) #> zg          |                      |                      |  0.13 ( 0.05,  0.21) #>  #> # Fixed Effects (Zero-Inflation Component) #>  #> Parameter   | m0 | m1 |                   m2 #> -------------------------------------------- #> (Intercept) |    |    | -0.92 (-2.07,  0.22) #> child       |    |    |  1.96 ( 1.38,  2.54) #>  #> # Random Effects #>  #> Parameter               | m0 |                   m1 |                   m2 #> -------------------------------------------------------------------------- #> SD (Intercept: ID)      |    |  0.27 ( 0.11,  0.63) |  0.28 ( 0.13,  0.60) #> SD (Intercept: persons) |    |  1.21 ( 0.60,  2.43) |                      #>  #> # Random Effects (Zero-Inflation Component) #>  #> Parameter               | m0 | m1 |                   m2 #> -------------------------------------------------------- #> SD (Intercept: persons) |    |    |  1.08 ( 0.49,  2.37) cp <- compare_parameters(m0, m1, m2, effects = \"all\", component = \"all\") print(cp, column_width = \"fixed\") #> # Fixed Effects #>  #> Parameter               |                   m0 |                   m1 |                   m2 #> -------------------------------------------------------------------------------------------- #> (Intercept)             |  0.91 ( 0.75,  1.07) |  0.68 (-0.54,  1.91) |  1.41 ( 1.06,  1.75) #> child                   | -1.23 (-1.39, -1.08) | -1.67 (-1.84, -1.51) | -0.53 (-0.77, -0.29) #> camper [1]              |  1.05 ( 0.88,  1.23) |  0.94 ( 0.77,  1.12) |  0.58 ( 0.39,  0.78) #> zg                      |                      |                      |  0.13 ( 0.05,  0.21) #>  #> # Fixed Effects (Zero-Inflation Component) #>  #> Parameter               |                   m0 |                   m1 |                   m2 #> -------------------------------------------------------------------------------------------- #> (Intercept)             |                      |                      | -0.92 (-2.07,  0.22) #> child                   |                      |                      |  1.96 ( 1.38,  2.54) #>  #> # Random Effects #>  #> Parameter               |                   m0 |                   m1 |                   m2 #> -------------------------------------------------------------------------------------------- #> SD (Intercept: ID)      |                      |  0.27 ( 0.11,  0.63) |  0.28 ( 0.13,  0.60) #> SD (Intercept: persons) |                      |  1.21 ( 0.60,  2.43) |                      #>  #> # Random Effects (Zero-Inflation Component) #>  #> Parameter               |                   m0 |                   m1 |                   m2 #> -------------------------------------------------------------------------------------------- #> SD (Intercept: persons) |                      |                      |  1.08 ( 0.49,  2.37)"},{"path":"https://easystats.github.io/parameters/articles/model_parameters_print.html","id":"group-parameters-of-multiple-model-tables","dir":"Articles","previous_headings":"Summaries for multiple models","what":"Group parameters of multiple model tables","title":"Printing Model Parameters","text":"Grouping parameters works compare_parameters() way shown model_parameters(). Note: default, interaction mark ×, * (see also section global options vignette). Since parameter names compare_parameters() already formatted printing, .data.frame(cp)$Parameter probably return special unicode characters need take care groups argument (unless use numeric indices).","code":"lm1 <- lm(Sepal.Length ~ Species + Petal.Length, data = iris) lm2 <- lm(Sepal.Width ~ Species * Petal.Length, data = iris)  # remove intercept cp <- compare_parameters(lm1, lm2, drop = \"^\\\\(Intercept\")  # look at parameters names, to know their names for \"groups\" argument as.data.frame(cp)$Parameter # note the unicode char as interaction mark #> [1] \"Species [versicolor]\"                \"Species [virginica]\"                 #> [3] \"Petal Length\"                        \"Species [versicolor] × Petal Length\" #> [5] \"Species [virginica] × Petal Length\"  # create groups. Interactions only present in 2nd model print(cp, groups = list(   Species = c(     \"Species [versicolor]\",     \"Species [virginica]\"   ),   Interactions = c(     \"Species [versicolor] × Petal Length\", # note the unicode char!     \"Species [virginica] × Petal Length\"   ),   Controls = \"Petal Length\" )) #> Parameter                             |                  lm1 |                  lm2 #> ----------------------------------------------------------------------------------- #> Species                               |                      |                      #>   Species [versicolor]                | -1.60 (-1.98, -1.22) | -1.69 (-2.80, -0.57) #>   Species [virginica]                 | -2.12 (-2.66, -1.58) | -1.19 (-2.37, -0.01) #> Interactions                          |                      |                      #>   Species [versicolor] × Petal Length |                      | -0.01 (-0.56,  0.53) #>   Species [virginica] × Petal Length  |                      | -0.15 (-0.69,  0.39) #> Controls                              |                      |                      #>   Petal Length                        |  0.90 ( 0.78,  1.03) |  0.39 (-0.13,  0.90) #> ----------------------------------------------------------------------------------- #>   Observations                        |                  150 |                  150"},{"path":"https://easystats.github.io/parameters/articles/model_parameters_print.html","id":"splitting-wide-tables-into-multiple-table-parts","dir":"Articles","previous_headings":"","what":"Splitting wide tables into multiple table parts","title":"Printing Model Parameters","text":"wide tables displayed properly, can use table_width argument print() method split tables multiple parts. table_width can numeric value, \"auto\", indicating width complete table. table_width = \"auto\" table wider current available width (.e. line length) console (source textual output, like markdown files), table split multiple parts. Else, table_width numeric table rows wider table_width, table split multiple parts.","code":"data(iris) lm1 <- lm(Sepal.Length ~ Species, data = iris) lm2 <- lm(Sepal.Length ~ Species + Petal.Length, data = iris) lm3 <- lm(Sepal.Length ~ Species * Petal.Length, data = iris) lm4 <- lm(Sepal.Length ~ Species * Petal.Length + Petal.Width, data = iris)  # very wide table compare_parameters(lm1, lm2, lm3, lm4) #> Parameter                           |               lm1 |                  lm2 #> ------------------------------------------------------------------------------ #> (Intercept)                         | 5.01 (4.86, 5.15) |  3.68 ( 3.47,  3.89) #> Species [versicolor]                | 0.93 (0.73, 1.13) | -1.60 (-1.98, -1.22) #> Species [virginica]                 | 1.58 (1.38, 1.79) | -2.12 (-2.66, -1.58) #> Petal Length                        |                   |  0.90 ( 0.78,  1.03) #> Species [versicolor] × Petal Length |                   |                      #> Species [virginica] × Petal Length  |                   |                      #> Petal Width                         |                   |                      #> ------------------------------------------------------------------------------ #> Observations                        |               150 |                  150 #>  #> Parameter                           |                  lm3 |                  lm4 #> --------------------------------------------------------------------------------- #> (Intercept)                         |  4.21 ( 3.41,  5.02) |  4.21 ( 3.41,  5.02) #> Species [versicolor]                | -1.81 (-2.99, -0.62) | -1.80 (-2.99, -0.62) #> Species [virginica]                 | -3.15 (-4.41, -1.90) | -3.19 (-4.50, -1.88) #> Petal Length                        |  0.54 ( 0.00,  1.09) |  0.54 (-0.02,  1.09) #> Species [versicolor] × Petal Length |  0.29 (-0.30,  0.87) |  0.28 (-0.30,  0.87) #> Species [virginica] × Petal Length  |  0.45 (-0.12,  1.03) |  0.45 (-0.12,  1.03) #> Petal Width                         |                      |  0.03 (-0.28,  0.34) #> --------------------------------------------------------------------------------- #> Observations                        |                  150 |                  150  # table split into two parts tab <- compare_parameters(lm1, lm2, lm3, lm4) print(tab, table_width = 80) #> Parameter                           |               lm1 |                  lm2 #> ------------------------------------------------------------------------------ #> (Intercept)                         | 5.01 (4.86, 5.15) |  3.68 ( 3.47,  3.89) #> Species [versicolor]                | 0.93 (0.73, 1.13) | -1.60 (-1.98, -1.22) #> Species [virginica]                 | 1.58 (1.38, 1.79) | -2.12 (-2.66, -1.58) #> Petal Length                        |                   |  0.90 ( 0.78,  1.03) #> Species [versicolor] × Petal Length |                   |                      #> Species [virginica] × Petal Length  |                   |                      #> Petal Width                         |                   |                      #> ------------------------------------------------------------------------------ #> Observations                        |               150 |                  150 #>  #> Parameter                           |                  lm3 |                  lm4 #> --------------------------------------------------------------------------------- #> (Intercept)                         |  4.21 ( 3.41,  5.02) |  4.21 ( 3.41,  5.02) #> Species [versicolor]                | -1.81 (-2.99, -0.62) | -1.80 (-2.99, -0.62) #> Species [virginica]                 | -3.15 (-4.41, -1.90) | -3.19 (-4.50, -1.88) #> Petal Length                        |  0.54 ( 0.00,  1.09) |  0.54 (-0.02,  1.09) #> Species [versicolor] × Petal Length |  0.29 (-0.30,  0.87) |  0.28 (-0.30,  0.87) #> Species [virginica] × Petal Length  |  0.45 (-0.12,  1.03) |  0.45 (-0.12,  1.03) #> Petal Width                         |                      |  0.03 (-0.28,  0.34) #> --------------------------------------------------------------------------------- #> Observations                        |                  150 |                  150"},{"path":"https://easystats.github.io/parameters/articles/model_parameters_print.html","id":"more-advances-tables-and-markdown-html-formatting","dir":"Articles","previous_headings":"","what":"More advances tables and markdown / HTML formatting","title":"Printing Model Parameters","text":"print_md() well print_html() functions can used create markdown (knitting PDF Word) HTML tables. Meanwhile, lot additional packages allow users even flexibility regarding table layouts. One package can recommend modelsummary package.","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/articles/model_parameters_robust.html","id":"robust-covariance-matrix-estimation-from-model-parameters","dir":"Articles","previous_headings":"Linear Regression Models","what":"Robust Covariance Matrix Estimation from Model Parameters","title":"Robust Estimation of Standard Errors, Confidence Intervals, and p-values","text":"Let us start simple example, uses heteroskedasticity-consistent covariance matrix estimation estimation-type “HC3” (.e. sandwich::vcovHC(type = \"HC3\")). First let’s create simple linear regression model, know violates homoscedasticity assumption, thus robust estimation methods considered. extract model parameters without robust estimation highlight difference makes standard errors, confidence intervals, t-statistic, p-values. Also, note coefficient estimate remains unchanged.","code":"data(cars) model <- lm(dist ~ speed, data = cars)  library(performance) check_heteroscedasticity(model) #> Warning: Heteroscedasticity (non-constant error variance) detected (p = 0.031). # model parameters, where SE, CI, and p-values are *not* based on robust estimation model_parameters(model) #> Parameter   | Coefficient |   SE |          95% CI | t(48) |      p #> ------------------------------------------------------------------- #> (Intercept) |      -17.58 | 6.76 | [-31.17, -3.99] | -2.60 | 0.012  #> speed       |        3.93 | 0.42 | [  3.10,  4.77] |  9.46 | < .001  # model parameters, where SE, CI, and p-values are based on robust estimation mp <- model_parameters(model, vcov = \"HC3\") mp #> Parameter   | Coefficient |   SE |          95% CI | t(48) |      p #> ------------------------------------------------------------------- #> (Intercept) |      -17.58 | 5.93 | [-29.51, -5.65] | -2.96 | 0.005  #> speed       |        3.93 | 0.43 | [  3.07,  4.79] |  9.20 | < .001  # compare standard errors to result from sandwich-package mp$SE #> [1] 5.93 0.43 unname(sqrt(diag(sandwich::vcovHC(model)))) #> [1] 5.93 0.43"},{"path":"https://easystats.github.io/parameters/articles/model_parameters_robust.html","id":"cluster-robust-covariance-matrix-estimation-sandwich","dir":"Articles","previous_headings":"Linear Regression Models","what":"Cluster-Robust Covariance Matrix Estimation (sandwich)","title":"Robust Estimation of Standard Errors, Confidence Intervals, and p-values","text":"different type covariance matrix estimation required, use vcov-argument. argument accepts name function sandwich clubSandwich packages string, \"vcovCL\" (just suffix \"CL\"). parameters call corresponding function content vcov_args arguments. specific estimation type can controlled passing type argument via vcov_args. See ?sandwich::vcovCL information different types covariance matrices function can produce (HC0 HC3). next example, use clustered covariance matrix estimation HC1-estimation type. Usually, clustered covariance matrix estimation used cluster-structure data. variable indicating cluster-structure can defined sandwich::vcovCL() cluster-argument. model_parameters(), additional arguments passed functions sandwich package can specified vcov_args:","code":"# let's create a more complicated model data(iris) model <- lm(Petal.Length ~ Sepal.Length * Species + Sepal.Width, data = iris)  # change estimation-type mp <- model_parameters(   model,   vcov = \"CL\", # type of covariance matrix   vcov_args = list(type = \"HC1\") # type of robust estimation )  mp #> Parameter                           | Coefficient |   SE |        95% CI #> ------------------------------------------------------------------------ #> (Intercept)                         |        0.87 | 0.42 | [ 0.03, 1.70] #> Sepal Length                        |        0.04 | 0.11 | [-0.18, 0.26] #> Species [versicolor]                |       -0.78 | 0.65 | [-2.07, 0.51] #> Species [virginica]                 |       -0.41 | 0.59 | [-1.57, 0.75] #> Sepal Width                         |        0.11 | 0.08 | [-0.05, 0.27] #> Sepal Length × Species [versicolor] |        0.61 | 0.12 | [ 0.37, 0.85] #> Sepal Length × Species [virginica]  |        0.68 | 0.11 | [ 0.46, 0.90] #>  #> Parameter                           | t(143) |      p #> ----------------------------------------------------- #> (Intercept)                         |   2.05 | 0.042  #> Sepal Length                        |   0.40 | 0.692  #> Species [versicolor]                |  -1.19 | 0.237  #> Species [virginica]                 |  -0.70 | 0.483  #> Sepal Width                         |   1.38 | 0.170  #> Sepal Length × Species [versicolor] |   4.96 | < .001 #> Sepal Length × Species [virginica]  |   6.15 | < .001  # compare standard errors to result from sandwich-package mp$SE #> [1] 0.422 0.111 0.653 0.587 0.079 0.123 0.111 unname(sqrt(diag(sandwich::vcovCL(model)))) #> [1] 0.422 0.111 0.653 0.587 0.079 0.123 0.111 iris$cluster <- factor(rep(LETTERS[1:8], length.out = nrow(iris)))  # change estimation-type, defining additional arguments mp <- model_parameters(   model,   vcov = \"vcovCL\",   vcov_args = list(type = \"HC1\", cluster = iris$cluster) )  mp #> Parameter                           | Coefficient |   SE |        95% CI #> ------------------------------------------------------------------------ #> (Intercept)                         |        0.87 | 0.34 | [ 0.20, 1.53] #> Sepal Length                        |        0.04 | 0.07 | [-0.10, 0.19] #> Species [versicolor]                |       -0.78 | 0.52 | [-1.80, 0.25] #> Species [virginica]                 |       -0.41 | 0.26 | [-0.94, 0.11] #> Sepal Width                         |        0.11 | 0.07 | [-0.03, 0.25] #> Sepal Length × Species [versicolor] |        0.61 | 0.10 | [ 0.42, 0.80] #> Sepal Length × Species [virginica]  |        0.68 | 0.05 | [ 0.58, 0.78] #>  #> Parameter                           | t(143) |      p #> ----------------------------------------------------- #> (Intercept)                         |   2.57 | 0.011  #> Sepal Length                        |   0.61 | 0.540  #> Species [versicolor]                |  -1.49 | 0.137  #> Species [virginica]                 |  -1.56 | 0.120  #> Sepal Width                         |   1.52 | 0.131  #> Sepal Length × Species [versicolor] |   6.29 | < .001 #> Sepal Length × Species [virginica]  |  13.28 | < .001  # compare standard errors to result from sandwich-package mp$SE #> [1] 0.337 0.072 0.519 0.264 0.072 0.097 0.051 unname(sqrt(diag(sandwich::vcovCL(model, cluster = iris$cluster)))) #> [1] 0.337 0.072 0.519 0.264 0.072 0.097 0.051"},{"path":"https://easystats.github.io/parameters/articles/model_parameters_robust.html","id":"cluster-robust-covariance-matrix-estimation-clubsandwich","dir":"Articles","previous_headings":"Linear Regression Models","what":"Cluster-Robust Covariance Matrix Estimation (clubSandwich)","title":"Robust Estimation of Standard Errors, Confidence Intervals, and p-values","text":"using clubSandwich::vcovCR(). Thus, vcov = \"CR\", related function clubSandwich package called. Note function requires specification cluster-argument.","code":"# create fake-cluster-variable, to demonstrate cluster robust standard errors iris$cluster <- factor(rep(LETTERS[1:8], length.out = nrow(iris)))  # cluster-robust estimation mp <- model_parameters(   model,   vcov = \"vcovCR\",   vcov_args = list(type = \"CR1\", cluster = iris$cluster) ) mp #> Parameter                           | Coefficient |   SE |        95% CI #> ------------------------------------------------------------------------ #> (Intercept)                         |        0.87 | 0.33 | [ 0.21, 1.52] #> Sepal Length                        |        0.04 | 0.07 | [-0.10, 0.18] #> Species [versicolor]                |       -0.78 | 0.51 | [-1.78, 0.23] #> Species [virginica]                 |       -0.41 | 0.26 | [-0.92, 0.10] #> Sepal Width                         |        0.11 | 0.07 | [-0.03, 0.25] #> Sepal Length × Species [versicolor] |        0.61 | 0.09 | [ 0.42, 0.79] #> Sepal Length × Species [virginica]  |        0.68 | 0.05 | [ 0.58, 0.78] #>  #> Parameter                           | t(143) |      p #> ----------------------------------------------------- #> (Intercept)                         |   2.62 | 0.010  #> Sepal Length                        |   0.63 | 0.531  #> Species [versicolor]                |  -1.53 | 0.129  #> Species [virginica]                 |  -1.60 | 0.112  #> Sepal Width                         |   1.55 | 0.123  #> Sepal Length × Species [versicolor] |   6.42 | < .001 #> Sepal Length × Species [virginica]  |  13.56 | < .001  # compare standard errors to result from clubSsandwich-package mp$SE #> [1] 0.330 0.070 0.508 0.259 0.071 0.095 0.050  unname(sqrt(diag(clubSandwich::vcovCR(model, type = \"CR1\", cluster = iris$cluster)))) #> [1] 0.330 0.070 0.508 0.259 0.071 0.095 0.050"},{"path":"https://easystats.github.io/parameters/articles/model_parameters_robust.html","id":"robust-covariance-matrix-estimation-on-standardized-model-parameters","dir":"Articles","previous_headings":"Linear Regression Models","what":"Robust Covariance Matrix Estimation on Standardized Model Parameters","title":"Robust Estimation of Standard Errors, Confidence Intervals, and p-values","text":"Finally, robust estimation can combined standardization. However, robust covariance matrix estimation works standardize = \"refit\".","code":"# model parameters, robust estimation on standardized model model_parameters(model, standardize = \"refit\", vcov = \"HC3\") #> Parameter                           | Coefficient |   SE |         95% CI #> ------------------------------------------------------------------------- #> (Intercept)                         |       -1.30 | 0.07 | [-1.44, -1.16] #> Sepal Length                        |        0.02 | 0.06 | [-0.09,  0.13] #> Species [versicolor]                |        1.57 | 0.09 | [ 1.40,  1.74] #> Species [virginica]                 |        2.02 | 0.09 | [ 1.84,  2.20] #> Sepal Width                         |        0.03 | 0.02 | [-0.01,  0.07] #> Sepal Length × Species [versicolor] |        0.28 | 0.06 | [ 0.16,  0.41] #> Sepal Length × Species [virginica]  |        0.32 | 0.06 | [ 0.21,  0.43] #>  #> Parameter                           | t(143) |      p #> ----------------------------------------------------- #> (Intercept)                         | -18.70 | < .001 #> Sepal Length                        |   0.37 | 0.711  #> Species [versicolor]                |  17.84 | < .001 #> Species [virginica]                 |  22.49 | < .001 #> Sepal Width                         |   1.32 | 0.190  #> Sepal Length × Species [versicolor] |   4.65 | < .001 #> Sepal Length × Species [virginica]  |   5.75 | < .001"},{"path":[]},{"path":"https://easystats.github.io/parameters/articles/model_parameters_robust.html","id":"robust-covariance-matrix-estimation-for-mixed-models","dir":"Articles","previous_headings":"Linear Mixed-Effects Regression Models","what":"Robust Covariance Matrix Estimation for Mixed Models","title":"Robust Estimation of Standard Errors, Confidence Intervals, and p-values","text":"linear mixed-effects models, definition clustered (hierarchical multilevel) structure data, also possible estimate cluster-robust covariance matrix. possible due clubSandwich package, thus need define arguments example. Notice robust estimation returns different standard errors, confidence intervals, test statistic p-values compared standard estimation. Also, note coefficient estimate remains unchanged.","code":"library(lme4) data(iris) set.seed(1234) iris$grp <- as.factor(sample(1:3, nrow(iris), replace = TRUE))  # fit example model model <- lme4::lmer(   Sepal.Length ~ Species * Sepal.Width + Petal.Length + (1 | grp),   data = iris )  # model parameters without robust estimation model_parameters(model) #> # Fixed Effects #>  #> Parameter                          | Coefficient |   SE |         95% CI #> ------------------------------------------------------------------------ #> (Intercept)                        |        1.55 | 0.40 | [ 0.76,  2.35] #> Species [versicolor]               |        0.41 | 0.55 | [-0.67,  1.50] #> Species [virginica]                |       -0.41 | 0.58 | [-1.56,  0.74] #> Sepal Width                        |        0.66 | 0.11 | [ 0.44,  0.89] #> Petal Length                       |        0.82 | 0.07 | [ 0.69,  0.95] #> Species [versicolor] × Sepal Width |       -0.48 | 0.19 | [-0.85, -0.12] #> Species [virginica] × Sepal Width  |       -0.36 | 0.18 | [-0.71,  0.00] #>  #> Parameter                          | t(141) |      p #> ---------------------------------------------------- #> (Intercept)                        |   3.87 | < .001 #> Species [versicolor]               |   0.75 | 0.454  #> Species [virginica]                |  -0.70 | 0.483  #> Sepal Width                        |   5.83 | < .001 #> Petal Length                       |  12.52 | < .001 #> Species [versicolor] × Sepal Width |  -2.60 | 0.010  #> Species [virginica] × Sepal Width  |  -1.99 | 0.048  #>  #> # Random Effects #>  #> Parameter           | Coefficient |   SE |       95% CI #> ------------------------------------------------------- #> SD (Intercept: grp) |        0.08 | 0.05 | [0.02, 0.29] #> SD (Residual)       |        0.30 | 0.02 | [0.27, 0.33]  # model parameters with cluster robust estimation model_parameters(   model,   vcov = \"vcovCR\",   vcov_args = list(type = \"CR1\", cluster = iris$grp) ) #> # Fixed Effects #>  #> Parameter                          | Coefficient |   SE |         95% CI #> ------------------------------------------------------------------------ #> (Intercept)                        |        1.55 | 0.40 | [ 0.76,  2.35] #> Species [versicolor]               |        0.41 | 0.80 | [-1.17,  1.99] #> Species [virginica]                |       -0.41 | 0.19 | [-0.78, -0.03] #> Sepal Width                        |        0.66 | 0.10 | [ 0.46,  0.86] #> Petal Length                       |        0.82 | 0.05 | [ 0.72,  0.91] #> Species [versicolor] × Sepal Width |       -0.48 | 0.35 | [-1.18,  0.21] #> Species [virginica] × Sepal Width  |       -0.36 | 0.11 | [-0.57, -0.15] #>  #> Parameter                          | t(141) |      p #> ---------------------------------------------------- #> (Intercept)                        |   3.87 | < .001 #> Species [versicolor]               |   0.51 | 0.608  #> Species [virginica]                |  -2.15 | 0.033  #> Sepal Width                        |   6.64 | < .001 #> Petal Length                       |  17.27 | < .001 #> Species [versicolor] × Sepal Width |  -1.37 | 0.172  #> Species [virginica] × Sepal Width  |  -3.39 | < .001 #>  #> # Random Effects #>  #> Parameter           | Coefficient |   SE |       95% CI #> ------------------------------------------------------- #> SD (Intercept: grp) |        0.08 | 0.05 | [0.02, 0.29] #> SD (Residual)       |        0.30 | 0.02 | [0.27, 0.33]"},{"path":"https://easystats.github.io/parameters/articles/model_parameters_robust.html","id":"robust-covariance-matrix-estimation-on-standardized-mixed-model-parameters","dir":"Articles","previous_headings":"Linear Mixed-Effects Regression Models","what":"Robust Covariance Matrix Estimation on Standardized Mixed Model Parameters","title":"Robust Estimation of Standard Errors, Confidence Intervals, and p-values","text":", robust estimation can combined standardization linear mixed-effects models well works standardize = \"refit\". Notice drastically p-values change robust-unstandardized model robust-standardized model.","code":"# model parameters, cluster robust estimation of standardized mixed model model_parameters(   model,   standardize = \"refit\",   vcov = \"vcovCR\",   vcov_args = list(type = \"CR1\", cluster = iris$grp) ) #> # Fixed Effects #>  #> Parameter                          | Coefficient |   SE |         95% CI #> ------------------------------------------------------------------------ #> (Intercept)                        |        0.97 | 0.08 | [ 0.82,  1.12] #> Species [versicolor]               |       -1.29 | 0.33 | [-1.95, -0.63] #> Species [virginica]                |       -1.81 | 0.23 | [-2.26, -1.37] #> Sepal Width                        |        0.35 | 0.05 | [ 0.24,  0.45] #> Petal Length                       |        1.74 | 0.10 | [ 1.54,  1.94] #> Species [versicolor] × Sepal Width |       -0.25 | 0.19 | [-0.62,  0.11] #> Species [virginica] × Sepal Width  |       -0.19 | 0.06 | [-0.30, -0.08] #>  #> Parameter                          | t(141) |      p #> ---------------------------------------------------- #> (Intercept)                        |  12.55 | < .001 #> Species [versicolor]               |  -3.85 | < .001 #> Species [virginica]                |  -8.01 | < .001 #> Sepal Width                        |   6.64 | < .001 #> Petal Length                       |  17.27 | < .001 #> Species [versicolor] × Sepal Width |  -1.37 | 0.172  #> Species [virginica] × Sepal Width  |  -3.39 | < .001 #>  #> # Random Effects #>  #> Parameter           | Coefficient |   SE |       95% CI #> ------------------------------------------------------- #> SD (Intercept: grp) |        0.10 | 0.06 | [0.03, 0.35] #> SD (Residual)       |        0.36 | 0.02 | [0.32, 0.40]"},{"path":"https://easystats.github.io/parameters/articles/overview_of_vignettes.html","id":"function-overview","dir":"Articles","previous_headings":"","what":"Function Overview","title":"Overview of Vignettes","text":"Function Reference","code":""},{"path":"https://easystats.github.io/parameters/articles/overview_of_vignettes.html","id":"description-of-parameters","dir":"Articles","previous_headings":"","what":"Description of Parameters","title":"Overview of Vignettes","text":"Summary Model Parameters Parameter Model Standardization Robust Estimation Standard Errors, Confidence Intervals, p-values Model Parameters Multiply Imputed Repeated Analyses Analysing Longitudinal Panel Data","code":""},{"path":"https://easystats.github.io/parameters/articles/overview_of_vignettes.html","id":"formatting-and-printing","dir":"Articles","previous_headings":"","what":"Formatting and Printing","title":"Overview of Vignettes","text":"Formatting Model Parameters Printing Model Parameters","code":""},{"path":"https://easystats.github.io/parameters/articles/overview_of_vignettes.html","id":"dimension-reduction-and-clustering","dir":"Articles","previous_headings":"","what":"Dimension Reduction and Clustering","title":"Overview of Vignettes","text":"Feature Reduction (PCA, cMDS, ICA, …) Structural Models (EFA, CFA, SEM, …) Selection Model Parameters Clustering easystats","code":""},{"path":"https://easystats.github.io/parameters/articles/overview_of_vignettes.html","id":"plotting-functions","dir":"Articles","previous_headings":"","what":"Plotting Functions","title":"Overview of Vignettes","text":"Plotting functions see package","code":""},{"path":"https://easystats.github.io/parameters/articles/parameters_reduction.html","id":"quick-and-exploratory-method","dir":"Articles","previous_headings":"","what":"Quick and Exploratory Method","title":"Feature Reduction (PCA, cMDS, ICA, ...)","text":"Let’s start fitting multiple linear regression model attitude dataset, available base R, predict overall rating employees organization remaining variables (handling employee complaints, special privileges, opportunity learning, raises, feedback considered critical opportunity advancement). can explore reduction number parameters reduce_parameters() function. output hints fact model represented via two “latent” dimensions, one correlated positive things company offer, one related amount negative critiques received employees. two dimensions positive negative relationship company rating, respectively. reduce_parameters() exactly ? function performs reduction parameter space (number variables). starts creating new set variables, based chosen method (default method “PCA”, available via method argument, “cMDS”, “DRR” “ICA”). , names new dimensions using original variables correlate . instance, example variable named raises_0.88/learning_0.82/complaints_0.78/privileges_0.70/advance_0.68 means respective variables (raises, learning, complaints, privileges, advance) correlate maximally (coefficients .88, .82, .78, .70, .68, respectively) dimension. different method (Classical Multidimensional Scaling - cMDS) suggests negative critiques significant impact rating, lack opportunities career advancement separate dimension importance . Although reduce_parameters() function can useful exploratory data analysis, ’s best perform dimension reduction step separate dedicated stage, important process data analysis workflow.","code":"data(\"attitude\") model <- lm(rating ~ ., data = attitude) parameters(model) #> Parameter   | Coefficient |    SE |          95% CI | t(23) |      p #> -------------------------------------------------------------------- #> (Intercept) |       10.79 | 11.59 | [-13.19, 34.76] |  0.93 | 0.362  #> complaints  |        0.61 |  0.16 | [  0.28,  0.95] |  3.81 | < .001 #> privileges  |       -0.07 |  0.14 | [ -0.35,  0.21] | -0.54 | 0.596  #> learning    |        0.32 |  0.17 | [ -0.03,  0.67] |  1.90 | 0.070  #> raises      |        0.08 |  0.22 | [ -0.38,  0.54] |  0.37 | 0.715  #> critical    |        0.04 |  0.15 | [ -0.27,  0.34] |  0.26 | 0.796  #> advance     |       -0.22 |  0.18 | [ -0.59,  0.15] | -1.22 | 0.236 newmodel <- reduce_parameters(model) parameters(newmodel) #> Parameter                                                              #> ---------------------------------------------------------------------- #> (Intercept)                                                            #> raises 0 88/learning 0 82/complaints 0 78/privileges 0 70/advance 0 68 #> critical -0 80                                                         #>  #> Coefficient |   SE |         95% CI | t(27) |      p #> ---------------------------------------------------- #>       64.63 | 1.57 | [61.41, 67.85] | 41.19 | < .001 #>        4.62 | 0.90 | [ 2.78,  6.46] |  5.16 | < .001 #>        3.41 | 1.59 | [ 0.14,  6.67] |  2.14 | 0.041 reduce_parameters(model, method = \"cMDS\") %>%   parameters() #> Parameter                                                 | Coefficient |   SE #> ------------------------------------------------------------------------------ #> (Intercept)                                               |       64.63 | 1.41 #> raises 0 85/complaints 0 84/learning 0 83/privileges 0 74 |        0.43 | 0.07 #> advance -0 60                                             |        0.32 | 0.13 #> critical -0 65                                            |       -0.24 | 0.15 #>  #> Parameter                                                 |         95% CI #> -------------------------------------------------------------------------- #> (Intercept)                                               | [61.73, 67.53] #> raises 0 85/complaints 0 84/learning 0 83/privileges 0 74 | [ 0.28,  0.57] #> advance -0 60                                             | [ 0.04,  0.59] #> critical -0 65                                            | [-0.56,  0.07] #>  #> Parameter                                                 | t(26) |      p #> -------------------------------------------------------------------------- #> (Intercept)                                               | 45.80 | < .001 #> raises 0 85/complaints 0 84/learning 0 83/privileges 0 74 |  6.14 | < .001 #> advance -0 60                                             |  2.36 | 0.026  #> critical -0 65                                            | -1.61 | 0.120"},{"path":"https://easystats.github.io/parameters/articles/parameters_reduction.html","id":"principal-component-analysis-pca","dir":"Articles","previous_headings":"","what":"Principal Component Analysis (PCA)","title":"Feature Reduction (PCA, cMDS, ICA, ...)","text":"PCA widely used procedure lies -dimension reduction structural modeling. Indeed, one ways reducing number predictors extract new set uncorrelated variables represent variance initial dataset. original variables relate can also question . can apply principal_components() function predictors model: principal_components() function automatically selected one component (number components specified, function uses n_factors() estimate optimal number keep) returned loadings, .e., relationship original variables. can see , seems new component captured essence (half total variance present original dataset) variables together. can extract values component observation using predict() method add response variable initial dataset. can know update model new component:","code":"pca <- principal_components(insight::get_predictors(model), n = \"auto\") pca #> # Loadings from Principal Component Analysis (no rotation) #>  #> Variable   |  PC1 | Complexity #> ------------------------------ #> complaints | 0.78 |       1.00 #> privileges | 0.70 |       1.00 #> learning   | 0.82 |       1.00 #> raises     | 0.88 |       1.00 #> critical   | 0.40 |       1.00 #> advance    | 0.68 |       1.00 #>  #> The unique principal component accounted for 52.82% of the total variance of the original data. newdata <- predict(pca) newdata$rating <- attitude$rating update(model, rating ~ PC1, data = newdata) %>%   parameters() #> Parameter   | Coefficient |   SE |         95% CI | t(28) |      p #> ------------------------------------------------------------------ #> (Intercept) |       64.63 | 1.67 | [61.22, 68.05] | 38.78 | < .001 #> PC1         |        4.62 | 0.95 | [ 2.67,  6.57] |  4.86 | < .001"},{"path":"https://easystats.github.io/parameters/articles/parameters_reduction.html","id":"using-the-psych-package-for-pca","dir":"Articles","previous_headings":"Principal Component Analysis (PCA)","what":"Using the psych package for PCA","title":"Feature Reduction (PCA, cMDS, ICA, ...)","text":"can also use different packages models, psych (Revelle 2018) FactoMineR PCA Exploratory Factor Analysis (EFA), allows flexibility control running procedures. functions package fully supported parameters model_parameters() function. instance, can redo analysis using psych package follows: Note: default, psych::principal() uses varimax rotation extract rotated components, possibly leading discrepancies results. Finally, refit model:","code":"library(psych)  # Fit the PCA pca <- model_parameters(psych::principal(attitude, nfactors = 1)) pca #> # Rotated loadings from Principal Component Analysis (varimax-rotation) #>  #> Variable   |  PC1 | Complexity | Uniqueness #> ------------------------------------------- #> rating     | 0.80 |       1.00 |       0.37 #> complaints | 0.85 |       1.00 |       0.28 #> privileges | 0.68 |       1.00 |       0.53 #> learning   | 0.83 |       1.00 |       0.32 #> raises     | 0.86 |       1.00 |       0.26 #> critical   | 0.36 |       1.00 |       0.87 #> advance    | 0.58 |       1.00 |       0.66 #>  #> The unique principal component (varimax rotation) accounted for 53.09% of the total variance of the original data. df <- cbind(attitude, predict(pca))  update(model, rating ~ PC1, data = df) %>%   model_parameters()"},{"path":[]},{"path":[]},{"path":"https://easystats.github.io/parameters/articles/parameters_selection.html","id":"fit-a-powerful-model","dir":"Articles","previous_headings":"Simple linear regression","what":"Fit a powerful model","title":"Selection of Model Parameters","text":"familiar R formula interface, know possibility including dot (.) formula, signifying “remaining variables”. Curiously, aware possibility additionally easily adding “interaction terms”. can achieved using .*. notation. Let’s try linear regression predicting Sepal.Length iris dataset, included default R. Wow, ’s lot parameters! almost none significant! weird, considering gorgeous R^2 0.882! wish research!","code":"model <- lm(Sepal.Length ~ . * ., data = iris) summary(model) #>  #> Call: #> lm(formula = Sepal.Length ~ . * ., data = iris) #>  #> Residuals: #>    Min     1Q Median     3Q    Max  #> -0.726 -0.210  0.014  0.213  0.713  #>  #> Coefficients: #>                                Estimate Std. Error t value Pr(>|t|)    #> (Intercept)                      1.6998     1.0576    1.61   0.1103    #> Sepal.Width                      0.8301     0.3047    2.72   0.0073 ** #> Petal.Length                     0.3178     0.7852    0.40   0.6863    #> Petal.Width                      2.5827     1.5874    1.63   0.1061    #> Speciesversicolor               -2.7193     1.6201   -1.68   0.0956 .  #> Speciesvirginica                -6.1704     3.2045   -1.93   0.0563 .  #> Sepal.Width:Petal.Length        -0.0149     0.2185   -0.07   0.9458    #> Sepal.Width:Petal.Width         -0.6112     0.4536   -1.35   0.1801    #> Sepal.Width:Speciesversicolor    0.4300     0.6666    0.65   0.5200    #> Sepal.Width:Speciesvirginica     0.8288     1.0031    0.83   0.4101    #> Petal.Length:Petal.Width        -0.1195     0.3300   -0.36   0.7178    #> Petal.Length:Speciesversicolor   0.7398     0.5166    1.43   0.1544    #> Petal.Length:Speciesvirginica    0.9034     0.6938    1.30   0.1951    #> Petal.Width:Speciesversicolor   -1.0070     1.2454   -0.81   0.4202    #> Petal.Width:Speciesvirginica    -0.2864     1.5065   -0.19   0.8495    #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: 0.3 on 135 degrees of freedom #> Multiple R-squared:  0.882,  Adjusted R-squared:  0.87  #> F-statistic: 72.1 on 14 and 135 DF,  p-value: <2e-16"},{"path":"https://easystats.github.io/parameters/articles/parameters_selection.html","id":"too-many-parameters","dir":"Articles","previous_headings":"Simple linear regression","what":"Too many parameters?","title":"Selection of Model Parameters","text":"might know, model performant always good thing. instance, can marker overfitting: model corresponds closely particular set data, may therefore fail predict future observations reliably. multiple regressions, can also fall Freedman’s paradox: predictors actually relation dependent variable predicted spuriously found statistically significant. Let’s run checks using performance package: main issue model seems high multicollinearity. suggests model might able give valid results individual predictor, tell predictors redundant respect others.","code":"library(performance)  check_normality(model) #> OK: residuals appear as normally distributed (p = 0.612). check_heteroscedasticity(model) #> OK: Error variance appears to be homoscedastic (p = 0.118). check_autocorrelation(model) #> OK: Residuals appear to be independent and not autocorrelated (p = 0.574). check_collinearity(model) #> # Check for Multicollinearity #>  #> High Correlation #>  #>                      Term      VIF           VIF 95% CI Increased SE Tolerance #>               Sepal.Width    29.42 [   22.31,    38.91]         5.42      0.03 #>              Petal.Length  3204.78 [ 2414.74,  4253.41]        56.61  3.12e-04 #>               Petal.Width  2442.10 [ 1840.11,  3241.14]        49.42  4.09e-04 #>                   Species 3.98e+05 [3.00e+05, 5.28e+05]       630.97  2.51e-06 #>  Sepal.Width:Petal.Length  2183.98 [ 1645.63,  2898.55]        46.73  4.58e-04 #>   Sepal.Width:Petal.Width  1866.48 [ 1406.42,  2477.15]        43.20  5.36e-04 #>       Sepal.Width:Species 3.49e+05 [2.63e+05, 4.64e+05]       591.13  2.86e-06 #>  Petal.Length:Petal.Width  4032.80 [ 3038.60,  5352.41]        63.50  2.48e-04 #>      Petal.Length:Species 1.23e+06 [9.27e+05, 1.63e+06]      1109.09  8.13e-07 #>       Petal.Width:Species 3.77e+05 [2.84e+05, 5.01e+05]       614.38  2.65e-06 #>  Tolerance 95% CI #>      [0.03, 0.04] #>      [0.00, 0.00] #>      [0.00, 0.00] #>      [0.00, 0.00] #>      [0.00, 0.00] #>      [0.00, 0.00] #>      [0.00, 0.00] #>      [0.00, 0.00] #>      [0.00, 0.00] #>      [0.00, 0.00]"},{"path":"https://easystats.github.io/parameters/articles/parameters_selection.html","id":"parameters-selection","dir":"Articles","previous_headings":"Simple linear regression","what":"Parameters selection","title":"Selection of Model Parameters","text":"Time variables selection! can easily done using select_parameters() function parameters. automatically select best variables update model accordingly. One way using tidy pipeline (using %>%), using output update new model. ’s still lot parameters, can see, almost now significant, R^2 change much. Although appealing, please note automated selection methods quite criticized, used place theoretical hypothetical reasons (.e., priori hypotheses parameters model want focus ).","code":"library(parameters) lm(Sepal.Length ~ . * ., data = iris) |>   select_parameters() |>   summary() #>  #> Call: #> lm(formula = Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width +  #>     Species + Sepal.Width:Petal.Width + Petal.Length:Species +  #>     Petal.Width:Species, data = iris) #>  #> Residuals: #>     Min      1Q  Median      3Q     Max  #> -0.7261 -0.2165  0.0021  0.2191  0.7439  #>  #> Coefficients: #>                                Estimate Std. Error t value Pr(>|t|)     #> (Intercept)                       2.090      0.528    3.95  0.00012 *** #> Sepal.Width                       0.734      0.130    5.66  8.3e-08 *** #> Petal.Length                      0.232      0.260    0.89  0.37310     #> Petal.Width                       1.051      0.532    1.98  0.04993 *   #> Speciesversicolor                -1.047      0.547   -1.92  0.05754 .   #> Speciesvirginica                 -2.682      0.638   -4.21  4.6e-05 *** #> Sepal.Width:Petal.Width          -0.232      0.103   -2.24  0.02667 *   #> Petal.Length:Speciesversicolor    0.660      0.298    2.22  0.02837 *   #> Petal.Length:Speciesvirginica     0.720      0.273    2.63  0.00941 **  #> Petal.Width:Speciesversicolor    -1.112      0.550   -2.02  0.04528 *   #> Petal.Width:Speciesvirginica     -0.499      0.460   -1.09  0.27934     #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: 0.3 on 139 degrees of freedom #> Multiple R-squared:  0.88,   Adjusted R-squared:  0.872  #> F-statistic:  102 on 10 and 139 DF,  p-value: <2e-16"},{"path":"https://easystats.github.io/parameters/articles/parameters_selection.html","id":"mixed-models","dir":"Articles","previous_headings":"","what":"Mixed models","title":"Selection of Model Parameters","text":"simple linear regressions , selection made using step() function (available base R). performs stepwise selection. However, procedures available types models, mixed models.","code":""},{"path":"https://easystats.github.io/parameters/articles/parameters_selection.html","id":"mixed-models-1","dir":"Articles","previous_headings":"Mixed models","what":"Mixed models","title":"Selection of Model Parameters","text":"mixed models (class merMod), stepwise selection based cAIC4::stepcAIC(). step function searches “best” model based random effects structure, .e. select_parameters() adds excludes random effects cAIC can’t improved . initial model looks like. model selected select_parameters(). Please notice differences random effects structure initial selected models:","code":"library(lme4) data(\"qol_cancer\")  # initial model lmer(   QoL ~ time + phq4 + age + (1 + time | hospital / ID),   data = qol_cancer ) |>   summary() #> Linear mixed model fit by REML ['lmerMod'] #> Formula: QoL ~ time + phq4 + age + (1 + time | hospital/ID) #>    Data: qol_cancer #>  #> REML criterion at convergence: 4647 #>  #> Scaled residuals:  #>    Min     1Q Median     3Q    Max  #> -3.581 -0.393  0.082  0.507  2.505  #>  #> Random effects: #>  Groups      Name        Variance Std.Dev. Corr  #>  ID:hospital (Intercept) 202.49   14.23          #>              time         12.54    3.54    -0.72 #>  hospital    (Intercept)   8.47    2.91          #>              time          1.27    1.13    -1.00 #>  Residual                143.11   11.96          #> Number of obs: 564, groups:  ID:hospital, 188; hospital, 2 #>  #> Fixed effects: #>             Estimate Std. Error t value #> (Intercept)  70.6514     3.1279   22.59 #> time          1.4896     1.2194    1.22 #> phq4         -4.7687     0.3235  -14.74 #> age          -0.0173     0.1889   -0.09 #>  #> Correlation of Fixed Effects: #>      (Intr) time   phq4   #> time -0.954               #> phq4  0.014 -0.011        #> age  -0.017  0.003  0.107 #> optimizer (nloptwrap) convergence code: 0 (OK) #> boundary (singular) fit: see help('isSingular') ## TODO: this is currently broken due to an issue in package cAIC4  # multiple models are checked, however, initial models # already seems to be the best one... lmer(   QoL ~ time + phq4 + age + (1 + time | hospital / ID),   data = qol_cancer ) |>   select_parameters() |>   summary()"},{"path":"https://easystats.github.io/parameters/articles/standardize_parameters_effsize.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Parameter and Model Standardization","text":"Standardizing parameters (.e., coefficients) can allow comparison within models, variables studies. Moreover, returns coefficients expressed terms change variance (instance, coefficients expressed terms SD response variable), can allow usage effect size interpretation guidelines, Cohen’s (1988) famous rules thumb. However, standardizing model’s parameters automatically mindlessly done: research fields, particular variables types studies (e.g., replications), sometimes makes sense keep, use interpret original parameters, especially well known easily understood. Critically, parameters standardization trivial process. Different techniques exist, can lead drastically different results. Thus, critical standardization method explicitly documented detailed.","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/articles/standardize_parameters_effsize.html","id":"standardized-associations","dir":"Articles","previous_headings":"Introduction > Standardizing Parameters of Simple Models","what":"Standardized Associations","title":"Parameter and Model Standardization","text":"Standardizing coefficient simple linear regression gives value know simple regression actually correlation? Thus, can eventually apply ()famous interpretation guidelines (e.g., Cohen’s rules thumb).","code":"library(parameters) library(effectsize)  m <- lm(rating ~ complaints, data = attitude)  standardize_parameters(m) > # Standardization method: refit >  > Parameter   | Std. Coef. |        95% CI > ---------------------------------------- > (Intercept) |  -9.80e-16 | [-0.21, 0.21] > complaints  |       0.83 | [ 0.61, 1.04] round(standardize_parameters(m)[2, 2], 2) > [1] 0.83 library(correlation) correlation(attitude, select = c(\"rating\", \"complaints\")) > # Correlation Matrix (pearson-method) >  > Parameter1 | Parameter2 |    r |       95% CI | t(28) |         p > ----------------------------------------------------------------- > rating     | complaints | 0.83 | [0.66, 0.91] |  7.74 | < .001*** >  > p-value adjustment method: Holm (1979) > Observations: 30"},{"path":"https://easystats.github.io/parameters/articles/standardize_parameters_effsize.html","id":"standardized-differences","dir":"Articles","previous_headings":"Introduction > Standardizing Parameters of Simple Models","what":"Standardized Differences","title":"Parameter and Model Standardization","text":"work case differences, factors entered differences given level reference level? might heard similar Cohen’s d. Well, let’s see. linear model suggests standardized difference Manual (reference level - model’s intercept) Automatic 1.20 standard deviation mpg (response variable standardized, right?). Let’s compute Cohen’s d two levels: larger! ? ? differences expressed units SD! SDs? Different SDs! looking difference groups slope, standardized parameter difference means SD_{mpg}. , slope Manual Automatic change 1.20 SD_{mpg}s. However, looking difference distance two populations, Cohen’s d distance means units pooled SDs. , distance Manual Automatic 1.48 SDs groups (assumed equal). simple model, pooled SD residual SD, can also estimate Cohen’s d : can also get approximation Cohen’s d converting t-statistic regression model via t_to_d(): also interesting note using smart method (explained detail ) standardizing parameters give indices equivalent Glass’ delta, standardized difference expressed terms SD reference group. … note standardized differences different others! :)","code":"# Select portion of data containing the two levels of interest mtcars$am <- factor(mtcars$am, labels = c(\"Manual\", \"Automatic\"))  m <- lm(mpg ~ am, data = mtcars) standardize_parameters(m) > # Standardization method: refit >  > Parameter      | Std. Coef. |         95% CI > -------------------------------------------- > (Intercept)    |      -0.49 | [-0.87, -0.11] > am [Automatic] |       1.20 | [ 0.60,  1.80] library(effectsize) cohens_d(mpg ~ am, data = mtcars) > Cohen's d |         95% CI > -------------------------- > -1.48     | [-2.27, -0.67] >  > - Estimated using pooled SD. coef(m)[2] / sigma(m) > amAutomatic  >         1.5 model_parameters(m) > Parameter      | Coefficient |   SE |         95% CI | t(30) |      p > --------------------------------------------------------------------- > (Intercept)    |       17.15 | 1.12 | [14.85, 19.44] | 15.25 | < .001 > am [Automatic] |        7.24 | 1.76 | [ 3.64, 10.85] |  4.11 | < .001 t_to_d(4.11, df_error = 30) > d    |       95% CI > ------------------- > 1.50 | [0.68, 2.30] m <- lm(mpg ~ am, data = mtcars)  standardize_parameters(m, method = \"smart\") > # Standardization method: smart >  > Parameter      | Std. Coef. |       95% CI > ------------------------------------------ > (Intercept)    |       0.00 | [0.00, 0.00] > am [Automatic] |       1.17 | [0.59, 1.76] glass_delta(mpg ~ am, data = mtcars) > Glass' delta (adj.) |         95% CI > ------------------------------------ > -1.10               | [-1.80, -0.37]"},{"path":"https://easystats.github.io/parameters/articles/standardize_parameters_effsize.html","id":"standardizing-parameters-of-linear-models","dir":"Articles","previous_headings":"Introduction","what":"Standardizing Parameters of Linear Models","title":"Parameter and Model Standardization","text":"mentioned , standardization parameters can also used compare among parameters within model. Essentially, prevents us normally able compare among different parameters underlying variables different scales.[^also noted , always issue. example, variables scale important interpretation results, standardization might fact hinder interpretation!] example, following example, use liner regression model predict worker’s salary (Shmekels) age (years), seniority (years), overtime (xtra_hours) many compliments give boss (n_comps). Let us explore different parameter standardization methods provided parameters.","code":""},{"path":"https://easystats.github.io/parameters/articles/standardize_parameters_effsize.html","id":"standardized-slopes-are-not-always-correlations","dir":"Articles","previous_headings":"Introduction > Standardizing Parameters of Linear Models","what":"Standardized Slopes are Not (Always) Correlations","title":"Parameter and Model Standardization","text":"saw simple linear models, standardized slope equal correlation outcome predictor - hold multiple regression well? effect regression model “adjusted” ones, might expect coefficients somewhat alike partial correlations. Let’s first start computing partial correlation numeric predictors outcome. Let’s compare standardized slopes: quite different! seems standardized slopes multiple linear regressions correlations partial correlations :( However, hope lost yet - can still try recover partial correlations model, another way: converting t-statistics (degrees freedom, df) partial correlation coefficient r. Wow, retrieved correlations coefficients regression model exactly partial correlations estimated ! “r” effect sizes can also used.","code":"data(\"hardlyworking\", package = \"effectsize\") head(hardlyworking) >   salary xtra_hours n_comps age seniority is_senior > 1  19745        4.2       1  32         3     FALSE > 2  11302        1.6       0  34         3     FALSE > 3  20636        1.2       3  33         5      TRUE > 4  23047        7.2       1  35         3     FALSE > 5  27342       11.3       0  33         4     FALSE > 6  25657        3.6       2  30         5      TRUE correlation(   hardlyworking,   select = \"salary\",   select2 = c(\"xtra_hours\", \"n_comps\", \"age\", \"seniority\"),   partial = TRUE # get partial correlations ) > # Correlation Matrix (pearson-method) >  > Parameter1 | Parameter2 |    r |       95% CI | t(498) |         p > ------------------------------------------------------------------ > salary     | xtra_hours | 0.87 | [0.85, 0.89] |  39.80 | < .001*** > salary     |    n_comps | 0.71 | [0.66, 0.75] |  22.40 | < .001*** > salary     |        age | 0.09 | [0.01, 0.18] |   2.10 | 0.037*    > salary     |  seniority | 0.19 | [0.10, 0.27] |   4.30 | < .001*** >  > p-value adjustment method: Holm (1979) > Observations: 500 mod <- lm(salary ~ xtra_hours + n_comps + age + seniority,   data = hardlyworking )  standardize_parameters(mod) > # Standardization method: refit >  > Parameter   | Std. Coef. |        95% CI > ---------------------------------------- > (Intercept) |   2.77e-16 | [-0.03, 0.03] > xtra hours  |       0.77 | [ 0.73, 0.81] > n comps     |       0.39 | [ 0.36, 0.42] > age         |       0.04 | [ 0.00, 0.07] > seniority   |       0.08 | [ 0.04, 0.12] params <- model_parameters(mod)  t_to_r(params$t[-1], df_error = params$df_error[-1]) > r    |       95% CI > ------------------- > 0.87 | [0.85, 0.89] > 0.71 | [0.67, 0.74] > 0.09 | [0.01, 0.18] > 0.19 | [0.10, 0.27]"},{"path":"https://easystats.github.io/parameters/articles/standardize_parameters_effsize.html","id":"methods-of-standardizing-parameters","dir":"Articles","previous_headings":"Introduction > Standardizing Parameters of Linear Models","what":"Methods of Standardizing Parameters","title":"Parameter and Model Standardization","text":"Let’s convert age 3-level factor: seems like best important predictor n_comps coefficient. However, hard compare among predictors, different scales. address issue, must predictors scale - usually arbitrary unit standard deviations.","code":"hardlyworking$age_g <- cut(hardlyworking$age,   breaks = c(25, 30, 35, 45) )  mod <- lm(salary ~ xtra_hours + n_comps + age_g + seniority,   data = hardlyworking )  model_parameters(mod) > Parameter      | Coefficient |     SE |              95% CI | t(494) |      p > ----------------------------------------------------------------------------- > (Intercept)    |     9806.10 | 446.71 | [8928.41, 10683.79] |  21.95 | < .001 > xtra hours     |     1221.35 |  30.72 | [1161.00,  1281.71] |  39.76 | < .001 > n comps        |     2944.87 | 131.12 | [2687.25,  3202.48] |  22.46 | < .001 > age g [>30-35] |      393.36 | 241.01 | [ -80.18,   866.90] |   1.63 | 0.103  > age g [>35-45] |      597.61 | 427.72 | [-242.77,  1437.99] |   1.40 | 0.163  > seniority      |      443.76 | 102.38 | [ 242.62,   644.91] |   4.33 | < .001"},{"path":"https://easystats.github.io/parameters/articles/standardize_parameters_effsize.html","id":"refit-re-fitting-the-model-with-standardized-data","dir":"Articles","previous_headings":"Introduction > Standardizing Parameters of Linear Models > Methods of Standardizing Parameters","what":"\"refit\": Re-fitting the model with standardized data","title":"Parameter and Model Standardization","text":"method based complete model re-fit standardized version data. Hence, method equal standardizing variables fitting model. “purest” accurate (Neter, Wasserman, Kutner 1989), also computationally costly long (especially heavy models Bayesian models, complex mixed models). method particularly recommended models include interactions transformations (e.g., exponentiation, log, polynomial spline terms). standardize_parameters also robust argument (default FALSE), enables robust standardization data, .e., based median MAD instead mean SD: Note since age_g factor, numerically standardized, standardized parameter still directly comparable numeric variables. address , can set two_sd = TRUE, thereby scaling parameters 2 SDs (MADs) predictors (Gelman 2008). parameters also comes helper function returns re-fit model, without summarizing , can used original model :","code":"standardize_parameters(mod, method = \"refit\") > # Standardization method: refit >  > Parameter      | Std. Coef. |        95% CI > ------------------------------------------- > (Intercept)    |      -0.05 | [-0.11, 0.02] > xtra hours     |       0.77 | [ 0.73, 0.81] > n comps        |       0.39 | [ 0.36, 0.43] > age g [>30-35] |       0.06 | [-0.01, 0.14] > age g [>35-45] |       0.10 | [-0.04, 0.23] > seniority      |       0.08 | [ 0.04, 0.12] standardize_parameters(mod, method = \"refit\", robust = TRUE) > # Standardization method: refit >  > Parameter      | Std. Coef. |         95% CI > -------------------------------------------- > (Intercept)    |      -0.20 | [-0.27, -0.13] > xtra hours     |       0.65 | [ 0.62,  0.68] > n comps        |       0.82 | [ 0.74,  0.89] > age g [>30-35] |       0.07 | [-0.01,  0.16] > age g [>35-45] |       0.11 | [-0.05,  0.27] > seniority      |       0.12 | [ 0.07,  0.18] >  > - Scaled by one MAD from the median. standardize_parameters(mod, method = \"refit\", two_sd = TRUE) > # Standardization method: refit >  > Parameter      | Std. Coef. |        95% CI > ------------------------------------------- > (Intercept)    |      -0.05 | [-0.11, 0.02] > xtra hours     |       1.54 | [ 1.46, 1.61] > n comps        |       0.78 | [ 0.72, 0.85] > age g [>30-35] |       0.06 | [-0.01, 0.14] > age g [>35-45] |       0.10 | [-0.04, 0.23] > seniority      |       0.16 | [ 0.09, 0.24] >  > - Scaled by two SDs from the mean. mod_z <- standardize(mod, two_sd = FALSE, robust = FALSE) mod_z >  > Call: > lm(formula = salary ~ xtra_hours + n_comps + age_g + seniority,  >     data = data_std) >  > Coefficients: >  (Intercept)    xtra_hours       n_comps  age_g(30,35]  age_g(35,45]   >      -0.0458        0.7692        0.3921        0.0635        0.0964   >    seniority   >       0.0821 model_parameters(mod_z) > Parameter      | Coefficient |   SE |        95% CI | t(494) |      p > --------------------------------------------------------------------- > (Intercept)    |       -0.05 | 0.03 | [-0.11, 0.02] |  -1.47 | 0.142  > xtra hours     |        0.77 | 0.02 | [ 0.73, 0.81] |  39.76 | < .001 > n comps        |        0.39 | 0.02 | [ 0.36, 0.43] |  22.46 | < .001 > age g [>30-35] |        0.06 | 0.04 | [-0.01, 0.14] |   1.63 | 0.103  > age g [>35-45] |        0.10 | 0.07 | [-0.04, 0.23] |   1.40 | 0.163  > seniority      |        0.08 | 0.02 | [ 0.04, 0.12] |   4.33 | < .001"},{"path":"https://easystats.github.io/parameters/articles/standardize_parameters_effsize.html","id":"posthoc-refit-without-refitting","dir":"Articles","previous_headings":"Introduction > Standardizing Parameters of Linear Models > Methods of Standardizing Parameters","what":"\"posthoc\": Refit without refitting","title":"Parameter and Model Standardization","text":"Post-hoc standardization parameters aims emulating results obtained \"refit\" without refitting model. coefficients divided standard deviation (MAD robust) outcome (becomes expression ‘unit’). , coefficients related numeric variables additionally multiplied standard deviation (MAD robust) related terms, correspond changes 1 SD predictor (e.g., “change 1 SD x related change 0.24 SD y). apply binary variables factors, coefficients still related changes levels. method accurate tend give aberrant results interactions specified. interaction posthoc-standardization problematic? regression model estimates coefficient two variables predictors 0 (fixed 0, people interpret “adjusted ”). standardized data passed (refit method), effects interactions estimated means predictors (0 mean standardized variable). Whereas posthoc-standardization, coefficient corresponds something different (0 different meanings standardized non-standardized data).","code":"standardize_parameters(mod, method = \"posthoc\") > # Standardization method: posthoc >  > Parameter      | Std. Coef. |        95% CI > ------------------------------------------- > (Intercept)    |       0.00 | [ 0.00, 0.00] > xtra hours     |       0.77 | [ 0.73, 0.81] > n comps        |       0.39 | [ 0.36, 0.43] > age g [>30-35] |       0.06 | [-0.01, 0.14] > age g [>35-45] |       0.10 | [-0.04, 0.23] > seniority      |       0.08 | [ 0.04, 0.12]"},{"path":"https://easystats.github.io/parameters/articles/standardize_parameters_effsize.html","id":"smart-standardization-of-models-parameters-with-adjustment-reconnaissance-and-transformation","dir":"Articles","previous_headings":"Introduction > Standardizing Parameters of Linear Models > Methods of Standardizing Parameters","what":"\"smart\": Standardization of Model’s parameters with Adjustment, Reconnaissance and Transformation","title":"Parameter and Model Standardization","text":"Experimental Similar method = \"posthoc\" involve model refitting. difference SD response computed relevant section data. instance, factor 3 levels (intercept), B C entered predictor, effect corresponding B vs. scaled variance response intercept . results, coefficients effects factors similar Glass’ delta.","code":"standardize_parameters(mod, method = \"smart\") > # Standardization method: smart >  > Parameter      | Std. Coef. |        95% CI > ------------------------------------------- > (Intercept)    |       0.00 | [ 0.00, 0.00] > xtra hours     |       0.77 | [ 0.73, 0.81] > n comps        |       0.39 | [ 0.36, 0.43] > age g [>30-35] |       0.06 | [-0.01, 0.14] > age g [>35-45] |       0.10 | [-0.04, 0.23] > seniority      |       0.08 | [ 0.04, 0.12]"},{"path":"https://easystats.github.io/parameters/articles/standardize_parameters_effsize.html","id":"basic-raw-scaling-of-the-model-frame","dir":"Articles","previous_headings":"Introduction > Standardizing Parameters of Linear Models > Methods of Standardizing Parameters","what":"\"basic\": Raw scaling of the model frame","title":"Parameter and Model Standardization","text":"method similar method = \"posthoc\", treats variables continuous: scales coefficient standard deviation model’s matrix’ parameter factors levels (transformed integers) binary predictors. Although can argued might inappropriate cases, method allows easier importance judgment across predictor type (numeric, factor, interactions…). also type standardization implemented default software packages (also lm.beta::lm.beta()), , can used reproducibility replication purposes.","code":"standardize_parameters(mod, method = \"basic\") > # Standardization method: basic >  > Parameter      | Std. Coef. |        95% CI > ------------------------------------------- > (Intercept)    |       0.00 | [ 0.00, 0.00] > xtra hours     |       0.77 | [ 0.73, 0.81] > n comps        |       0.39 | [ 0.36, 0.43] > age g [>30-35] |       0.03 | [-0.01, 0.07] > age g [>35-45] |       0.03 | [-0.01, 0.06] > seniority      |       0.08 | [ 0.04, 0.12]"},{"path":"https://easystats.github.io/parameters/articles/standardize_parameters_effsize.html","id":"standardizing-parameters-in-mixed-models","dir":"Articles","previous_headings":"Introduction > Standardizing Parameters of Linear Models","what":"Standardizing Parameters In Mixed Models","title":"Parameter and Model Standardization","text":"Linear mixed models (LMM/HLM/MLM) offer additional conundrum standardization - one even calculate SDs various predictors? response - deviations within group? perhaps ? solution: standardize according level predictor (Hoffman 2015, 342)! Level 1 parameters standardized according variance within groups, level 2 parameters standardized according variance groups. resulting standardized coefficient also called pseudo-standardized coefficients.[^Note like method \"basic\", based model matrix.]","code":"m <- lme4::lmer(Reaction ~ Days + (Days | Subject), data = lme4::sleepstudy)  standardize_parameters(m, method = \"pseudo\", ci_method = \"satterthwaite\") > # Standardization method: pseudo >  > Parameter   | Std. Coef. |       95% CI > --------------------------------------- > (Intercept) |       0.00 | [0.00, 0.00] > Days        |       0.68 | [0.47, 0.89] # compare to: standardize_parameters(m, method = \"basic\", ci_method = \"satterthwaite\") > # Standardization method: basic >  > Parameter   | Std. Coef. |       95% CI > --------------------------------------- > (Intercept) |       0.00 | [0.00, 0.00] > Days        |       0.54 | [0.37, 0.70]"},{"path":"https://easystats.github.io/parameters/articles/standardize_parameters_effsize.html","id":"standardizing-parameters-in-generalized-linear-models","dir":"Articles","previous_headings":"Introduction > Standardizing Parameters of Linear Models","what":"Standardizing Parameters In Generalized Linear Models","title":"Parameter and Model Standardization","text":"Unlike linear (/mixed) models, generalized linear (/mixed) models (GLMs) less need standardization. ? many GLMs estimated coefficients measures effect size, odds-ratios () logistic regression, incidence rate ratios (IRR) Poisson regressions. model outcome arbitrary scale - , meaning rates probabilities changed arbitrary linear transformations. still, standardization sometimes needed, predictors. Luckily, standardize_parameters() (standardize()) smart enough know GLMs passed standardize according predictors: can converted (exp()) discussed “change Odds function change one SD x”. can directly ask coefficients exponentiated:","code":"mod_b <- glm(am ~ mpg + factor(cyl),   data = mtcars,   family = binomial() )  standardize_parameters(mod_b, method = \"refit\", two_sd = TRUE) > # Standardization method: refit >  > Parameter                 | Std. Coef. |         95% CI > ------------------------------------------------------- > (Intercept)               |      -0.91 | [-3.32,  1.33] > mpg                       |       4.46 | [ 0.30, 10.54] > cyl [-0.0524939042876197] |       0.73 | [-2.04,  3.66] > cyl [0.507441074780324]   |       0.70 | [-3.13,  4.78] >  > - Scaled by two SDs from the mean. > - Response is unstandardized. # standardize_parameters(mod_b, method = \"posthoc\", two_sd = TRUE) # standardize_parameters(mod_b, method = \"basic\") std <- standardize_parameters(mod_b, method = \"refit\", two_sd = TRUE) exp(std$Std_Coefficient) > [1]  0.4 86.4  2.1  2.0 standardize_parameters(mod_b, method = \"refit\", two_sd = TRUE, exponentiate = TRUE) > # Standardization method: refit >  > Parameter                 | Std_Odds_Ratio |           95% CI > ------------------------------------------------------------- > (Intercept)               |           0.40 | [0.04,     3.76] > mpg                       |          86.40 | [1.36, 37955.41] > cyl [-0.0524939042876197] |           2.08 | [0.13,    39.04] > cyl [0.507441074780324]   |           2.02 | [0.04,   119.12] >  > - Scaled by two SDs from the mean. > - Response is unstandardized."},{"path":[]},{"path":"https://easystats.github.io/parameters/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Daniel Lüdecke. Author, maintainer. Dominique Makowski. Author. Mattan S. Ben-Shachar. Author. Indrajeet Patil. Author. Søren Højsgaard. Author. Brenton M. Wiernik. Author. Zen J. Lau. Contributor. Vincent Arel-Bundock. Contributor. Jeffrey Girard. Contributor. Christina Maimone. Reviewer. Niels Ohlsen. Reviewer. Douglas Ezra Morrison. Contributor. Joseph Luchman. Contributor.","code":""},{"path":"https://easystats.github.io/parameters/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Lüdecke D, Ben-Shachar M, Patil , Makowski D (2020). “Extracting, Computing Exploring Parameters Statistical Models using R.” Journal Open Source Software, 5(53), 2445. doi:10.21105/joss.02445.","code":"@Article{,   title = {Extracting, Computing and Exploring the Parameters of Statistical Models using {R}.},   volume = {5},   doi = {10.21105/joss.02445},   number = {53},   journal = {Journal of Open Source Software},   author = {Daniel Lüdecke and Mattan S. Ben-Shachar and Indrajeet Patil and Dominique Makowski},   year = {2020},   pages = {2445}, }"},{"path":"https://easystats.github.io/parameters/index.html","id":"parameters-","dir":"","previous_headings":"","what":"Processing of Model Parameters","title":"Processing of Model Parameters","text":"Describe understand model’s parameters! parameters’ primary goal provide utilities processing parameters various statistical models (see list supported models). Beyond computing p-values, CIs, Bayesian indices measures wide variety models, package implements features like bootstrapping parameters models, feature reduction (feature extraction variable selection), tools data reduction like functions perform cluster, factor principal component analysis. Another important goal parameters package facilitate streamline process reporting results statistical models, includes easy intuitive calculation standardized estimates robust standard errors p-values. parameters therefor offers simple unified syntax process large variety (model) objects many different packages.","code":""},{"path":"https://easystats.github.io/parameters/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Processing of Model Parameters","text":"Tip Instead library(parameters), use library(easystats). make features easystats-ecosystem available. stay updated, use easystats::install_latest().","code":""},{"path":"https://easystats.github.io/parameters/index.html","id":"documentation","dir":"","previous_headings":"","what":"Documentation","title":"Processing of Model Parameters","text":"Click buttons access package documentation easystats blog, check-vignettes: Summary Model Parameters Parameter Model Standardization Robust Estimation Standard Errors, Confidence Intervals p-values Model Parameters Missing Data Feature reduction (PCA, cMDS, ICA…) Structural models (EFA, CFA, SEM…) Parameters selection Practical Guide Panel Data Analysis Plotting functions","code":""},{"path":"https://easystats.github.io/parameters/index.html","id":"contributing-and-support","dir":"","previous_headings":"","what":"Contributing and Support","title":"Processing of Model Parameters","text":"case want file issue contribute another way package, please follow guide. questions functionality, may either contact us via email also file issue.","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/index.html","id":"models-parameters-description","dir":"","previous_headings":"","what":"Model’s parameters description","title":"Processing of Model Parameters","text":"model_parameters() function (can accessed via parameters() shortcut) allows extract parameters characteristics various models consistent way. can considered lightweight alternative broom::tidy(), notable differences: column names returned data frame specific content. instance, column containing statistic named following statistic name, .e., t, z, etc., instead generic name statistic (however, can get standardized (generic) column names using standardize_names()). able compute extract indices available default, p-values, CIs, etc. includes feature engineering capabilities, including parameters bootstrapping.","code":""},{"path":"https://easystats.github.io/parameters/index.html","id":"classical-regression-models","dir":"","previous_headings":"Model’s parameters description","what":"Classical Regression Models","title":"Processing of Model Parameters","text":"","code":"model <- lm(Sepal.Width ~ Petal.Length * Species + Petal.Width, data = iris)  # regular model parameters model_parameters(model) #> Parameter                           | Coefficient |   SE |         95% CI | t(143) |      p #> ------------------------------------------------------------------------------------------- #> (Intercept)                         |        2.89 | 0.36 | [ 2.18,  3.60] |   8.01 | < .001 #> Petal Length                        |        0.26 | 0.25 | [-0.22,  0.75] |   1.07 | 0.287  #> Species [versicolor]                |       -1.66 | 0.53 | [-2.71, -0.62] |  -3.14 | 0.002  #> Species [virginica]                 |       -1.92 | 0.59 | [-3.08, -0.76] |  -3.28 | 0.001  #> Petal Width                         |        0.62 | 0.14 | [ 0.34,  0.89] |   4.41 | < .001 #> Petal Length × Species [versicolor] |       -0.09 | 0.26 | [-0.61,  0.42] |  -0.36 | 0.721  #> Petal Length × Species [virginica]  |       -0.13 | 0.26 | [-0.64,  0.38] |  -0.50 | 0.618  # standardized parameters model_parameters(model, standardize = \"refit\") #> Parameter                           | Coefficient |   SE |         95% CI | t(143) |      p #> ------------------------------------------------------------------------------------------- #> (Intercept)                         |        3.59 | 1.30 | [ 1.01,  6.17] |   2.75 | 0.007  #> Petal Length                        |        1.07 | 1.00 | [-0.91,  3.04] |   1.07 | 0.287  #> Species [versicolor]                |       -4.62 | 1.31 | [-7.21, -2.03] |  -3.53 | < .001 #> Species [virginica]                 |       -5.51 | 1.38 | [-8.23, -2.79] |  -4.00 | < .001 #> Petal Width                         |        1.08 | 0.24 | [ 0.59,  1.56] |   4.41 | < .001 #> Petal Length × Species [versicolor] |       -0.38 | 1.06 | [-2.48,  1.72] |  -0.36 | 0.721  #> Petal Length × Species [virginica]  |       -0.52 | 1.04 | [-2.58,  1.54] |  -0.50 | 0.618  # heteroscedasticity-consitent SE and CI model_parameters(model, vcov = \"HC3\") #> Parameter                           | Coefficient |   SE |         95% CI | t(143) |      p #> ------------------------------------------------------------------------------------------- #> (Intercept)                         |        2.89 | 0.43 | [ 2.03,  3.75] |   6.66 | < .001 #> Petal Length                        |        0.26 | 0.29 | [-0.30,  0.83] |   0.92 | 0.357  #> Species [versicolor]                |       -1.66 | 0.53 | [-2.70, -0.62] |  -3.16 | 0.002  #> Species [virginica]                 |       -1.92 | 0.77 | [-3.43, -0.41] |  -2.51 | 0.013  #> Petal Width                         |        0.62 | 0.12 | [ 0.38,  0.85] |   5.23 | < .001 #> Petal Length × Species [versicolor] |       -0.09 | 0.29 | [-0.67,  0.48] |  -0.32 | 0.748  #> Petal Length × Species [virginica]  |       -0.13 | 0.31 | [-0.73,  0.48] |  -0.42 | 0.675"},{"path":"https://easystats.github.io/parameters/index.html","id":"mixed-models","dir":"","previous_headings":"Model’s parameters description","what":"Mixed Models","title":"Processing of Model Parameters","text":"","code":"library(lme4) model <- lmer(Sepal.Width ~ Petal.Length + (1 | Species), data = iris)  # model parameters with CI, df and p-values based on Wald approximation model_parameters(model) #> # Fixed Effects #>  #> Parameter    | Coefficient |   SE |       95% CI | t(146) |      p #> ------------------------------------------------------------------ #> (Intercept)  |        2.00 | 0.56 | [0.89, 3.11] |   3.56 | < .001 #> Petal Length |        0.28 | 0.06 | [0.16, 0.40] |   4.75 | < .001 #>  #> # Random Effects #>  #> Parameter               | Coefficient |   SE |       95% CI #> ----------------------------------------------------------- #> SD (Intercept: Species) |        0.89 | 0.46 | [0.33, 2.43] #> SD (Residual)           |        0.32 | 0.02 | [0.28, 0.35]  # model parameters with CI, df and p-values based on Kenward-Roger approximation model_parameters(model, ci_method = \"kenward\", effects = \"fixed\") #> # Fixed Effects #>  #> Parameter    | Coefficient |   SE |       95% CI |    t |     df |      p #> ------------------------------------------------------------------------- #> (Intercept)  |        2.00 | 0.57 | [0.07, 3.93] | 3.53 |   2.67 | 0.046  #> Petal Length |        0.28 | 0.06 | [0.16, 0.40] | 4.58 | 140.98 | < .001"},{"path":"https://easystats.github.io/parameters/index.html","id":"structural-models","dir":"","previous_headings":"Model’s parameters description","what":"Structural Models","title":"Processing of Model Parameters","text":"Besides many types regression models packages, also works types models, structural models (EFA, CFA, SEM…).","code":"library(psych)  model <- psych::fa(attitude, nfactors = 3) model_parameters(model) #> # Rotated loadings from Factor Analysis (oblimin-rotation) #>  #> Variable   |   MR1 |   MR2 |   MR3 | Complexity | Uniqueness #> ------------------------------------------------------------ #> rating     |  0.90 | -0.07 | -0.05 |       1.02 |       0.23 #> complaints |  0.97 | -0.06 |  0.04 |       1.01 |       0.10 #> privileges |  0.44 |  0.25 | -0.05 |       1.64 |       0.65 #> learning   |  0.47 |  0.54 | -0.28 |       2.51 |       0.24 #> raises     |  0.55 |  0.43 |  0.25 |       2.35 |       0.23 #> critical   |  0.16 |  0.17 |  0.48 |       1.46 |       0.67 #> advance    | -0.11 |  0.91 |  0.07 |       1.04 |       0.22 #>  #> The 3 latent factors (oblimin rotation) accounted for 66.60% of the total variance of the original data (MR1 = 38.19%, MR2 = 22.69%, MR3 = 5.72%)."},{"path":"https://easystats.github.io/parameters/index.html","id":"variable-and-parameters-selection","dir":"","previous_headings":"","what":"Variable and parameters selection","title":"Processing of Model Parameters","text":"select_parameters() can help quickly select retain relevant predictors using methods tailored model type.","code":"lm(disp ~ ., data = mtcars) |>   select_parameters() |>   model_parameters() #> Parameter   | Coefficient |     SE |            95% CI | t(26) |      p #> ----------------------------------------------------------------------- #> (Intercept) |      141.70 | 125.67 | [-116.62, 400.02] |  1.13 | 0.270  #> cyl         |       13.14 |   7.90 | [  -3.10,  29.38] |  1.66 | 0.108  #> hp          |        0.63 |   0.20 | [   0.22,   1.03] |  3.18 | 0.004  #> wt          |       80.45 |  12.22 | [  55.33, 105.57] |  6.58 | < .001 #> qsec        |      -14.68 |   6.14 | [ -27.31,  -2.05] | -2.39 | 0.024  #> carb        |      -28.75 |   5.60 | [ -40.28, -17.23] | -5.13 | < .001"},{"path":"https://easystats.github.io/parameters/index.html","id":"statistical-inference---how-to-quantify-evidence","dir":"","previous_headings":"","what":"Statistical inference - how to quantify evidence","title":"Processing of Model Parameters","text":"standardized approach drawing conclusions based available data statistical models. frequently chosen also much criticized approach evaluate results based statistical significance (Amrhein, Korner-Nievergelt, & Roth, 2017). sophisticated way test whether estimated effects exceed “smallest effect size interest”, avoid even smallest effects considered relevant simply statistically significant, clinically practically irrelevant (Lakens, 2024; Lakens, Scheel, & Isager, 2018). rather unconventional approach, nevertheless advocated various authors, interpret results classical regression models terms probabilities, similar usual approach Bayesian statistics (Greenland, Rafi, Matthews, & Higgs, 2022; Rafi & Greenland, 2020; Schweder, 2018; Schweder & Hjort, 2003; Vos & Holbert, 2022). parameters package provides several options functions aid statistical inference. , example: equivalence_test(), compute (conditional) equivalence test frequentist models p_significance(), compute probability practical significance, can conceptualized unidirectional equivalence test p_function(), consonance function, compute p-values compatibility (confidence) intervals statistical models pd argument (setting pd = TRUE) model_parameters() includes column probability direction, .e. probability parameter strictly positive negative. See bayestestR::p_direction() details. s_value argument (setting s_value = TRUE) model_parameters() replaces p-values related S-values (@ Rafi & Greenland, 2020) finally, possible generate distributions model coefficients generating bootstrap-samples (setting bootstrap = TRUE) simulating draws model coefficients using simulate_model(). samples can treated “posterior samples” used many functions bayestestR package. shown options functions derive methods originally implemented Bayesian models (Makowski, Ben-Shachar, Chen, & Lüdecke, 2019). However, assuming model assumptions met (means, model fits well data, correct model chosen reflects data generating process (distributional model family) etc.), seems appropriate interpret results classical frequentist models “Bayesian way” (details: documentation p_function()).","code":""},{"path":"https://easystats.github.io/parameters/index.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Processing of Model Parameters","text":"order cite package, please use following command:","code":"citation(\"parameters\") To cite package 'parameters' in publications use:    Lüdecke D, Ben-Shachar M, Patil I, Makowski D (2020). \"Extracting,   Computing and Exploring the Parameters of Statistical Models using   R.\" _Journal of Open Source Software_, *5*(53), 2445.   doi:10.21105/joss.02445 <https://doi.org/10.21105/joss.02445>.  A BibTeX entry for LaTeX users is    @Article{,     title = {Extracting, Computing and Exploring the Parameters of Statistical Models using {R}.},     volume = {5},     doi = {10.21105/joss.02445},     number = {53},     journal = {Journal of Open Source Software},     author = {Daniel Lüdecke and Mattan S. Ben-Shachar and Indrajeet Patil and Dominique Makowski},     year = {2020},     pages = {2445},   }"},{"path":"https://easystats.github.io/parameters/index.html","id":"code-of-conduct","dir":"","previous_headings":"","what":"Code of Conduct","title":"Processing of Model Parameters","text":"Please note parameters project released Contributor Code Conduct. contributing project, agree abide terms.","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/bootstrap_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Model bootstrapping — bootstrap_model","title":"Model bootstrapping — bootstrap_model","text":"Bootstrap statistical model n times return data frame estimates.","code":""},{"path":"https://easystats.github.io/parameters/reference/bootstrap_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Model bootstrapping — bootstrap_model","text":"","code":"bootstrap_model(model, iterations = 1000, ...)  # Default S3 method bootstrap_model(   model,   iterations = 1000,   type = \"ordinary\",   parallel = \"no\",   n_cpus = 1,   cluster = NULL,   verbose = FALSE,   ... )"},{"path":"https://easystats.github.io/parameters/reference/bootstrap_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Model bootstrapping — bootstrap_model","text":"model Statistical model. iterations number draws simulate/bootstrap. ... Arguments passed methods. type Character string specifying type bootstrap. mixed models class merMod glmmTMB, may \"parametric\" (default) \"semiparametric\" (see ?lme4::bootMer details). models, see argument sim ?boot::boot (defaults \"ordinary\"). parallel type parallel operation used (). n_cpus Number processes used parallel operation. cluster Optional cluster parallel = \"snow\". See ?lme4::bootMer details. verbose Toggle warnings messages.","code":""},{"path":"https://easystats.github.io/parameters/reference/bootstrap_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Model bootstrapping — bootstrap_model","text":"data frame bootstrapped estimates.","code":""},{"path":"https://easystats.github.io/parameters/reference/bootstrap_model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Model bootstrapping — bootstrap_model","text":"default, boot::boot() used generate bootstraps model data, used update() model, .e. refit model bootstrapped samples. merMod objects (lme4) models glmmTMB, lme4::bootMer() function used obtain bootstrapped samples. bootstrap_parameters() summarizes bootstrapped model estimates.","code":""},{"path":"https://easystats.github.io/parameters/reference/bootstrap_model.html","id":"using-with-emmeans","dir":"Reference","previous_headings":"","what":"Using with emmeans","title":"Model bootstrapping — bootstrap_model","text":"output can passed directly various functions emmeans package, obtain bootstrapped estimates, contrasts, simple slopes, etc. confidence intervals. can passed model_parameter() obtain standard errors, p-values, etc. (see example). Note p-values returned estimated assumption translation equivariance: shape sampling distribution unaffected null true . assumption hold, p-values can biased, suggested use proper permutation tests obtain non-parametric p-values.","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/bootstrap_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Model bootstrapping — bootstrap_model","text":"","code":"# \\donttest{ model <- lm(mpg ~ wt + factor(cyl), data = mtcars) b <- bootstrap_model(model) print(head(b)) #>   (Intercept)        wt factor(cyl)6 factor(cyl)8 #> 1    32.80447 -3.275128    -2.994874    -5.535547 #> 2    33.53835 -3.192280    -3.371982    -5.269348 #> 3    33.50110 -3.043621    -4.561783    -6.336212 #> 4    33.73882 -3.031721    -4.529576    -6.089992 #> 5    30.77663 -2.298175    -4.044469    -5.561024 #> 6    32.50119 -2.431631    -5.943601    -7.659333  est <- emmeans::emmeans(b, consec ~ cyl) print(model_parameters(est)) #> # Estimated Marginal Means  #>  #> Parameter | Median |         95% CI |   pd #> ------------------------------------------ #> 4         |  23.47 | [21.35, 26.20] | 100% #> 6         |  19.39 | [18.61, 20.31] | 100% #> 8         |  17.55 | [16.42, 19.22] | 100% #>  #> # Contrasts  #>  #> Parameter   | Median |         95% CI |     pd #> ---------------------------------------------- #> cyl6 - cyl4 |  -4.08 | [-6.85, -1.92] | 99.90% #> cyl8 - cyl6 |  -1.81 | [-3.31,  0.12] | 97.10% # }"},{"path":"https://easystats.github.io/parameters/reference/bootstrap_parameters.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameters bootstrapping — bootstrap_parameters","title":"Parameters bootstrapping — bootstrap_parameters","text":"Compute bootstrapped parameters related indices Confidence Intervals (CI) p-values.","code":""},{"path":"https://easystats.github.io/parameters/reference/bootstrap_parameters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parameters bootstrapping — bootstrap_parameters","text":"","code":"bootstrap_parameters(model, ...)  # Default S3 method bootstrap_parameters(   model,   iterations = 1000,   centrality = \"median\",   ci = 0.95,   ci_method = \"quantile\",   test = \"p-value\",   ... )"},{"path":"https://easystats.github.io/parameters/reference/bootstrap_parameters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameters bootstrapping — bootstrap_parameters","text":"model Statistical model. ... Arguments passed methods, like bootstrap_model() bayestestR::describe_posterior(). iterations number draws simulate/bootstrap. centrality point-estimates (centrality indices) compute. Character (vector) list one options: \"median\", \"mean\", \"MAP\" (see map_estimate()), \"trimmed\" (just mean(x, trim = threshold)), \"mode\" \"\". ci Value vector probability CI (0 1) estimated. Default 0.95 (95%). ci_method type index used Credible Interval. Can \"ETI\" (default, see eti()), \"HDI\" (see hdi()), \"BCI\" (see bci()), \"SPI\" (see spi()), \"SI\" (see si()). test indices compute. Character (vector) one options: \"p-value\" (\"p\"), \"p_direction\" (\"pd\"), \"rope\", \"p_map\", \"equivalence_test\" (\"equitest\"), \"bayesfactor\" (\"bf\") \"\" compute tests. \"test\", corresponding bayestestR function called (e.g. bayestestR::rope() bayestestR::p_direction()) results included summary output.","code":""},{"path":"https://easystats.github.io/parameters/reference/bootstrap_parameters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parameters bootstrapping — bootstrap_parameters","text":"data frame summarizing bootstrapped parameters.","code":""},{"path":"https://easystats.github.io/parameters/reference/bootstrap_parameters.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Parameters bootstrapping — bootstrap_parameters","text":"function first calls bootstrap_model() generate bootstrapped coefficients. resulting replicated coefficient treated \"distribution\", passed bayestestR::describe_posterior() calculate related indices defined \"test\" argument. Note p-values returned estimated assumption translation equivariance: shape sampling distribution unaffected null true . assumption hold, p-values can biased, suggested use proper permutation tests obtain non-parametric p-values.","code":""},{"path":"https://easystats.github.io/parameters/reference/bootstrap_parameters.html","id":"using-with-emmeans","dir":"Reference","previous_headings":"","what":"Using with emmeans","title":"Parameters bootstrapping — bootstrap_parameters","text":"output can passed directly various functions emmeans package, obtain bootstrapped estimates, contrasts, simple slopes, etc. confidence intervals. can passed model_parameter() obtain standard errors, p-values, etc. (see example). Note p-values returned estimated assumption translation equivariance: shape sampling distribution unaffected null true . assumption hold, p-values can biased, suggested use proper permutation tests obtain non-parametric p-values.","code":""},{"path":"https://easystats.github.io/parameters/reference/bootstrap_parameters.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Parameters bootstrapping — bootstrap_parameters","text":"Davison, . C., & Hinkley, D. V. (1997). Bootstrap methods application (Vol. 1). Cambridge university press.","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/bootstrap_parameters.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parameters bootstrapping — bootstrap_parameters","text":"","code":"# \\donttest{ set.seed(2) model <- lm(Sepal.Length ~ Species * Petal.Width, data = iris) b <- bootstrap_parameters(model) print(b) #> # Fixed Effects #>  #> Parameter                     | Coefficient |        95% CI |      p #> -------------------------------------------------------------------- #> (Intercept)                   |        4.78 | [ 4.50, 5.00] | < .001 #> Speciesversicolor             |       -0.72 | [-1.62, 0.08] | 0.082  #> Speciesvirginica              |        0.50 | [-0.67, 1.65] | 0.422  #> Petal.Width                   |        0.91 | [ 0.22, 1.97] | 0.016  #> Speciesversicolor:Petal.Width |        0.50 | [-0.66, 1.52] | 0.390  #> Speciesvirginica:Petal.Width  |       -0.27 | [-1.36, 0.67] | 0.558   # different type of bootstrapping set.seed(2) b <- bootstrap_parameters(model, type = \"balanced\") print(b) #> # Fixed Effects #>  #> Parameter                     | Coefficient |        95% CI |      p #> -------------------------------------------------------------------- #> (Intercept)                   |        4.77 | [ 4.53, 5.00] | < .001 #> Speciesversicolor             |       -0.73 | [-1.67, 0.05] | 0.076  #> Speciesvirginica              |        0.53 | [-0.71, 1.74] | 0.428  #> Petal.Width                   |        0.93 | [ 0.24, 1.86] | 0.020  #> Speciesversicolor:Petal.Width |        0.49 | [-0.56, 1.47] | 0.366  #> Speciesvirginica:Petal.Width  |       -0.29 | [-1.34, 0.65] | 0.560   est <- emmeans::emmeans(b, trt.vs.ctrl ~ Species) #> NOTE: Results may be misleading due to involvement in interactions print(model_parameters(est)) #> # Estimated Marginal Means  #>  #> Parameter  | Median |       95% CI |   pd #> ----------------------------------------- #> setosa     |   5.89 | [5.25, 6.78] | 100% #> versicolor |   5.75 | [5.63, 5.89] | 100% #> virginica  |   6.05 | [5.52, 6.60] | 100% #>  #> # Contrasts  #>  #> Parameter           | Median |        95% CI |     pd #> ----------------------------------------------------- #> versicolor - setosa |  -0.14 | [-1.04, 0.53] | 64.20% #> virginica - setosa  |   0.13 | [-0.87, 1.01] | 60.10% # }"},{"path":"https://easystats.github.io/parameters/reference/ci.default.html","id":null,"dir":"Reference","previous_headings":"","what":"Confidence Intervals (CI) — ci.default","title":"Confidence Intervals (CI) — ci.default","text":"ci() attempts return confidence intervals model parameters.","code":""},{"path":"https://easystats.github.io/parameters/reference/ci.default.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Confidence Intervals (CI) — ci.default","text":"","code":"# Default S3 method ci(   x,   ci = 0.95,   dof = NULL,   method = NULL,   iterations = 500,   component = \"all\",   vcov = NULL,   vcov_args = NULL,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/parameters/reference/ci.default.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Confidence Intervals (CI) — ci.default","text":"x statistical model. ci Confidence Interval (CI) level. Default 0.95 (95%). dof Number degrees freedom used calculating confidence intervals. NULL (default), degrees freedom retrieved calling insight::get_df() approximation method defined method. NULL, use argument override default degrees freedom used compute confidence intervals. method Method computing degrees freedom confidence intervals (CI) related p-values. Allowed following options (vary depending model class): \"residual\", \"normal\", \"likelihood\", \"satterthwaite\", \"kenward\", \"wald\", \"profile\", \"boot\", \"uniroot\", \"ml1\", \"betwithin\", \"hdi\", \"quantile\", \"ci\", \"eti\", \"si\", \"bci\", \"bcai\". See section Confidence intervals approximation degrees freedom model_parameters() details. iterations number bootstrap replicates. applies models class merMod method=boot. component Model component parameters shown. See documentation object's class model_parameters() p_value() details, see section Model components. vcov Variance-covariance matrix used compute uncertainty estimates (e.g., robust standard errors). argument accepts covariance matrix, function returns covariance matrix, string identifies function used compute covariance matrix. covariance matrix function returns covariance matrix (e.g., stats::vcov()) string indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC Cluster-robust: \"CR\", \"CR0\", \"CR1\", \"CR1p\", \"CR1S\", \"CR2\", \"CR3\". See ?clubSandwich::vcovCR Bootstrap: \"BS\", \"xy\", \"residual\", \"wild\", \"mammen\", \"fractional\", \"jackknife\", \"norm\", \"webb\". See ?sandwich::vcovBS sandwich package functions: \"HAC\", \"PC\", \"CL\", \"OPG\", \"PL\". vcov_args List arguments passed function identified vcov argument. function typically supplied sandwich clubSandwich packages. Please refer documentation (e.g., ?sandwich::vcovHAC) see list available arguments. estimation type (argument type) given, default type \"HC\" equals default sandwich package; type \"CR\", default set \"CR3\". verbose Toggle warnings messages. ... Additional arguments passed underlying functions. E.g., arguments like vcov vcov_args can used compute confidence intervals using specific variance-covariance matrix standard errors.","code":""},{"path":"https://easystats.github.io/parameters/reference/ci.default.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Confidence Intervals (CI) — ci.default","text":"data frame containing CI bounds.","code":""},{"path":"https://easystats.github.io/parameters/reference/ci.default.html","id":"confidence-intervals-and-approximation-of-degrees-of-freedom","dir":"Reference","previous_headings":"","what":"Confidence intervals and approximation of degrees of freedom","title":"Confidence Intervals (CI) — ci.default","text":"different ways approximating degrees freedom depending different assumptions nature model sampling distribution. ci_method argument modulates method computing degrees freedom (df) used calculate confidence intervals (CI) related p-values. Following options allowed, depending model class: Classical methods: Classical inference generally based Wald method. Wald approach inference computes test statistic dividing parameter estimate standard error (Coefficient / SE), comparing statistic t- normal distribution. approach can used compute CIs p-values. \"wald\": Applies non-Bayesian models. linear models, CIs computed using Wald method (SE t-distribution residual df); p-values computed using Wald method t-distribution residual df. models, CIs computed using Wald method (SE normal distribution); p-values computed using Wald method normal distribution. \"normal\" Applies non-Bayesian models. Compute Wald CIs p-values, always use normal distribution. \"residual\" Applies non-Bayesian models. Compute Wald CIs p-values, always use t-distribution residual df possible. residual df model determined, normal distribution used instead. Methods mixed models: Compared fixed effects (single-level) models, determining appropriate df Wald-based inference mixed models difficult. See R GLMM FAQ discussion. Several approximate methods computing df available, also consider instead using profile likelihood (\"profile\") bootstrap (\"boot\") CIs p-values instead. \"satterthwaite\" Applies linear mixed models. CIs computed using Wald method (SE t-distribution Satterthwaite df); p-values computed using Wald method t-distribution Satterthwaite df. \"kenward\" Applies linear mixed models. CIs computed using Wald method (Kenward-Roger SE t-distribution Kenward-Roger df); p-values computed using Wald method Kenward-Roger SE t-distribution Kenward-Roger df. \"ml1\" Applies linear mixed models. CIs computed using Wald method (SE t-distribution m-l-1 approximated df); p-values computed using Wald method t-distribution m-l-1 approximated df. See ci_ml1(). \"betwithin\" Applies linear mixed models generalized linear mixed models. CIs computed using Wald method (SE t-distribution -within df); p-values computed using Wald method t-distribution -within df. See ci_betwithin(). Likelihood-based methods: Likelihood-based inference based comparing likelihood maximum-likelihood estimate likelihood models one parameter values changed (e.g., set zero range alternative values). Likelihood ratios maximum-likelihood alternative models compared \\(\\chi\\)-squared distribution compute CIs p-values. \"profile\" Applies non-Bayesian models class glm, polr, merMod glmmTMB. CIs computed profiling likelihood curve parameter, using linear interpolation find likelihood ratio equals critical value; p-values computed using Wald method normal-distribution (note: might change future update!) \"uniroot\" Applies non-Bayesian models class glmmTMB. CIs computed profiling likelihood curve parameter, using root finding find likelihood ratio equals critical value; p-values computed using Wald method normal-distribution (note: might change future update!) Methods bootstrapped Bayesian models: Bootstrap-based inference based resampling refitting model resampled datasets. distribution parameter estimates across resampled datasets used approximate parameter's sampling distribution. Depending type model, several different methods bootstrapping constructing CIs p-values bootstrap distribution available. Bayesian models, inference based drawing samples model posterior distribution. \"quantile\" (\"eti\") Applies models (including Bayesian models). non-Bayesian models, applies bootstrap = TRUE. CIs computed equal tailed intervals using quantiles bootstrap posterior samples; p-values based probability direction. See bayestestR::eti(). \"hdi\" Applies models (including Bayesian models). non-Bayesian models, applies bootstrap = TRUE. CIs computed highest density intervals bootstrap posterior samples; p-values based probability direction. See bayestestR::hdi(). \"bci\" (\"bcai\") Applies models (including Bayesian models). non-Bayesian models, applies bootstrap = TRUE. CIs computed bias corrected accelerated intervals bootstrap posterior samples; p-values based probability direction. See bayestestR::bci(). \"si\" Applies Bayesian models proper priors. CIs computed support intervals comparing posterior samples prior samples; p-values based probability direction. See bayestestR::si(). \"boot\" Applies non-Bayesian models class merMod. CIs computed using parametric bootstrapping (simulating data fitted model); p-values computed using Wald method normal-distribution) (note: might change future update!). iteration-based methods \"boot\" (\"hdi\", \"quantile\", \"ci\", \"eti\", \"si\", \"bci\", \"bcai\"), p-values based probability direction (bayestestR::p_direction()), converted p-value using bayestestR::pd_to_p().","code":""},{"path":"https://easystats.github.io/parameters/reference/ci.default.html","id":"model-components","dir":"Reference","previous_headings":"","what":"Model components","title":"Confidence Intervals (CI) — ci.default","text":"Possible values component argument depend model class. Following valid options: \"\": returns model components, applies models, effect models just conditional model component. \"conditional\": returns conditional component, .e. \"fixed effects\" terms model. effect models just conditional model component. \"smooth_terms\": returns smooth terms, applies GAMs (similar models may contain smooth terms). \"zero_inflated\" (\"zi\"): returns zero-inflation component. \"dispersion\": returns dispersion model component. common models zero-inflation can model dispersion parameter. \"instruments\": instrumental-variable fixed effects regression, returns instruments. \"nonlinear\": non-linear models (like models class nlmerMod nls), returns staring estimates nonlinear parameters. \"correlation\": models correlation-component, like gls, variables used describe correlation structure returned. Special models model classes also allow rather uncommon options. : mhurdle: \"infrequent_purchase\", \"ip\", \"auxiliary\" BGGM: \"correlation\" \"intercept\" BFBayesFactor, glmx: \"extra\" averaging:\"conditional\" \"full\" mjoint: \"survival\" mfx: \"precision\", \"marginal\" betareg, DirichletRegModel: \"precision\" mvord: \"thresholds\" \"correlation\" clm2: \"scale\" selection: \"selection\", \"outcome\", \"auxiliary\" lavaan: One \"regression\", \"correlation\", \"loading\", \"variance\", \"defined\", \"mean\". Can also \"\" include components. models class brmsfit (package brms), even options possible component argument, documented detail .","code":""},{"path":"https://easystats.github.io/parameters/reference/ci.default.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Confidence Intervals (CI) — ci.default","text":"","code":"data(qol_cancer) model <- lm(QoL ~ time + age + education, data = qol_cancer)  # regular confidence intervals ci(model) #>       Parameter   CI    CI_low    CI_high #> 1   (Intercept) 0.95 58.455237 69.2799382 #> 2          time 0.95 -1.073378  2.8464276 #> 3           age 0.95 -0.320625  0.3709297 #> 4  educationmid 0.95  4.434914 13.0868340 #> 5 educationhigh 0.95  9.326662 19.3815413  # using heteroscedasticity-robust standard errors ci(model, vcov = \"HC3\") #>       Parameter   CI     CI_low    CI_high #> 1   (Intercept) 0.95 58.3265330 69.4086418 #> 2          time 0.95 -1.1252812  2.8983308 #> 3           age 0.95 -0.3293582  0.3796629 #> 4  educationmid 0.95  4.2133861 13.3083623 #> 5 educationhigh 0.95  9.3661349 19.3420686  # \\donttest{ library(parameters) data(Salamanders, package = \"glmmTMB\") model <- glmmTMB::glmmTMB(   count ~ spp + mined + (1 | site),   ziformula = ~mined,   family = poisson(),   data = Salamanders )  ci(model) #>      Parameter   CI       CI_low    CI_high     Component #> 1  (Intercept) 0.95 -0.904868203  0.1834728   conditional #> 2        sppPR 0.95 -1.741720718 -0.7977701   conditional #> 3        sppDM 0.95 -0.001515455  0.5395142   conditional #> 4      sppEC-A 0.95 -0.967367323 -0.1630136   conditional #> 5      sppEC-L 0.95  0.414693327  0.9167312   conditional #> 6     sppDES-L 0.95  0.378400449  0.8723050   conditional #> 7        sppDF 0.95 -0.173790668  0.4038560   conditional #> 8      minedno 0.95  0.742998151  1.7998569   conditional #> 9  (Intercept) 0.95  0.255245254  1.3247538 zero_inflated #> 10     minedno 0.95 -2.460449166 -1.2293688 zero_inflated ci(model, component = \"zi\") #>     Parameter   CI     CI_low   CI_high     Component #> 1 (Intercept) 0.95  0.2552453  1.324754 zero_inflated #> 2     minedno 0.95 -2.4604492 -1.229369 zero_inflated # }"},{"path":"https://easystats.github.io/parameters/reference/cluster_analysis.html","id":null,"dir":"Reference","previous_headings":"","what":"Cluster Analysis — cluster_analysis","title":"Cluster Analysis — cluster_analysis","text":"Compute hierarchical kmeans cluster analysis return group assignment observation vector.","code":""},{"path":"https://easystats.github.io/parameters/reference/cluster_analysis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cluster Analysis — cluster_analysis","text":"","code":"cluster_analysis(   x,   n = NULL,   method = \"kmeans\",   include_factors = FALSE,   standardize = TRUE,   verbose = TRUE,   distance_method = \"euclidean\",   hclust_method = \"complete\",   kmeans_method = \"Hartigan-Wong\",   dbscan_eps = 15,   iterations = 100,   ... )"},{"path":"https://easystats.github.io/parameters/reference/cluster_analysis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cluster Analysis — cluster_analysis","text":"x data frame (least two variables), matrix (least two columns). n Number clusters used supervised cluster methods. NULL, number clusters extract determined calling n_clusters(). Note argument apply unsupervised clustering methods like dbscan, hdbscan, mixture, pvclust, pamk. method Method computing cluster analysis. Can \"kmeans\" (default; k-means using kmeans()), \"hkmeans\" (hierarchical k-means using factoextra::hkmeans()), pam (K-Medoids using cluster::pam()), pamk (K-Medoids finds number clusters), \"hclust\" (hierarchical clustering using hclust() pvclust::pvclust()), dbscan (DBSCAN using dbscan::dbscan()), hdbscan (Hierarchical DBSCAN using dbscan::hdbscan()), mixture (Mixture modeling using mclust::Mclust(), requires user run library(mclust) ). include_factors Logical, TRUE, factors converted numerical values order included data determining number clusters. default, factors removed, methods determine number clusters need numeric input . standardize Standardize dataframe clustering (default). verbose Toggle warnings messages. distance_method Distance measure used methods based distances (e.g., method = \"hclust\" hierarchical clustering. methods, \"kmeans\", argument ignored). Must one \"euclidean\", \"maximum\", \"manhattan\", \"canberra\", \"binary\" \"minkowski\". See dist() pvclust::pvclust() information. hclust_method Agglomeration method used method = \"hclust\" method = \"hkmeans\" (hierarchical clustering). one \"ward\", \"ward.D2\", \"single\", \"complete\", \"average\", \"mcquitty\", \"median\" \"centroid\". Default \"complete\" (see hclust()). kmeans_method Algorithm used calculating kmeans cluster. applies, method = \"kmeans\". May one \"Hartigan-Wong\" (default), \"Lloyd\" (used SPSS), \"MacQueen\". See kmeans() details argument. dbscan_eps eps argument DBSCAN method. See n_clusters_dbscan(). iterations number replications. ... Arguments passed methods.","code":""},{"path":"https://easystats.github.io/parameters/reference/cluster_analysis.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cluster Analysis — cluster_analysis","text":"group classification observation vector. returned vector includes missing values, length nrow(x).","code":""},{"path":"https://easystats.github.io/parameters/reference/cluster_analysis.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cluster Analysis — cluster_analysis","text":"print() plot() methods show (standardized) mean value variable within cluster. Thus, higher absolute value indicates certain variable characteristic pronounced within specific cluster (compared cluster groups lower absolute mean values). Clusters classification can obtained via print(x, newdata = NULL, ...).","code":""},{"path":"https://easystats.github.io/parameters/reference/cluster_analysis.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Cluster Analysis — cluster_analysis","text":"also plot()-method implemented see-package.","code":""},{"path":"https://easystats.github.io/parameters/reference/cluster_analysis.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cluster Analysis — cluster_analysis","text":"Maechler M, Rousseeuw P, Struyf , Hubert M, Hornik K (2014) cluster: Cluster Analysis Basics Extensions. R package.","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/cluster_analysis.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cluster Analysis — cluster_analysis","text":"","code":"set.seed(33) # K-Means ==================================================== rez <- cluster_analysis(iris[1:4], n = 3, method = \"kmeans\") rez # Show results #> # Clustering Solution #>  #> The 3 clusters accounted for 68.16% of the total variance of the original data. #>  #> Cluster | n_Obs | Sum_Squares | Sepal.Length | Sepal.Width | Petal.Length | Petal.Width #> --------------------------------------------------------------------------------------- #> 1       |    21 |       23.16 |        -1.32 |       -0.37 |        -1.13 |       -1.11 #> 2       |    33 |       17.33 |        -0.81 |        1.31 |        -1.28 |       -1.22 #> 3       |    96 |      149.26 |         0.57 |       -0.37 |         0.69 |        0.66 #>  #>   Sum_Squares_Total Sum_Squares_Between Sum_Squares_Within        R2 #> 1               596            406.2488           189.7512 0.6816254 #>  #> # You can access the predicted clusters via `predict()`. #>  predict(rez) # Get clusters #>   [1] 2 1 1 1 2 2 2 2 1 1 2 2 1 1 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 1 1 2 2 2 1 1 2 #>  [38] 2 1 2 2 1 1 2 2 1 2 1 2 2 3 3 3 3 3 3 3 1 3 3 1 3 3 3 3 3 3 3 3 3 3 3 3 3 #>  [75] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 1 3 3 3 3 1 3 3 3 3 3 3 3 3 3 3 3 3 #> [112] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 #> [149] 3 3 summary(rez) # Extract the centers values (can use 'plot()' on that) #>   Cluster Sepal.Length Sepal.Width Petal.Length Petal.Width #> 1       1   -1.3232208  -0.3718921   -1.1334386  -1.1111395 #> 2       2   -0.8135055   1.3145538   -1.2825372  -1.2156393 #> 3       3    0.5690971  -0.3705265    0.6888118   0.6609378 if (requireNamespace(\"MASS\", quietly = TRUE)) {   cluster_discrimination(rez) # Perform LDA } #> # Accuracy of Cluster Group Classification via Linear Discriminant Analysis (LDA) #>  #>  Group Accuracy #>      1  100.00% #>      2   71.43% #>      3  100.00% #>  #> Overall accuracy of classification: 96.00% #>   # Hierarchical k-means (more robust k-means) if (require(\"factoextra\", quietly = TRUE)) {   rez <- cluster_analysis(iris[1:4], n = 3, method = \"hkmeans\")   rez # Show results   predict(rez) # Get clusters } #> Welcome! Want to learn more? See two factoextra-related books at https://goo.gl/ve3WBa #>   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 #>  [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 3 3 3 2 2 2 3 2 2 2 2 2 2 2 2 3 2 2 2 2 3 2 2 2 #>  [75] 2 3 3 3 2 2 2 2 2 2 2 3 3 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2 3 3 3 3 2 3 3 3 3 #> [112] 3 3 2 2 3 3 3 3 2 3 2 3 2 3 3 2 3 3 3 3 3 3 2 2 3 3 3 2 3 3 3 2 3 3 3 2 3 #> [149] 3 2  # Hierarchical Clustering (hclust) =========================== rez <- cluster_analysis(iris[1:4], n = 3, method = \"hclust\") rez # Show results #> # Clustering Solution #>  #> The 3 clusters accounted for 74.35% of the total variance of the original data. #>  #> Cluster | n_Obs | Sum_Squares | Sepal.Length | Sepal.Width | Petal.Length | Petal.Width #> --------------------------------------------------------------------------------------- #> 1       |    49 |       40.12 |        -1.00 |        0.90 |        -1.30 |       -1.25 #> 2       |    24 |       18.65 |        -0.40 |       -1.36 |         0.06 |       -0.04 #> 3       |    77 |       94.08 |         0.76 |       -0.15 |         0.81 |        0.81 #>  #>   Sum_Squares_Total Sum_Squares_Between Sum_Squares_Within        R2 #> 1               596            443.1431           152.8569 0.7435286 #>  #> # You can access the predicted clusters via `predict()`. #>  predict(rez) # Get clusters #>   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 #>  [38] 1 1 1 1 2 1 1 1 1 1 1 1 1 3 3 3 2 3 2 3 2 3 2 2 3 2 3 3 3 3 2 2 2 3 3 3 3 #>  [75] 3 3 3 3 3 2 2 2 2 3 3 3 3 2 3 2 2 3 2 2 2 3 3 3 2 2 3 3 3 3 3 3 2 3 3 3 3 #> [112] 3 3 3 3 3 3 3 3 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 #> [149] 3 3  # K-Medoids (pam) ============================================ if (require(\"cluster\", quietly = TRUE)) {   rez <- cluster_analysis(iris[1:4], n = 3, method = \"pam\")   rez # Show results   predict(rez) # Get clusters } #>   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 #>  [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 3 3 3 2 3 3 3 3 3 3 3 3 2 3 3 3 3 3 3 3 3 #>  [75] 3 2 2 2 3 3 3 3 3 3 3 3 2 3 3 3 3 3 3 3 3 3 3 3 3 3 2 3 2 2 2 2 3 2 2 2 2 #> [112] 2 2 3 2 2 2 2 2 3 2 3 2 3 2 2 3 3 2 2 2 2 2 3 3 2 2 2 3 2 2 2 3 2 2 2 3 2 #> [149] 2 3  # PAM with automated number of clusters if (require(\"fpc\", quietly = TRUE)) {   rez <- cluster_analysis(iris[1:4], method = \"pamk\")   rez # Show results   predict(rez) # Get clusters } #>   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 #>  [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 #>  [75] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 #> [112] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 #> [149] 2 2  # DBSCAN ==================================================== if (require(\"dbscan\", quietly = TRUE)) {   # Note that you can assimilate more outliers (cluster 0) to neighbouring   # clusters by setting borderPoints = TRUE.   rez <- cluster_analysis(iris[1:4], method = \"dbscan\", dbscan_eps = 1.45)   rez # Show results   predict(rez) # Get clusters } #>  #> Attaching package: ‘dbscan’ #> The following object is masked from ‘package:fpc’: #>  #>     dbscan #> The following object is masked from ‘package:stats’: #>  #>     as.dendrogram #>   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 #>  [38] 1 1 1 1 0 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 #>  [75] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 #> [112] 2 2 2 2 2 2 0 0 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 #> [149] 2 2  # Mixture ==================================================== if (require(\"mclust\", quietly = TRUE)) {   library(mclust) # Needs the package to be loaded   rez <- cluster_analysis(iris[1:4], method = \"mixture\")   rez # Show results   predict(rez) # Get clusters } #> Package 'mclust' version 6.1.1 #> Type 'citation(\"mclust\")' for citing this R package in publications. #>   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 #>  [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 #>  [75] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 #> [112] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 #> [149] 2 2"},{"path":"https://easystats.github.io/parameters/reference/cluster_centers.html","id":null,"dir":"Reference","previous_headings":"","what":"Find the cluster centers in your data — cluster_centers","title":"Find the cluster centers in your data — cluster_centers","text":"cluster, computes mean (indices) variables. Can used retrieve centers clusters. Also returns within Sum Squares.","code":""},{"path":"https://easystats.github.io/parameters/reference/cluster_centers.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find the cluster centers in your data — cluster_centers","text":"","code":"cluster_centers(data, clusters, fun = mean, ...)"},{"path":"https://easystats.github.io/parameters/reference/cluster_centers.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find the cluster centers in your data — cluster_centers","text":"data data.frame. clusters vector clusters assignments (must length rows data). fun function use, mean default. ... arguments passed functions.","code":""},{"path":"https://easystats.github.io/parameters/reference/cluster_centers.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find the cluster centers in your data — cluster_centers","text":"dataframe containing cluster centers. Attributes include performance statistics distance observation respective cluster centre.","code":""},{"path":"https://easystats.github.io/parameters/reference/cluster_centers.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find the cluster centers in your data — cluster_centers","text":"","code":"k <- kmeans(iris[1:4], 3) cluster_centers(iris[1:4], clusters = k$cluster) #>   Cluster n_Obs Sum_Squares Sepal.Length Sepal.Width Petal.Length Petal.Width #> 1       1    62    39.82097     5.901613    2.748387     4.393548    1.433871 #> 2       2    38    23.87947     6.850000    3.073684     5.742105    2.071053 #> 3       3    50    15.15100     5.006000    3.428000     1.462000    0.246000 cluster_centers(iris[1:4], clusters = k$cluster, fun = median) #>   Cluster n_Obs Sum_Squares Sepal.Length Sepal.Width Petal.Length Petal.Width #> 1       1    62    39.82097          5.9         2.8         4.50         1.4 #> 2       2    38    23.87947          6.7         3.0         5.65         2.1 #> 3       3    50    15.15100          5.0         3.4         1.50         0.2"},{"path":"https://easystats.github.io/parameters/reference/cluster_discrimination.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute a linear discriminant analysis on classified cluster groups — cluster_discrimination","title":"Compute a linear discriminant analysis on classified cluster groups — cluster_discrimination","text":"Computes linear discriminant analysis (LDA) classified cluster groups, determines goodness classification cluster group. See MASS::lda() details.","code":""},{"path":"https://easystats.github.io/parameters/reference/cluster_discrimination.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute a linear discriminant analysis on classified cluster groups — cluster_discrimination","text":"","code":"cluster_discrimination(x, cluster_groups = NULL, ...)"},{"path":"https://easystats.github.io/parameters/reference/cluster_discrimination.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute a linear discriminant analysis on classified cluster groups — cluster_discrimination","text":"x data frame cluster_groups Group classification cluster analysis, can retrieved cluster_analysis() function. ... arguments passed .","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/cluster_discrimination.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute a linear discriminant analysis on classified cluster groups — cluster_discrimination","text":"","code":"# Retrieve group classification from hierarchical cluster analysis clustering <- cluster_analysis(iris[, 1:4], n = 3)  # Goodness of group classification cluster_discrimination(clustering) #> # Accuracy of Cluster Group Classification via Linear Discriminant Analysis (LDA) #>  #>  Group Accuracy #>      1   82.98% #>      2   94.34% #>      3  100.00% #>  #> Overall accuracy of classification: 92.67% #>"},{"path":"https://easystats.github.io/parameters/reference/cluster_meta.html","id":null,"dir":"Reference","previous_headings":"","what":"Metaclustering — cluster_meta","title":"Metaclustering — cluster_meta","text":"One core \"issue\" statistical clustering , many cases, different methods give different results. metaclustering approach proposed easystats (finds echoes consensus clustering; see Monti et al., 2003) consists treating unique clustering solutions ensemble, can derive probability matrix. matrix contains, pair observations, probability cluster. instance, 6th 9th row dataframe assigned similar cluster 5 10 clustering methods, probability grouped together 0.5.","code":""},{"path":"https://easystats.github.io/parameters/reference/cluster_meta.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Metaclustering — cluster_meta","text":"","code":"cluster_meta(list_of_clusters, rownames = NULL, ...)"},{"path":"https://easystats.github.io/parameters/reference/cluster_meta.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Metaclustering — cluster_meta","text":"list_of_clusters list vectors clustering assignments various methods. rownames optional vector row.names matrix. ... Currently used.","code":""},{"path":"https://easystats.github.io/parameters/reference/cluster_meta.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Metaclustering — cluster_meta","text":"matrix containing pairwise (observation) probabilities clustered together methods.","code":""},{"path":"https://easystats.github.io/parameters/reference/cluster_meta.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Metaclustering — cluster_meta","text":"Metaclustering based hypothesis , clustering algorithm embodies different prism sees data, running infinite amount algorithms result emergence \"true\" clusters. number algorithms parameters finite, probabilistic perspective useful proxy. method interesting obvious reasons prefer one another clustering method, well investigate robust clusters different algorithms. metaclustering probability matrix can transformed dissimilarity matrix (one produced dist()) submitted instance hierarchical clustering (hclust()). See example .","code":""},{"path":"https://easystats.github.io/parameters/reference/cluster_meta.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Metaclustering — cluster_meta","text":"","code":"# \\donttest{ data <- iris[1:4]  rez1 <- cluster_analysis(data, n = 2, method = \"kmeans\") rez2 <- cluster_analysis(data, n = 3, method = \"kmeans\") rez3 <- cluster_analysis(data, n = 6, method = \"kmeans\")  list_of_clusters <- list(rez1, rez2, rez3)  m <- cluster_meta(list_of_clusters)  # Visualize matrix without reordering heatmap(m, Rowv = NA, Colv = NA, scale = \"none\") # Without reordering  # Reordered heatmap heatmap(m, scale = \"none\")   # Extract 3 clusters predict(m, n = 3) #> 150 149 148 147 146 145 144 143 142 141 140 139 138 137 136 135 134 133 132 131  #>   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1  #> 130 129 128 127 126 125 124 123 122 121 120 119 118 117 116 115 114 113 112 111  #>   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1  #> 110 109 108 107 106 105 104 103 102 101 100  99  98  97  96  95  94  93  92  91  #>   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1  #>  90  89  88  87  86  85  84  83  82  81  80  79  78  77  76  75  74  73  72  71  #>   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1  #>  70  69  68  67  66  65  64  63  62  61  60  59  58  57  56  55  54  53  52  51  #>   1   1   1   1   1   1   1   1   1   1   1   1   2   1   1   1   3   1   1   1  #>  50  49  48  47  46  45  44  43  42  41  40  39  38  37  36  35  34  33  32  31  #>   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1  #>  30  29  28  27  26  25  24  23  22  21  20  19  18  17  16  15  14  13  12  11  #>   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1  #>  10   9   8   7   6   5   4   3   2   1  #>   1   1   1   1   1   1   1   1   1   1   # Convert to dissimilarity d <- as.dist(abs(m - 1)) model <- hclust(d) plot(model, hang = -1)  # }"},{"path":"https://easystats.github.io/parameters/reference/cluster_performance.html","id":null,"dir":"Reference","previous_headings":"","what":"Performance of clustering models — cluster_performance","title":"Performance of clustering models — cluster_performance","text":"Compute performance indices clustering solutions.","code":""},{"path":"https://easystats.github.io/parameters/reference/cluster_performance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Performance of clustering models — cluster_performance","text":"","code":"cluster_performance(model, ...)  # S3 method for class 'hclust' cluster_performance(model, data, clusters, ...)"},{"path":"https://easystats.github.io/parameters/reference/cluster_performance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Performance of clustering models — cluster_performance","text":"model Cluster model. ... Arguments passed methods. data data frame. clusters vector clusters assignments (must length rows data).","code":""},{"path":"https://easystats.github.io/parameters/reference/cluster_performance.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Performance of clustering models — cluster_performance","text":"","code":"# kmeans model <- kmeans(iris[1:4], 3) cluster_performance(model) #> # Indices of model performance #>  #> Sum_Squares_Total | Sum_Squares_Between | Sum_Squares_Within |    R2 #> -------------------------------------------------------------------- #> 681.371           |             538.617 |            142.754 | 0.790  # hclust data <- iris[1:4] model <- hclust(dist(data)) clusters <- cutree(model, 3) cluster_performance(model, data, clusters) #> # Indices of model performance #>  #> Sum_Squares_Total | Sum_Squares_Between | Sum_Squares_Within |    R2 #> -------------------------------------------------------------------- #> 681.371           |             591.846 |             89.525 | 0.869  # Retrieve performance from parameters params <- model_parameters(kmeans(iris[1:4], 3)) cluster_performance(params) #> # Indices of model performance #>  #> Sum_Squares_Total | Sum_Squares_Between | Sum_Squares_Within |    R2 #> -------------------------------------------------------------------- #> 681.371           |             602.519 |             78.851 | 0.884"},{"path":"https://easystats.github.io/parameters/reference/compare_parameters.html","id":null,"dir":"Reference","previous_headings":"","what":"Compare model parameters of multiple models — compare_parameters","title":"Compare model parameters of multiple models — compare_parameters","text":"Compute extract model parameters multiple regression models. See model_parameters() details.","code":""},{"path":"https://easystats.github.io/parameters/reference/compare_parameters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compare model parameters of multiple models — compare_parameters","text":"","code":"compare_parameters(   ...,   ci = 0.95,   effects = \"fixed\",   component = \"conditional\",   standardize = NULL,   exponentiate = FALSE,   ci_method = \"wald\",   p_adjust = NULL,   select = NULL,   column_names = NULL,   pretty_names = TRUE,   coefficient_names = NULL,   keep = NULL,   drop = NULL,   include_reference = FALSE,   groups = NULL,   verbose = TRUE )  compare_models(   ...,   ci = 0.95,   effects = \"fixed\",   component = \"conditional\",   standardize = NULL,   exponentiate = FALSE,   ci_method = \"wald\",   p_adjust = NULL,   select = NULL,   column_names = NULL,   pretty_names = TRUE,   coefficient_names = NULL,   keep = NULL,   drop = NULL,   include_reference = FALSE,   groups = NULL,   verbose = TRUE )"},{"path":"https://easystats.github.io/parameters/reference/compare_parameters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compare model parameters of multiple models — compare_parameters","text":"... One regression model objects, objects returned model_parameters(). Regression models may different model types. Model objects may passed comma separated, list. model objects passed names list named elements, names used column names. ci Confidence Interval (CI) level. Default 0.95 (95%). effects parameters fixed effects (\"fixed\"), random effects (\"random\"), (\"\") returned? applies mixed models. May abbreviated. calculation random effects parameters takes long, may use effects = \"fixed\". component Model component parameters shown. See documentation related model class model_parameters(). standardize method used standardizing parameters. Can NULL (default; standardization), \"refit\" (re-fitting model standardized data) one \"basic\", \"posthoc\", \"smart\", \"pseudo\". See 'Details' standardize_parameters(). Importantly: \"refit\" method standardize categorical predictors (.e. factors), may different behaviour compared R packages (lm.beta) software packages (like SPSS). mimic behaviours, either use standardize=\"basic\" standardize data datawizard::standardize(force=TRUE) fitting model. mixed models, using methods \"refit\", fixed effects standardized. Robust estimation (.e., vcov set value NULL) standardized parameters works standardize=\"refit\". exponentiate Logical, indicating whether exponentiate coefficients (related confidence intervals). typical logistic regression, generally speaking, models log logit links. also recommended use exponentiate = TRUE models log-transformed response values. models log-transformed response variable, exponentiate = TRUE, one-unit increase predictor associated multiplying outcome predictor's coefficient. Note: Delta-method standard errors also computed (multiplying standard errors transformed coefficients). mimic behaviour software packages, Stata, standard errors poorly estimate uncertainty transformed coefficient. transformed confidence interval clearly captures uncertainty. compare_parameters(), exponentiate = \"nongaussian\" exponentiate coefficients non-Gaussian families. ci_method Method computing degrees freedom p-values confidence intervals (CI). See documentation related model class model_parameters(). p_adjust Character vector, NULL, indicates method adjust p-values. See stats::p.adjust() details. possible adjustment methods \"tukey\", \"scheffe\", \"sidak\" \"none\" explicitly disable adjustment emmGrid objects (emmeans). select Determines columns layout columns printed. three options argument: Selecting columns name index select can character vector (numeric index) column names printed, columns extracted data frame returned model_parameters() related functions. two pre-defined options selecting columns: select = \"minimal\" prints coefficients, confidence intervals p-values, select = \"short\" prints coefficients, standard errors p-values. string expression layout pattern select string \"tokens\" enclosed braces. tokens replaced associated columns, selected columns collapsed one column. Following tokens replaced related coefficients statistics: {estimate}, {se}, {ci} ({ci_low} {ci_high}), {p} {stars}. token {ci} replaced {ci_low}, {ci_high}. Example: select = \"{estimate}{stars} ({ci})\" possible create multiple columns well. | separates values new cells/columns. Example: select = \"{estimate} ({ci})|{p}\". format = \"html\", <br> inserts line break inside cell. See 'Examples'. *. string indicating pre-defined layout select can one following string values, create one following pre-defined column layouts: \"ci\": Estimates confidence intervals, asterisks p-values. equivalent select = \"{estimate} ({ci})\". \"se\": Estimates standard errors, asterisks p-values. equivalent select = \"{estimate} ({se})\". \"ci_p\": Estimates, confidence intervals asterisks p-values. equivalent select = \"{estimate}{stars} ({ci})\". \"se_p\": Estimates, standard errors asterisks p-values. equivalent select = \"{estimate}{stars} ({se})\".. \"ci_p2\": Estimates, confidence intervals numeric p-values, two columns. equivalent select = \"{estimate} ({ci})|{p}\". \"se_p2\": Estimate, standard errors numeric p-values, two columns. equivalent select = \"{estimate} ({se})|{p}\". model_parameters(), glue-like syntax still experimental case complex models (like mixed models) may return expected results. column_names Character vector strings used column headers. Must length number models .... pretty_names Can TRUE, return \"pretty\" (.e. human readable) parameter names. \"labels\", case value variable labels used parameters names. latter works \"labelled\" data, .e. data used fit model \"label\" \"labels\" attributes. See also section Global Options Customize Messages Printing. coefficient_names Character vector strings used column headers coefficient column. Must length number models ..., length 1. length 1, name used coefficient columns. NULL, name coefficient column detected automatically (model_parameters()). keep Character containing regular expression pattern describes parameters included (keep) excluded (drop) returned data frame. keep may also named list regular expressions. non-matching parameters removed output. keep character vector, every parameter name \"Parameter\" column matches regular expression keep selected returned data frame (vice versa, parameter names matching drop excluded). Furthermore, keep one element, merged operator regular expression pattern like : \"(one|two|three)\". keep named list regular expression patterns, names list-element equal column name selection applied. useful model objects model_parameters() returns multiple columns parameter components, like model_parameters.lavaan(). Note regular expression pattern match parameter names stored returned data frame, can different printed. Inspect $Parameter column parameters table get exact parameter names. drop See keep. include_reference Logical, TRUE, reference level factors added parameters table. relevant models categorical predictors. coefficient reference level always 0 (except exponentiate = TRUE, coefficient 1), just completeness. groups Named list, can used group parameters printed output. List elements may either character vectors match name parameters belong one group, list elements can row numbers parameter rows belong one group. names list elements used group names, inserted \"header row\". possible use case might emphasize focal predictors control variables, see 'Examples'. Parameters re-ordered according order used groups, non-matching parameters added end. verbose Toggle warnings messages.","code":""},{"path":"https://easystats.github.io/parameters/reference/compare_parameters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compare model parameters of multiple models — compare_parameters","text":"data frame indices related model's parameters.","code":""},{"path":"https://easystats.github.io/parameters/reference/compare_parameters.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compare model parameters of multiple models — compare_parameters","text":"function early stage yet cope complex models, probably yet properly render model components. also noted including models interaction terms, values parameters change, meaning (main effects, simple slopes), thereby making comparisons hard. Therefore, use function compare models interaction terms models without interaction terms.","code":""},{"path":"https://easystats.github.io/parameters/reference/compare_parameters.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compare model parameters of multiple models — compare_parameters","text":"","code":"data(iris) lm1 <- lm(Sepal.Length ~ Species, data = iris) lm2 <- lm(Sepal.Length ~ Species + Petal.Length, data = iris) compare_parameters(lm1, lm2) #> Parameter            |               lm1 |                  lm2 #> --------------------------------------------------------------- #> (Intercept)          | 5.01 (4.86, 5.15) |  3.68 ( 3.47,  3.89) #> Species [versicolor] | 0.93 (0.73, 1.13) | -1.60 (-1.98, -1.22) #> Species [virginica]  | 1.58 (1.38, 1.79) | -2.12 (-2.66, -1.58) #> Petal Length         |                   |  0.90 ( 0.78,  1.03) #> --------------------------------------------------------------- #> Observations         |               150 |                  150  # custom style compare_parameters(lm1, lm2, select = \"{estimate}{stars} ({se})\") #> Parameter            |            lm1 |             lm2 #> ------------------------------------------------------- #> (Intercept)          | 5.01*** (0.07) |  3.68*** (0.11) #> Species [versicolor] | 0.93*** (0.10) | -1.60*** (0.19) #> Species [virginica]  | 1.58*** (0.10) | -2.12*** (0.27) #> Petal Length         |                |  0.90*** (0.06) #> ------------------------------------------------------- #> Observations         |            150 |             150  # \\donttest{ # custom style, in HTML result <- compare_parameters(lm1, lm2, select = \"{estimate}<br>({se})|{p}\") print_html(result)     Parameter                lm1                       lm2            Estimate(SE)       p       Estimate(SE)       p     (Intercept) 5.01(0.07) <0.001 3.68(0.11) <0.001Species (versicolor) 0.93(0.10) <0.001 -1.60(0.19) <0.001Species (virginica) 1.58(0.10) <0.001 -2.12(0.27) <0.001Petal Length   0.90(0.06) <0.001    Observations 150  150      # }  data(mtcars) m1 <- lm(mpg ~ wt, data = mtcars) m2 <- glm(vs ~ wt + cyl, data = mtcars, family = \"binomial\") compare_parameters(m1, m2) #> Parameter    |                   m1 |                   m2 #> ---------------------------------------------------------- #> (Intercept)  | 37.29 (33.45, 41.12) | 10.62 ( 2.45, 18.79) #> wt           | -5.34 (-6.49, -4.20) |  2.10 (-0.93,  5.13) #> cyl          |                      | -2.93 (-5.63, -0.23) #> ---------------------------------------------------------- #> Observations |                   32 |                   32 # \\donttest{ # exponentiate coefficients, but not for lm compare_parameters(m1, m2, exponentiate = \"nongaussian\") #> Parameter    |                   m1 |                         m2 #> ---------------------------------------------------------------- #> (Intercept)  | 37.29 (33.45, 41.12) | 40911.34 (11.59, 1.44e+08) #> wt           | -5.34 (-6.49, -4.20) |     8.17 ( 0.39,   169.06) #> cyl          |                      |     0.05 ( 0.00,     0.80) #> ---------------------------------------------------------------- #> Observations |                   32 |                         32  # change column names compare_parameters(\"linear model\" = m1, \"logistic reg.\" = m2) #> Parameter    |         linear model |        logistic reg. #> ---------------------------------------------------------- #> (Intercept)  | 37.29 (33.45, 41.12) | 10.62 ( 2.45, 18.79) #> wt           | -5.34 (-6.49, -4.20) |  2.10 (-0.93,  5.13) #> cyl          |                      | -2.93 (-5.63, -0.23) #> ---------------------------------------------------------- #> Observations |                   32 |                   32 compare_parameters(m1, m2, column_names = c(\"linear model\", \"logistic reg.\")) #> Parameter    |         linear model |        logistic reg. #> ---------------------------------------------------------- #> (Intercept)  | 37.29 (33.45, 41.12) | 10.62 ( 2.45, 18.79) #> wt           | -5.34 (-6.49, -4.20) |  2.10 (-0.93,  5.13) #> cyl          |                      | -2.93 (-5.63, -0.23) #> ---------------------------------------------------------- #> Observations |                   32 |                   32  # or as list compare_parameters(list(m1, m2)) #> Parameter    |              Model 1 |              Model 2 #> ---------------------------------------------------------- #> (Intercept)  | 37.29 (33.45, 41.12) | 10.62 ( 2.45, 18.79) #> wt           | -5.34 (-6.49, -4.20) |  2.10 (-0.93,  5.13) #> cyl          |                      | -2.93 (-5.63, -0.23) #> ---------------------------------------------------------- #> Observations |                   32 |                   32 compare_parameters(list(\"linear model\" = m1, \"logistic reg.\" = m2)) #> Parameter    |         linear model |        logistic reg. #> ---------------------------------------------------------- #> (Intercept)  | 37.29 (33.45, 41.12) | 10.62 ( 2.45, 18.79) #> wt           | -5.34 (-6.49, -4.20) |  2.10 (-0.93,  5.13) #> cyl          |                      | -2.93 (-5.63, -0.23) #> ---------------------------------------------------------- #> Observations |                   32 |                   32 # }"},{"path":"https://easystats.github.io/parameters/reference/convert_efa_to_cfa.html","id":null,"dir":"Reference","previous_headings":"","what":"Conversion between EFA results and CFA structure — convert_efa_to_cfa","title":"Conversion between EFA results and CFA structure — convert_efa_to_cfa","text":"Enables conversion Exploratory Factor Analysis (EFA) Confirmatory Factor Analysis (CFA) lavaan-ready structure.","code":""},{"path":"https://easystats.github.io/parameters/reference/convert_efa_to_cfa.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conversion between EFA results and CFA structure — convert_efa_to_cfa","text":"","code":"convert_efa_to_cfa(model, ...)  # S3 method for class 'fa' convert_efa_to_cfa(   model,   threshold = \"max\",   names = NULL,   max_per_dimension = NULL,   ... )  efa_to_cfa(model, ...)"},{"path":"https://easystats.github.io/parameters/reference/convert_efa_to_cfa.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conversion between EFA results and CFA structure — convert_efa_to_cfa","text":"model EFA model (e.g., psych::fa object). ... Arguments passed methods. threshold value 0 1 indicates (absolute) values loadings removed. integer higher 1 indicates n strongest loadings retain. Can also \"max\", case display maximum loading per variable (simple structure). names Vector containing dimension names. max_per_dimension Maximum number variables keep per dimension.","code":""},{"path":"https://easystats.github.io/parameters/reference/convert_efa_to_cfa.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Conversion between EFA results and CFA structure — convert_efa_to_cfa","text":"Converted index.","code":""},{"path":"https://easystats.github.io/parameters/reference/convert_efa_to_cfa.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conversion between EFA results and CFA structure — convert_efa_to_cfa","text":"","code":"# \\donttest{ library(parameters) data(attitude) efa <- psych::fa(attitude, nfactors = 3) #> Loading required namespace: GPArotation  model1 <- efa_to_cfa(efa) model2 <- efa_to_cfa(efa, threshold = 0.3) model3 <- efa_to_cfa(efa, max_per_dimension = 2)  suppressWarnings(anova(   lavaan::cfa(model1, data = attitude),   lavaan::cfa(model2, data = attitude),   lavaan::cfa(model3, data = attitude) )) #>  #> Chi-Squared Difference Test #>  #>                                      Df    AIC    BIC   Chisq Chisq diff  RMSEA #> lavaan::cfa(model3, data = attitude)  3 1111.9 1128.7  3.2673                   #> lavaan::cfa(model2, data = attitude) 10 1540.5 1565.7  9.1827     5.9155 0.0000 #> lavaan::cfa(model1, data = attitude) 12 1549.8 1572.2 22.4374    13.2547 0.4331 #>                                      Df diff Pr(>Chisq)    #> lavaan::cfa(model3, data = attitude)                       #> lavaan::cfa(model2, data = attitude)       7   0.549655    #> lavaan::cfa(model1, data = attitude)       2   0.001324 ** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 # }"},{"path":"https://easystats.github.io/parameters/reference/degrees_of_freedom.html","id":null,"dir":"Reference","previous_headings":"","what":"Degrees of Freedom (DoF) — degrees_of_freedom","title":"Degrees of Freedom (DoF) — degrees_of_freedom","text":"Estimate extract degrees freedom models parameters.","code":""},{"path":"https://easystats.github.io/parameters/reference/degrees_of_freedom.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Degrees of Freedom (DoF) — degrees_of_freedom","text":"","code":"degrees_of_freedom(model, method = \"analytical\", ...)  dof(model, method = \"analytical\", ...)"},{"path":"https://easystats.github.io/parameters/reference/degrees_of_freedom.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Degrees of Freedom (DoF) — degrees_of_freedom","text":"model statistical model. method Type approximation degrees freedom. Can one following: \"residual\" (aka \"analytical\") returns residual degrees freedom, usually stats::df.residual() returns. model object method extract residual degrees freedom, calculated n-p, .e. number observations minus number estimated parameters. residual degrees freedom extracted either approach, returns Inf. \"wald\" returns residual (aka analytical) degrees freedom models t-statistic, 1 models Chi-squared statistic, Inf models. Also returns Inf residual degrees freedom extracted. \"normal\" always returns Inf. \"model\" returns model-based degrees freedom, .e. number (estimated) parameters. mixed models, can also \"ml1\" (\"m-l-1\", approximation degrees freedom based \"m-l-1\" heuristic suggested Elff et al. 2019) \"-within\" (\"betwithin\"). mixed models class merMod, type can also \"satterthwaite\" \"kenward-roger\" (\"kenward\"). See 'Details'. Usually, degrees freedom required calculate p-values confidence intervals, type = \"wald\" likely best choice cases. ... Currently used.","code":""},{"path":"https://easystats.github.io/parameters/reference/degrees_of_freedom.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Degrees of Freedom (DoF) — degrees_of_freedom","text":"many cases, degrees_of_freedom() returns df.residuals(), n-k (number observations minus number parameters). However, degrees_of_freedom() refers model's parameters degrees freedom distribution related test statistic. Thus, models z-statistic, results degrees_of_freedom() df.residuals() differ. Furthermore, approximation methods like \"kenward\" \"satterthwaite\", model parameter can different degree freedom.","code":""},{"path":"https://easystats.github.io/parameters/reference/degrees_of_freedom.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Degrees of Freedom (DoF) — degrees_of_freedom","text":"","code":"model <- lm(Sepal.Length ~ Petal.Length * Species, data = iris) dof(model) #> [1] 144  model <- glm(vs ~ mpg * cyl, data = mtcars, family = \"binomial\") dof(model) #> [1] 28 # \\donttest{ model <- lmer(Sepal.Length ~ Petal.Length + (1 | Species), data = iris) dof(model) #> [1] 146  if (require(\"rstanarm\", quietly = TRUE)) {   model <- stan_glm(     Sepal.Length ~ Petal.Length * Species,     data = iris,     chains = 2,     refresh = 0   )   dof(model) } #> This is rstanarm version 2.32.1 #> - See https://mc-stan.org/rstanarm/articles/priors for changes to default priors! #> - Default priors may change, so it's safest to specify priors, even if equivalent to the defaults. #> - For execution on a local, multicore CPU with excess RAM we recommend calling #>   options(mc.cores = parallel::detectCores()) #>  #> Attaching package: ‘rstanarm’ #> The following object is masked from ‘package:psych’: #>  #>     logit #> The following object is masked from ‘package:boot’: #>  #>     logit #> The following object is masked from ‘package:parameters’: #>  #>     compare_models #> [1] 144 # }"},{"path":"https://easystats.github.io/parameters/reference/display.parameters_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Print tables in different output formats — display.parameters_model","title":"Print tables in different output formats — display.parameters_model","text":"Prints tables (.e. data frame) different output formats. print_md() alias display(format = \"markdown\"), print_html() alias display(format = \"html\"). print_table() specific use cases , currently works compare_parameters() objects.","code":""},{"path":"https://easystats.github.io/parameters/reference/display.parameters_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print tables in different output formats — display.parameters_model","text":"","code":"# S3 method for class 'parameters_model' display(   object,   format = \"markdown\",   pretty_names = TRUE,   split_components = TRUE,   select = NULL,   caption = NULL,   subtitle = NULL,   footer = NULL,   align = NULL,   digits = 2,   ci_digits = digits,   p_digits = 3,   footer_digits = 3,   ci_brackets = c(\"(\", \")\"),   show_sigma = FALSE,   show_formula = FALSE,   zap_small = FALSE,   font_size = \"100%\",   line_padding = 4,   column_labels = NULL,   include_reference = FALSE,   verbose = TRUE,   ... )  # S3 method for class 'parameters_sem' display(   object,   format = \"markdown\",   digits = 2,   ci_digits = digits,   p_digits = 3,   ci_brackets = c(\"(\", \")\"),   ... )  # S3 method for class 'parameters_efa_summary' display(object, format = \"markdown\", digits = 3, ...)  # S3 method for class 'parameters_efa' display(   object,   format = \"markdown\",   digits = 2,   sort = FALSE,   threshold = NULL,   labels = NULL,   ... )  # S3 method for class 'equivalence_test_lm' display(object, format = \"markdown\", digits = 2, ...)  print_table(x, digits = 2, p_digits = 3, theme = \"default\", ...)"},{"path":"https://easystats.github.io/parameters/reference/display.parameters_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print tables in different output formats — display.parameters_model","text":"object object returned model_parameters(),simulate_parameters(), equivalence_test() principal_components(). format String, indicating output format. Can \"markdown\" \"html\". pretty_names Can TRUE, return \"pretty\" (.e. human readable) parameter names. \"labels\", case value variable labels used parameters names. latter works \"labelled\" data, .e. data used fit model \"label\" \"labels\" attributes. See also section Global Options Customize Messages Printing. split_components Logical, TRUE (default), models multiple components (zero-inflation, smooth terms, ...), component printed separate table. FALSE, model parameters printed single table Component column added output. select Determines columns layout columns printed. three options argument: Selecting columns name index select can character vector (numeric index) column names printed, columns extracted data frame returned model_parameters() related functions. two pre-defined options selecting columns: select = \"minimal\" prints coefficients, confidence intervals p-values, select = \"short\" prints coefficients, standard errors p-values. string expression layout pattern select string \"tokens\" enclosed braces. tokens replaced associated columns, selected columns collapsed one column. Following tokens replaced related coefficients statistics: {estimate}, {se}, {ci} ({ci_low} {ci_high}), {p} {stars}. token {ci} replaced {ci_low}, {ci_high}. Example: select = \"{estimate}{stars} ({ci})\" possible create multiple columns well. | separates values new cells/columns. Example: select = \"{estimate} ({ci})|{p}\". format = \"html\", <br> inserts line break inside cell. See 'Examples'. *. string indicating pre-defined layout select can one following string values, create one following pre-defined column layouts: \"ci\": Estimates confidence intervals, asterisks p-values. equivalent select = \"{estimate} ({ci})\". \"se\": Estimates standard errors, asterisks p-values. equivalent select = \"{estimate} ({se})\". \"ci_p\": Estimates, confidence intervals asterisks p-values. equivalent select = \"{estimate}{stars} ({ci})\". \"se_p\": Estimates, standard errors asterisks p-values. equivalent select = \"{estimate}{stars} ({se})\".. \"ci_p2\": Estimates, confidence intervals numeric p-values, two columns. equivalent select = \"{estimate} ({ci})|{p}\". \"se_p2\": Estimate, standard errors numeric p-values, two columns. equivalent select = \"{estimate} ({se})|{p}\". model_parameters(), glue-like syntax still experimental case complex models (like mixed models) may return expected results. caption Table caption string. NULL, depending model, either default caption table caption printed. Use caption = \"\" suppress table caption. subtitle Table title (caption) subtitle, strings. NULL, title subtitle printed, unless stored attributes (table_title, alias table_caption, table_subtitle). x list data frames, caption may list table captions, one table. footer Can either FALSE empty string (.e. \"\") suppress footer, NULL print default footer, string. latter combine string value default footer. align applies HTML tables. May one \"left\", \"right\" \"center\". digits, ci_digits, p_digits Number digits rounding significant figures. May also \"signif\" return significant figures \"scientific\" return scientific notation. Control number digits adding value suffix, e.g. digits = \"scientific4\" scientific notation 4 decimal places, digits = \"signif5\" 5 significant figures (see also signif()). footer_digits Number decimal places values footer summary. ci_brackets Logical, TRUE (default), CI-values encompassed square brackets (else parentheses). show_sigma Logical, TRUE, adds information residual standard deviation. show_formula Logical, TRUE, adds model formula output. zap_small Logical, TRUE, small values rounded digits decimal places. FALSE, values decimal places digits printed scientific notation. font_size HTML tables, font size. line_padding HTML tables, distance (pixel) lines. column_labels Labels columns HTML tables. NULL, automatic column names generated. See 'Examples'. include_reference Logical, TRUE, reference level factors added parameters table. relevant models categorical predictors. coefficient reference level always 0 (except exponentiate = TRUE, coefficient 1), just completeness. verbose Toggle messages warnings. ... Arguments passed format.parameters_model(), insight::format_table() insight::export_table() sort Sort loadings. threshold value 0 1 indicates (absolute) values loadings removed. integer higher 1 indicates n strongest loadings retain. Can also \"max\", case display maximum loading per variable (simple structure). labels character vector containing labels added loadings data. Usually, question related item. x object returned model_parameters(). theme String, indicating table theme. Can one \"default\", \"grid\", \"striped\", \"bootstrap\" \"darklines\".","code":""},{"path":"https://easystats.github.io/parameters/reference/display.parameters_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print tables in different output formats — display.parameters_model","text":"format = \"markdown\", return value character vector markdown-table format. format = \"html\", object class gt_tbl. print_table(), object class tinytable returned.","code":""},{"path":"https://easystats.github.io/parameters/reference/display.parameters_model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Print tables in different output formats — display.parameters_model","text":"display() useful table-output functions, usually printed formatted text-table console, formatted pretty table-rendering markdown documents, knitted rmarkdown PDF Word files. See vignette examples. print_table() special function compare_parameters() objects, prints output formatted HTML table. still somewhat experimental, thus, fixed layout-style available moment (columns estimates, confidence intervals p-values). However, possible include model components, like zero-inflation, random effects table. See 'Examples'. alternative set engine = \"tt\" print_html() use tinytable package creating HTML tables.","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/display.parameters_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print tables in different output formats — display.parameters_model","text":"","code":"model <- lm(mpg ~ wt + cyl, data = mtcars) mp <- model_parameters(model) display(mp) #>  #>  #> |Parameter   | Coefficient |   SE |         95% CI | t(29) |      p | #> |:-----------|:-----------:|:----:|:--------------:|:-----:|:------:| #> |(Intercept) |       39.69 | 1.71 | (36.18, 43.19) | 23.14 | < .001 | #> |wt          |       -3.19 | 0.76 | (-4.74, -1.64) | -4.22 | < .001 | #> |cyl         |       -1.51 | 0.41 | (-2.36, -0.66) | -3.64 | 0.001  |  # \\donttest{ data(iris) lm1 <- lm(Sepal.Length ~ Species, data = iris) lm2 <- lm(Sepal.Length ~ Species + Petal.Length, data = iris) lm3 <- lm(Sepal.Length ~ Species * Petal.Length, data = iris) out <- compare_parameters(lm1, lm2, lm3)  print_html(   out,   select = \"{coef}{stars}|({ci})\",   column_labels = c(\"Estimate\", \"95% CI\") )     Parameter                lm1                       lm2                       lm3            Estimate       95% CI       Estimate       95% CI       Estimate       95% CI     (Intercept) 5.01*** (4.86, 5.15) 3.68*** (3.47, 3.89) 4.21*** (3.41, 5.02)Species (versicolor) 0.93*** (0.73, 1.13) -1.60*** (-1.98, -1.22) -1.81** (-2.99, -0.62)Species (virginica) 1.58*** (1.38, 1.79) -2.12*** (-2.66, -1.58) -3.15*** (-4.41, -1.90)Petal Length   0.90*** (0.78, 1.03) 0.54 (-4.76e-03, 1.09)Species (versicolor) × Petal Length     0.29 (-0.30, 0.87)Species (virginica) × Petal Length     0.45 (-0.12, 1.03)      Observations 150  150  150       # line break, unicode minus-sign print_html(   out,   select = \"{estimate}{stars}<br>({ci_low} \\u2212 {ci_high})\",   column_labels = c(\"Est. (95% CI)\") )     Parameter       Est. (95% CI)       Est. (95% CI)       Est. (95% CI)     (Intercept) 5.01***(4.86 − 5.15) 3.68***(3.47 − 3.89) 4.21***(3.41 − 5.02)Species (versicolor) 0.93***(0.73 − 1.13) -1.60***(-1.98 − -1.22) -1.81**(-2.99 − -0.62)Species (virginica) 1.58***(1.38 − 1.79) -2.12***(-2.66 − -1.58) -3.15***(-4.41 − -1.90)Petal Length  0.90***(0.78 − 1.03) 0.54(-4.76e-03 − 1.09)Species (versicolor) × Petal Length   0.29(-0.30 − 0.87)Species (virginica) × Petal Length   0.45(-0.12 − 1.03)   Observations 150 150 150     # } # \\donttest{ data(iris) data(Salamanders, package = \"glmmTMB\") m1 <- lm(Sepal.Length ~ Species * Petal.Length, data = iris) m2 <- lme4::lmer(   Sepal.Length ~ Petal.Length + Petal.Width + (1 | Species),   data = iris ) m3 <- glmmTMB::glmmTMB(   count ~ spp + mined + (1 | site),   ziformula = ~mined,   family = poisson(),   data = Salamanders ) out <- compare_parameters(m1, m2, m3, effects = \"all\", component = \"all\") print_table(out) #> <!-- preamble start --> #> <!DOCTYPE html>  #> <html lang=\"en\"> #>   <head> #>     <meta charset=\"UTF-8\"> #>     <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"> #>     <title>tinytable_v1mrbt9a9zi6btpr5kel<\/title> #>     <link href=\"https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css\" rel=\"stylesheet\"> #>   <\/head> #>   <body> #> <!-- preamble end --> #>  #>     <script> #>  #>       function styleCell_v1mrbt9a9zi6btpr5kel(i, j, css_id) { #>           var table = document.getElementById(\"tinytable_v1mrbt9a9zi6btpr5kel\"); #>           var cell = table.rows[i]?.cells[j];  // Safe navigation to avoid errors #>           if (cell) { #>               console.log(`Styling cell at (${i}, ${j}) with class ${css_id}`); #>               cell.classList.add(css_id); #>           } else { #>               console.warn(`Cell at (${i}, ${j}) not found.`); #>           } #>       } #>       function insertSpanRow_jqdwe9tz2qtv56gifz98(i, colspan, content) { #>         var table = document.getElementById('tinytable_v1mrbt9a9zi6btpr5kel'); #>         var newRow = table.insertRow(i); #>         var newCell = newRow.insertCell(0); #>         newCell.setAttribute(\"colspan\", colspan); #>         // newCell.innerText = content; #>         // this may be unsafe, but innerText does not interpret <br> #>         newCell.innerHTML = content; #>       } #>       function spanCell_v1mrbt9a9zi6btpr5kel(i, j, rowspan, colspan) { #>         var table = document.getElementById(\"tinytable_v1mrbt9a9zi6btpr5kel\"); #>         const targetRow = table.rows[i]; #>         const targetCell = targetRow.cells[j]; #>         for (let r = 0; r < rowspan; r++) { #>           // Only start deleting cells to the right for the first row (r == 0) #>           if (r === 0) { #>             // Delete cells to the right of the target cell in the first row #>             for (let c = colspan - 1; c > 0; c--) { #>               if (table.rows[i + r].cells[j + c]) { #>                 table.rows[i + r].deleteCell(j + c); #>               } #>             } #>           } #>           // For rows below the first, delete starting from the target column #>           if (r > 0) { #>             for (let c = colspan - 1; c >= 0; c--) { #>               if (table.rows[i + r] && table.rows[i + r].cells[j]) { #>                 table.rows[i + r].deleteCell(j); #>               } #>             } #>           } #>         } #>         // Set rowspan and colspan of the target cell #>         targetCell.rowSpan = rowspan; #>         targetCell.colSpan = colspan; #>       } #>       // tinytable span after #> window.addEventListener('load', function () { insertSpanRow_jqdwe9tz2qtv56gifz98(18, 10, 'Random Effects Variances') }); #> window.addEventListener('load', function () { insertSpanRow_jqdwe9tz2qtv56gifz98(16, 10, 'Fixed Effects (Zero-Inflation Component)') }); #> window.addEventListener('load', function () { insertSpanRow_jqdwe9tz2qtv56gifz98(2, 10, 'Fixed Effects') }); #>       window.addEventListener('load', function () { #>           var cellsToStyle = [ #>             // tinytable style arrays after #>           { positions: [ { i: 20, j: 0 }, { i: 17, j: 3 }, { i: 20, j: 1 }, { i: 17, j: 5 }, { i: 17, j: 0 }, { i: 17, j: 1 }, { i: 17, j: 4 }, { i: 17, j: 2 }, { i: 20, j: 2 }, { i: 17, j: 6 }, { i: 17, j: 9 }, { i: 17, j: 7 }, { i: 20, j: 7 }, { i: 20, j: 5 }, { i: 20, j: 3 }, { i: 20, j: 6 }, { i: 20, j: 4 }, { i: 17, j: 8 }, { i: 20, j: 8 }, { i: 20, j: 9 },  ], css_id: 'tinytable_css_pme1h57cr18eo5291ykb',},  #>           { positions: [ { i: 23, j: 0 },  ], css_id: 'tinytable_css_mty5rvreydubda3pbmoh',},  #>           { positions: [ { i: 1, j: 0 }, { i: 1, j: 8 }, { i: 1, j: 6 }, { i: 1, j: 4 }, { i: 1, j: 2 }, { i: 1, j: 5 }, { i: 1, j: 3 }, { i: 1, j: 9 }, { i: 1, j: 7 }, { i: 1, j: 1 },  ], css_id: 'tinytable_css_j3jtj2bzu6tqeds0w381',},  #>           { positions: [ { i: 8, j: 0 }, { i: 5, j: 0 }, { i: 6, j: 0 }, { i: 7, j: 0 }, { i: 12, j: 0 }, { i: 13, j: 0 }, { i: 14, j: 0 }, { i: 15, j: 0 }, { i: 3, j: 0 }, { i: 4, j: 0 }, { i: 18, j: 0 }, { i: 19, j: 0 }, { i: 11, j: 0 }, { i: 21, j: 0 }, { i: 9, j: 0 }, { i: 10, j: 0 }, { i: 16, j: 0 }, { i: 22, j: 0 },  ], css_id: 'tinytable_css_hj8668kg55wr7mxgbu82',},  #>           { positions: [ { i: 0, j: 1 }, { i: 0, j: 2 }, { i: 0, j: 3 },  ], css_id: 'tinytable_css_gf8q1vwxl0d2sl4sdmw0',},  #>           { positions: [ { i: 0, j: 0 },  ], css_id: 'tinytable_css_dz2528uf6d84vf5qck5z',},  #>           { positions: [ { i: 2, j: 4 }, { i: 2, j: 3 }, { i: 2, j: 1 }, { i: 2, j: 2 }, { i: 2, j: 0 }, { i: 2, j: 8 }, { i: 2, j: 6 }, { i: 2, j: 9 }, { i: 2, j: 7 }, { i: 2, j: 5 },  ], css_id: 'tinytable_css_ce7lhpivtykp79irgoen',},  #>           { positions: [ { i: 23, j: 2 }, { i: 23, j: 1 }, { i: 23, j: 7 }, { i: 23, j: 3 }, { i: 23, j: 8 }, { i: 23, j: 4 }, { i: 23, j: 9 }, { i: 23, j: 5 }, { i: 23, j: 6 },  ], css_id: 'tinytable_css_7akw5q12gu9fg5mdos3v',},  #>           { positions: [ { i: 0, j: 8 }, { i: 0, j: 4 }, { i: 0, j: 7 }, { i: 0, j: 5 }, { i: 0, j: 6 }, { i: 0, j: 9 },  ], css_id: 'tinytable_css_2ziwexp7b81feld7alr8',},  #>           ]; #>  #>           // Loop over the arrays to style the cells #>           cellsToStyle.forEach(function (group) { #>               group.positions.forEach(function (cell) { #>                   styleCell_v1mrbt9a9zi6btpr5kel(cell.i, cell.j, group.css_id); #>               }); #>           }); #>       }); #>     <\/script> #>  #>     <style> #>       /* tinytable css entries after */ #>       .table td.tinytable_css_pme1h57cr18eo5291ykb, .table th.tinytable_css_pme1h57cr18eo5291ykb { font-style: italic; border-bottom: solid #d4d4d4 0.05em; } #>       .table td.tinytable_css_mty5rvreydubda3pbmoh, .table th.tinytable_css_mty5rvreydubda3pbmoh { padding-left: 1em; border-bottom: solid #d4d4d4 0.1em; border-bottom: solid #d3d8dc 0.1em; } #>       .table td.tinytable_css_j3jtj2bzu6tqeds0w381, .table th.tinytable_css_j3jtj2bzu6tqeds0w381 { border-bottom: solid #d3d8dc 0.05em; } #>       .table td.tinytable_css_hj8668kg55wr7mxgbu82, .table th.tinytable_css_hj8668kg55wr7mxgbu82 { padding-left: 1em; } #>       .table td.tinytable_css_gf8q1vwxl0d2sl4sdmw0, .table th.tinytable_css_gf8q1vwxl0d2sl4sdmw0 { border-top: solid #d4d4d4 0.1em; border-bottom: solid #d4d4d4 0.1em; border-top: solid #d3d8dc 0.1em; text-align: center; border-bottom: solid #d3d8dc 0.05em; text-align: center; } #>       .table td.tinytable_css_dz2528uf6d84vf5qck5z, .table th.tinytable_css_dz2528uf6d84vf5qck5z { border-top: solid #d4d4d4 0.1em; border-top: solid #d3d8dc 0.1em; text-align: center; text-align: center; } #>       .table td.tinytable_css_ce7lhpivtykp79irgoen, .table th.tinytable_css_ce7lhpivtykp79irgoen { font-style: italic; } #>       .table td.tinytable_css_7akw5q12gu9fg5mdos3v, .table th.tinytable_css_7akw5q12gu9fg5mdos3v { border-bottom: solid #d4d4d4 0.1em; border-bottom: solid #d3d8dc 0.1em; } #>       .table td.tinytable_css_2ziwexp7b81feld7alr8, .table th.tinytable_css_2ziwexp7b81feld7alr8 { border-top: solid #d4d4d4 0.1em; border-bottom: solid #d4d4d4 0.1em; border-top: solid #d3d8dc 0.1em; text-align: center; text-align: center; } #>     <\/style> #>     <div class=\"container\"> #>       <table class=\"table table-borderless\" id=\"tinytable_v1mrbt9a9zi6btpr5kel\" style=\"width: auto; margin-left: auto; margin-right: auto;\" data-quarto-disable-processing='true'> #>         <thead> #> <tr> #> <th scope=\"col\" align=\"center\" colspan=1> <\/th> #> <th scope=\"col\" align=\"center\" colspan=3>m1<\/th> #> <th scope=\"col\" align=\"center\" colspan=3>m2<\/th> #> <th scope=\"col\" align=\"center\" colspan=3>m3<\/th> #> <\/tr> #>          #>               <tr> #>                 <th scope=\"col\">Parameter<\/th> #>                 <th scope=\"col\">Coefficient<\/th> #>                 <th scope=\"col\">95% CI<\/th> #>                 <th scope=\"col\">p<\/th> #>                 <th scope=\"col\">Coefficient<\/th> #>                 <th scope=\"col\">95% CI<\/th> #>                 <th scope=\"col\">p<\/th> #>                 <th scope=\"col\">Log-Mean<\/th> #>                 <th scope=\"col\">95% CI<\/th> #>                 <th scope=\"col\">p<\/th> #>               <\/tr> #>         <\/thead> #>          #>         <tbody> #>                 <tr> #>                   <td>(Intercept)                        <\/td> #>                   <td>4.21 <\/td> #>                   <td>3.41, 5.02  <\/td> #>                   <td>< .001<\/td> #>                   <td>2.51 <\/td> #>                   <td>1.20, 3.83 <\/td> #>                   <td>< .001<\/td> #>                   <td>-0.36<\/td> #>                   <td>-0.90, 0.18 <\/td> #>                   <td>0.194 <\/td> #>                 <\/tr> #>                 <tr> #>                   <td>Species [versicolor] × Petal Length<\/td> #>                   <td>0.29 <\/td> #>                   <td>-0.30, 0.87 <\/td> #>                   <td>0.334 <\/td> #>                   <td>     <\/td> #>                   <td>           <\/td> #>                   <td>      <\/td> #>                   <td>     <\/td> #>                   <td>            <\/td> #>                   <td>      <\/td> #>                 <\/tr> #>                 <tr> #>                   <td>Petal Length                       <\/td> #>                   <td>0.54 <\/td> #>                   <td>0.00, 1.09  <\/td> #>                   <td>0.052 <\/td> #>                   <td>0.89 <\/td> #>                   <td>0.75, 1.04 <\/td> #>                   <td>< .001<\/td> #>                   <td>     <\/td> #>                   <td>            <\/td> #>                   <td>      <\/td> #>                 <\/tr> #>                 <tr> #>                   <td>Species [versicolor]               <\/td> #>                   <td>-1.81<\/td> #>                   <td>-2.99, -0.62<\/td> #>                   <td>0.003 <\/td> #>                   <td>     <\/td> #>                   <td>           <\/td> #>                   <td>      <\/td> #>                   <td>     <\/td> #>                   <td>            <\/td> #>                   <td>      <\/td> #>                 <\/tr> #>                 <tr> #>                   <td>Species [virginica]                <\/td> #>                   <td>-3.15<\/td> #>                   <td>-4.41, -1.90<\/td> #>                   <td>< .001<\/td> #>                   <td>     <\/td> #>                   <td>           <\/td> #>                   <td>      <\/td> #>                   <td>     <\/td> #>                   <td>            <\/td> #>                   <td>      <\/td> #>                 <\/tr> #>                 <tr> #>                   <td>Species [virginica] × Petal Length <\/td> #>                   <td>0.45 <\/td> #>                   <td>-0.12, 1.03 <\/td> #>                   <td>0.120 <\/td> #>                   <td>     <\/td> #>                   <td>           <\/td> #>                   <td>      <\/td> #>                   <td>     <\/td> #>                   <td>            <\/td> #>                   <td>      <\/td> #>                 <\/tr> #>                 <tr> #>                   <td>Petal Width                        <\/td> #>                   <td>     <\/td> #>                   <td>            <\/td> #>                   <td>      <\/td> #>                   <td>-0.02<\/td> #>                   <td>-0.33, 0.28<\/td> #>                   <td>0.877 <\/td> #>                   <td>     <\/td> #>                   <td>            <\/td> #>                   <td>      <\/td> #>                 <\/tr> #>                 <tr> #>                   <td>spp [EC-L]                         <\/td> #>                   <td>     <\/td> #>                   <td>            <\/td> #>                   <td>      <\/td> #>                   <td>     <\/td> #>                   <td>           <\/td> #>                   <td>      <\/td> #>                   <td>0.67 <\/td> #>                   <td>0.41, 0.92  <\/td> #>                   <td>< .001<\/td> #>                 <\/tr> #>                 <tr> #>                   <td>spp [PR]                           <\/td> #>                   <td>     <\/td> #>                   <td>            <\/td> #>                   <td>      <\/td> #>                   <td>     <\/td> #>                   <td>           <\/td> #>                   <td>      <\/td> #>                   <td>-1.27<\/td> #>                   <td>-1.74, -0.80<\/td> #>                   <td>< .001<\/td> #>                 <\/tr> #>                 <tr> #>                   <td>spp [DM]                           <\/td> #>                   <td>     <\/td> #>                   <td>            <\/td> #>                   <td>      <\/td> #>                   <td>     <\/td> #>                   <td>           <\/td> #>                   <td>      <\/td> #>                   <td>0.27 <\/td> #>                   <td>0.00, 0.54  <\/td> #>                   <td>0.051 <\/td> #>                 <\/tr> #>                 <tr> #>                   <td>spp [EC-A]                         <\/td> #>                   <td>     <\/td> #>                   <td>            <\/td> #>                   <td>      <\/td> #>                   <td>     <\/td> #>                   <td>           <\/td> #>                   <td>      <\/td> #>                   <td>-0.57<\/td> #>                   <td>-0.97, -0.16<\/td> #>                   <td>0.006 <\/td> #>                 <\/tr> #>                 <tr> #>                   <td>spp [DES-L]                        <\/td> #>                   <td>     <\/td> #>                   <td>            <\/td> #>                   <td>      <\/td> #>                   <td>     <\/td> #>                   <td>           <\/td> #>                   <td>      <\/td> #>                   <td>0.63 <\/td> #>                   <td>0.38, 0.87  <\/td> #>                   <td>< .001<\/td> #>                 <\/tr> #>                 <tr> #>                   <td>spp [DF]                           <\/td> #>                   <td>     <\/td> #>                   <td>            <\/td> #>                   <td>      <\/td> #>                   <td>     <\/td> #>                   <td>           <\/td> #>                   <td>      <\/td> #>                   <td>0.12 <\/td> #>                   <td>-0.17, 0.40 <\/td> #>                   <td>0.435 <\/td> #>                 <\/tr> #>                 <tr> #>                   <td>mined [no]                         <\/td> #>                   <td>     <\/td> #>                   <td>            <\/td> #>                   <td>      <\/td> #>                   <td>     <\/td> #>                   <td>           <\/td> #>                   <td>      <\/td> #>                   <td>1.27 <\/td> #>                   <td>0.74, 1.80  <\/td> #>                   <td>< .001<\/td> #>                 <\/tr> #>                 <tr> #>                   <td>(Intercept) (zi)                   <\/td> #>                   <td>     <\/td> #>                   <td>            <\/td> #>                   <td>      <\/td> #>                   <td>     <\/td> #>                   <td>           <\/td> #>                   <td>      <\/td> #>                   <td>0.79 <\/td> #>                   <td>0.26, 1.32  <\/td> #>                   <td>0.004 <\/td> #>                 <\/tr> #>                 <tr> #>                   <td>minedno (zi)                       <\/td> #>                   <td>     <\/td> #>                   <td>            <\/td> #>                   <td>      <\/td> #>                   <td>     <\/td> #>                   <td>           <\/td> #>                   <td>      <\/td> #>                   <td>-1.84<\/td> #>                   <td>-2.46, -1.23<\/td> #>                   <td>< .001<\/td> #>                 <\/tr> #>                 <tr> #>                   <td>SD (Residual)                      <\/td> #>                   <td>     <\/td> #>                   <td>            <\/td> #>                   <td>      <\/td> #>                   <td>0.34 <\/td> #>                   <td>0.30, 0.38 <\/td> #>                   <td>      <\/td> #>                   <td>     <\/td> #>                   <td>            <\/td> #>                   <td>      <\/td> #>                 <\/tr> #>                 <tr> #>                   <td>SD (Intercept: Species)            <\/td> #>                   <td>     <\/td> #>                   <td>            <\/td> #>                   <td>      <\/td> #>                   <td>1.07 <\/td> #>                   <td>0.39, 2.91 <\/td> #>                   <td>      <\/td> #>                   <td>     <\/td> #>                   <td>            <\/td> #>                   <td>      <\/td> #>                 <\/tr> #>                 <tr> #>                   <td>SD (Intercept: site)               <\/td> #>                   <td>     <\/td> #>                   <td>            <\/td> #>                   <td>      <\/td> #>                   <td>     <\/td> #>                   <td>           <\/td> #>                   <td>      <\/td> #>                   <td>0.33 <\/td> #>                   <td>0.18, 0.63  <\/td> #>                   <td>      <\/td> #>                 <\/tr> #>         <\/tbody> #>       <\/table> #>     <\/div> #> <!-- postamble start --> #>   <\/body> #>  #> <\/html> #> <!-- postamble end --> #> <!-- hack to avoid NA insertion in last line -->  # }"},{"path":"https://easystats.github.io/parameters/reference/dominance_analysis.html","id":null,"dir":"Reference","previous_headings":"","what":"Dominance Analysis — dominance_analysis","title":"Dominance Analysis — dominance_analysis","text":"Computes Dominance Analysis Statistics Designations","code":""},{"path":"https://easystats.github.io/parameters/reference/dominance_analysis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dominance Analysis — dominance_analysis","text":"","code":"dominance_analysis(   model,   sets = NULL,   all = NULL,   conditional = TRUE,   complete = TRUE,   quote_args = NULL,   contrasts = model$contrasts,   ... )"},{"path":"https://easystats.github.io/parameters/reference/dominance_analysis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Dominance Analysis — dominance_analysis","text":"model model object supported performance::r2(). See 'Details'. sets (named) list formula objects left hand side/response.  list names, name provided element used label set.  Unnamed list elements provided set number name based position among sets entered. Predictors formula bound together set dominance analysis dominance statistics designations computed predictors together.  Predictors sets must present model submitted model argument argument. formula left hand side/response. Predictors formula included subset dominance analysis R2 value associated subtracted overall value.  Predictors must present model submitted model argument sets argument. conditional Logical.  FALSE conditional dominance matrix computed. conditional dominance desired importance criterion, avoiding computing conditional dominance matrix can save computation time. complete Logical.  FALSE complete dominance matrix computed. complete dominance desired importance criterion, avoiding computing complete dominance designations can save computation time. quote_args character vector arguments model submitted model quote() prior submitting dominance analysis.  necessary data masked arguments (e.g., weights) prevent evaluated applied model causing error. contrasts named list contrasts used model object. list required order correct mapping parameters predictors output model creates indicator codes factor variables using insight::get_modelmatrix(). default, contrast element model object submitted used. model object contrast element user can supply named list. ... used current.","code":""},{"path":"https://easystats.github.io/parameters/reference/dominance_analysis.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Dominance Analysis — dominance_analysis","text":"Object class \"parameters_da\". object class \"parameters_da\" list data.frames composed following elements: General data.frame associates dominance statistics model parameters. variables data.frame include: Parameter Parameter names. General_Dominance Vector general dominance statistics. R2 ascribed variables argument also reported though general dominance statistics. Percent Vector general dominance statistics normalized sum 1. Ranks Vector ranks applied general dominance statistics. Subset Names subset parameter belongs dominance analysis.  data.frame returned refer subset names. Conditional data.frame conditional dominance statistics.  observation represents subset variable represents average increment R2 specific number subsets model.  NULL conditional argument FALSE. Complete data.frame complete dominance designations. subsets observations compared subsets referenced variable. Whether subset variable dominates subset observation represented  logical value. NULL complete argument FALSE.","code":""},{"path":"https://easystats.github.io/parameters/reference/dominance_analysis.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Dominance Analysis — dominance_analysis","text":"Computes two decompositions model's R2 returns matrix designations predictor relative importance determinations can obtained. Note output \"constant\" subset associated component model directly contribute R2 intercept. \"\" subset apportioned component fit statistic considered part dominance analysis therefore receive rank, conditional dominance statistics, complete dominance designations. input model parsed using insight::find_predictors(), yet support interactions, transformations, offsets applied R formula, fail error terms detected. model submitted must accept formula object formula argument.  addition, model object must accept data model estimated data argument.  Formulas submitted using object references (.e., lm(mtcars$mpg ~ mtcars$vs)) functions accept data non-data argument (e.g., survey::svyglm() uses design) fail error. Models return TRUE insight::model_info() function's values \"is_bayesian\", \"is_mixed\", \"is_gam\", is_multivariate\", \"is_zero_inflated\", \"is_hurdle\" supported current. performance::r2() returns multiple values, first used default.","code":""},{"path":"https://easystats.github.io/parameters/reference/dominance_analysis.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Dominance Analysis — dominance_analysis","text":"Azen, R., & Budescu, D. V. (2003). dominance analysis approach comparing predictors multiple regression. Psychological Methods, 8(2), 129-148. doi:10.1037/1082-989X.8.2.129 Budescu, D. V. (1993). Dominance analysis: new approach problem relative importance predictors multiple regression. Psychological Bulletin, 114(3), 542-551. doi:10.1037/0033-2909.114.3.542 Groemping, U. (2007). Estimators relative importance linear regression based variance decomposition. American Statistician, 61(2), 139-147. doi:10.1198/000313007X188252","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/dominance_analysis.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Dominance Analysis — dominance_analysis","text":"Joseph Luchman","code":""},{"path":"https://easystats.github.io/parameters/reference/dominance_analysis.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Dominance Analysis — dominance_analysis","text":"","code":"data(mtcars)  # Dominance Analysis with Logit Regression model <- glm(vs ~ cyl + carb + mpg, data = mtcars, family = binomial())  performance::r2(model) #> # R2 for Logistic Regression #>   Tjur's R2: 0.741 dominance_analysis(model) #> # Dominance Analysis Results #>  #> Model R2 Value:  0.741  #>  #> General Dominance Statistics #>  #> Parameter   | General Dominance | Percent | Ranks |   Subset #> ------------------------------------------------------------ #> (Intercept) |                   |         |       | constant #> cyl         |             0.366 |   0.493 |     1 |      cyl #> carb        |             0.178 |   0.241 |     3 |     carb #> mpg         |             0.197 |   0.266 |     2 |      mpg #>  #> Conditional Dominance Statistics #>  #> Subset | IVs: 1 | IVs: 2 | IVs: 3 #> --------------------------------- #> cyl    |  0.654 |  0.254 |  0.190 #> carb   |  0.394 |  0.066 |  0.074 #> mpg    |  0.474 |  0.085 |  0.032 #>  #> Complete Dominance Designations #>  #> Subset | < cyl | < carb | < mpg #> ------------------------------- #> cyl    |       |  FALSE | FALSE #> carb   |  TRUE |        |       #> mpg    |  TRUE |        |        # Dominance Analysis with Weighted Logit Regression model_wt <- glm(vs ~ cyl + carb + mpg,   data = mtcars,   weights = wt, family = quasibinomial() )  dominance_analysis(model_wt, quote_args = \"weights\") #> # Dominance Analysis Results #>  #> Model R2 Value:  0.776  #>  #> General Dominance Statistics #>  #> Parameter   | General Dominance | Percent | Ranks |   Subset #> ------------------------------------------------------------ #> (Intercept) |                   |         |       | constant #> cyl         |             0.390 |   0.503 |     1 |      cyl #> carb        |             0.174 |   0.224 |     3 |     carb #> mpg         |             0.212 |   0.273 |     2 |      mpg #>  #> Conditional Dominance Statistics #>  #> Subset | IVs: 1 | IVs: 2 | IVs: 3 #> --------------------------------- #> cyl    |  0.679 |  0.279 |  0.213 #> carb   |  0.376 |  0.062 |  0.083 #> mpg    |  0.496 |  0.100 |  0.039 #>  #> Complete Dominance Designations #>  #> Subset | < cyl | < carb | < mpg #> ------------------------------- #> cyl    |       |  FALSE | FALSE #> carb   |  TRUE |        |       #> mpg    |  TRUE |        |"},{"path":"https://easystats.github.io/parameters/reference/dot-data_frame.html","id":null,"dir":"Reference","previous_headings":"","what":"help-functions — .data_frame","title":"help-functions — .data_frame","text":"help-functions","code":""},{"path":"https://easystats.github.io/parameters/reference/dot-data_frame.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"help-functions — .data_frame","text":"","code":".data_frame(...)"},{"path":"https://easystats.github.io/parameters/reference/dot-factor_to_dummy.html","id":null,"dir":"Reference","previous_headings":"","what":"Safe transformation from factor/character to numeric — .factor_to_dummy","title":"Safe transformation from factor/character to numeric — .factor_to_dummy","text":"Safe transformation factor/character numeric","code":""},{"path":"https://easystats.github.io/parameters/reference/dot-factor_to_dummy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Safe transformation from factor/character to numeric — .factor_to_dummy","text":"","code":".factor_to_dummy(x)"},{"path":"https://easystats.github.io/parameters/reference/dot-filter_component.html","id":null,"dir":"Reference","previous_headings":"","what":"for models with zero-inflation component, return required component of model-summary — .filter_component","title":"for models with zero-inflation component, return required component of model-summary — .filter_component","text":"models zero-inflation component, return required component model-summary","code":""},{"path":"https://easystats.github.io/parameters/reference/dot-filter_component.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"for models with zero-inflation component, return required component of model-summary — .filter_component","text":"","code":".filter_component(dat, component)"},{"path":"https://easystats.github.io/parameters/reference/dot-n_factors_bartlett.html","id":null,"dir":"Reference","previous_headings":"","what":"Bartlett, Anderson and Lawley Procedures — .n_factors_bartlett","title":"Bartlett, Anderson and Lawley Procedures — .n_factors_bartlett","text":"Bartlett, Anderson Lawley Procedures","code":""},{"path":"https://easystats.github.io/parameters/reference/dot-n_factors_bartlett.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bartlett, Anderson and Lawley Procedures — .n_factors_bartlett","text":"","code":".n_factors_bartlett(eigen_values = NULL, model = \"factors\", nobs = NULL)"},{"path":"https://easystats.github.io/parameters/reference/dot-n_factors_bentler.html","id":null,"dir":"Reference","previous_headings":"","what":"Bentler and Yuan's Procedure — .n_factors_bentler","title":"Bentler and Yuan's Procedure — .n_factors_bentler","text":"Bentler Yuan's Procedure","code":""},{"path":"https://easystats.github.io/parameters/reference/dot-n_factors_bentler.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bentler and Yuan's Procedure — .n_factors_bentler","text":"","code":".n_factors_bentler(eigen_values = NULL, model = \"factors\", nobs = NULL)"},{"path":"https://easystats.github.io/parameters/reference/dot-n_factors_cng.html","id":null,"dir":"Reference","previous_headings":"","what":"Cattell-Nelson-Gorsuch CNG Indices — .n_factors_cng","title":"Cattell-Nelson-Gorsuch CNG Indices — .n_factors_cng","text":"Cattell-Nelson-Gorsuch CNG Indices","code":""},{"path":"https://easystats.github.io/parameters/reference/dot-n_factors_cng.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cattell-Nelson-Gorsuch CNG Indices — .n_factors_cng","text":"","code":".n_factors_cng(eigen_values = NULL, model = \"factors\")"},{"path":"https://easystats.github.io/parameters/reference/dot-n_factors_mreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Multiple Regression Procedure — .n_factors_mreg","title":"Multiple Regression Procedure — .n_factors_mreg","text":"Multiple Regression Procedure","code":""},{"path":"https://easystats.github.io/parameters/reference/dot-n_factors_mreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multiple Regression Procedure — .n_factors_mreg","text":"","code":".n_factors_mreg(eigen_values = NULL, model = \"factors\")"},{"path":"https://easystats.github.io/parameters/reference/dot-n_factors_scree.html","id":null,"dir":"Reference","previous_headings":"","what":"Non Graphical Cattell's Scree Test — .n_factors_scree","title":"Non Graphical Cattell's Scree Test — .n_factors_scree","text":"Non Graphical Cattell's Scree Test","code":""},{"path":"https://easystats.github.io/parameters/reference/dot-n_factors_scree.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Non Graphical Cattell's Scree Test — .n_factors_scree","text":"","code":".n_factors_scree(eigen_values = NULL, model = \"factors\")"},{"path":"https://easystats.github.io/parameters/reference/dot-n_factors_sescree.html","id":null,"dir":"Reference","previous_headings":"","what":"Standard Error Scree and Coefficient of Determination Procedures — .n_factors_sescree","title":"Standard Error Scree and Coefficient of Determination Procedures — .n_factors_sescree","text":"Standard Error Scree Coefficient Determination Procedures","code":""},{"path":"https://easystats.github.io/parameters/reference/dot-n_factors_sescree.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Standard Error Scree and Coefficient of Determination Procedures — .n_factors_sescree","text":"","code":".n_factors_sescree(eigen_values = NULL, model = \"factors\")"},{"path":"https://easystats.github.io/parameters/reference/equivalence_test.lm.html","id":null,"dir":"Reference","previous_headings":"","what":"Equivalence test — equivalence_test.lm","title":"Equivalence test — equivalence_test.lm","text":"Compute (conditional) equivalence test frequentist models.","code":""},{"path":"https://easystats.github.io/parameters/reference/equivalence_test.lm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Equivalence test — equivalence_test.lm","text":"","code":"# S3 method for class 'lm' equivalence_test(   x,   range = \"default\",   ci = 0.95,   rule = \"classic\",   effects = \"fixed\",   vcov = NULL,   vcov_args = NULL,   verbose = TRUE,   ... )  # S3 method for class 'ggeffects' equivalence_test(   x,   range = \"default\",   rule = \"classic\",   test = \"pairwise\",   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/parameters/reference/equivalence_test.lm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Equivalence test — equivalence_test.lm","text":"x statistical model. range range practical equivalence effect. May \"default\", automatically define range based properties model's data. ci Confidence Interval (CI) level. Default 0.95 (95%). rule Character, indicating rules testing practical equivalence. Can \"bayes\", \"classic\" \"cet\". See 'Details'. effects parameters fixed effects (\"fixed\"), random effects (\"random\"), (\"\") returned? applies mixed models. May abbreviated. calculation random effects parameters takes long, may use effects = \"fixed\". vcov Variance-covariance matrix used compute uncertainty estimates (e.g., robust standard errors). argument accepts covariance matrix, function returns covariance matrix, string identifies function used compute covariance matrix. covariance matrix function returns covariance matrix (e.g., stats::vcov()) string indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC Cluster-robust: \"CR\", \"CR0\", \"CR1\", \"CR1p\", \"CR1S\", \"CR2\", \"CR3\". See ?clubSandwich::vcovCR Bootstrap: \"BS\", \"xy\", \"residual\", \"wild\", \"mammen\", \"fractional\", \"jackknife\", \"norm\", \"webb\". See ?sandwich::vcovBS sandwich package functions: \"HAC\", \"PC\", \"CL\", \"OPG\", \"PL\". vcov_args List arguments passed function identified vcov argument. function typically supplied sandwich clubSandwich packages. Please refer documentation (e.g., ?sandwich::vcovHAC) see list available arguments. estimation type (argument type) given, default type \"HC\" equals default sandwich package; type \"CR\", default set \"CR3\". verbose Toggle warnings messages. ... Arguments passed methods. test Hypothesis test computing contrasts pairwise comparisons. See ?ggeffects::test_predictions details.","code":""},{"path":"https://easystats.github.io/parameters/reference/equivalence_test.lm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Equivalence test — equivalence_test.lm","text":"data frame.","code":""},{"path":"https://easystats.github.io/parameters/reference/equivalence_test.lm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Equivalence test — equivalence_test.lm","text":"classical null hypothesis significance testing (NHST) within frequentist framework, possible accept null hypothesis, H0 - unlike Bayesian statistics, probability statements possible. \"... one can reject null hypothesis test statistics falls critical region(s), fail reject hypothesis. latter case, can say significant effect observed, one conclude null hypothesis true.\" (Pernet 2017). One way address issues without Bayesian methods Equivalence Testing, implemented equivalence_test(). either can reject null hypothesis claim inconclusive result NHST, equivalence test - according Pernet - adds third category, \"accept\". Roughly speaking, idea behind equivalence testing frequentist framework check whether estimate uncertainty (.e. confidence interval) falls within region \"practical equivalence\". Depending rule test (see ), statistical significance necessarily indicate whether null hypothesis can rejected , .e. classical interpretation p-value may differ results returned equivalence test.","code":""},{"path":"https://easystats.github.io/parameters/reference/equivalence_test.lm.html","id":"calculation-of-equivalence-testing","dir":"Reference","previous_headings":"","what":"Calculation of equivalence testing","title":"Equivalence test — equivalence_test.lm","text":"\"bayes\" - Bayesian rule (Kruschke 2018) rule follows \"HDI+ROPE decision rule\" (Kruschke, 2014, 2018) used Bayesian counterpart(). means, confidence intervals completely outside ROPE, \"null hypothesis\" parameter \"rejected\". ROPE completely covers CI, null hypothesis accepted. Else, undecided whether accept reject null hypothesis. Desirable results low proportions inside ROPE (closer zero better). \"classic\" - TOST rule (Lakens 2017) rule follows \"TOST rule\", .e. two one-sided test procedure (Lakens 2017). Following rule... practical equivalence assumed (.e. H0 \"accepted\") narrow confidence intervals completely inside ROPE, matter effect statistically significant ; practical equivalence (.e. H0) rejected, coefficient statistically significant, narrow confidence intervals (.e. 1-2*alpha) include exclude ROPE boundaries, narrow confidence intervals fully covered ROPE; else decision whether accept reject practical equivalence undecided (.e. effects statistically significant narrow confidence intervals overlaps ROPE). \"cet\" - Conditional Equivalence Testing (Campbell/Gustafson 2018) Conditional Equivalence Testing described Campbell Gustafson 2018. According rule, practical equivalence rejected coefficient statistically significant. effect significant narrow confidence intervals completely inside ROPE, accept (.e. assume) practical equivalence, else undecided.","code":""},{"path":"https://easystats.github.io/parameters/reference/equivalence_test.lm.html","id":"levels-of-confidence-intervals-used-for-equivalence-testing","dir":"Reference","previous_headings":"","what":"Levels of Confidence Intervals used for Equivalence Testing","title":"Equivalence test — equivalence_test.lm","text":"rule = \"classic\", \"narrow\" confidence intervals used equivalence testing. \"Narrow\" means, intervals 1 - alpha, 1 - 2 * alpha. Thus, ci = .95, alpha assumed 0.05 internally ci-level 0.90 used. rule = \"cet\" uses regular narrow confidence intervals, rule = \"bayes\" uses regular intervals.","code":""},{"path":"https://easystats.github.io/parameters/reference/equivalence_test.lm.html","id":"p-values","dir":"Reference","previous_headings":"","what":"p-Values","title":"Equivalence test — equivalence_test.lm","text":"equivalence p-value area (cumulative) confidence distribution outside region equivalence. can interpreted p-value rejecting alternative hypothesis accepting \"null hypothesis\" (.e. assuming practical equivalence). , high p-value means reject assumption practical equivalence accept alternative hypothesis.","code":""},{"path":"https://easystats.github.io/parameters/reference/equivalence_test.lm.html","id":"second-generation-p-value-sgpv-","dir":"Reference","previous_headings":"","what":"Second Generation p-Value (SGPV)","title":"Equivalence test — equivalence_test.lm","text":"Second generation p-values (SGPV) proposed statistic represents proportion data-supported hypotheses also null hypotheses (Blume et al. 2018, Lakens Delacre 2020). represents proportion full confidence interval range (assuming normally t-distributed, equal-tailed interval, based model) inside ROPE. SGPV ranges zero one. Higher values indicate effect likely practically equivalent (\"interest\"). Note assumed interval, used calculate SGPV, estimation full interval based chosen confidence level. example, 95% confidence interval coefficient ranges -1 1, underlying full (normally t-distributed) interval approximately ranges -1.9 1.9, see also following code:   ensures SGPV always refers general compatible parameter space coefficients, independent confidence interval chosen testing practical equivalence. Therefore, SGPV full interval similar ROPE coverage Bayesian equivalence tests, see following code:","code":"# simulate full normal distribution out <- bayestestR::distribution_normal(10000, 0, 0.5) # range of \"full\" distribution range(out) # range of 95% CI round(quantile(out, probs = c(0.025, 0.975)), 2) library(bayestestR) library(brms) m <- lm(mpg ~ gear + wt + cyl + hp, data = mtcars) m2 <- brm(mpg ~ gear + wt + cyl + hp, data = mtcars) # SGPV for frequentist models equivalence_test(m) # similar to ROPE coverage of Bayesian models equivalence_test(m2) # similar to ROPE coverage of simulated draws / bootstrap samples equivalence_test(simulate_model(m))"},{"path":"https://easystats.github.io/parameters/reference/equivalence_test.lm.html","id":"rope-range","dir":"Reference","previous_headings":"","what":"ROPE range","title":"Equivalence test — equivalence_test.lm","text":"attention required finding suitable values ROPE limits (argument range). See 'Details' bayestestR::rope_range() information.","code":""},{"path":"https://easystats.github.io/parameters/reference/equivalence_test.lm.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Equivalence test — equivalence_test.lm","text":"also plot()-method implemented see-package.","code":""},{"path":"https://easystats.github.io/parameters/reference/equivalence_test.lm.html","id":"statistical-inference-how-to-quantify-evidence","dir":"Reference","previous_headings":"","what":"Statistical inference - how to quantify evidence","title":"Equivalence test — equivalence_test.lm","text":"standardized approach drawing conclusions based available data statistical models. frequently chosen also much criticized approach evaluate results based statistical significance (Amrhein et al. 2017). sophisticated way test whether estimated effects exceed \"smallest effect size interest\", avoid even smallest effects considered relevant simply statistically significant, clinically practically irrelevant (Lakens et al. 2018, Lakens 2024). rather unconventional approach, nevertheless advocated various authors, interpret results classical regression models either terms probabilities, similar usual approach Bayesian statistics (Schweder 2018; Schweder Hjort 2003; Vos 2022) terms relative measure \"evidence\" \"compatibility\" data (Greenland et al. 2022; Rafi Greenland 2020), nevertheless comes close probabilistic interpretation. detailed discussion topic found documentation p_function(). parameters package provides several options functions aid statistical inference. , example: equivalence_test(), compute (conditional) equivalence test frequentist models p_significance(), compute probability practical significance, can conceptualized unidirectional equivalence test p_function(), consonance function, compute p-values compatibility (confidence) intervals statistical models pd argument (setting pd = TRUE) model_parameters() includes column probability direction, .e. probability parameter strictly positive negative. See bayestestR::p_direction() details. plotting desired, p_direction() function can used, together plot(). s_value argument (setting s_value = TRUE) model_parameters() replaces p-values related S-values (Rafi Greenland 2020) finally, possible generate distributions model coefficients generating bootstrap-samples (setting bootstrap = TRUE) simulating draws model coefficients using simulate_model(). samples can treated \"posterior samples\" used many functions bayestestR package. shown options functions derive methods originally implemented Bayesian models (Makowski et al. 2019). However, assuming model assumptions met (means, model fits well data, correct model chosen reflects data generating process (distributional model family) etc.), seems appropriate interpret results classical frequentist models \"Bayesian way\" (details: documentation p_function()).","code":""},{"path":"https://easystats.github.io/parameters/reference/equivalence_test.lm.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Equivalence test — equivalence_test.lm","text":"Amrhein, V., Korner-Nievergelt, F., Roth, T. (2017). earth flat (p > 0.05): Significance thresholds crisis unreplicable research. PeerJ, 5, e3544. doi:10.7717/peerj.3544 Blume, J. D., D'Agostino McGowan, L., Dupont, W. D., & Greevy, R. . (2018). Second-generation p-values: Improved rigor, reproducibility, & transparency statistical analyses. PLOS ONE, 13(3), e0188299. https://doi.org/10.1371/journal.pone.0188299 Campbell, H., & Gustafson, P. (2018). Conditional equivalence testing: alternative remedy publication bias. PLOS ONE, 13(4), e0195145. doi: 10.1371/journal.pone.0195145 Greenland S, Rafi Z, Matthews R, Higgs M. Aid Scientific Inference, Emphasize Unconditional Compatibility Descriptions Statistics. (2022) https://arxiv.org/abs/1909.08583v7 (Accessed November 10, 2022) Kruschke, J. K. (2014). Bayesian data analysis: tutorial R, JAGS, Stan. Academic Press Kruschke, J. K. (2018). Rejecting accepting parameter values Bayesian estimation. Advances Methods Practices Psychological Science, 1(2), 270-280. doi: 10.1177/2515245918771304 Lakens, D. (2017). Equivalence Tests: Practical Primer t Tests, Correlations, Meta-Analyses. Social Psychological Personality Science, 8(4), 355–362. doi: 10.1177/1948550617697177 Lakens, D. (2024). Improving Statistical Inferences (Version v1.5.1). Retrieved https://lakens.github.io/statistical_inferences/. doi:10.5281/ZENODO.6409077 Lakens, D., Delacre, M. (2020). Equivalence Testing Second Generation P-Value. Meta-Psychology, 4. https://doi.org/10.15626/MP.2018.933 Lakens, D., Scheel, . M., Isager, P. M. (2018). Equivalence Testing Psychological Research: Tutorial. Advances Methods Practices Psychological Science, 1(2), 259–269. doi:10.1177/2515245918770963 Makowski, D., Ben-Shachar, M. S., Chen, S. H. ., Lüdecke, D. (2019). Indices Effect Existence Significance Bayesian Framework. Frontiers Psychology, 10, 2767. doi:10.3389/fpsyg.2019.02767 Pernet, C. (2017). Null hypothesis significance testing: guide commonly misunderstood concepts recommendations good practice. F1000Research, 4, 621. doi: 10.12688/f1000research.6963.5 Rafi Z, Greenland S. Semantic cognitive tools aid statistical science: replace confidence significance compatibility surprise. BMC Medical Research Methodology (2020) 20:244. Schweder T. Confidence epistemic probability empirical science. Journal Statistical Planning Inference (2018) 195:116–125. doi:10.1016/j.jspi.2017.09.016 Schweder T, Hjort NL. Frequentist analogues priors posteriors. Stigum, B. (ed.), Econometrics Philosophy Economics: Theory Data Confrontation Economics, pp. 285-217. Princeton University Press, Princeton, NJ, 2003 Vos P, Holbert D. Frequentist statistical inference without repeated sampling. Synthese 200, 89 (2022). doi:10.1007/s11229-022-03560-x","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/equivalence_test.lm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Equivalence test — equivalence_test.lm","text":"","code":"data(qol_cancer) model <- lm(QoL ~ time + age + education, data = qol_cancer)  # default rule equivalence_test(model) #> # TOST-test for Practical Equivalence #>  #>   ROPE: [-1.99 1.99] #>  #> Parameter        |         90% CI |   SGPV | Equivalence |      p #> ----------------------------------------------------------------- #> (Intercept)      | [59.33, 68.41] | < .001 |    Rejected | > .999 #> time             | [-0.76,  2.53] | 0.905  |   Undecided | 0.137  #> age              | [-0.26,  0.32] | > .999 |    Accepted | < .001 #> education [mid]  | [ 5.13, 12.39] | < .001 |    Rejected | 0.999  #> education [high] | [10.14, 18.57] | < .001 |    Rejected | > .999  # using heteroscedasticity-robust standard errors equivalence_test(model, vcov = \"HC3\") #> # TOST-test for Practical Equivalence #>  #>   ROPE: [-1.99 1.99] #>  #> Parameter        |         90% CI |   SGPV | Equivalence |      p #> ----------------------------------------------------------------- #> (Intercept)      | [59.22, 68.52] | < .001 |    Rejected | > .999 #> time             | [-0.80,  2.57] | 0.899  |   Undecided | 0.144  #> age              | [-0.27,  0.32] | > .999 |    Accepted | < .001 #> education [mid]  | [ 4.95, 12.58] | < .001 |    Rejected | 0.998  #> education [high] | [10.17, 18.54] | < .001 |    Rejected | > .999  # conditional equivalence test equivalence_test(model, rule = \"cet\") #> # Conditional Equivalence Testing #>  #>   ROPE: [-1.99 1.99] #>  #> Parameter        |         90% CI |   SGPV | Equivalence |      p #> ----------------------------------------------------------------- #> (Intercept)      | [59.33, 68.41] | < .001 |    Rejected | > .999 #> time             | [-0.76,  2.53] | 0.905  |   Undecided | 0.137  #> age              | [-0.26,  0.32] | > .999 |    Accepted | < .001 #> education [mid]  | [ 5.13, 12.39] | < .001 |    Rejected | 0.999  #> education [high] | [10.14, 18.57] | < .001 |    Rejected | > .999  # plot method if (require(\"see\", quietly = TRUE)) {   result <- equivalence_test(model)   plot(result) }"},{"path":"https://easystats.github.io/parameters/reference/fish.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample data set — fish","title":"Sample data set — fish","text":"sample data set, used tests examples.","code":""},{"path":"https://easystats.github.io/parameters/reference/format_df_adjust.html","id":null,"dir":"Reference","previous_headings":"","what":"Format the name of the degrees-of-freedom adjustment methods — format_df_adjust","title":"Format the name of the degrees-of-freedom adjustment methods — format_df_adjust","text":"Format name degrees--freedom adjustment methods.","code":""},{"path":"https://easystats.github.io/parameters/reference/format_df_adjust.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Format the name of the degrees-of-freedom adjustment methods — format_df_adjust","text":"","code":"format_df_adjust(   method,   approx_string = \"-approximated\",   dof_string = \" degrees of freedom\" )"},{"path":"https://easystats.github.io/parameters/reference/format_df_adjust.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Format the name of the degrees-of-freedom adjustment methods — format_df_adjust","text":"method Name method. approx_string, dof_string Suffix added name method returned string.","code":""},{"path":"https://easystats.github.io/parameters/reference/format_df_adjust.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Format the name of the degrees-of-freedom adjustment methods — format_df_adjust","text":"formatted string.","code":""},{"path":"https://easystats.github.io/parameters/reference/format_df_adjust.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Format the name of the degrees-of-freedom adjustment methods — format_df_adjust","text":"","code":"library(parameters)  format_df_adjust(\"kenward\") #> [1] \"Kenward-Roger-approximated degrees of freedom\" format_df_adjust(\"kenward\", approx_string = \"\", dof_string = \" DoF\") #> [1] \"Kenward-Roger DoF\""},{"path":"https://easystats.github.io/parameters/reference/format_order.html","id":null,"dir":"Reference","previous_headings":"","what":"Order (first, second, ...) formatting — format_order","title":"Order (first, second, ...) formatting — format_order","text":"Format order.","code":""},{"path":"https://easystats.github.io/parameters/reference/format_order.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Order (first, second, ...) formatting — format_order","text":"","code":"format_order(order, textual = TRUE, ...)"},{"path":"https://easystats.github.io/parameters/reference/format_order.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Order (first, second, ...) formatting — format_order","text":"order value vector orders. textual Return number words. FALSE, run insight::format_value(). ... Arguments passed insight::format_value() textual FALSE.","code":""},{"path":"https://easystats.github.io/parameters/reference/format_order.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Order (first, second, ...) formatting — format_order","text":"formatted string.","code":""},{"path":"https://easystats.github.io/parameters/reference/format_order.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Order (first, second, ...) formatting — format_order","text":"","code":"format_order(2) #> [1] \"second\" format_order(8) #> [1] \"eigth\" format_order(25, textual = FALSE) #> [1] \"25th\""},{"path":"https://easystats.github.io/parameters/reference/format_p_adjust.html","id":null,"dir":"Reference","previous_headings":"","what":"Format the name of the p-value adjustment methods — format_p_adjust","title":"Format the name of the p-value adjustment methods — format_p_adjust","text":"Format name p-value adjustment methods.","code":""},{"path":"https://easystats.github.io/parameters/reference/format_p_adjust.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Format the name of the p-value adjustment methods — format_p_adjust","text":"","code":"format_p_adjust(method)"},{"path":"https://easystats.github.io/parameters/reference/format_p_adjust.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Format the name of the p-value adjustment methods — format_p_adjust","text":"method Name method.","code":""},{"path":"https://easystats.github.io/parameters/reference/format_p_adjust.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Format the name of the p-value adjustment methods — format_p_adjust","text":"string full surname(s) author(s), including year publication, adjustment-method.","code":""},{"path":"https://easystats.github.io/parameters/reference/format_p_adjust.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Format the name of the p-value adjustment methods — format_p_adjust","text":"","code":"library(parameters)  format_p_adjust(\"holm\") #> [1] \"Holm (1979)\" format_p_adjust(\"bonferroni\") #> [1] \"Bonferroni\""},{"path":"https://easystats.github.io/parameters/reference/format_parameters.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameter names formatting — format_parameters","title":"Parameter names formatting — format_parameters","text":"functions formats names model parameters (coefficients) make human-readable.","code":""},{"path":"https://easystats.github.io/parameters/reference/format_parameters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parameter names formatting — format_parameters","text":"","code":"format_parameters(model, ...)  # Default S3 method format_parameters(model, brackets = c(\"[\", \"]\"), ...)"},{"path":"https://easystats.github.io/parameters/reference/format_parameters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameter names formatting — format_parameters","text":"model statistical model. ... Currently used. brackets character vector length two, indicating opening closing brackets.","code":""},{"path":"https://easystats.github.io/parameters/reference/format_parameters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parameter names formatting — format_parameters","text":"(names) character vector formatted parameter names. value names refer original names coefficients.","code":""},{"path":"https://easystats.github.io/parameters/reference/format_parameters.html","id":"interpretation-of-interaction-terms","dir":"Reference","previous_headings":"","what":"Interpretation of Interaction Terms","title":"Parameter names formatting — format_parameters","text":"Note interpretation interaction terms depends many characteristics model. number parameters, overall performance model, can differ * b, : b, / b, suggesting sometimes interaction terms give different parameterizations model, times gives completely different models (depending b factors covariates, included main effects , etc.). interpretation depends full context model, inferred parameters table alone - rather, recommend use packages calculate estimated marginal means marginal effects, modelbased, emmeans, ggeffects, marginaleffects. raise awareness issue, may use print(...,show_formula=TRUE) add model-specification output print() method model_parameters().","code":""},{"path":"https://easystats.github.io/parameters/reference/format_parameters.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parameter names formatting — format_parameters","text":"","code":"model <- lm(Sepal.Length ~ Species * Sepal.Width, data = iris) format_parameters(model) #>                          (Intercept)                    Speciesversicolor  #>                        \"(Intercept)\"               \"Species [versicolor]\"  #>                     Speciesvirginica                          Sepal.Width  #>                \"Species [virginica]\"                        \"Sepal Width\"  #>        Speciesversicolor:Sepal.Width         Speciesvirginica:Sepal.Width  #> \"Species [versicolor] × Sepal Width\"  \"Species [virginica] × Sepal Width\"   model <- lm(Sepal.Length ~ Petal.Length + (Species / Sepal.Width), data = iris) format_parameters(model) #>                          (Intercept)                         Petal.Length  #>                        \"(Intercept)\"                       \"Petal Length\"  #>                    Speciesversicolor                     Speciesvirginica  #>               \"Species [versicolor]\"                \"Species [virginica]\"  #>            Speciessetosa:Sepal.Width        Speciesversicolor:Sepal.Width  #>     \"Species [setosa] × Sepal Width\" \"Species [versicolor] × Sepal Width\"  #>         Speciesvirginica:Sepal.Width  #>  \"Species [virginica] × Sepal Width\"   model <- lm(Sepal.Length ~ Species + poly(Sepal.Width, 2), data = iris) format_parameters(model) #>                (Intercept)          Speciesversicolor  #>              \"(Intercept)\"     \"Species [versicolor]\"  #>           Speciesvirginica      poly(Sepal.Width, 2)1  #>      \"Species [virginica]\" \"Sepal Width [1st degree]\"  #>      poly(Sepal.Width, 2)2  #> \"Sepal Width [2nd degree]\"   model <- lm(Sepal.Length ~ Species + poly(Sepal.Width, 2, raw = TRUE), data = iris) format_parameters(model) #>                       (Intercept)                 Speciesversicolor  #>                     \"(Intercept)\"            \"Species [versicolor]\"  #>                  Speciesvirginica poly(Sepal.Width, 2, raw = TRUE)1  #>             \"Species [virginica]\"        \"Sepal Width [1st degree]\"  #> poly(Sepal.Width, 2, raw = TRUE)2  #>        \"Sepal Width [2nd degree]\""},{"path":"https://easystats.github.io/parameters/reference/get_scores.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Scores from Principal Component Analysis (PCA) — get_scores","title":"Get Scores from Principal Component Analysis (PCA) — get_scores","text":"get_scores() takes n_items amount items load (either loading cutoff number) component, computes average.","code":""},{"path":"https://easystats.github.io/parameters/reference/get_scores.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Scores from Principal Component Analysis (PCA) — get_scores","text":"","code":"get_scores(x, n_items = NULL)"},{"path":"https://easystats.github.io/parameters/reference/get_scores.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Scores from Principal Component Analysis (PCA) — get_scores","text":"x object returned principal_components(). n_items Number required (.e. non-missing) items build sum score. NULL, value chosen match half number columns data frame.","code":""},{"path":"https://easystats.github.io/parameters/reference/get_scores.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Scores from Principal Component Analysis (PCA) — get_scores","text":"data frame subscales, average sum scores items component.","code":""},{"path":"https://easystats.github.io/parameters/reference/get_scores.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get Scores from Principal Component Analysis (PCA) — get_scores","text":"get_scores() takes results principal_components() extracts variables component found PCA. , \"subscales\", row means calculated (equals adding single items dividing number items). results sum score component PCA, scale original, single items used compute PCA.","code":""},{"path":"https://easystats.github.io/parameters/reference/get_scores.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Scores from Principal Component Analysis (PCA) — get_scores","text":"","code":"if (require(\"psych\")) {   pca <- principal_components(mtcars[, 1:7], n = 2, rotation = \"varimax\")    # PCA extracted two components   pca    # assignment of items to each component   closest_component(pca)    # now we want to have sum scores for each component   get_scores(pca)    # compare to manually computed sum score for 2nd component, which   # consists of items \"hp\" and \"qsec\"   (mtcars$hp + mtcars$qsec) / 2 } #>  [1]  63.230  63.510  55.805  64.720  96.010  62.610 130.420  41.000  58.950 #> [10]  70.650  70.950  98.700  98.800  99.000 111.490 116.410 123.710  42.735 #> [19]  35.260  42.450  58.505  83.435  83.650 130.205  96.025  42.450  53.850 #> [28]  64.950 139.250  95.250 174.800  63.800"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.BFBayesFactor.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameters from BayesFactor objects — model_parameters.BFBayesFactor","title":"Parameters from BayesFactor objects — model_parameters.BFBayesFactor","text":"Parameters BFBayesFactor objects {BayesFactor} package.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.BFBayesFactor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parameters from BayesFactor objects — model_parameters.BFBayesFactor","text":"","code":"# S3 method for class 'BFBayesFactor' model_parameters(   model,   centrality = \"median\",   dispersion = FALSE,   ci = 0.95,   ci_method = \"eti\",   test = \"pd\",   rope_range = \"default\",   rope_ci = 0.95,   priors = TRUE,   es_type = NULL,   include_proportions = FALSE,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.BFBayesFactor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameters from BayesFactor objects — model_parameters.BFBayesFactor","text":"model Object class BFBayesFactor. centrality point-estimates (centrality indices) compute. Character (vector) list one options: \"median\", \"mean\", \"MAP\" (see map_estimate()), \"trimmed\" (just mean(x, trim = threshold)), \"mode\" \"\". dispersion Logical, TRUE, computes indices dispersion related estimate(s) (SD MAD mean median, respectively). Dispersion available \"MAP\" \"mode\" centrality indices. ci Value vector probability CI (0 1) estimated. Default 0.95 (95%). ci_method type index used Credible Interval. Can \"ETI\" (default, see eti()), \"HDI\" (see hdi()), \"BCI\" (see bci()), \"SPI\" (see spi()), \"SI\" (see si()). test indices effect existence compute. Character (vector) list one options: \"p_direction\" (\"pd\"), \"rope\", \"p_map\", \"equivalence_test\" (\"equitest\"), \"bayesfactor\" (\"bf\") \"\" compute tests. \"test\", corresponding bayestestR function called (e.g. rope() p_direction()) results included summary output. rope_range ROPE's lower higher bounds. vector two values (e.g., c(-0.1, 0.1)), \"default\" list numeric vectors length numbers parameters. \"default\", bounds set x +- 0.1*SD(response). rope_ci Credible Interval (CI) probability, corresponding proportion HDI, use percentage ROPE. priors Add prior used parameter. es_type effect size interest. possibly effect sizes applicable model object. See 'Details'. Anova models, can also character vector multiple effect size names. include_proportions Logical decides whether include posterior cell proportions/counts Bayesian contingency table analysis (BayesFactor::contingencyTableBF()). Defaults FALSE, information often redundant. verbose Toggle warnings. ... Additional arguments passed methods.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.BFBayesFactor.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parameters from BayesFactor objects — model_parameters.BFBayesFactor","text":"data frame indices related model's parameters.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.BFBayesFactor.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Parameters from BayesFactor objects — model_parameters.BFBayesFactor","text":"meaning extracted parameters: BayesFactor::ttestBF(): Difference raw difference means. BayesFactor::correlationBF(): rho linear correlation estimate (equivalent Pearson's r). BayesFactor::lmBF() / BayesFactor::generalTestBF() / BayesFactor::regressionBF() / BayesFactor::anovaBF(): addition parameters fixed random effects, : mu (mean-centered) intercept; sig2 model's sigma; g / g_* g parameters; See Bayes Factors ANOVAs paper (doi:10.1016/j.jmp.2012.08.001 ).","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.BFBayesFactor.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parameters from BayesFactor objects — model_parameters.BFBayesFactor","text":"","code":"# \\donttest{ # Bayesian t-test model <- BayesFactor::ttestBF(x = rnorm(100, 1, 1)) model_parameters(model) #> Bayesian t-test #>  #> Parameter  | Median |       95% CI |   pd |              Prior |       BF #> ------------------------------------------------------------------------- #> Difference |   0.86 | [0.64, 1.07] | 100% | Cauchy (0 +- 0.71) | 5.08e+09 #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) #>   computed using a MCMC distribution approximation. model_parameters(model, es_type = \"cohens_d\", ci = 0.9) #> Bayesian t-test #>  #> Parameter  | Median |       90% CI | Cohen's d |     d 90% CI |   pd #> -------------------------------------------------------------------- #> Difference |   0.86 | [0.68, 1.04] |      0.80 | [0.60, 0.98] | 100% #>  #> Parameter  |              Prior |       BF #> ------------------------------------------ #> Difference | Cauchy (0 +- 0.71) | 5.08e+09 #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) #>   computed using a MCMC distribution approximation.  # Bayesian contingency table analysis data(raceDolls) bf <- BayesFactor::contingencyTableBF(   raceDolls,   sampleType = \"indepMulti\",   fixedMargin = \"cols\" ) model_parameters(bf,   centrality = \"mean\",   dispersion = TRUE,   verbose = FALSE,   es_type = \"cramers_v\" ) #> Bayesian contingency table analysis #>  #> Parameter |   SD | Cramer's V (adj.) | Cramers 95% CI #> ----------------------------------------------------- #> Ratio     | 0.08 |              0.14 |   [0.00, 0.30] #>  #> Parameter |                            Prior |   BF #> --------------------------------------------------- #> Ratio     | Independent multinomial (0 +- 1) | 1.81 # }"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.aov.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameters from ANOVAs — model_parameters.aov","title":"Parameters from ANOVAs — model_parameters.aov","text":"Parameters ANOVAs","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.aov.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parameters from ANOVAs — model_parameters.aov","text":"","code":"# S3 method for class 'aov' model_parameters(   model,   type = NULL,   df_error = NULL,   ci = NULL,   alternative = NULL,   test = NULL,   power = FALSE,   es_type = NULL,   keep = NULL,   drop = NULL,   table_wide = FALSE,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.aov.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameters from ANOVAs — model_parameters.aov","text":"model Object class aov(), anova(), aovlist, Gam, manova(), Anova.mlm, afex_aov maov. type Numeric, type sums squares. May 1, 2 3. 2 3, ANOVA-tables using car::Anova() returned. (Ignored afex_aov.) df_error Denominator degrees freedom (degrees freedom error estimate, .e., residuals). used compute effect sizes ANOVA-tables mixed models. See 'Examples'. (Ignored afex_aov.) ci Confidence Interval (CI) level effect sizes specified es_type. default, NULL, compute confidence intervals. ci scalar 0 1. alternative character string specifying alternative hypothesis; Controls type CI returned: \"two.sided\" (default, two-sided CI), \"greater\" \"less\" (one-sided CI). Partial matching allowed (e.g., \"g\", \"l\", \"two\"...). See section One-Sided CIs effectsize_CIs vignette. test String, indicating type test Anova.mlm returned. \"multivariate\" (NULL), returns summary multivariate test (also given print-method). test = \"univariate\", returns summary univariate test. power Logical, TRUE, adds column power parameter. es_type effect size interest. possibly effect sizes applicable model object. See 'Details'. Anova models, can also character vector multiple effect size names. keep Character containing regular expression pattern describes parameters included (keep) excluded (drop) returned data frame. keep may also named list regular expressions. non-matching parameters removed output. keep character vector, every parameter name \"Parameter\" column matches regular expression keep selected returned data frame (vice versa, parameter names matching drop excluded). Furthermore, keep one element, merged operator regular expression pattern like : \"(one|two|three)\". keep named list regular expression patterns, names list-element equal column name selection applied. useful model objects model_parameters() returns multiple columns parameter components, like model_parameters.lavaan(). Note regular expression pattern match parameter names stored returned data frame, can different printed. Inspect $Parameter column parameters table get exact parameter names. drop See keep. table_wide Logical decides whether ANOVA table wide format, .e. numerator denominator degrees freedom row. Default: FALSE. verbose Toggle warnings messages. ... Arguments passed effectsize::effectsize(). example, calculate partial effect sizes types, use partial = TRUE. objects class htest BFBayesFactor, adjust = TRUE can used return bias-corrected effect sizes, advisable small samples large tables. See also ?effectsize::eta_squared arguments partial generalized; ?effectsize::phi adjust; ?effectsize::oddratio log.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.aov.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parameters from ANOVAs — model_parameters.aov","text":"data frame indices related model's parameters.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.aov.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Parameters from ANOVAs — model_parameters.aov","text":"object class htest, data extracted via insight::get_data(), passed relevant function according : t-test depending type: \"cohens_d\" (default), \"hedges_g\", one \"p_superiority\", \"u1\", \"u2\", \"u3\", \"overlap\". Paired t-test: depending type: \"rm_rm\", \"rm_av\", \"rm_b\", \"rm_d\", \"rm_z\". Chi-squared tests independence Fisher's Exact Test, depending type: \"cramers_v\" (default), \"tschuprows_t\", \"phi\", \"cohens_w\", \"pearsons_c\", \"cohens_h\", \"oddsratio\", \"riskratio\", \"arr\", \"nnt\". Chi-squared tests goodness--fit, depending type: \"fei\" (default) \"cohens_w\", \"pearsons_c\" One-way ANOVA test, depending type: \"eta\" (default), \"omega\" \"epsilon\" -squared, \"f\", \"f2\". McNemar test returns Cohen's g. Wilcoxon test depending type: returns \"rank_biserial\" correlation (default) one \"p_superiority\", \"vda\", \"u2\", \"u3\", \"overlap\". Kruskal-Wallis test depending type: \"epsilon\" (default) \"eta\". Friedman test returns Kendall's W. (applicable, ci alternative taken htest otherwise provided.) object class BFBayesFactor, using bayestestR::describe_posterior(), t-test depending type: \"cohens_d\" (default) one \"p_superiority\", \"u1\", \"u2\", \"u3\", \"overlap\". correlation test returns r. contingency table test, depending type: \"cramers_v\" (default), \"phi\", \"tschuprows_t\", \"cohens_w\", \"pearsons_c\", \"cohens_h\", \"oddsratio\", \"riskratio\", \"arr\", \"nnt\". proportion test returns p. Objects class anova, aov, aovlist afex_aov, depending type: \"eta\" (default), \"omega\" \"epsilon\" -squared, \"f\", \"f2\". objects passed parameters::standardize_parameters(). statistical models recommended directly use listed functions, full range options provide.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.aov.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Parameters from ANOVAs — model_parameters.aov","text":"ANOVA-tables mixed models (.e. anova(lmer())), partial adjusted effect sizes can computed. Note type 3 ANOVAs interactions involved give sensible informative results covariates mean-centred factors coded orthogonal contrasts (produced contr.sum, contr.poly, contr.helmert, default contr.treatment).","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.aov.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parameters from ANOVAs — model_parameters.aov","text":"","code":"df <- iris df$Sepal.Big <- ifelse(df$Sepal.Width >= 3, \"Yes\", \"No\")  model <- aov(Sepal.Length ~ Sepal.Big, data = df) model_parameters(model) #> Parameter | Sum_Squares |  df | Mean_Square |    F |     p #> ---------------------------------------------------------- #> Sepal.Big |        1.10 |   1 |        1.10 | 1.61 | 0.207 #> Residuals |      101.07 | 148 |        0.68 |      |       #>  #> Anova Table (Type 1 tests)  model_parameters(model, es_type = c(\"omega\", \"eta\"), ci = 0.9) #> Parameter | Sum_Squares |  df | Mean_Square |    F |     p |   Omega2 #> --------------------------------------------------------------------- #> Sepal.Big |        1.10 |   1 |        1.10 | 1.61 | 0.207 | 4.04e-03 #> Residuals |      101.07 | 148 |        0.68 |      |       |          #>  #> Parameter | Omega2 90% CI | Eta2 |  Eta2 90% CI #> ----------------------------------------------- #> Sepal.Big |  [0.00, 1.00] | 0.01 | [0.00, 1.00] #> Residuals |               |      |              #>  #> Anova Table (Type 1 tests)  model <- anova(lm(Sepal.Length ~ Sepal.Big, data = df)) model_parameters(model) #> Parameter | Sum_Squares |  df | Mean_Square |    F |     p #> ---------------------------------------------------------- #> Sepal.Big |        1.10 |   1 |        1.10 | 1.61 | 0.207 #> Residuals |      101.07 | 148 |        0.68 |      |       #>  #> Anova Table (Type 1 tests) model_parameters(   model,   es_type = c(\"omega\", \"eta\", \"epsilon\"),   alternative = \"greater\" ) #> Parameter | Sum_Squares |  df | Mean_Square |    F |     p |   Omega2 | Eta2 | Epsilon2 #> --------------------------------------------------------------------------------------- #> Sepal.Big |        1.10 |   1 |        1.10 | 1.61 | 0.207 | 4.04e-03 | 0.01 | 4.07e-03 #> Residuals |      101.07 | 148 |        0.68 |      |       |          |      |          #>  #> Anova Table (Type 1 tests)  model <- aov(Sepal.Length ~ Sepal.Big + Error(Species), data = df) model_parameters(model) #> # Species  #>  #> Parameter | Sum_Squares | df | Mean_Square |    F |     p #> --------------------------------------------------------- #> Sepal.Big |       28.27 |  1 |       28.27 | 0.81 | 0.534 #> Residuals |       34.94 |  1 |       34.94 |      |       #>  #> # Within  #>  #> Parameter | Sum_Squares |  df | Mean_Square |     F |      p #> ------------------------------------------------------------ #> Sepal.Big |        4.74 |   1 |        4.74 | 20.24 | < .001 #> Residuals |       34.21 | 146 |        0.23 |       |        #>  #> Anova Table (Type 1 tests) # \\donttest{ df <- iris df$Sepal.Big <- ifelse(df$Sepal.Width >= 3, \"Yes\", \"No\") mm <- lme4::lmer(Sepal.Length ~ Sepal.Big + Petal.Width + (1 | Species), data = df) #> boundary (singular) fit: see help('isSingular') model <- anova(mm)  # simple parameters table model_parameters(model) #> Parameter   | Sum_Squares | df | Mean_Square |      F #> ----------------------------------------------------- #> Sepal.Big   |        1.10 |  1 |        1.10 |   4.96 #> Petal.Width |       68.50 |  1 |       68.50 | 309.23 #>  #> Anova Table (Type 1 tests)  # parameters table including effect sizes model_parameters(   model,   es_type = \"eta\",   ci = 0.9,   df_error = dof_satterthwaite(mm)[2:3] ) #> Parameter   | Sum_Squares | df | Mean_Square |      F | Eta2 (partial) |  Eta2 90% CI #> ------------------------------------------------------------------------------------- #> Sepal.Big   |        1.10 |  1 |        1.10 |   4.96 |           0.03 | [0.01, 1.00] #> Petal.Width |       68.50 |  1 |       68.50 | 309.23 |           0.68 | [0.63, 1.00] #>  #> Anova Table (Type 1 tests) # }"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.befa.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameters from Bayesian Exploratory Factor Analysis — model_parameters.befa","title":"Parameters from Bayesian Exploratory Factor Analysis — model_parameters.befa","text":"Format Bayesian Exploratory Factor Analysis objects BayesFM package.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.befa.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parameters from Bayesian Exploratory Factor Analysis — model_parameters.befa","text":"","code":"# S3 method for class 'befa' model_parameters(   model,   sort = FALSE,   centrality = \"median\",   dispersion = FALSE,   ci = 0.95,   ci_method = \"eti\",   test = NULL,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.befa.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameters from Bayesian Exploratory Factor Analysis — model_parameters.befa","text":"model Bayesian EFA created BayesFM::befa. sort Sort loadings. centrality point-estimates (centrality indices) compute. Character (vector) list one options: \"median\", \"mean\", \"MAP\" (see map_estimate()), \"trimmed\" (just mean(x, trim = threshold)), \"mode\" \"\". dispersion Logical, TRUE, computes indices dispersion related estimate(s) (SD MAD mean median, respectively). Dispersion available \"MAP\" \"mode\" centrality indices. ci Value vector probability CI (0 1) estimated. Default 0.95 (95%). ci_method type index used Credible Interval. Can \"ETI\" (default, see eti()), \"HDI\" (see hdi()), \"BCI\" (see bci()), \"SPI\" (see spi()), \"SI\" (see si()). test indices effect existence compute. Character (vector) list one options: \"p_direction\" (\"pd\"), \"rope\", \"p_map\", \"equivalence_test\" (\"equitest\"), \"bayesfactor\" (\"bf\") \"\" compute tests. \"test\", corresponding bayestestR function called (e.g. rope() p_direction()) results included summary output. verbose Toggle warnings. ... Arguments passed methods.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.befa.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parameters from Bayesian Exploratory Factor Analysis — model_parameters.befa","text":"data frame loadings.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.befa.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parameters from Bayesian Exploratory Factor Analysis — model_parameters.befa","text":"","code":"library(parameters) # \\donttest{ if (require(\"BayesFM\")) {   efa <- BayesFM::befa(mtcars, iter = 1000)   results <- model_parameters(efa, sort = TRUE, verbose = FALSE)   results   efa_to_cfa(results, verbose = FALSE) } #> Loading required package: BayesFM #> starting MCMC sampling... #>     5% #>    10% #>    15% #>    20% #>    25% #>    30% #>    35% #>    40% #>    45% #> done with burn-in period #>    50% #>    55% #>    60% #>    65% #>    70% #>    75% #>    80% #>    85% #>    90% #>    95% #>   100% #> done with sampling! #> # Latent variables #> F1 =~ am + mpg + vs #> F2 =~ carb + cyl + disp + hp + wt #> F3 =~ drat + gear + qsec # }"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.brmsfit.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameters from Bayesian Models — model_parameters.data.frame","title":"Parameters from Bayesian Models — model_parameters.data.frame","text":"Model parameters Bayesian models. function internally calls bayestestR::describe_posterior() get relevant information output.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.brmsfit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parameters from Bayesian Models — model_parameters.data.frame","text":"","code":"# S3 method for class 'data.frame' model_parameters(   model,   as_draws = FALSE,   exponentiate = FALSE,   verbose = TRUE,   ... )  # S3 method for class 'brmsfit' model_parameters(   model,   centrality = \"median\",   dispersion = FALSE,   ci = 0.95,   ci_method = \"eti\",   test = \"pd\",   rope_range = \"default\",   rope_ci = 0.95,   bf_prior = NULL,   diagnostic = c(\"ESS\", \"Rhat\"),   priors = FALSE,   effects = \"fixed\",   component = \"all\",   exponentiate = FALSE,   standardize = NULL,   group_level = FALSE,   keep = NULL,   drop = NULL,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.brmsfit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameters from Bayesian Models — model_parameters.data.frame","text":"model Bayesian model (including SEM blavaan. May also data frame posterior samples, however, as_draws must set TRUE (else, data frames NULL returned). as_draws Logical, TRUE model class data.frame, data frame treated posterior samples handled similar Bayesian models. arguments ... passed model_parameters.draws(). exponentiate Logical, indicating whether exponentiate coefficients (related confidence intervals). typical logistic regression, generally speaking, models log logit links. also recommended use exponentiate = TRUE models log-transformed response values. models log-transformed response variable, exponentiate = TRUE, one-unit increase predictor associated multiplying outcome predictor's coefficient. Note: Delta-method standard errors also computed (multiplying standard errors transformed coefficients). mimic behaviour software packages, Stata, standard errors poorly estimate uncertainty transformed coefficient. transformed confidence interval clearly captures uncertainty. compare_parameters(), exponentiate = \"nongaussian\" exponentiate coefficients non-Gaussian families. verbose Toggle warnings messages. ... Arguments passed methods. instance, bootstrap = TRUE, arguments like type parallel passed bootstrap_model(). non-documented arguments : digits, p_digits, ci_digits footer_digits set number digits output. groups can used group coefficients. arguments passed print-method, can directly used print(), see documentation print.parameters_model(). s_value = TRUE, p-value replaced S-value output (cf. Rafi Greenland 2020). pd adds additional column probability direction (see bayestestR::p_direction() details). Furthermore, see 'Examples' function. developers, whose interest mainly get \"tidy\" data frame model summaries, recommended set pretty_names = FALSE speed computation summary table. centrality point-estimates (centrality indices) compute. Character (vector) list one options: \"median\", \"mean\", \"MAP\" (see map_estimate()), \"trimmed\" (just mean(x, trim = threshold)), \"mode\" \"\". dispersion Logical, TRUE, computes indices dispersion related estimate(s) (SD MAD mean median, respectively). Dispersion available \"MAP\" \"mode\" centrality indices. ci Credible Interval (CI) level. Default 0.95 (95%). See bayestestR::ci() details. ci_method Method computing degrees freedom confidence intervals (CI) related p-values. Allowed following options (vary depending model class): \"residual\", \"normal\", \"likelihood\", \"satterthwaite\", \"kenward\", \"wald\", \"profile\", \"boot\", \"uniroot\", \"ml1\", \"betwithin\", \"hdi\", \"quantile\", \"ci\", \"eti\", \"si\", \"bci\", \"bcai\". See section Confidence intervals approximation degrees freedom model_parameters() details. ci_method=NULL, cases \"wald\" used . test indices effect existence compute. Character (vector) list one options: \"p_direction\" (\"pd\"), \"rope\", \"p_map\", \"equivalence_test\" (\"equitest\"), \"bayesfactor\" (\"bf\") \"\" compute tests. \"test\", corresponding bayestestR function called (e.g. rope() p_direction()) results included summary output. rope_range ROPE's lower higher bounds. vector two values (e.g., c(-0.1, 0.1)), \"default\" list numeric vectors length numbers parameters. \"default\", bounds set x +- 0.1*SD(response). rope_ci Credible Interval (CI) probability, corresponding proportion HDI, use percentage ROPE. bf_prior Distribution representing prior computation Bayes factors / SI. Used input posterior, otherwise (case models) ignored. diagnostic Diagnostic metrics compute.  Character (vector) list one options: \"ESS\", \"Rhat\", \"MCSE\" \"\". priors Add prior used parameter. effects results fixed effects, random effects returned? applies mixed models. May abbreviated. component type parameters return, parameters conditional model, zero-inflation part model, dispersion term, auxiliary parameters returned? Applies models zero-inflation /dispersion formula, parameters sigma included. May abbreviated. Note conditional component also called count mean component, depending model. three convenient shortcuts: component = \"\" returns possible parameters. component = \"location\", location parameters conditional, zero_inflated, smooth_terms, returned (everything fixed random effects - depending effects argument - auxiliary parameters). component = \"distributional\" (\"auxiliary\"), components like sigma, dispersion, beta (auxiliary parameters) returned. standardize method used standardizing parameters. Can NULL (default; standardization), \"refit\" (re-fitting model standardized data) one \"basic\", \"posthoc\", \"smart\", \"pseudo\". See 'Details' standardize_parameters(). Importantly: \"refit\" method standardize categorical predictors (.e. factors), may different behaviour compared R packages (lm.beta) software packages (like SPSS). mimic behaviours, either use standardize=\"basic\" standardize data datawizard::standardize(force=TRUE) fitting model. mixed models, using methods \"refit\", fixed effects standardized. Robust estimation (.e., vcov set value NULL) standardized parameters works standardize=\"refit\". group_level Logical, multilevel models (.e. models random effects) effects = \"\" effects = \"random\", include parameters group level random effects. group_level = FALSE (default), information SD COR shown. keep Character containing regular expression pattern describes parameters included (keep) excluded (drop) returned data frame. keep may also named list regular expressions. non-matching parameters removed output. keep character vector, every parameter name \"Parameter\" column matches regular expression keep selected returned data frame (vice versa, parameter names matching drop excluded). Furthermore, keep one element, merged operator regular expression pattern like : \"(one|two|three)\". keep named list regular expression patterns, names list-element equal column name selection applied. useful model objects model_parameters() returns multiple columns parameter components, like model_parameters.lavaan(). Note regular expression pattern match parameter names stored returned data frame, can different printed. Inspect $Parameter column parameters table get exact parameter names. drop See keep.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.brmsfit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parameters from Bayesian Models — model_parameters.data.frame","text":"data frame indices related model's parameters.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.brmsfit.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Parameters from Bayesian Models — model_parameters.data.frame","text":"standardize = \"refit\", columns diagnostic, bf_prior priors refer original model. model data frame, arguments diagnostic, bf_prior priors ignored. also plot()-method implemented see-package.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.brmsfit.html","id":"confidence-intervals-and-approximation-of-degrees-of-freedom","dir":"Reference","previous_headings":"","what":"Confidence intervals and approximation of degrees of freedom","title":"Parameters from Bayesian Models — model_parameters.data.frame","text":"different ways approximating degrees freedom depending different assumptions nature model sampling distribution. ci_method argument modulates method computing degrees freedom (df) used calculate confidence intervals (CI) related p-values. Following options allowed, depending model class: Classical methods: Classical inference generally based Wald method. Wald approach inference computes test statistic dividing parameter estimate standard error (Coefficient / SE), comparing statistic t- normal distribution. approach can used compute CIs p-values. \"wald\": Applies non-Bayesian models. linear models, CIs computed using Wald method (SE t-distribution residual df); p-values computed using Wald method t-distribution residual df. models, CIs computed using Wald method (SE normal distribution); p-values computed using Wald method normal distribution. \"normal\" Applies non-Bayesian models. Compute Wald CIs p-values, always use normal distribution. \"residual\" Applies non-Bayesian models. Compute Wald CIs p-values, always use t-distribution residual df possible. residual df model determined, normal distribution used instead. Methods mixed models: Compared fixed effects (single-level) models, determining appropriate df Wald-based inference mixed models difficult. See R GLMM FAQ discussion. Several approximate methods computing df available, also consider instead using profile likelihood (\"profile\") bootstrap (\"boot\") CIs p-values instead. \"satterthwaite\" Applies linear mixed models. CIs computed using Wald method (SE t-distribution Satterthwaite df); p-values computed using Wald method t-distribution Satterthwaite df. \"kenward\" Applies linear mixed models. CIs computed using Wald method (Kenward-Roger SE t-distribution Kenward-Roger df); p-values computed using Wald method Kenward-Roger SE t-distribution Kenward-Roger df. \"ml1\" Applies linear mixed models. CIs computed using Wald method (SE t-distribution m-l-1 approximated df); p-values computed using Wald method t-distribution m-l-1 approximated df. See ci_ml1(). \"betwithin\" Applies linear mixed models generalized linear mixed models. CIs computed using Wald method (SE t-distribution -within df); p-values computed using Wald method t-distribution -within df. See ci_betwithin(). Likelihood-based methods: Likelihood-based inference based comparing likelihood maximum-likelihood estimate likelihood models one parameter values changed (e.g., set zero range alternative values). Likelihood ratios maximum-likelihood alternative models compared \\(\\chi\\)-squared distribution compute CIs p-values. \"profile\" Applies non-Bayesian models class glm, polr, merMod glmmTMB. CIs computed profiling likelihood curve parameter, using linear interpolation find likelihood ratio equals critical value; p-values computed using Wald method normal-distribution (note: might change future update!) \"uniroot\" Applies non-Bayesian models class glmmTMB. CIs computed profiling likelihood curve parameter, using root finding find likelihood ratio equals critical value; p-values computed using Wald method normal-distribution (note: might change future update!) Methods bootstrapped Bayesian models: Bootstrap-based inference based resampling refitting model resampled datasets. distribution parameter estimates across resampled datasets used approximate parameter's sampling distribution. Depending type model, several different methods bootstrapping constructing CIs p-values bootstrap distribution available. Bayesian models, inference based drawing samples model posterior distribution. \"quantile\" (\"eti\") Applies models (including Bayesian models). non-Bayesian models, applies bootstrap = TRUE. CIs computed equal tailed intervals using quantiles bootstrap posterior samples; p-values based probability direction. See bayestestR::eti(). \"hdi\" Applies models (including Bayesian models). non-Bayesian models, applies bootstrap = TRUE. CIs computed highest density intervals bootstrap posterior samples; p-values based probability direction. See bayestestR::hdi(). \"bci\" (\"bcai\") Applies models (including Bayesian models). non-Bayesian models, applies bootstrap = TRUE. CIs computed bias corrected accelerated intervals bootstrap posterior samples; p-values based probability direction. See bayestestR::bci(). \"si\" Applies Bayesian models proper priors. CIs computed support intervals comparing posterior samples prior samples; p-values based probability direction. See bayestestR::si(). \"boot\" Applies non-Bayesian models class merMod. CIs computed using parametric bootstrapping (simulating data fitted model); p-values computed using Wald method normal-distribution) (note: might change future update!). iteration-based methods \"boot\" (\"hdi\", \"quantile\", \"ci\", \"eti\", \"si\", \"bci\", \"bcai\"), p-values based probability direction (bayestestR::p_direction()), converted p-value using bayestestR::pd_to_p().","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.brmsfit.html","id":"model-components","dir":"Reference","previous_headings":"","what":"Model components","title":"Parameters from Bayesian Models — model_parameters.data.frame","text":"Possible values component argument depend model class. Following valid options: \"\": returns model components, applies models, effect models just conditional model component. \"conditional\": returns conditional component, .e. \"fixed effects\" terms model. effect models just conditional model component. \"smooth_terms\": returns smooth terms, applies GAMs (similar models may contain smooth terms). \"zero_inflated\" (\"zi\"): returns zero-inflation component. \"dispersion\": returns dispersion model component. common models zero-inflation can model dispersion parameter. \"instruments\": instrumental-variable fixed effects regression, returns instruments. \"nonlinear\": non-linear models (like models class nlmerMod nls), returns staring estimates nonlinear parameters. \"correlation\": models correlation-component, like gls, variables used describe correlation structure returned. Special models model classes also allow rather uncommon options. : mhurdle: \"infrequent_purchase\", \"ip\", \"auxiliary\" BGGM: \"correlation\" \"intercept\" BFBayesFactor, glmx: \"extra\" averaging:\"conditional\" \"full\" mjoint: \"survival\" mfx: \"precision\", \"marginal\" betareg, DirichletRegModel: \"precision\" mvord: \"thresholds\" \"correlation\" clm2: \"scale\" selection: \"selection\", \"outcome\", \"auxiliary\" lavaan: One \"regression\", \"correlation\", \"loading\", \"variance\", \"defined\", \"mean\". Can also \"\" include components. models class brmsfit (package brms), even options possible component argument, documented detail .","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/model_parameters.brmsfit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parameters from Bayesian Models — model_parameters.data.frame","text":"","code":"# \\donttest{ library(parameters) if (require(\"rstanarm\")) {   model <- suppressWarnings(stan_glm(     Sepal.Length ~ Petal.Length * Species,     data = iris, iter = 500, refresh = 0   ))   model_parameters(model) } #> Parameter                      | Median |         95% CI |     pd |  Rhat #> ------------------------------------------------------------------------- #> (Intercept)                    |   4.12 | [ 3.45,  4.88] |   100% | 1.023 #> Petal.Length                   |   0.61 | [ 0.08,  1.06] | 99.30% | 1.025 #> Speciesversicolor              |  -1.65 | [-2.86, -0.59] |   100% | 1.012 #> Speciesvirginica               |  -3.04 | [-4.20, -1.85] |   100% | 1.004 #> Petal.Length:Speciesversicolor |   0.20 | [-0.28,  0.74] | 79.90% | 1.024 #> Petal.Length:Speciesvirginica  |   0.38 | [-0.10,  0.93] | 93.80% | 1.018 #>  #> Parameter                      |    ESS |                 Prior #> --------------------------------------------------------------- #> (Intercept)                    | 159.00 | Normal (5.84 +- 2.07) #> Petal.Length                   | 156.00 | Normal (0.00 +- 1.17) #> Speciesversicolor              | 271.00 | Normal (0.00 +- 4.38) #> Speciesvirginica               | 426.00 | Normal (0.00 +- 4.38) #> Petal.Length:Speciesversicolor | 159.00 | Normal (0.00 +- 1.02) #> Petal.Length:Speciesvirginica  | 181.00 | Normal (0.00 +- 0.78) #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) #>   computed using a MCMC distribution approximation. # }"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.cgam.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameters from Generalized Additive (Mixed) Models — model_parameters.cgam","title":"Parameters from Generalized Additive (Mixed) Models — model_parameters.cgam","text":"Extract compute indices measures describe parameters generalized additive models (GAM(M)s).","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.cgam.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parameters from Generalized Additive (Mixed) Models — model_parameters.cgam","text":"","code":"# S3 method for class 'cgam' model_parameters(   model,   ci = 0.95,   ci_method = \"residual\",   bootstrap = FALSE,   iterations = 1000,   standardize = NULL,   exponentiate = FALSE,   p_adjust = NULL,   keep = NULL,   drop = NULL,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.cgam.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameters from Generalized Additive (Mixed) Models — model_parameters.cgam","text":"model gam/gamm model. ci Confidence Interval (CI) level. Default 0.95 (95%). ci_method Method computing degrees freedom confidence intervals (CI) related p-values. Allowed following options (vary depending model class): \"residual\", \"normal\", \"likelihood\", \"satterthwaite\", \"kenward\", \"wald\", \"profile\", \"boot\", \"uniroot\", \"ml1\", \"betwithin\", \"hdi\", \"quantile\", \"ci\", \"eti\", \"si\", \"bci\", \"bcai\". See section Confidence intervals approximation degrees freedom model_parameters() details. ci_method=NULL, cases \"wald\" used . bootstrap estimates based bootstrapped model? TRUE, arguments Bayesian regressions apply (see also bootstrap_parameters()). iterations number bootstrap replicates. apply case bootstrapped frequentist models. standardize method used standardizing parameters. Can NULL (default; standardization), \"refit\" (re-fitting model standardized data) one \"basic\", \"posthoc\", \"smart\", \"pseudo\". See 'Details' standardize_parameters(). Importantly: \"refit\" method standardize categorical predictors (.e. factors), may different behaviour compared R packages (lm.beta) software packages (like SPSS). mimic behaviours, either use standardize=\"basic\" standardize data datawizard::standardize(force=TRUE) fitting model. mixed models, using methods \"refit\", fixed effects standardized. Robust estimation (.e., vcov set value NULL) standardized parameters works standardize=\"refit\". exponentiate Logical, indicating whether exponentiate coefficients (related confidence intervals). typical logistic regression, generally speaking, models log logit links. also recommended use exponentiate = TRUE models log-transformed response values. models log-transformed response variable, exponentiate = TRUE, one-unit increase predictor associated multiplying outcome predictor's coefficient. Note: Delta-method standard errors also computed (multiplying standard errors transformed coefficients). mimic behaviour software packages, Stata, standard errors poorly estimate uncertainty transformed coefficient. transformed confidence interval clearly captures uncertainty. compare_parameters(), exponentiate = \"nongaussian\" exponentiate coefficients non-Gaussian families. p_adjust Character vector, NULL, indicates method adjust p-values. See stats::p.adjust() details. possible adjustment methods \"tukey\", \"scheffe\", \"sidak\" \"none\" explicitly disable adjustment emmGrid objects (emmeans). keep Character containing regular expression pattern describes parameters included (keep) excluded (drop) returned data frame. keep may also named list regular expressions. non-matching parameters removed output. keep character vector, every parameter name \"Parameter\" column matches regular expression keep selected returned data frame (vice versa, parameter names matching drop excluded). Furthermore, keep one element, merged operator regular expression pattern like : \"(one|two|three)\". keep named list regular expression patterns, names list-element equal column name selection applied. useful model objects model_parameters() returns multiple columns parameter components, like model_parameters.lavaan(). Note regular expression pattern match parameter names stored returned data frame, can different printed. Inspect $Parameter column parameters table get exact parameter names. drop See keep. verbose Toggle warnings messages. ... Arguments passed methods. instance, bootstrap = TRUE, arguments like type parallel passed bootstrap_model(). non-documented arguments : digits, p_digits, ci_digits footer_digits set number digits output. groups can used group coefficients. arguments passed print-method, can directly used print(), see documentation print.parameters_model(). s_value = TRUE, p-value replaced S-value output (cf. Rafi Greenland 2020). pd adds additional column probability direction (see bayestestR::p_direction() details). Furthermore, see 'Examples' function. developers, whose interest mainly get \"tidy\" data frame model summaries, recommended set pretty_names = FALSE speed computation summary table.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.cgam.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parameters from Generalized Additive (Mixed) Models — model_parameters.cgam","text":"data frame indices related model's parameters.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.cgam.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Parameters from Generalized Additive (Mixed) Models — model_parameters.cgam","text":"reporting degrees freedom spline terms slightly differs output summary(model), example case mgcv::gam(). estimated degrees freedom, column edf summary-output, named df returned data frame, column df_error returned data frame refers residual degrees freedom returned df.residual(). Hence, values column df_error differ column Ref.df summary, intentional, reference degrees freedom “interpretable” (web).","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/model_parameters.cgam.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parameters from Generalized Additive (Mixed) Models — model_parameters.cgam","text":"","code":"library(parameters) if (require(\"mgcv\")) {   dat <- gamSim(1, n = 400, dist = \"normal\", scale = 2)   model <- gam(y ~ s(x0) + s(x1) + s(x2) + s(x3), data = dat)   model_parameters(model) } #> Loading required package: mgcv #> Loading required package: nlme #>  #> Attaching package: ‘nlme’ #> The following object is masked from ‘package:lme4’: #>  #>     lmList #> This is mgcv 1.9-1. For overview type 'help(\"mgcv-package\")'. #>  #> Attaching package: ‘mgcv’ #> The following object is masked from ‘package:mclust’: #>  #>     mvn #> Gu & Wahba 4 term additive model #> # Fixed Effects  #>  #> Parameter   | Coefficient |   SE |       95% CI | t(383.03) |      p #> -------------------------------------------------------------------- #> (Intercept) |        7.90 | 0.09 | [7.72, 8.09] |     83.78 | < .001 #>  #> # Smooth Terms  #>  #> Parameter        |      F |   df |      p #> ----------------------------------------- #> Smooth term (x0) |  17.65 | 3.10 | < .001 #> Smooth term (x1) | 101.86 | 3.68 | < .001 #> Smooth term (x2) |  98.39 | 7.97 | < .001 #> Smooth term (x3) |   0.56 | 1.22 | 0.421"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.default.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameters from (General) Linear Models — model_parameters.default","title":"Parameters from (General) Linear Models — model_parameters.default","text":"Extract compute indices measures describe parameters (generalized) linear models (GLMs).","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.default.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parameters from (General) Linear Models — model_parameters.default","text":"","code":"# Default S3 method model_parameters(   model,   ci = 0.95,   ci_method = NULL,   bootstrap = FALSE,   iterations = 1000,   standardize = NULL,   exponentiate = FALSE,   p_adjust = NULL,   vcov = NULL,   vcov_args = NULL,   summary = getOption(\"parameters_summary\", FALSE),   include_info = getOption(\"parameters_info\", FALSE),   keep = NULL,   drop = NULL,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.default.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameters from (General) Linear Models — model_parameters.default","text":"model Model object. ci Confidence Interval (CI) level. Default 0.95 (95%). ci_method Method computing degrees freedom confidence intervals (CI) related p-values. Allowed following options (vary depending model class): \"residual\", \"normal\", \"likelihood\", \"satterthwaite\", \"kenward\", \"wald\", \"profile\", \"boot\", \"uniroot\", \"ml1\", \"betwithin\", \"hdi\", \"quantile\", \"ci\", \"eti\", \"si\", \"bci\", \"bcai\". See section Confidence intervals approximation degrees freedom model_parameters() details. ci_method=NULL, cases \"wald\" used . bootstrap estimates based bootstrapped model? TRUE, arguments Bayesian regressions apply (see also bootstrap_parameters()). iterations number bootstrap replicates. apply case bootstrapped frequentist models. standardize method used standardizing parameters. Can NULL (default; standardization), \"refit\" (re-fitting model standardized data) one \"basic\", \"posthoc\", \"smart\", \"pseudo\". See 'Details' standardize_parameters(). Importantly: \"refit\" method standardize categorical predictors (.e. factors), may different behaviour compared R packages (lm.beta) software packages (like SPSS). mimic behaviours, either use standardize=\"basic\" standardize data datawizard::standardize(force=TRUE) fitting model. mixed models, using methods \"refit\", fixed effects standardized. Robust estimation (.e., vcov set value NULL) standardized parameters works standardize=\"refit\". exponentiate Logical, indicating whether exponentiate coefficients (related confidence intervals). typical logistic regression, generally speaking, models log logit links. also recommended use exponentiate = TRUE models log-transformed response values. models log-transformed response variable, exponentiate = TRUE, one-unit increase predictor associated multiplying outcome predictor's coefficient. Note: Delta-method standard errors also computed (multiplying standard errors transformed coefficients). mimic behaviour software packages, Stata, standard errors poorly estimate uncertainty transformed coefficient. transformed confidence interval clearly captures uncertainty. compare_parameters(), exponentiate = \"nongaussian\" exponentiate coefficients non-Gaussian families. p_adjust Character vector, NULL, indicates method adjust p-values. See stats::p.adjust() details. possible adjustment methods \"tukey\", \"scheffe\", \"sidak\" \"none\" explicitly disable adjustment emmGrid objects (emmeans). vcov Variance-covariance matrix used compute uncertainty estimates (e.g., robust standard errors). argument accepts covariance matrix, function returns covariance matrix, string identifies function used compute covariance matrix. covariance matrix function returns covariance matrix (e.g., stats::vcov()) string indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC Cluster-robust: \"CR\", \"CR0\", \"CR1\", \"CR1p\", \"CR1S\", \"CR2\", \"CR3\". See ?clubSandwich::vcovCR Bootstrap: \"BS\", \"xy\", \"residual\", \"wild\", \"mammen\", \"fractional\", \"jackknife\", \"norm\", \"webb\". See ?sandwich::vcovBS sandwich package functions: \"HAC\", \"PC\", \"CL\", \"OPG\", \"PL\". vcov_args List arguments passed function identified vcov argument. function typically supplied sandwich clubSandwich packages. Please refer documentation (e.g., ?sandwich::vcovHAC) see list available arguments. estimation type (argument type) given, default type \"HC\" equals default sandwich package; type \"CR\", default set \"CR3\". summary Deprecated, please use info instead. include_info Logical, TRUE, prints summary information model (model formula, number observations, residual standard deviation ). keep Character containing regular expression pattern describes parameters included (keep) excluded (drop) returned data frame. keep may also named list regular expressions. non-matching parameters removed output. keep character vector, every parameter name \"Parameter\" column matches regular expression keep selected returned data frame (vice versa, parameter names matching drop excluded). Furthermore, keep one element, merged operator regular expression pattern like : \"(one|two|three)\". keep named list regular expression patterns, names list-element equal column name selection applied. useful model objects model_parameters() returns multiple columns parameter components, like model_parameters.lavaan(). Note regular expression pattern match parameter names stored returned data frame, can different printed. Inspect $Parameter column parameters table get exact parameter names. drop See keep. verbose Toggle warnings messages. ... Arguments passed methods. instance, bootstrap = TRUE, arguments like type parallel passed bootstrap_model(). non-documented arguments : digits, p_digits, ci_digits footer_digits set number digits output. groups can used group coefficients. arguments passed print-method, can directly used print(), see documentation print.parameters_model(). s_value = TRUE, p-value replaced S-value output (cf. Rafi Greenland 2020). pd adds additional column probability direction (see bayestestR::p_direction() details). Furthermore, see 'Examples' function. developers, whose interest mainly get \"tidy\" data frame model summaries, recommended set pretty_names = FALSE speed computation summary table.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.default.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parameters from (General) Linear Models — model_parameters.default","text":"data frame indices related model's parameters.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.default.html","id":"confidence-intervals-and-approximation-of-degrees-of-freedom","dir":"Reference","previous_headings":"","what":"Confidence intervals and approximation of degrees of freedom","title":"Parameters from (General) Linear Models — model_parameters.default","text":"different ways approximating degrees freedom depending different assumptions nature model sampling distribution. ci_method argument modulates method computing degrees freedom (df) used calculate confidence intervals (CI) related p-values. Following options allowed, depending model class: Classical methods: Classical inference generally based Wald method. Wald approach inference computes test statistic dividing parameter estimate standard error (Coefficient / SE), comparing statistic t- normal distribution. approach can used compute CIs p-values. \"wald\": Applies non-Bayesian models. linear models, CIs computed using Wald method (SE t-distribution residual df); p-values computed using Wald method t-distribution residual df. models, CIs computed using Wald method (SE normal distribution); p-values computed using Wald method normal distribution. \"normal\" Applies non-Bayesian models. Compute Wald CIs p-values, always use normal distribution. \"residual\" Applies non-Bayesian models. Compute Wald CIs p-values, always use t-distribution residual df possible. residual df model determined, normal distribution used instead. Methods mixed models: Compared fixed effects (single-level) models, determining appropriate df Wald-based inference mixed models difficult. See R GLMM FAQ discussion. Several approximate methods computing df available, also consider instead using profile likelihood (\"profile\") bootstrap (\"boot\") CIs p-values instead. \"satterthwaite\" Applies linear mixed models. CIs computed using Wald method (SE t-distribution Satterthwaite df); p-values computed using Wald method t-distribution Satterthwaite df. \"kenward\" Applies linear mixed models. CIs computed using Wald method (Kenward-Roger SE t-distribution Kenward-Roger df); p-values computed using Wald method Kenward-Roger SE t-distribution Kenward-Roger df. \"ml1\" Applies linear mixed models. CIs computed using Wald method (SE t-distribution m-l-1 approximated df); p-values computed using Wald method t-distribution m-l-1 approximated df. See ci_ml1(). \"betwithin\" Applies linear mixed models generalized linear mixed models. CIs computed using Wald method (SE t-distribution -within df); p-values computed using Wald method t-distribution -within df. See ci_betwithin(). Likelihood-based methods: Likelihood-based inference based comparing likelihood maximum-likelihood estimate likelihood models one parameter values changed (e.g., set zero range alternative values). Likelihood ratios maximum-likelihood alternative models compared \\(\\chi\\)-squared distribution compute CIs p-values. \"profile\" Applies non-Bayesian models class glm, polr, merMod glmmTMB. CIs computed profiling likelihood curve parameter, using linear interpolation find likelihood ratio equals critical value; p-values computed using Wald method normal-distribution (note: might change future update!) \"uniroot\" Applies non-Bayesian models class glmmTMB. CIs computed profiling likelihood curve parameter, using root finding find likelihood ratio equals critical value; p-values computed using Wald method normal-distribution (note: might change future update!) Methods bootstrapped Bayesian models: Bootstrap-based inference based resampling refitting model resampled datasets. distribution parameter estimates across resampled datasets used approximate parameter's sampling distribution. Depending type model, several different methods bootstrapping constructing CIs p-values bootstrap distribution available. Bayesian models, inference based drawing samples model posterior distribution. \"quantile\" (\"eti\") Applies models (including Bayesian models). non-Bayesian models, applies bootstrap = TRUE. CIs computed equal tailed intervals using quantiles bootstrap posterior samples; p-values based probability direction. See bayestestR::eti(). \"hdi\" Applies models (including Bayesian models). non-Bayesian models, applies bootstrap = TRUE. CIs computed highest density intervals bootstrap posterior samples; p-values based probability direction. See bayestestR::hdi(). \"bci\" (\"bcai\") Applies models (including Bayesian models). non-Bayesian models, applies bootstrap = TRUE. CIs computed bias corrected accelerated intervals bootstrap posterior samples; p-values based probability direction. See bayestestR::bci(). \"si\" Applies Bayesian models proper priors. CIs computed support intervals comparing posterior samples prior samples; p-values based probability direction. See bayestestR::si(). \"boot\" Applies non-Bayesian models class merMod. CIs computed using parametric bootstrapping (simulating data fitted model); p-values computed using Wald method normal-distribution) (note: might change future update!). iteration-based methods \"boot\" (\"hdi\", \"quantile\", \"ci\", \"eti\", \"si\", \"bci\", \"bcai\"), p-values based probability direction (bayestestR::p_direction()), converted p-value using bayestestR::pd_to_p().","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/model_parameters.default.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parameters from (General) Linear Models — model_parameters.default","text":"","code":"library(parameters) model <- lm(mpg ~ wt + cyl, data = mtcars)  model_parameters(model) #> Parameter   | Coefficient |   SE |         95% CI | t(29) |      p #> ------------------------------------------------------------------ #> (Intercept) |       39.69 | 1.71 | [36.18, 43.19] | 23.14 | < .001 #> wt          |       -3.19 | 0.76 | [-4.74, -1.64] | -4.22 | < .001 #> cyl         |       -1.51 | 0.41 | [-2.36, -0.66] | -3.64 | 0.001  #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) #>   computed using a Wald t-distribution approximation.  # bootstrapped parameters model_parameters(model, bootstrap = TRUE) #> Parameter   | Coefficient |         95% CI |      p #> --------------------------------------------------- #> (Intercept) |       39.65 | [35.41, 43.97] | < .001 #> wt          |       -3.22 | [-4.80, -1.95] | < .001 #> cyl         |       -1.46 | [-2.15, -0.74] | < .001 #>  #> Uncertainty intervals (equal-tailed) are naıve bootstrap #>   intervals.  # standardized parameters model_parameters(model, standardize = \"refit\") #> Parameter   | Coefficient |   SE |         95% CI |    t(29) |      p #> --------------------------------------------------------------------- #> (Intercept) |    5.37e-17 | 0.08 | [-0.15,  0.15] | 7.13e-16 | > .999 #> wt          |       -0.52 | 0.12 | [-0.77, -0.27] |    -4.22 | < .001 #> cyl         |       -0.45 | 0.12 | [-0.70, -0.20] |    -3.64 | 0.001  #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) #>   computed using a Wald t-distribution approximation.  # robust, heteroskedasticity-consistent standard errors model_parameters(model, vcov = \"HC3\") #> Parameter   | Coefficient |   SE |         95% CI | t(29) |      p #> ------------------------------------------------------------------ #> (Intercept) |       39.69 | 2.30 | [34.97, 44.40] | 17.22 | < .001 #> wt          |       -3.19 | 0.78 | [-4.78, -1.60] | -4.10 | < .001 #> cyl         |       -1.51 | 0.39 | [-2.30, -0.72] | -3.90 | < .001 #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) #>   computed using a Wald t-distribution approximation.  model_parameters(model,   vcov = \"vcovCL\",   vcov_args = list(cluster = mtcars$cyl) ) #> Parameter   | Coefficient |   SE |         95% CI | t(29) |      p #> ------------------------------------------------------------------ #> (Intercept) |       39.69 | 1.50 | [36.61, 42.76] | 26.43 | < .001 #> wt          |       -3.19 | 1.20 | [-5.65, -0.73] | -2.65 | 0.013  #> cyl         |       -1.51 | 0.40 | [-2.32, -0.70] | -3.82 | < .001 #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) #>   computed using a Wald t-distribution approximation.  # different p-value style in output model_parameters(model, p_digits = 5) #> Parameter   | Coefficient |   SE |         95% CI | t(29) |           p #> ----------------------------------------------------------------------- #> (Intercept) |       39.69 | 1.71 | [36.18, 43.19] | 23.14 | 3.04318e-20 #> wt          |       -3.19 | 0.76 | [-4.74, -1.64] | -4.22 | 0.00022     #> cyl         |       -1.51 | 0.41 | [-2.36, -0.66] | -3.64 | 0.00106     #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) #>   computed using a Wald t-distribution approximation. model_parameters(model, digits = 3, ci_digits = 4, p_digits = \"scientific\") #> Parameter   | Coefficient |    SE |             95% CI |  t(29) |           p #> ----------------------------------------------------------------------------- #> (Intercept) |      39.686 | 1.715 | [36.1787, 43.1938] | 23.141 | 3.04318e-20 #> wt          |      -3.191 | 0.757 | [-4.7390, -1.6429] | -4.216 | 2.22020e-04 #> cyl         |      -1.508 | 0.415 | [-2.3559, -0.6597] | -3.636 | 1.06428e-03 #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) #>   computed using a Wald t-distribution approximation.  # report S-value or probability of direction for parameters model_parameters(model, s_value = TRUE) #> Parameter   | Coefficient |   SE |         95% CI | t(29) |     s #> ----------------------------------------------------------------- #> (Intercept) |       39.69 | 1.71 | [36.18, 43.19] | 23.14 | 64.83 #> wt          |       -3.19 | 0.76 | [-4.74, -1.64] | -4.22 | 12.14 #> cyl         |       -1.51 | 0.41 | [-2.36, -0.66] | -3.64 |  9.88 #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) #>   computed using a Wald t-distribution approximation. model_parameters(model, pd = TRUE) #> Parameter   | Coefficient |   SE |         95% CI | t(29) |      p |     pd #> --------------------------------------------------------------------------- #> (Intercept) |       39.69 | 1.71 | [36.18, 43.19] | 23.14 | < .001 |   100% #> wt          |       -3.19 | 0.76 | [-4.74, -1.64] | -4.22 | < .001 | 99.99% #> cyl         |       -1.51 | 0.41 | [-2.36, -0.66] | -3.64 | 0.001  | 99.95% #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) #>   computed using a Wald t-distribution approximation.  # \\donttest{ # logistic regression model model <- glm(vs ~ wt + cyl, data = mtcars, family = \"binomial\") model_parameters(model) #> Parameter   | Log-Odds |   SE |         95% CI |     z |     p #> -------------------------------------------------------------- #> (Intercept) |    10.62 | 4.17 | [ 4.79, 22.66] |  2.55 | 0.011 #> wt          |     2.10 | 1.55 | [-0.53,  6.24] |  1.36 | 0.174 #> cyl         |    -2.93 | 1.38 | [-6.92, -1.07] | -2.12 | 0.034 #>  #> Uncertainty intervals (profile-likelihood) and p-values #>   (two-tailed) computed using a Wald z-distribution approximation. #>  #> The model has a log- or logit-link. Consider using `exponentiate = #>   TRUE` to interpret coefficients as ratios. #>    #> Some coefficients seem to be rather large, which may indicate issues #>   with (quasi) complete separation. Consider using bias-corrected or #>   penalized regression models.  # show odds ratio / exponentiated coefficients model_parameters(model, exponentiate = TRUE) #> Parameter   | Odds Ratio |       SE |             95% CI |     z |     p #> ------------------------------------------------------------------------ #> (Intercept) |   40911.34 | 1.71e+05 | [120.16, 6.95e+09] |  2.55 | 0.011 #> wt          |       8.17 |    12.63 | [  0.59,   514.10] |  1.36 | 0.174 #> cyl         |       0.05 |     0.07 | [  0.00,     0.34] | -2.12 | 0.034 #>  #> Uncertainty intervals (profile-likelihood) and p-values #>   (two-tailed) computed using a Wald z-distribution approximation.  # bias-corrected logistic regression with penalized maximum likelihood model <- glm(   vs ~ wt + cyl,   data = mtcars,   family = \"binomial\",   method = \"brglmFit\" ) model_parameters(model) #> Parameter   | Log-Odds |   SE |         95% CI |     z |     p #> -------------------------------------------------------------- #> (Intercept) |     7.71 | 2.66 | [ 2.49, 12.93] |  2.89 | 0.004 #> wt          |     1.46 | 1.08 | [-0.65,  3.57] |  1.35 | 0.176 #> cyl         |    -2.09 | 0.85 | [-3.76, -0.41] | -2.44 | 0.015 #>  #> Uncertainty intervals (profile-likelihood) and p-values #>   (two-tailed) computed using a Wald z-distribution approximation. # }"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.glht.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameters from Hypothesis Testing — model_parameters.glht","title":"Parameters from Hypothesis Testing — model_parameters.glht","text":"Parameters Hypothesis Testing.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.glht.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parameters from Hypothesis Testing — model_parameters.glht","text":"","code":"# S3 method for class 'glht' model_parameters(   model,   ci = 0.95,   exponentiate = FALSE,   keep = NULL,   drop = NULL,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.glht.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameters from Hypothesis Testing — model_parameters.glht","text":"model Object class multcomp::glht() (multcomp) class PMCMR, trendPMCMR osrt (PMCMRplus). ci Confidence Interval (CI) level. Default 0.95 (95%). exponentiate Logical, indicating whether exponentiate coefficients (related confidence intervals). typical logistic regression, generally speaking, models log logit links. also recommended use exponentiate = TRUE models log-transformed response values. models log-transformed response variable, exponentiate = TRUE, one-unit increase predictor associated multiplying outcome predictor's coefficient. Note: Delta-method standard errors also computed (multiplying standard errors transformed coefficients). mimic behaviour software packages, Stata, standard errors poorly estimate uncertainty transformed coefficient. transformed confidence interval clearly captures uncertainty. compare_parameters(), exponentiate = \"nongaussian\" exponentiate coefficients non-Gaussian families. keep Character containing regular expression pattern describes parameters included (keep) excluded (drop) returned data frame. keep may also named list regular expressions. non-matching parameters removed output. keep character vector, every parameter name \"Parameter\" column matches regular expression keep selected returned data frame (vice versa, parameter names matching drop excluded). Furthermore, keep one element, merged operator regular expression pattern like : \"(one|two|three)\". keep named list regular expression patterns, names list-element equal column name selection applied. useful model objects model_parameters() returns multiple columns parameter components, like model_parameters.lavaan(). Note regular expression pattern match parameter names stored returned data frame, can different printed. Inspect $Parameter column parameters table get exact parameter names. drop See keep. verbose Toggle warnings messages. ... Arguments passed methods. instance, bootstrap = TRUE, arguments like type parallel passed bootstrap_model(). non-documented arguments : digits, p_digits, ci_digits footer_digits set number digits output. groups can used group coefficients. arguments passed print-method, can directly used print(), see documentation print.parameters_model(). s_value = TRUE, p-value replaced S-value output (cf. Rafi Greenland 2020). pd adds additional column probability direction (see bayestestR::p_direction() details). Furthermore, see 'Examples' function. developers, whose interest mainly get \"tidy\" data frame model summaries, recommended set pretty_names = FALSE speed computation summary table.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.glht.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parameters from Hypothesis Testing — model_parameters.glht","text":"data frame indices related model's parameters.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.glht.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parameters from Hypothesis Testing — model_parameters.glht","text":"","code":"# \\donttest{ if (require(\"multcomp\", quietly = TRUE)) {   # multiple linear model, swiss data   lmod <- lm(Fertility ~ ., data = swiss)   mod <- glht(     model = lmod,     linfct = c(       \"Agriculture = 0\",       \"Examination = 0\",       \"Education = 0\",       \"Catholic = 0\",       \"Infant.Mortality = 0\"     )   )   model_parameters(mod) } #>  #> Attaching package: ‘mvtnorm’ #> The following object is masked from ‘package:mclust’: #>  #>     dmvnorm #>  #> Attaching package: ‘survival’ #> The following object is masked from ‘package:boot’: #>  #>     aml #>  #> Attaching package: ‘TH.data’ #> The following object is masked from ‘package:MASS’: #>  #>     geyser #> # Fixed Effects #>  #> Parameter             | Coefficient |   SE |         95% CI | t(41) |      p #> ---------------------------------------------------------------------------- #> Agriculture == 0      |       -0.17 | 0.07 | [-0.36,  0.01] | -2.45 | 0.080  #> Examination == 0      |       -0.26 | 0.25 | [-0.93,  0.41] | -1.02 | 0.785  #> Education == 0        |       -0.87 | 0.18 | [-1.36, -0.39] | -4.76 | < .001 #> Catholic == 0         |        0.10 | 0.04 | [ 0.01,  0.20] |  2.95 | 0.023  #> Infant Mortality == 0 |        1.08 | 0.38 | [ 0.07,  2.09] |  2.82 | 0.033  #>  #> p-value adjustment method: single-step #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) #>   computed using a Wald t-distribution approximation. if (require(\"PMCMRplus\", quietly = TRUE)) {   model <- suppressWarnings(     kwAllPairsConoverTest(count ~ spray, data = InsectSprays)   )   model_parameters(model) } #> Conover's all-pairs test #>  #> Group1 | Group2 | Statistic |      p | alternative | Distribution | p_adjustment #> -------------------------------------------------------------------------------- #> B      |      A |      0.89 | 0.988  |   two.sided |            q |  single-step #> C      |      A |    -13.58 | < .001 |   two.sided |            q |  single-step #> C      |      B |    -14.47 | < .001 |   two.sided |            q |  single-step #> D      |      A |     -8.87 | < .001 |   two.sided |            q |  single-step #> D      |      B |     -9.76 | < .001 |   two.sided |            q |  single-step #> D      |      C |      4.71 | 0.017  |   two.sided |            q |  single-step #> E      |      A |    -10.95 | < .001 |   two.sided |            q |  single-step #> E      |      B |    -11.84 | < .001 |   two.sided |            q |  single-step #> E      |      C |      2.63 | 0.437  |   two.sided |            q |  single-step #> E      |      D |     -2.09 | 0.681  |   two.sided |            q |  single-step #> F      |      A |      1.15 | 0.964  |   two.sided |            q |  single-step #> F      |      B |      0.26 | > .999 |   two.sided |            q |  single-step #> F      |      C |     14.74 | < .001 |   two.sided |            q |  single-step #> F      |      D |     10.02 | < .001 |   two.sided |            q |  single-step #> F      |      E |     12.11 | < .001 |   two.sided |            q |  single-step # }"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.glimML.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameters from special models — model_parameters.glimML","title":"Parameters from special models — model_parameters.glimML","text":"Parameters special regression models listed one previous categories yet.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.glimML.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parameters from special models — model_parameters.glimML","text":"","code":"# S3 method for class 'glimML' model_parameters(   model,   ci = 0.95,   bootstrap = FALSE,   iterations = 1000,   component = \"conditional\",   standardize = NULL,   exponentiate = FALSE,   p_adjust = NULL,   summary = getOption(\"parameters_summary\", FALSE),   include_info = getOption(\"parameters_info\", FALSE),   keep = NULL,   drop = NULL,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.glimML.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameters from special models — model_parameters.glimML","text":"model Model object. ci Confidence Interval (CI) level. Default 0.95 (95%). bootstrap estimates based bootstrapped model? TRUE, arguments Bayesian regressions apply (see also bootstrap_parameters()). iterations number bootstrap replicates. apply case bootstrapped frequentist models. component Model component parameters shown. May one \"conditional\", \"precision\" (e.g. betareg), \"scale\" (e.g. ordinal), \"extra\" (e.g. glmx), \"marginal\" (e.g. mfx), \"conditional\" \"full\" (MuMIn::model.avg()) \"\". See section Model components overview possible options component. standardize method used standardizing parameters. Can NULL (default; standardization), \"refit\" (re-fitting model standardized data) one \"basic\", \"posthoc\", \"smart\", \"pseudo\". See 'Details' standardize_parameters(). Importantly: \"refit\" method standardize categorical predictors (.e. factors), may different behaviour compared R packages (lm.beta) software packages (like SPSS). mimic behaviours, either use standardize=\"basic\" standardize data datawizard::standardize(force=TRUE) fitting model. mixed models, using methods \"refit\", fixed effects standardized. Robust estimation (.e., vcov set value NULL) standardized parameters works standardize=\"refit\". exponentiate Logical, indicating whether exponentiate coefficients (related confidence intervals). typical logistic regression, generally speaking, models log logit links. also recommended use exponentiate = TRUE models log-transformed response values. models log-transformed response variable, exponentiate = TRUE, one-unit increase predictor associated multiplying outcome predictor's coefficient. Note: Delta-method standard errors also computed (multiplying standard errors transformed coefficients). mimic behaviour software packages, Stata, standard errors poorly estimate uncertainty transformed coefficient. transformed confidence interval clearly captures uncertainty. compare_parameters(), exponentiate = \"nongaussian\" exponentiate coefficients non-Gaussian families. p_adjust Character vector, NULL, indicates method adjust p-values. See stats::p.adjust() details. possible adjustment methods \"tukey\", \"scheffe\", \"sidak\" \"none\" explicitly disable adjustment emmGrid objects (emmeans). summary Deprecated, please use info instead. include_info Logical, TRUE, prints summary information model (model formula, number observations, residual standard deviation ). keep Character containing regular expression pattern describes parameters included (keep) excluded (drop) returned data frame. keep may also named list regular expressions. non-matching parameters removed output. keep character vector, every parameter name \"Parameter\" column matches regular expression keep selected returned data frame (vice versa, parameter names matching drop excluded). Furthermore, keep one element, merged operator regular expression pattern like : \"(one|two|three)\". keep named list regular expression patterns, names list-element equal column name selection applied. useful model objects model_parameters() returns multiple columns parameter components, like model_parameters.lavaan(). Note regular expression pattern match parameter names stored returned data frame, can different printed. Inspect $Parameter column parameters table get exact parameter names. drop See keep. verbose Toggle warnings messages. ... Arguments passed methods. instance, bootstrap = TRUE, arguments like type parallel passed bootstrap_model(). non-documented arguments : digits, p_digits, ci_digits footer_digits set number digits output. groups can used group coefficients. arguments passed print-method, can directly used print(), see documentation print.parameters_model(). s_value = TRUE, p-value replaced S-value output (cf. Rafi Greenland 2020). pd adds additional column probability direction (see bayestestR::p_direction() details). Furthermore, see 'Examples' function. developers, whose interest mainly get \"tidy\" data frame model summaries, recommended set pretty_names = FALSE speed computation summary table.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.glimML.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parameters from special models — model_parameters.glimML","text":"data frame indices related model's parameters.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.glimML.html","id":"model-components","dir":"Reference","previous_headings":"","what":"Model components","title":"Parameters from special models — model_parameters.glimML","text":"Possible values component argument depend model class. Following valid options: \"\": returns model components, applies models, effect models just conditional model component. \"conditional\": returns conditional component, .e. \"fixed effects\" terms model. effect models just conditional model component. \"smooth_terms\": returns smooth terms, applies GAMs (similar models may contain smooth terms). \"zero_inflated\" (\"zi\"): returns zero-inflation component. \"dispersion\": returns dispersion model component. common models zero-inflation can model dispersion parameter. \"instruments\": instrumental-variable fixed effects regression, returns instruments. \"nonlinear\": non-linear models (like models class nlmerMod nls), returns staring estimates nonlinear parameters. \"correlation\": models correlation-component, like gls, variables used describe correlation structure returned. Special models model classes also allow rather uncommon options. : mhurdle: \"infrequent_purchase\", \"ip\", \"auxiliary\" BGGM: \"correlation\" \"intercept\" BFBayesFactor, glmx: \"extra\" averaging:\"conditional\" \"full\" mjoint: \"survival\" mfx: \"precision\", \"marginal\" betareg, DirichletRegModel: \"precision\" mvord: \"thresholds\" \"correlation\" clm2: \"scale\" selection: \"selection\", \"outcome\", \"auxiliary\" lavaan: One \"regression\", \"correlation\", \"loading\", \"variance\", \"defined\", \"mean\". Can also \"\" include components. models class brmsfit (package brms), even options possible component argument, documented detail .","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/model_parameters.glimML.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parameters from special models — model_parameters.glimML","text":"","code":"library(parameters) if (require(\"brglm2\", quietly = TRUE)) {   data(\"stemcell\")   model <- bracl(     research ~ as.numeric(religion) + gender,     weights = frequency,     data = stemcell,     type = \"ML\"   )   model_parameters(model) } #> # Response level: definitely #>  #> Parameter       | Log-Odds |   SE |         95% CI |     z |      p #> ------------------------------------------------------------------- #> (Intercept)     |    -1.25 | 0.26 | [-1.76, -0.73] | -4.76 | < .001 #> religion        |     0.44 | 0.10 | [ 0.23,  0.64] |  4.20 | < .001 #> gender [female] |    -0.14 | 0.17 | [-0.47,  0.19] | -0.82 | 0.414  #>  #> # Response level: probably #>  #> Parameter       | Log-Odds |   SE |        95% CI |    z |     p #> ---------------------------------------------------------------- #> (Intercept)     |     0.47 | 0.29 | [-0.10, 1.04] | 1.62 | 0.105 #> religion        |     0.26 | 0.13 | [ 0.01, 0.51] | 2.01 | 0.044 #> gender [female] |     0.19 | 0.21 | [-0.22, 0.60] | 0.90 | 0.370 #>  #> # Response level: probably not #>  #> Parameter       | Log-Odds |   SE |        95% CI |     z |     p #> ----------------------------------------------------------------- #> (Intercept)     |     0.43 | 0.39 | [-0.33, 1.18] |  1.11 | 0.268 #> religion        |     0.01 | 0.17 | [-0.33, 0.35] |  0.07 | 0.945 #> gender [female] |    -0.16 | 0.28 | [-0.71, 0.39] | -0.57 | 0.566 #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) #>   computed using a Wald z-distribution approximation."},{"path":"https://easystats.github.io/parameters/reference/model_parameters.glmmTMB.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameters from Mixed Models — model_parameters.glmmTMB","title":"Parameters from Mixed Models — model_parameters.glmmTMB","text":"Parameters (linear) mixed models.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.glmmTMB.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parameters from Mixed Models — model_parameters.glmmTMB","text":"","code":"# S3 method for class 'glmmTMB' model_parameters(   model,   ci = 0.95,   ci_method = \"wald\",   ci_random = NULL,   bootstrap = FALSE,   iterations = 1000,   standardize = NULL,   effects = \"all\",   component = \"all\",   group_level = FALSE,   exponentiate = FALSE,   p_adjust = NULL,   wb_component = TRUE,   summary = getOption(\"parameters_mixed_summary\", FALSE),   include_info = getOption(\"parameters_mixed_info\", FALSE),   include_sigma = FALSE,   keep = NULL,   drop = NULL,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.glmmTMB.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameters from Mixed Models — model_parameters.glmmTMB","text":"model mixed model. ci Confidence Interval (CI) level. Default 0.95 (95%). ci_method Method computing degrees freedom confidence intervals (CI) related p-values. Allowed following options (vary depending model class): \"residual\", \"normal\", \"likelihood\", \"satterthwaite\", \"kenward\", \"wald\", \"profile\", \"boot\", \"uniroot\", \"ml1\", \"betwithin\", \"hdi\", \"quantile\", \"ci\", \"eti\", \"si\", \"bci\", \"bcai\". See section Confidence intervals approximation degrees freedom model_parameters() details. ci_method=NULL, cases \"wald\" used . ci_random Logical, TRUE, includes confidence intervals random effects parameters. applies effects \"fixed\" ci NULL. Set ci_random = FALSE computation model summary much time consuming. default, ci_random = NULL, uses heuristic guess computation confidence intervals random effects fast enough . models larger sample size /complex random effects structures, confidence intervals computed default, simpler models fewer observations, confidence intervals included. Set explicitly TRUE FALSE enforce omit calculation confidence intervals. bootstrap estimates based bootstrapped model? TRUE, arguments Bayesian regressions apply (see also bootstrap_parameters()). iterations number bootstrap replicates. apply case bootstrapped frequentist models. standardize method used standardizing parameters. Can NULL (default; standardization), \"refit\" (re-fitting model standardized data) one \"basic\", \"posthoc\", \"smart\", \"pseudo\". See 'Details' standardize_parameters(). Importantly: \"refit\" method standardize categorical predictors (.e. factors), may different behaviour compared R packages (lm.beta) software packages (like SPSS). mimic behaviours, either use standardize=\"basic\" standardize data datawizard::standardize(force=TRUE) fitting model. mixed models, using methods \"refit\", fixed effects standardized. Robust estimation (.e., vcov set value NULL) standardized parameters works standardize=\"refit\". effects parameters fixed effects (\"fixed\"), random effects (\"random\"), (\"\") returned? applies mixed models. May abbreviated. calculation random effects parameters takes long, may use effects = \"fixed\". component type parameters return, parameters conditional model, zero-inflation part model, dispersion term, auxiliary parameters returned? Applies models zero-inflation /dispersion formula, parameters sigma included. May abbreviated. Note conditional component also called count mean component, depending model. three convenient shortcuts: component = \"\" returns possible parameters. component = \"location\", location parameters conditional, zero_inflated, smooth_terms, returned (everything fixed random effects - depending effects argument - auxiliary parameters). component = \"distributional\" (\"auxiliary\"), components like sigma, dispersion, beta (auxiliary parameters) returned. group_level Logical, multilevel models (.e. models random effects) effects = \"\" effects = \"random\", include parameters group level random effects. group_level = FALSE (default), information SD COR shown. exponentiate Logical, indicating whether exponentiate coefficients (related confidence intervals). typical logistic regression, generally speaking, models log logit links. also recommended use exponentiate = TRUE models log-transformed response values. models log-transformed response variable, exponentiate = TRUE, one-unit increase predictor associated multiplying outcome predictor's coefficient. Note: Delta-method standard errors also computed (multiplying standard errors transformed coefficients). mimic behaviour software packages, Stata, standard errors poorly estimate uncertainty transformed coefficient. transformed confidence interval clearly captures uncertainty. compare_parameters(), exponentiate = \"nongaussian\" exponentiate coefficients non-Gaussian families. p_adjust Character vector, NULL, indicates method adjust p-values. See stats::p.adjust() details. possible adjustment methods \"tukey\", \"scheffe\", \"sidak\" \"none\" explicitly disable adjustment emmGrid objects (emmeans). wb_component Logical, TRUE models contains within- -effects (see datawizard::demean()), Component column indicate variables belong within-effects, -effects, cross-level interactions. default, Component column indicates, parameters belong conditional zero-inflation component model. summary Deprecated, please use info instead. include_info Logical, TRUE, prints summary information model (model formula, number observations, residual standard deviation ). include_sigma Logical, TRUE, includes residual standard deviation. mixed models, defined sum distribution-specific variance variance additive overdispersion term (see insight::get_variance() details). Defaults FALSE mixed models due longer computation time. keep Character containing regular expression pattern describes parameters included (keep) excluded (drop) returned data frame. keep may also named list regular expressions. non-matching parameters removed output. keep character vector, every parameter name \"Parameter\" column matches regular expression keep selected returned data frame (vice versa, parameter names matching drop excluded). Furthermore, keep one element, merged operator regular expression pattern like : \"(one|two|three)\". keep named list regular expression patterns, names list-element equal column name selection applied. useful model objects model_parameters() returns multiple columns parameter components, like model_parameters.lavaan(). Note regular expression pattern match parameter names stored returned data frame, can different printed. Inspect $Parameter column parameters table get exact parameter names. drop See keep. verbose Toggle warnings messages. ... Arguments passed methods. instance, bootstrap = TRUE, arguments like type parallel passed bootstrap_model(). non-documented arguments : digits, p_digits, ci_digits footer_digits set number digits output. groups can used group coefficients. arguments passed print-method, can directly used print(), see documentation print.parameters_model(). s_value = TRUE, p-value replaced S-value output (cf. Rafi Greenland 2020). pd adds additional column probability direction (see bayestestR::p_direction() details). Furthermore, see 'Examples' function. developers, whose interest mainly get \"tidy\" data frame model summaries, recommended set pretty_names = FALSE speed computation summary table.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.glmmTMB.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parameters from Mixed Models — model_parameters.glmmTMB","text":"data frame indices related model's parameters.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.glmmTMB.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Parameters from Mixed Models — model_parameters.glmmTMB","text":"calculation random effects parameters takes long, may use effects = \"fixed\". also plot()-method implemented see-package.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.glmmTMB.html","id":"confidence-intervals-for-random-effects-variances","dir":"Reference","previous_headings":"","what":"Confidence intervals for random effects variances","title":"Parameters from Mixed Models — model_parameters.glmmTMB","text":"models class merMod glmmTMB, confidence intervals random effect variances can calculated. models package lme4, ci_method either \"profile\" \"boot\", effects either \"random\" \"\", profiled resp. bootstrapped confidence intervals computed random effects. options ci_method, merDeriv package installed, confidence intervals random effects based normal-distribution approximation, using delta-method transform standard errors constructing intervals around log-transformed SD parameters. back-transformed, random effect variances, standard errors confidence intervals shown original scale. Due transformation, intervals asymmetrical, however, within correct bounds (.e. negative interval SD, interval correlations within range -1 +1). models class glmmTMB, confidence intervals random effect variances always use Wald t-distribution approximation.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.glmmTMB.html","id":"singular-fits-random-effects-variances-near-zero-","dir":"Reference","previous_headings":"","what":"Singular fits (random effects variances near zero)","title":"Parameters from Mixed Models — model_parameters.glmmTMB","text":"model \"singular\", means dimensions variance-covariance matrix estimated exactly zero. often occurs mixed models complex random effects structures. gold-standard deal singularity random-effects specification choose. One way fully go Bayesian (informative priors). proposals listed documentation performance::check_singularity(). However, since version 1.1.9, glmmTMB package allows use priors frequentist framework, . One recommendation use Gamma prior (Chung et al. 2013). mean may vary 1 large values (like 1e8), shape parameter set value 2.5. can update() model specified prior. glmmTMB, code look like :   Large values mean parameter Gamma prior large impact random effects variances terms \"bias\". Thus, 1 fix singular fit, can safely try larger values.","code":"# \"model\" is an object of class gmmmTMB prior <- data.frame(   prior = \"gamma(1, 2.5)\",  # mean can be 1, but even 1e8   class = \"ranef\"           # for random effects ) model_with_priors <- update(model, priors = prior)"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.glmmTMB.html","id":"dispersion-parameters-in-glmmtmb","dir":"Reference","previous_headings":"","what":"Dispersion parameters in glmmTMB","title":"Parameters from Mixed Models — model_parameters.glmmTMB","text":"models package glmmTMB, dispersion parameter residual variance random effects parameters shown. Usually, presented different scales, e.g.   models dispersion parameter residual variance , residual variance shown output.","code":"model <- glmmTMB(Sepal.Width ~ Petal.Length + (1|Species), data = iris) exp(fixef(model)$disp) # 0.09902987 sigma(model)^2         # 0.09902987"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.glmmTMB.html","id":"model-components","dir":"Reference","previous_headings":"","what":"Model components","title":"Parameters from Mixed Models — model_parameters.glmmTMB","text":"Possible values component argument depend model class. Following valid options: \"\": returns model components, applies models, effect models just conditional model component. \"conditional\": returns conditional component, .e. \"fixed effects\" terms model. effect models just conditional model component. \"smooth_terms\": returns smooth terms, applies GAMs (similar models may contain smooth terms). \"zero_inflated\" (\"zi\"): returns zero-inflation component. \"dispersion\": returns dispersion model component. common models zero-inflation can model dispersion parameter. \"instruments\": instrumental-variable fixed effects regression, returns instruments. \"nonlinear\": non-linear models (like models class nlmerMod nls), returns staring estimates nonlinear parameters. \"correlation\": models correlation-component, like gls, variables used describe correlation structure returned. Special models model classes also allow rather uncommon options. : mhurdle: \"infrequent_purchase\", \"ip\", \"auxiliary\" BGGM: \"correlation\" \"intercept\" BFBayesFactor, glmx: \"extra\" averaging:\"conditional\" \"full\" mjoint: \"survival\" mfx: \"precision\", \"marginal\" betareg, DirichletRegModel: \"precision\" mvord: \"thresholds\" \"correlation\" clm2: \"scale\" selection: \"selection\", \"outcome\", \"auxiliary\" lavaan: One \"regression\", \"correlation\", \"loading\", \"variance\", \"defined\", \"mean\". Can also \"\" include components. models class brmsfit (package brms), even options possible component argument, documented detail .","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.glmmTMB.html","id":"confidence-intervals-and-approximation-of-degrees-of-freedom","dir":"Reference","previous_headings":"","what":"Confidence intervals and approximation of degrees of freedom","title":"Parameters from Mixed Models — model_parameters.glmmTMB","text":"different ways approximating degrees freedom depending different assumptions nature model sampling distribution. ci_method argument modulates method computing degrees freedom (df) used calculate confidence intervals (CI) related p-values. Following options allowed, depending model class: Classical methods: Classical inference generally based Wald method. Wald approach inference computes test statistic dividing parameter estimate standard error (Coefficient / SE), comparing statistic t- normal distribution. approach can used compute CIs p-values. \"wald\": Applies non-Bayesian models. linear models, CIs computed using Wald method (SE t-distribution residual df); p-values computed using Wald method t-distribution residual df. models, CIs computed using Wald method (SE normal distribution); p-values computed using Wald method normal distribution. \"normal\" Applies non-Bayesian models. Compute Wald CIs p-values, always use normal distribution. \"residual\" Applies non-Bayesian models. Compute Wald CIs p-values, always use t-distribution residual df possible. residual df model determined, normal distribution used instead. Methods mixed models: Compared fixed effects (single-level) models, determining appropriate df Wald-based inference mixed models difficult. See R GLMM FAQ discussion. Several approximate methods computing df available, also consider instead using profile likelihood (\"profile\") bootstrap (\"boot\") CIs p-values instead. \"satterthwaite\" Applies linear mixed models. CIs computed using Wald method (SE t-distribution Satterthwaite df); p-values computed using Wald method t-distribution Satterthwaite df. \"kenward\" Applies linear mixed models. CIs computed using Wald method (Kenward-Roger SE t-distribution Kenward-Roger df); p-values computed using Wald method Kenward-Roger SE t-distribution Kenward-Roger df. \"ml1\" Applies linear mixed models. CIs computed using Wald method (SE t-distribution m-l-1 approximated df); p-values computed using Wald method t-distribution m-l-1 approximated df. See ci_ml1(). \"betwithin\" Applies linear mixed models generalized linear mixed models. CIs computed using Wald method (SE t-distribution -within df); p-values computed using Wald method t-distribution -within df. See ci_betwithin(). Likelihood-based methods: Likelihood-based inference based comparing likelihood maximum-likelihood estimate likelihood models one parameter values changed (e.g., set zero range alternative values). Likelihood ratios maximum-likelihood alternative models compared \\(\\chi\\)-squared distribution compute CIs p-values. \"profile\" Applies non-Bayesian models class glm, polr, merMod glmmTMB. CIs computed profiling likelihood curve parameter, using linear interpolation find likelihood ratio equals critical value; p-values computed using Wald method normal-distribution (note: might change future update!) \"uniroot\" Applies non-Bayesian models class glmmTMB. CIs computed profiling likelihood curve parameter, using root finding find likelihood ratio equals critical value; p-values computed using Wald method normal-distribution (note: might change future update!) Methods bootstrapped Bayesian models: Bootstrap-based inference based resampling refitting model resampled datasets. distribution parameter estimates across resampled datasets used approximate parameter's sampling distribution. Depending type model, several different methods bootstrapping constructing CIs p-values bootstrap distribution available. Bayesian models, inference based drawing samples model posterior distribution. \"quantile\" (\"eti\") Applies models (including Bayesian models). non-Bayesian models, applies bootstrap = TRUE. CIs computed equal tailed intervals using quantiles bootstrap posterior samples; p-values based probability direction. See bayestestR::eti(). \"hdi\" Applies models (including Bayesian models). non-Bayesian models, applies bootstrap = TRUE. CIs computed highest density intervals bootstrap posterior samples; p-values based probability direction. See bayestestR::hdi(). \"bci\" (\"bcai\") Applies models (including Bayesian models). non-Bayesian models, applies bootstrap = TRUE. CIs computed bias corrected accelerated intervals bootstrap posterior samples; p-values based probability direction. See bayestestR::bci(). \"si\" Applies Bayesian models proper priors. CIs computed support intervals comparing posterior samples prior samples; p-values based probability direction. See bayestestR::si(). \"boot\" Applies non-Bayesian models class merMod. CIs computed using parametric bootstrapping (simulating data fitted model); p-values computed using Wald method normal-distribution) (note: might change future update!). iteration-based methods \"boot\" (\"hdi\", \"quantile\", \"ci\", \"eti\", \"si\", \"bci\", \"bcai\"), p-values based probability direction (bayestestR::p_direction()), converted p-value using bayestestR::pd_to_p().","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.glmmTMB.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Parameters from Mixed Models — model_parameters.glmmTMB","text":"Chung Y, Rabe-Hesketh S, Dorie V, Gelman , Liu J. 2013. \"Nondegenerate Penalized Likelihood Estimator Variance Parameters Multilevel Models.\" Psychometrika 78 (4): 685–709. doi:10.1007/s11336-013-9328-2","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/model_parameters.glmmTMB.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parameters from Mixed Models — model_parameters.glmmTMB","text":"","code":"library(parameters) data(mtcars) model <- lme4::lmer(mpg ~ wt + (1 | gear), data = mtcars) model_parameters(model) #> # Fixed Effects  #>  #> Parameter   | Coefficient |   SE |         95% CI | t(28) |      p #> ------------------------------------------------------------------ #> (Intercept) |       36.19 | 2.19 | [31.70, 40.68] | 16.52 | < .001 #> wt          |       -5.05 | 0.64 | [-6.36, -3.73] | -7.89 | < .001 #>  #> # Random Effects  #>  #> Parameter            | Coefficient |   SE |       95% CI #> -------------------------------------------------------- #> SD (Intercept: gear) |        1.26 | 1.12 | [0.22, 7.17] #> SD (Residual)        |        2.91 | 0.39 | [2.24, 3.78] #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) #>   computed using a Wald t-distribution approximation. Uncertainty #>   intervals for random effect variances computed using a Wald #>   z-distribution approximation.  # \\donttest{ data(Salamanders, package = \"glmmTMB\") model <- glmmTMB::glmmTMB(   count ~ spp + mined + (1 | site),   ziformula = ~mined,   family = poisson(),   data = Salamanders ) model_parameters(model, effects = \"all\") #> # Fixed Effects (Count Model)  #>  #> Parameter   | Log-Mean |   SE |         95% CI |     z |      p #> --------------------------------------------------------------- #> (Intercept) |    -0.36 | 0.28 | [-0.90,  0.18] | -1.30 | 0.194  #> spp [PR]    |    -1.27 | 0.24 | [-1.74, -0.80] | -5.27 | < .001 #> spp [DM]    |     0.27 | 0.14 | [ 0.00,  0.54] |  1.95 | 0.051  #> spp [EC-A]  |    -0.57 | 0.21 | [-0.97, -0.16] | -2.75 | 0.006  #> spp [EC-L]  |     0.67 | 0.13 | [ 0.41,  0.92] |  5.20 | < .001 #> spp [DES-L] |     0.63 | 0.13 | [ 0.38,  0.87] |  4.96 | < .001 #> spp [DF]    |     0.12 | 0.15 | [-0.17,  0.40] |  0.78 | 0.435  #> mined [no]  |     1.27 | 0.27 | [ 0.74,  1.80] |  4.72 | < .001 #>  #> # Fixed Effects (Zero-Inflation Component)  #>  #> Parameter   | Log-Odds |   SE |         95% CI |     z |      p #> --------------------------------------------------------------- #> (Intercept) |     0.79 | 0.27 | [ 0.26,  1.32] |  2.90 | 0.004  #> mined [no]  |    -1.84 | 0.31 | [-2.46, -1.23] | -5.87 | < .001 #>  #> # Random Effects Variances  #>  #> Parameter            | Coefficient |       95% CI #> ------------------------------------------------- #> SD (Intercept: site) |        0.33 | [0.18, 0.63] #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) #>   computed using a Wald z-distribution approximation.  model <- lme4::lmer(mpg ~ wt + (1 | gear), data = mtcars) model_parameters(model, bootstrap = TRUE, iterations = 50, verbose = FALSE) #> # Fixed Effects #>  #> Parameter   | Coefficient |         95% CI |      p #> --------------------------------------------------- #> (Intercept) |       36.25 | [31.78, 40.55] | < .001 #> wt          |       -4.89 | [-6.02, -3.62] | < .001 # }"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.hclust.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameters from Cluster Models (k-means, ...) — model_parameters.hclust","title":"Parameters from Cluster Models (k-means, ...) — model_parameters.hclust","text":"Format cluster models obtained example kmeans().","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.hclust.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parameters from Cluster Models (k-means, ...) — model_parameters.hclust","text":"","code":"# S3 method for class 'hclust' model_parameters(model, data = NULL, clusters = NULL, ...)"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.hclust.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameters from Cluster Models (k-means, ...) — model_parameters.hclust","text":"model Cluster model. data data frame. clusters vector clusters assignments (must length rows data). ... Arguments passed methods.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.hclust.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parameters from Cluster Models (k-means, ...) — model_parameters.hclust","text":"","code":"# \\donttest{ # # K-means ------------------------------- model <- kmeans(iris[1:4], centers = 3) rez <- model_parameters(model) rez #> # Clustering Solution #>  #> The 3 clusters accounted for 88.43% of the total variance of the original data. #>  #> Cluster | n_Obs | Sum_Squares | Sepal.Length | Sepal.Width | Petal.Length | Petal.Width #> --------------------------------------------------------------------------------------- #> 1       |    38 |       23.88 |         6.85 |        3.07 |         5.74 |        2.07 #> 2       |    62 |       39.82 |         5.90 |        2.75 |         4.39 |        1.43 #> 3       |    50 |       15.15 |         5.01 |        3.43 |         1.46 |        0.25  # Get clusters predict(rez) #>   [1] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 #>  [38] 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 #>  [75] 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 1 1 1 1 2 1 1 1 1 #> [112] 1 1 2 2 1 1 1 1 2 1 2 1 2 1 1 2 2 1 1 1 1 1 2 1 1 1 1 2 1 1 1 2 1 1 1 2 1 #> [149] 1 2  # Clusters centers in long form attributes(rez)$means #>    Cluster n_Obs Sum_Squares     Variable     Mean #> 1        1    38    23.87947 Sepal.Length 6.850000 #> 2        1    38    23.87947  Sepal.Width 3.073684 #> 3        1    38    23.87947 Petal.Length 5.742105 #> 4        1    38    23.87947  Petal.Width 2.071053 #> 5        2    62    39.82097 Sepal.Length 5.901613 #> 6        2    62    39.82097  Sepal.Width 2.748387 #> 7        2    62    39.82097 Petal.Length 4.393548 #> 8        2    62    39.82097  Petal.Width 1.433871 #> 9        3    50    15.15100 Sepal.Length 5.006000 #> 10       3    50    15.15100  Sepal.Width 3.428000 #> 11       3    50    15.15100 Petal.Length 1.462000 #> 12       3    50    15.15100  Petal.Width 0.246000  # Between and Total Sum of Squares attributes(rez)$Sum_Squares_Total #> [1] 681.3706 attributes(rez)$Sum_Squares_Between #> [1] 602.5192  # # Hierarchical clustering (hclust) --------------------------- data <- iris[1:4] model <- hclust(dist(data)) clusters <- cutree(model, 3)  rez <- model_parameters(model, data, clusters) rez #> # Clustering Solution #>  #> The 3 clusters accounted for 86.86% of the total variance of the original data. #>  #> Cluster | n_Obs | Sum_Squares | Sepal.Length | Sepal.Width | Petal.Length | Petal.Width #> --------------------------------------------------------------------------------------- #> 1       |    50 |       15.15 |         5.01 |        3.43 |         1.46 |        0.25 #> 2       |    72 |       64.62 |         6.55 |        2.96 |         5.27 |        1.85 #> 3       |    28 |        9.75 |         5.53 |        2.64 |         3.96 |        1.23  # Get clusters predict(rez) #>   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 #>  [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 3 2 3 2 3 2 3 3 3 3 2 3 2 3 3 2 3 2 3 2 2 #>  [75] 2 2 2 2 2 3 3 3 3 2 3 2 2 2 3 3 3 2 3 3 3 3 3 2 3 3 2 2 2 2 2 2 3 2 2 2 2 #> [112] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 #> [149] 2 2  # Clusters centers in long form attributes(rez)$means #>    Cluster n_Obs Sum_Squares     Variable     Mean #> 1        1    50   15.151000 Sepal.Length 5.006000 #> 2        1    50   15.151000  Sepal.Width 3.428000 #> 3        1    50   15.151000 Petal.Length 1.462000 #> 4        1    50   15.151000  Petal.Width 0.246000 #> 5        2    72   64.624722 Sepal.Length 6.545833 #> 6        2    72   64.624722  Sepal.Width 2.963889 #> 7        2    72   64.624722 Petal.Length 5.273611 #> 8        2    72   64.624722  Petal.Width 1.850000 #> 9        3    28    9.749286 Sepal.Length 5.532143 #> 10       3    28    9.749286  Sepal.Width 2.635714 #> 11       3    28    9.749286 Petal.Length 3.960714 #> 12       3    28    9.749286  Petal.Width 1.228571  # Between and Total Sum of Squares attributes(rez)$Total_Sum_Squares #> NULL attributes(rez)$Between_Sum_Squares #> NULL  # # Hierarchical K-means (factoextra::hkclust) ---------------------- data <- iris[1:4] model <- factoextra::hkmeans(data, k = 3)  rez <- model_parameters(model) rez #> # Clustering Solution #>  #> The 3 clusters accounted for 88.43% of the total variance of the original data. #>  #> Cluster | n_Obs | Sum_Squares | Sepal.Length | Sepal.Width | Petal.Length | Petal.Width #> --------------------------------------------------------------------------------------- #> 1       |    50 |       15.15 |         5.01 |        3.43 |         1.46 |        0.25 #> 2       |    62 |       39.82 |         5.90 |        2.75 |         4.39 |        1.43 #> 3       |    38 |       23.88 |         6.85 |        3.07 |         5.74 |        2.07  # Get clusters predict(rez) #>   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 #>  [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 #>  [75] 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2 3 3 3 3 2 3 3 3 3 #> [112] 3 3 2 2 3 3 3 3 2 3 2 3 2 3 3 2 2 3 3 3 3 3 2 3 3 3 3 2 3 3 3 2 3 3 3 2 3 #> [149] 3 2  # Clusters centers in long form attributes(rez)$means #>    Cluster n_Obs Sum_Squares     Variable     Mean #> 1        1    50    15.15100 Sepal.Length 5.006000 #> 2        1    50    15.15100  Sepal.Width 3.428000 #> 3        1    50    15.15100 Petal.Length 1.462000 #> 4        1    50    15.15100  Petal.Width 0.246000 #> 5        2    62    39.82097 Sepal.Length 5.901613 #> 6        2    62    39.82097  Sepal.Width 2.748387 #> 7        2    62    39.82097 Petal.Length 4.393548 #> 8        2    62    39.82097  Petal.Width 1.433871 #> 9        3    38    23.87947 Sepal.Length 6.850000 #> 10       3    38    23.87947  Sepal.Width 3.073684 #> 11       3    38    23.87947 Petal.Length 5.742105 #> 12       3    38    23.87947  Petal.Width 2.071053  # Between and Total Sum of Squares attributes(rez)$Sum_Squares_Total #> [1] 681.3706 attributes(rez)$Sum_Squares_Between #> [1] 602.5192  # K-Medoids (PAM and HPAM) ============== model <- cluster::pam(iris[1:4], k = 3) model_parameters(model) #> # Clustering Solution #>  #> The 3 clusters accounted for 88.43% of the total variance of the original data. #>  #> Cluster | n_Obs | Sum_Squares | Sepal.Length | Sepal.Width | Petal.Length | Petal.Width #> --------------------------------------------------------------------------------------- #> 1       |    50 |       15.15 |         5.01 |        3.43 |         1.46 |        0.25 #> 2       |    62 |       39.82 |         5.90 |        2.75 |         4.39 |        1.43 #> 3       |    38 |       23.88 |         6.85 |        3.07 |         5.74 |        2.07  model <- fpc::pamk(iris[1:4], criterion = \"ch\") model_parameters(model) #> # Clustering Solution #>  #> The 3 clusters accounted for 88.43% of the total variance of the original data. #>  #> Cluster | n_Obs | Sum_Squares | Sepal.Length | Sepal.Width | Petal.Length | Petal.Width #> --------------------------------------------------------------------------------------- #> 1       |    50 |       15.15 |         5.01 |        3.43 |         1.46 |        0.25 #> 2       |    62 |       39.82 |         5.90 |        2.75 |         4.39 |        1.43 #> 3       |    38 |       23.88 |         6.85 |        3.07 |         5.74 |        2.07  # DBSCAN --------------------------- model <- dbscan::dbscan(iris[1:4], eps = 1.45, minPts = 10)  rez <- model_parameters(model, iris[1:4]) rez #> # Clustering Solution #>  #> The 2 clusters accounted for 77.26% of the total variance of the original data. #>  #> Cluster | n_Obs | Sum_Squares | Sepal.Length | Sepal.Width | Petal.Length | Petal.Width #> --------------------------------------------------------------------------------------- #> 1       |    50 |       15.15 |         5.01 |        3.43 |         1.46 |        0.25 #> 2       |   100 |      139.80 |         6.26 |        2.87 |         4.91 |        1.68  # Get clusters predict(rez) #> NULL  # Clusters centers in long form attributes(rez)$means #>   Cluster n_Obs Sum_Squares     Variable  Mean #> 1       1    50      15.151 Sepal.Length 5.006 #> 2       1    50      15.151  Sepal.Width 3.428 #> 3       1    50      15.151 Petal.Length 1.462 #> 4       1    50      15.151  Petal.Width 0.246 #> 5       2   100     139.796 Sepal.Length 6.262 #> 6       2   100     139.796  Sepal.Width 2.872 #> 7       2   100     139.796 Petal.Length 4.906 #> 8       2   100     139.796  Petal.Width 1.676  # Between and Total Sum of Squares attributes(rez)$Sum_Squares_Total #> [1] 681.3706 attributes(rez)$Sum_Squares_Between #> [1] 526.4236  # HDBSCAN model <- dbscan::hdbscan(iris[1:4], minPts = 10) model_parameters(model, iris[1:4]) #> # Clustering Solution #>  #> The 2 clusters accounted for 77.26% of the total variance of the original data. #>  #> Cluster | n_Obs | Sum_Squares | Sepal.Length | Sepal.Width | Petal.Length | Petal.Width #> --------------------------------------------------------------------------------------- #> 1       |   100 |      139.80 |         6.26 |        2.87 |         4.91 |        1.68 #> 2       |    50 |       15.15 |         5.01 |        3.43 |         1.46 |        0.25 # }"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.htest.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameters from hypothesis tests — model_parameters.htest","title":"Parameters from hypothesis tests — model_parameters.htest","text":"Parameters h-tests (correlations, t-tests, chi-squared, ...).","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.htest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parameters from hypothesis tests — model_parameters.htest","text":"","code":"# S3 method for class 'htest' model_parameters(   model,   ci = 0.95,   alternative = NULL,   bootstrap = FALSE,   es_type = NULL,   verbose = TRUE,   ... )  # S3 method for class 'coeftest' model_parameters(   model,   ci = 0.95,   ci_method = \"wald\",   keep = NULL,   drop = NULL,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.htest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameters from hypothesis tests — model_parameters.htest","text":"model Object class htest pairwise.htest. ci Level confidence intervals effect size statistic. Currently applies objects chisq.test() oneway.test(). alternative character string specifying alternative hypothesis; Controls type CI returned: \"two.sided\" (default, two-sided CI), \"greater\" \"less\" (one-sided CI). Partial matching allowed (e.g., \"g\", \"l\", \"two\"...). See section One-Sided CIs effectsize_CIs vignette. bootstrap estimates bootstrapped? es_type effect size interest. possibly effect sizes applicable model object. See 'Details'. Anova models, can also character vector multiple effect size names. verbose Toggle warnings messages. ... Arguments passed methods. instance, bootstrap = TRUE, arguments like type parallel passed bootstrap_model(). non-documented arguments : digits, p_digits, ci_digits footer_digits set number digits output. groups can used group coefficients. arguments passed print-method, can directly used print(), see documentation print.parameters_model(). s_value = TRUE, p-value replaced S-value output (cf. Rafi Greenland 2020). pd adds additional column probability direction (see bayestestR::p_direction() details). Furthermore, see 'Examples' function. developers, whose interest mainly get \"tidy\" data frame model summaries, recommended set pretty_names = FALSE speed computation summary table. ci_method Method computing degrees freedom confidence intervals (CI) related p-values. Allowed following options (vary depending model class): \"residual\", \"normal\", \"likelihood\", \"satterthwaite\", \"kenward\", \"wald\", \"profile\", \"boot\", \"uniroot\", \"ml1\", \"betwithin\", \"hdi\", \"quantile\", \"ci\", \"eti\", \"si\", \"bci\", \"bcai\". See section Confidence intervals approximation degrees freedom model_parameters() details. ci_method=NULL, cases \"wald\" used . keep Character containing regular expression pattern describes parameters included (keep) excluded (drop) returned data frame. keep may also named list regular expressions. non-matching parameters removed output. keep character vector, every parameter name \"Parameter\" column matches regular expression keep selected returned data frame (vice versa, parameter names matching drop excluded). Furthermore, keep one element, merged operator regular expression pattern like : \"(one|two|three)\". keep named list regular expression patterns, names list-element equal column name selection applied. useful model objects model_parameters() returns multiple columns parameter components, like model_parameters.lavaan(). Note regular expression pattern match parameter names stored returned data frame, can different printed. Inspect $Parameter column parameters table get exact parameter names. drop See keep.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.htest.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parameters from hypothesis tests — model_parameters.htest","text":"data frame indices related model's parameters.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.htest.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Parameters from hypothesis tests — model_parameters.htest","text":"object class htest, data extracted via insight::get_data(), passed relevant function according : t-test depending type: \"cohens_d\" (default), \"hedges_g\", one \"p_superiority\", \"u1\", \"u2\", \"u3\", \"overlap\". Paired t-test: depending type: \"rm_rm\", \"rm_av\", \"rm_b\", \"rm_d\", \"rm_z\". Chi-squared tests independence Fisher's Exact Test, depending type: \"cramers_v\" (default), \"tschuprows_t\", \"phi\", \"cohens_w\", \"pearsons_c\", \"cohens_h\", \"oddsratio\", \"riskratio\", \"arr\", \"nnt\". Chi-squared tests goodness--fit, depending type: \"fei\" (default) \"cohens_w\", \"pearsons_c\" One-way ANOVA test, depending type: \"eta\" (default), \"omega\" \"epsilon\" -squared, \"f\", \"f2\". McNemar test returns Cohen's g. Wilcoxon test depending type: returns \"rank_biserial\" correlation (default) one \"p_superiority\", \"vda\", \"u2\", \"u3\", \"overlap\". Kruskal-Wallis test depending type: \"epsilon\" (default) \"eta\". Friedman test returns Kendall's W. (applicable, ci alternative taken htest otherwise provided.) object class BFBayesFactor, using bayestestR::describe_posterior(), t-test depending type: \"cohens_d\" (default) one \"p_superiority\", \"u1\", \"u2\", \"u3\", \"overlap\". correlation test returns r. contingency table test, depending type: \"cramers_v\" (default), \"phi\", \"tschuprows_t\", \"cohens_w\", \"pearsons_c\", \"cohens_h\", \"oddsratio\", \"riskratio\", \"arr\", \"nnt\". proportion test returns p. Objects class anova, aov, aovlist afex_aov, depending type: \"eta\" (default), \"omega\" \"epsilon\" -squared, \"f\", \"f2\". objects passed parameters::standardize_parameters(). statistical models recommended directly use listed functions, full range options provide.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.htest.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parameters from hypothesis tests — model_parameters.htest","text":"","code":"model <- cor.test(mtcars$mpg, mtcars$cyl, method = \"pearson\") model_parameters(model) #> Pearson's product-moment correlation #>  #> Parameter1 | Parameter2 |     r |         95% CI | t(30) |      p #> ----------------------------------------------------------------- #> mtcars$mpg | mtcars$cyl | -0.85 | [-0.93, -0.72] | -8.92 | < .001 #>  #> Alternative hypothesis: true correlation is not equal to 0  model <- t.test(iris$Sepal.Width, iris$Sepal.Length) model_parameters(model, es_type = \"hedges_g\") #> Welch Two Sample t-test #>  #> Parameter1       |        Parameter2 | Mean_Parameter1 | Mean_Parameter2 #> ------------------------------------------------------------------------ #> iris$Sepal.Width | iris$Sepal.Length |            3.06 |            5.84 #>  #> Parameter1       | Difference |         95% CI | Hedges' g |       g 95% CI #> --------------------------------------------------------------------------- #> iris$Sepal.Width |      -2.79 | [-2.94, -2.64] |     -4.20 | [-4.64, -3.75] #>  #> Parameter1       | t(225.68) |      p #> ------------------------------------- #> iris$Sepal.Width |    -36.46 | < .001 #>  #> Alternative hypothesis: true difference in means is not equal to 0  model <- t.test(mtcars$mpg ~ mtcars$vs) model_parameters(model, es_type = \"hedges_g\") #> Welch Two Sample t-test #>  #> Parameter  |     Group | Mean_Group1 | Mean_Group2 | Difference #> --------------------------------------------------------------- #> mtcars$mpg | mtcars$vs |       16.62 |       24.56 |      -7.94 #>  #> Parameter  |          95% CI | Hedges' g |       g 95% CI | t(22.72) |      p #> ----------------------------------------------------------------------------- #> mtcars$mpg | [-11.46, -4.42] |     -1.64 | [-2.46, -0.79] |    -4.67 | < .001 #>  #> Alternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0  model <- t.test(iris$Sepal.Width, mu = 1) model_parameters(model, es_type = \"cohens_d\") #> One Sample t-test #>  #> Parameter        |   mu | Difference |       95% CI | Cohen's d |     d 95% CI #> ------------------------------------------------------------------------------ #> iris$Sepal.Width | 1.00 |       2.06 | [2.99, 3.13] |      4.72 | [4.15, 5.27] #>  #> Parameter        | t(149) |      p #> ---------------------------------- #> iris$Sepal.Width |  57.81 | < .001 #>  #> Alternative hypothesis: true mean is not equal to 1  data(airquality) airquality$Month <- factor(airquality$Month, labels = month.abb[5:9]) model <- pairwise.t.test(airquality$Ozone, airquality$Month) model_parameters(model) #> # Fixed Effects #>  #> Group1 | Group2 |      p #> ------------------------ #> Jun    |    May | > .999 #> Jul    |    May | < .001 #> Jul    |    Jun | 0.051  #> Aug    |    May | < .001 #> Aug    |    Jun | 0.050  #> Aug    |    Jul | > .999 #> Sep    |    May | > .999 #> Sep    |    Jun | > .999 #> Sep    |    Jul | 0.005  #> Sep    |    Aug | 0.004  #>  #> p-value adjustment method: Holm (1979)  smokers <- c(83, 90, 129, 70) patients <- c(86, 93, 136, 82) model <- suppressWarnings(pairwise.prop.test(smokers, patients)) model_parameters(model) #> # Fixed Effects #>  #> Group1 | Group2 |      p #> ------------------------ #> 2      |      1 | > .999 #> 3      |      1 | > .999 #> 3      |      2 | > .999 #> 4      |      1 | 0.119  #> 4      |      2 | 0.093  #> 4      |      3 | 0.124  #>  #> p-value adjustment method: Holm (1979)  model <- suppressWarnings(chisq.test(table(mtcars$am, mtcars$cyl))) model_parameters(model, es_type = \"cramers_v\") #> Pearson's Chi-squared test #>  #> Chi2(2) | Cramer's V (adj.) | Cramers 95% CI |     p #> ---------------------------------------------------- #> 8.74    |              0.46 |   [0.00, 1.00] | 0.013"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.html","id":null,"dir":"Reference","previous_headings":"","what":"Model Parameters — model_parameters","title":"Model Parameters — model_parameters","text":"Compute extract model parameters. available options arguments depend modeling package model class. Follow one links read model-specific documentation: Default method: lm, glm, stats, censReg, MASS, survey, ... Additive models: bamlss, gamlss, mgcv, scam, VGAM, Gam (although output Gam Anova-alike), gamm, ... ANOVA: afex, aov, anova, Gam, ... Bayesian: BayesFactor, blavaan, brms, MCMCglmm, posterior, rstanarm, bayesQR, bcplm, BGGM, blmrm, blrm, mcmc.list, MCMCglmm, ... Clustering: hclust, kmeans, mclust, pam, ... Correlations, t-tests, etc.: lmtest, htest, pairwise.htest, ... Meta-Analysis: metaBMA, metafor, metaplus, ... Mixed models: cplm, glmmTMB, lme4, lmerTest, nlme, ordinal, robustlmm, spaMM, mixed, MixMod, ... Multinomial, ordinal cumulative link: brglm2, DirichletReg, nnet, ordinal, mlm, ... Multiple imputation: mice PCA, FA, CFA, SEM: FactoMineR, lavaan, psych, sem, ... Zero-inflated hurdle: cplm, mhurdle, pscl, ... models: aod, bbmle, betareg, emmeans, epiR, ggeffects, glmx, ivfixed, ivprobit, JRM, lmodel2, logitsf, marginaleffects, margins, maxLik, mediation, mfx, multcomp, mvord, plm, PMCMRplus, quantreg, selection, systemfit, tidymodels, varEST, WRS2, bfsl, deltaMethod, fitdistr, mjoint, mle, model.avg, ...","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Model Parameters — model_parameters","text":"","code":"model_parameters(model, ...)  parameters(model, ...)"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Model Parameters — model_parameters","text":"model Statistical Model. ... Arguments passed methods. Non-documented arguments digits, p_digits, ci_digits footer_digits set number digits output. groups can used group coefficients. arguments passed print-method, can directly used print(), see documentation print.parameters_model(). s_value = TRUE, p-value replaced S-value output (cf. Rafi Greenland 2020). pd adds additional column probability direction (see bayestestR::p_direction() details). Furthermore, see 'Examples' model_parameters.default(). developers, whose interest mainly get \"tidy\" data frame model summaries, recommended set pretty_names = FALSE speed computation summary table.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Model Parameters — model_parameters","text":"data frame indices related model's parameters.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Model Parameters — model_parameters","text":"full overview can found : https://easystats.github.io/parameters/reference/","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Model Parameters — model_parameters","text":"print() method several arguments tweak output. also plot()-method implemented see-package, dedicated method use inside rmarkdown files, print_md(). developers, speed performance issue, can use (undocumented) pretty_names argument, e.g. model_parameters(..., pretty_names = FALSE). skip formatting coefficient names makes model_parameters() faster.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.html","id":"standardization-of-model-coefficients","dir":"Reference","previous_headings":"","what":"Standardization of model coefficients","title":"Model Parameters — model_parameters","text":"Standardization based standardize_parameters(). case standardize = \"refit\", data used fit model standardized model completely refitted. cases, standard errors confidence intervals refer standardized coefficient. default, standardize = \"refit\", never standardizes categorical predictors (.e. factors), may different behaviour compared R packages software packages (like SPSS). mimic behaviour SPSS packages lm.beta, use standardize = \"basic\".","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.html","id":"standardization-methods","dir":"Reference","previous_headings":"","what":"Standardization Methods","title":"Model Parameters — model_parameters","text":"refit: method based complete model re-fit standardized version data. Hence, method equal standardizing variables fitting model. \"purest\" accurate (Neter et al., 1989), also computationally costly long (especially heavy models Bayesian models). method particularly recommended complex models include interactions transformations (e.g., polynomial spline terms). robust (default FALSE) argument enables robust standardization data, .e., based median MAD instead mean SD. See datawizard::standardize() details. Note standardize_parameters(method = \"refit\") may return results fitting model data standardized standardize(); standardize_parameters() used data used model fitting function, might data missing values. see remove_na argument standardize(). posthoc: Post-hoc standardization parameters, aiming emulating results obtained \"refit\" without refitting model. coefficients divided standard deviation (MAD robust) outcome (becomes expression 'unit'). , coefficients related numeric variables additionally multiplied standard deviation (MAD robust) related terms, correspond changes 1 SD predictor (e.g., \"change 1 SD x related change 0.24 SD y). apply binary variables factors, coefficients still related changes levels. method accurate tend give aberrant results interactions specified. basic: method similar method = \"posthoc\", treats variables continuous: also scales coefficient standard deviation model's matrix' parameter factors levels (transformed integers) binary predictors. Although inappropriate cases, method one implemented default software packages, lm.beta::lm.beta(). smart (Standardization Model's parameters Adjustment, Reconnaissance Transformation - experimental): Similar method = \"posthoc\" involve model refitting. difference SD (MAD robust) response computed relevant section data. instance, factor 3 levels (intercept), B C entered predictor, effect corresponding B vs. scaled variance response intercept . results, coefficients effects factors similar Glass' delta. pseudo (2-level (G)LMMs ): (post-hoc) method, response predictor standardized based level prediction (levels detected performance::check_heterogeneity_bias()): Predictors standardized based SD level prediction (see also datawizard::demean()); outcome (linear LMMs) standardized based fitted random-intercept-model, sqrt(random-intercept-variance) used level 2 predictors, sqrt(residual-variance) used level 1 predictors (Hoffman 2015, page 342). warning given within-group variable found access -group variance. See also package vignette.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.html","id":"labeling-the-degrees-of-freedom","dir":"Reference","previous_headings":"","what":"Labeling the Degrees of Freedom","title":"Model Parameters — model_parameters","text":"Throughout parameters package, decided label residual degrees freedom df_error. reason degrees freedom always refer residuals. certain models, refer estimate error - linear model , - instance - mixed effects model, strictly true. Hence, think df_error generic label degrees freedom.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.html","id":"confidence-intervals-and-approximation-of-degrees-of-freedom","dir":"Reference","previous_headings":"","what":"Confidence intervals and approximation of degrees of freedom","title":"Model Parameters — model_parameters","text":"different ways approximating degrees freedom depending different assumptions nature model sampling distribution. ci_method argument modulates method computing degrees freedom (df) used calculate confidence intervals (CI) related p-values. Following options allowed, depending model class: Classical methods: Classical inference generally based Wald method. Wald approach inference computes test statistic dividing parameter estimate standard error (Coefficient / SE), comparing statistic t- normal distribution. approach can used compute CIs p-values. \"wald\": Applies non-Bayesian models. linear models, CIs computed using Wald method (SE t-distribution residual df); p-values computed using Wald method t-distribution residual df. models, CIs computed using Wald method (SE normal distribution); p-values computed using Wald method normal distribution. \"normal\" Applies non-Bayesian models. Compute Wald CIs p-values, always use normal distribution. \"residual\" Applies non-Bayesian models. Compute Wald CIs p-values, always use t-distribution residual df possible. residual df model determined, normal distribution used instead. Methods mixed models: Compared fixed effects (single-level) models, determining appropriate df Wald-based inference mixed models difficult. See R GLMM FAQ discussion. Several approximate methods computing df available, also consider instead using profile likelihood (\"profile\") bootstrap (\"boot\") CIs p-values instead. \"satterthwaite\" Applies linear mixed models. CIs computed using Wald method (SE t-distribution Satterthwaite df); p-values computed using Wald method t-distribution Satterthwaite df. \"kenward\" Applies linear mixed models. CIs computed using Wald method (Kenward-Roger SE t-distribution Kenward-Roger df); p-values computed using Wald method Kenward-Roger SE t-distribution Kenward-Roger df. \"ml1\" Applies linear mixed models. CIs computed using Wald method (SE t-distribution m-l-1 approximated df); p-values computed using Wald method t-distribution m-l-1 approximated df. See ci_ml1(). \"betwithin\" Applies linear mixed models generalized linear mixed models. CIs computed using Wald method (SE t-distribution -within df); p-values computed using Wald method t-distribution -within df. See ci_betwithin(). Likelihood-based methods: Likelihood-based inference based comparing likelihood maximum-likelihood estimate likelihood models one parameter values changed (e.g., set zero range alternative values). Likelihood ratios maximum-likelihood alternative models compared \\(\\chi\\)-squared distribution compute CIs p-values. \"profile\" Applies non-Bayesian models class glm, polr, merMod glmmTMB. CIs computed profiling likelihood curve parameter, using linear interpolation find likelihood ratio equals critical value; p-values computed using Wald method normal-distribution (note: might change future update!) \"uniroot\" Applies non-Bayesian models class glmmTMB. CIs computed profiling likelihood curve parameter, using root finding find likelihood ratio equals critical value; p-values computed using Wald method normal-distribution (note: might change future update!) Methods bootstrapped Bayesian models: Bootstrap-based inference based resampling refitting model resampled datasets. distribution parameter estimates across resampled datasets used approximate parameter's sampling distribution. Depending type model, several different methods bootstrapping constructing CIs p-values bootstrap distribution available. Bayesian models, inference based drawing samples model posterior distribution. \"quantile\" (\"eti\") Applies models (including Bayesian models). non-Bayesian models, applies bootstrap = TRUE. CIs computed equal tailed intervals using quantiles bootstrap posterior samples; p-values based probability direction. See bayestestR::eti(). \"hdi\" Applies models (including Bayesian models). non-Bayesian models, applies bootstrap = TRUE. CIs computed highest density intervals bootstrap posterior samples; p-values based probability direction. See bayestestR::hdi(). \"bci\" (\"bcai\") Applies models (including Bayesian models). non-Bayesian models, applies bootstrap = TRUE. CIs computed bias corrected accelerated intervals bootstrap posterior samples; p-values based probability direction. See bayestestR::bci(). \"si\" Applies Bayesian models proper priors. CIs computed support intervals comparing posterior samples prior samples; p-values based probability direction. See bayestestR::si(). \"boot\" Applies non-Bayesian models class merMod. CIs computed using parametric bootstrapping (simulating data fitted model); p-values computed using Wald method normal-distribution) (note: might change future update!). iteration-based methods \"boot\" (\"hdi\", \"quantile\", \"ci\", \"eti\", \"si\", \"bci\", \"bcai\"), p-values based probability direction (bayestestR::p_direction()), converted p-value using bayestestR::pd_to_p().","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.html","id":"statistical-inference-how-to-quantify-evidence","dir":"Reference","previous_headings":"","what":"Statistical inference - how to quantify evidence","title":"Model Parameters — model_parameters","text":"standardized approach drawing conclusions based available data statistical models. frequently chosen also much criticized approach evaluate results based statistical significance (Amrhein et al. 2017). sophisticated way test whether estimated effects exceed \"smallest effect size interest\", avoid even smallest effects considered relevant simply statistically significant, clinically practically irrelevant (Lakens et al. 2018, Lakens 2024). rather unconventional approach, nevertheless advocated various authors, interpret results classical regression models either terms probabilities, similar usual approach Bayesian statistics (Schweder 2018; Schweder Hjort 2003; Vos 2022) terms relative measure \"evidence\" \"compatibility\" data (Greenland et al. 2022; Rafi Greenland 2020), nevertheless comes close probabilistic interpretation. detailed discussion topic found documentation p_function(). parameters package provides several options functions aid statistical inference. , example: equivalence_test(), compute (conditional) equivalence test frequentist models p_significance(), compute probability practical significance, can conceptualized unidirectional equivalence test p_function(), consonance function, compute p-values compatibility (confidence) intervals statistical models pd argument (setting pd = TRUE) model_parameters() includes column probability direction, .e. probability parameter strictly positive negative. See bayestestR::p_direction() details. plotting desired, p_direction() function can used, together plot(). s_value argument (setting s_value = TRUE) model_parameters() replaces p-values related S-values (Rafi Greenland 2020) finally, possible generate distributions model coefficients generating bootstrap-samples (setting bootstrap = TRUE) simulating draws model coefficients using simulate_model(). samples can treated \"posterior samples\" used many functions bayestestR package. shown options functions derive methods originally implemented Bayesian models (Makowski et al. 2019). However, assuming model assumptions met (means, model fits well data, correct model chosen reflects data generating process (distributional model family) etc.), seems appropriate interpret results classical frequentist models \"Bayesian way\" (details: documentation p_function()).","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.html","id":"interpretation-of-interaction-terms","dir":"Reference","previous_headings":"","what":"Interpretation of Interaction Terms","title":"Model Parameters — model_parameters","text":"Note interpretation interaction terms depends many characteristics model. number parameters, overall performance model, can differ * b, : b, / b, suggesting sometimes interaction terms give different parameterizations model, times gives completely different models (depending b factors covariates, included main effects , etc.). interpretation depends full context model, inferred parameters table alone - rather, recommend use packages calculate estimated marginal means marginal effects, modelbased, emmeans, ggeffects, marginaleffects. raise awareness issue, may use print(...,show_formula=TRUE) add model-specification output print() method model_parameters().","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.html","id":"global-options-to-customize-messages-and-tables-when-printing","dir":"Reference","previous_headings":"","what":"Global Options to Customize Messages and Tables when Printing","title":"Model Parameters — model_parameters","text":"verbose argument can used display silence messages warnings different functions parameters package. However, messages providing additional information can displayed suppressed using options(): parameters_info: options(parameters_info = TRUE) override include_info argument model_parameters() always show model summary non-mixed models. parameters_mixed_info: options(parameters_mixed_info = TRUE) override include_info argument model_parameters() mixed models, always show model summary. parameters_cimethod: options(parameters_cimethod = TRUE) show additional information approximation method used calculate confidence intervals p-values. Set FALSE hide message printing model_parameters() objects. parameters_exponentiate: options(parameters_exponentiate = TRUE) show additional information interpret coefficients models log-transformed response variables log-/logit-links exponentiate argument model_parameters() TRUE. Set option FALSE hide message printing model_parameters() objects. options can used modify default behaviour printed outputs: parameters_labels: options(parameters_labels = TRUE) use variable value labels pretty names, data labelled. labels available, default pretty names used. parameters_interaction: options(parameters_interaction = <character>) replace interaction mark (default, *) related character. parameters_select: options(parameters_select = <value>) set default select argument. See argument's documentation available options. easystats_table_width: options(easystats_table_width = <value>) set default width tables text-format, .e. outputs printed console. specified, tables adjusted current available width, e.g. console (source textual output, like markdown files). argument table_width can also used print() methods specify table width desired. easystats_html_engine: options(easystats_html_engine = \"gt\") set default HTML engine tables gt, .e. gt package used create HTML tables. set tt, tinytable package used. insight_use_symbols: options(insight_use_symbols = TRUE) try print unicode-chars symbols column names, wherever possible (e.g., ω instead Omega).","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Model Parameters — model_parameters","text":"Amrhein, V., Korner-Nievergelt, F., Roth, T. (2017). earth flat (p > 0.05): Significance thresholds crisis unreplicable research. PeerJ, 5, e3544. doi:10.7717/peerj.3544 Greenland S, Rafi Z, Matthews R, Higgs M. Aid Scientific Inference, Emphasize Unconditional Compatibility Descriptions Statistics. (2022) https://arxiv.org/abs/1909.08583v7 (Accessed November 10, 2022) Hoffman, L. (2015). Longitudinal analysis: Modeling within-person fluctuation change. Routledge. Lakens, D. (2024). Improving Statistical Inferences (Version v1.5.1). Retrieved https://lakens.github.io/statistical_inferences/. doi:10.5281/ZENODO.6409077 Lakens, D., Scheel, . M., Isager, P. M. (2018). Equivalence Testing Psychological Research: Tutorial. Advances Methods Practices Psychological Science, 1(2), 259–269. doi:10.1177/2515245918770963 Makowski, D., Ben-Shachar, M. S., Chen, S. H. ., Lüdecke, D. (2019). Indices Effect Existence Significance Bayesian Framework. Frontiers Psychology, 10, 2767. doi:10.3389/fpsyg.2019.02767 Neter, J., Wasserman, W., Kutner, M. H. (1989). Applied linear regression models. Rafi Z, Greenland S. Semantic cognitive tools aid statistical science: replace confidence significance compatibility surprise. BMC Medical Research Methodology (2020) 20:244. Schweder T. Confidence epistemic probability empirical science. Journal Statistical Planning Inference (2018) 195:116–125. doi:10.1016/j.jspi.2017.09.016 Schweder T, Hjort NL. Frequentist analogues priors posteriors. Stigum, B. (ed.), Econometrics Philosophy Economics: Theory Data Confrontation Economics, pp. 285-217. Princeton University Press, Princeton, NJ, 2003 Vos P, Holbert D. Frequentist statistical inference without repeated sampling. Synthese 200, 89 (2022). doi:10.1007/s11229-022-03560-x","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/model_parameters.mira.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameters from multiply imputed repeated analyses — model_parameters.mira","title":"Parameters from multiply imputed repeated analyses — model_parameters.mira","text":"Format models class mira, obtained mice::width.mids(), class mipo.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.mira.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parameters from multiply imputed repeated analyses — model_parameters.mira","text":"","code":"# S3 method for class 'mira' model_parameters(   model,   ci = 0.95,   exponentiate = FALSE,   p_adjust = NULL,   keep = NULL,   drop = NULL,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.mira.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameters from multiply imputed repeated analyses — model_parameters.mira","text":"model object class mira mipo. ci Confidence Interval (CI) level. Default 0.95 (95%). exponentiate Logical, indicating whether exponentiate coefficients (related confidence intervals). typical logistic regression, generally speaking, models log logit links. also recommended use exponentiate = TRUE models log-transformed response values. models log-transformed response variable, exponentiate = TRUE, one-unit increase predictor associated multiplying outcome predictor's coefficient. Note: Delta-method standard errors also computed (multiplying standard errors transformed coefficients). mimic behaviour software packages, Stata, standard errors poorly estimate uncertainty transformed coefficient. transformed confidence interval clearly captures uncertainty. compare_parameters(), exponentiate = \"nongaussian\" exponentiate coefficients non-Gaussian families. p_adjust Character vector, NULL, indicates method adjust p-values. See stats::p.adjust() details. possible adjustment methods \"tukey\", \"scheffe\", \"sidak\" \"none\" explicitly disable adjustment emmGrid objects (emmeans). keep Character containing regular expression pattern describes parameters included (keep) excluded (drop) returned data frame. keep may also named list regular expressions. non-matching parameters removed output. keep character vector, every parameter name \"Parameter\" column matches regular expression keep selected returned data frame (vice versa, parameter names matching drop excluded). Furthermore, keep one element, merged operator regular expression pattern like : \"(one|two|three)\". keep named list regular expression patterns, names list-element equal column name selection applied. useful model objects model_parameters() returns multiple columns parameter components, like model_parameters.lavaan(). Note regular expression pattern match parameter names stored returned data frame, can different printed. Inspect $Parameter column parameters table get exact parameter names. drop See keep. verbose Toggle warnings messages. ... Arguments passed methods.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.mira.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Parameters from multiply imputed repeated analyses — model_parameters.mira","text":"model_parameters() objects class mira works similar summary(mice::pool()), .e. generates pooled summary multiple imputed repeated regression analyses.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.mira.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parameters from multiply imputed repeated analyses — model_parameters.mira","text":"","code":"library(parameters) data(nhanes2, package = \"mice\") imp <- mice::mice(nhanes2) #>  #>  iter imp variable #>   1   1  bmi  hyp  chl #>   1   2  bmi  hyp  chl #>   1   3  bmi  hyp  chl #>   1   4  bmi  hyp  chl #>   1   5  bmi  hyp  chl #>   2   1  bmi  hyp  chl #>   2   2  bmi  hyp  chl #>   2   3  bmi  hyp  chl #>   2   4  bmi  hyp  chl #>   2   5  bmi  hyp  chl #>   3   1  bmi  hyp  chl #>   3   2  bmi  hyp  chl #>   3   3  bmi  hyp  chl #>   3   4  bmi  hyp  chl #>   3   5  bmi  hyp  chl #>   4   1  bmi  hyp  chl #>   4   2  bmi  hyp  chl #>   4   3  bmi  hyp  chl #>   4   4  bmi  hyp  chl #>   4   5  bmi  hyp  chl #>   5   1  bmi  hyp  chl #>   5   2  bmi  hyp  chl #>   5   3  bmi  hyp  chl #>   5   4  bmi  hyp  chl #>   5   5  bmi  hyp  chl fit <- with(data = imp, exp = lm(bmi ~ age + hyp + chl)) model_parameters(fit) #> # Fixed Effects #>  #> Parameter   | Coefficient |   SE |          95% CI | Statistic |    df |      p #> ------------------------------------------------------------------------------- #> (Intercept) |       17.76 | 3.68 | [  9.66, 25.86] |      4.83 | 10.96 | < .001 #> age40-59    |       -5.50 | 2.20 | [-10.74, -0.27] |     -2.50 |  6.80 | 0.042  #> age60-99    |       -7.66 | 3.08 | [-15.66,  0.33] |     -2.49 |  4.86 | 0.057  #> hypyes      |        2.57 | 2.06 | [ -2.06,  7.20] |      1.25 |  9.37 | 0.243  #> chl         |        0.06 | 0.02 | [  0.02,  0.10] |      3.06 | 12.41 | 0.010  #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) #>   computed using a Wald distribution approximation. # \\donttest{ # model_parameters() also works for models that have no \"tidy\"-method in mice data(warpbreaks) set.seed(1234) warpbreaks$tension[sample(1:nrow(warpbreaks), size = 10)] <- NA imp <- mice::mice(warpbreaks) #>  #>  iter imp variable #>   1   1  tension #>   1   2  tension #>   1   3  tension #>   1   4  tension #>   1   5  tension #>   2   1  tension #>   2   2  tension #>   2   3  tension #>   2   4  tension #>   2   5  tension #>   3   1  tension #>   3   2  tension #>   3   3  tension #>   3   4  tension #>   3   5  tension #>   4   1  tension #>   4   2  tension #>   4   3  tension #>   4   4  tension #>   4   5  tension #>   5   1  tension #>   5   2  tension #>   5   3  tension #>   5   4  tension #>   5   5  tension fit <- with(data = imp, expr = gee::gee(breaks ~ tension, id = wool)) #> Beginning Cgee S-function, @(#) geeformula.q 4.13 98/01/27 #> running glm to get initial regression estimate #> (Intercept)    tensionM    tensionH  #>    36.04762   -12.26984   -13.71429  #> Beginning Cgee S-function, @(#) geeformula.q 4.13 98/01/27 #> running glm to get initial regression estimate #> (Intercept)    tensionM    tensionH  #>    35.04545   -10.29545   -12.98295  #> Beginning Cgee S-function, @(#) geeformula.q 4.13 98/01/27 #> running glm to get initial regression estimate #> (Intercept)    tensionM    tensionH  #>   35.150000   -8.973529  -13.267647  #> Beginning Cgee S-function, @(#) geeformula.q 4.13 98/01/27 #> running glm to get initial regression estimate #> (Intercept)    tensionM    tensionH  #>    36.66667   -13.26667   -14.50000  #> Beginning Cgee S-function, @(#) geeformula.q 4.13 98/01/27 #> running glm to get initial regression estimate #> (Intercept)    tensionM    tensionH  #>    36.15000   -11.37222   -14.21250   # does not work: # summary(mice::pool(fit))  model_parameters(fit) #> New names: #> • `` -> `...6` #> New names: #> • `` -> `...6` #> New names: #> • `` -> `...6` #> New names: #> • `` -> `...6` #> New names: #> • `` -> `...6` #> # Fixed Effects #>  #> Parameter   | Coefficient |   SE | 95% CI | Statistic #> ----------------------------------------------------- #> (Intercept) |       35.81 | 2.71 |        |     13.21 #> tensionM    |      -11.24 | 4.31 |        |     -2.61 #> tensionH    |      -13.74 | 3.98 |        |     -3.45 #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) #>   computed using a Wald distribution approximation. # }  # and it works with pooled results data(\"nhanes2\", package = \"mice\") imp <- mice::mice(nhanes2) #>  #>  iter imp variable #>   1   1  bmi  hyp  chl #>   1   2  bmi  hyp  chl #>   1   3  bmi  hyp  chl #>   1   4  bmi  hyp  chl #>   1   5  bmi  hyp  chl #>   2   1  bmi  hyp  chl #>   2   2  bmi  hyp  chl #>   2   3  bmi  hyp  chl #>   2   4  bmi  hyp  chl #>   2   5  bmi  hyp  chl #>   3   1  bmi  hyp  chl #>   3   2  bmi  hyp  chl #>   3   3  bmi  hyp  chl #>   3   4  bmi  hyp  chl #>   3   5  bmi  hyp  chl #>   4   1  bmi  hyp  chl #>   4   2  bmi  hyp  chl #>   4   3  bmi  hyp  chl #>   4   4  bmi  hyp  chl #>   4   5  bmi  hyp  chl #>   5   1  bmi  hyp  chl #>   5   2  bmi  hyp  chl #>   5   3  bmi  hyp  chl #>   5   4  bmi  hyp  chl #>   5   5  bmi  hyp  chl fit <- with(data = imp, exp = lm(bmi ~ age + hyp + chl)) pooled <- mice::pool(fit)  model_parameters(pooled) #> # Fixed Effects #>  #> Parameter   | Coefficient |   SE |          95% CI | Statistic |    df |      p #> ------------------------------------------------------------------------------- #> (Intercept) |       19.05 | 3.39 | [ 11.82, 26.28] |      5.61 | 15.19 | < .001 #> age40-59    |       -4.97 | 1.86 | [ -9.02, -0.92] |     -2.67 | 12.12 | 0.020  #> age60-99    |       -6.14 | 1.89 | [-10.15, -2.12] |     -3.25 | 15.35 | 0.005  #> hypyes      |        2.11 | 2.29 | [ -3.38,  7.59] |      0.92 |  6.60 | 0.390  #> chl         |        0.05 | 0.02 | [  0.01,  0.09] |      2.83 | 15.74 | 0.012  #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) #>   computed using a Wald distribution approximation."},{"path":"https://easystats.github.io/parameters/reference/model_parameters.mlm.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameters from multinomial or cumulative link models — model_parameters.mlm","title":"Parameters from multinomial or cumulative link models — model_parameters.mlm","text":"Parameters multinomial cumulative link models","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.mlm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parameters from multinomial or cumulative link models — model_parameters.mlm","text":"","code":"# S3 method for class 'mlm' model_parameters(   model,   ci = 0.95,   vcov = NULL,   vcov_args = NULL,   bootstrap = FALSE,   iterations = 1000,   standardize = NULL,   exponentiate = FALSE,   p_adjust = NULL,   keep = NULL,   drop = NULL,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.mlm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameters from multinomial or cumulative link models — model_parameters.mlm","text":"model model multinomial categorical response value. ci Confidence Interval (CI) level. Default 0.95 (95%). vcov Variance-covariance matrix used compute uncertainty estimates (e.g., robust standard errors). argument accepts covariance matrix, function returns covariance matrix, string identifies function used compute covariance matrix. covariance matrix function returns covariance matrix (e.g., stats::vcov()) string indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC Cluster-robust: \"CR\", \"CR0\", \"CR1\", \"CR1p\", \"CR1S\", \"CR2\", \"CR3\". See ?clubSandwich::vcovCR Bootstrap: \"BS\", \"xy\", \"residual\", \"wild\", \"mammen\", \"fractional\", \"jackknife\", \"norm\", \"webb\". See ?sandwich::vcovBS sandwich package functions: \"HAC\", \"PC\", \"CL\", \"OPG\", \"PL\". vcov_args List arguments passed function identified vcov argument. function typically supplied sandwich clubSandwich packages. Please refer documentation (e.g., ?sandwich::vcovHAC) see list available arguments. estimation type (argument type) given, default type \"HC\" equals default sandwich package; type \"CR\", default set \"CR3\". bootstrap estimates based bootstrapped model? TRUE, arguments Bayesian regressions apply (see also bootstrap_parameters()). iterations number bootstrap replicates. apply case bootstrapped frequentist models. standardize method used standardizing parameters. Can NULL (default; standardization), \"refit\" (re-fitting model standardized data) one \"basic\", \"posthoc\", \"smart\", \"pseudo\". See 'Details' standardize_parameters(). Importantly: \"refit\" method standardize categorical predictors (.e. factors), may different behaviour compared R packages (lm.beta) software packages (like SPSS). mimic behaviours, either use standardize=\"basic\" standardize data datawizard::standardize(force=TRUE) fitting model. mixed models, using methods \"refit\", fixed effects standardized. Robust estimation (.e., vcov set value NULL) standardized parameters works standardize=\"refit\". exponentiate Logical, indicating whether exponentiate coefficients (related confidence intervals). typical logistic regression, generally speaking, models log logit links. also recommended use exponentiate = TRUE models log-transformed response values. models log-transformed response variable, exponentiate = TRUE, one-unit increase predictor associated multiplying outcome predictor's coefficient. Note: Delta-method standard errors also computed (multiplying standard errors transformed coefficients). mimic behaviour software packages, Stata, standard errors poorly estimate uncertainty transformed coefficient. transformed confidence interval clearly captures uncertainty. compare_parameters(), exponentiate = \"nongaussian\" exponentiate coefficients non-Gaussian families. p_adjust Character vector, NULL, indicates method adjust p-values. See stats::p.adjust() details. possible adjustment methods \"tukey\", \"scheffe\", \"sidak\" \"none\" explicitly disable adjustment emmGrid objects (emmeans). keep Character containing regular expression pattern describes parameters included (keep) excluded (drop) returned data frame. keep may also named list regular expressions. non-matching parameters removed output. keep character vector, every parameter name \"Parameter\" column matches regular expression keep selected returned data frame (vice versa, parameter names matching drop excluded). Furthermore, keep one element, merged operator regular expression pattern like : \"(one|two|three)\". keep named list regular expression patterns, names list-element equal column name selection applied. useful model objects model_parameters() returns multiple columns parameter components, like model_parameters.lavaan(). Note regular expression pattern match parameter names stored returned data frame, can different printed. Inspect $Parameter column parameters table get exact parameter names. drop See keep. verbose Toggle warnings messages. ... Arguments passed methods. instance, bootstrap = TRUE, arguments like type parallel passed bootstrap_model(). non-documented arguments : digits, p_digits, ci_digits footer_digits set number digits output. groups can used group coefficients. arguments passed print-method, can directly used print(), see documentation print.parameters_model(). s_value = TRUE, p-value replaced S-value output (cf. Rafi Greenland 2020). pd adds additional column probability direction (see bayestestR::p_direction() details). Furthermore, see 'Examples' function. developers, whose interest mainly get \"tidy\" data frame model summaries, recommended set pretty_names = FALSE speed computation summary table.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.mlm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parameters from multinomial or cumulative link models — model_parameters.mlm","text":"data frame indices related model's parameters.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.mlm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Parameters from multinomial or cumulative link models — model_parameters.mlm","text":"Multinomial cumulative link models, .e. models response value (dependent variable) categorical two levels, usually return coefficients response level. Hence, output model_parameters() split coefficient tables different levels model's response.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.mlm.html","id":"model-components","dir":"Reference","previous_headings":"","what":"Model components","title":"Parameters from multinomial or cumulative link models — model_parameters.mlm","text":"Possible values component argument depend model class. Following valid options: \"\": returns model components, applies models, effect models just conditional model component. \"conditional\": returns conditional component, .e. \"fixed effects\" terms model. effect models just conditional model component. \"smooth_terms\": returns smooth terms, applies GAMs (similar models may contain smooth terms). \"zero_inflated\" (\"zi\"): returns zero-inflation component. \"dispersion\": returns dispersion model component. common models zero-inflation can model dispersion parameter. \"instruments\": instrumental-variable fixed effects regression, returns instruments. \"nonlinear\": non-linear models (like models class nlmerMod nls), returns staring estimates nonlinear parameters. \"correlation\": models correlation-component, like gls, variables used describe correlation structure returned. Special models model classes also allow rather uncommon options. : mhurdle: \"infrequent_purchase\", \"ip\", \"auxiliary\" BGGM: \"correlation\" \"intercept\" BFBayesFactor, glmx: \"extra\" averaging:\"conditional\" \"full\" mjoint: \"survival\" mfx: \"precision\", \"marginal\" betareg, DirichletRegModel: \"precision\" mvord: \"thresholds\" \"correlation\" clm2: \"scale\" selection: \"selection\", \"outcome\", \"auxiliary\" lavaan: One \"regression\", \"correlation\", \"loading\", \"variance\", \"defined\", \"mean\". Can also \"\" include components. models class brmsfit (package brms), even options possible component argument, documented detail .","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/model_parameters.mlm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parameters from multinomial or cumulative link models — model_parameters.mlm","text":"","code":"data(\"stemcell\", package = \"brglm2\") model <- brglm2::bracl(   research ~ as.numeric(religion) + gender,   weights = frequency,   data = stemcell,   type = \"ML\" ) model_parameters(model) #> # Response level: definitely #>  #> Parameter       | Log-Odds |   SE |         95% CI |     z |      p #> ------------------------------------------------------------------- #> (Intercept)     |    -1.25 | 0.26 | [-1.76, -0.73] | -4.76 | < .001 #> religion        |     0.44 | 0.10 | [ 0.23,  0.64] |  4.20 | < .001 #> gender [female] |    -0.14 | 0.17 | [-0.47,  0.19] | -0.82 | 0.414  #>  #> # Response level: probably #>  #> Parameter       | Log-Odds |   SE |        95% CI |    z |     p #> ---------------------------------------------------------------- #> (Intercept)     |     0.47 | 0.29 | [-0.10, 1.04] | 1.62 | 0.105 #> religion        |     0.26 | 0.13 | [ 0.01, 0.51] | 2.01 | 0.044 #> gender [female] |     0.19 | 0.21 | [-0.22, 0.60] | 0.90 | 0.370 #>  #> # Response level: probably not #>  #> Parameter       | Log-Odds |   SE |        95% CI |     z |     p #> ----------------------------------------------------------------- #> (Intercept)     |     0.43 | 0.39 | [-0.33, 1.18] |  1.11 | 0.268 #> religion        |     0.01 | 0.17 | [-0.33, 0.35] |  0.07 | 0.945 #> gender [female] |    -0.16 | 0.28 | [-0.71, 0.39] | -0.57 | 0.566 #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) #>   computed using a Wald z-distribution approximation."},{"path":"https://easystats.github.io/parameters/reference/model_parameters.principal.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameters from PCA, FA, CFA, SEM — model_parameters.lavaan","title":"Parameters from PCA, FA, CFA, SEM — model_parameters.lavaan","text":"Format structural models psych FactoMineR packages.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.principal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parameters from PCA, FA, CFA, SEM — model_parameters.lavaan","text":"","code":"# S3 method for class 'lavaan' model_parameters(   model,   ci = 0.95,   standardize = FALSE,   component = c(\"regression\", \"correlation\", \"loading\", \"defined\"),   keep = NULL,   drop = NULL,   verbose = TRUE,   ... )  # S3 method for class 'principal' model_parameters(   model,   sort = FALSE,   threshold = NULL,   labels = NULL,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.principal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameters from PCA, FA, CFA, SEM — model_parameters.lavaan","text":"model Model object. ci Confidence Interval (CI) level. Default 0.95 (95%). standardize Return standardized parameters (standardized coefficients). Can TRUE (\"\" \"std.\") standardized estimates based variances observed latent variables; \"latent\" (\"std.lv\") standardized estimates based variances latent variables ; \"no_exogenous\" (\"std.nox\") standardized estimates based variances observed latent variables, variances exogenous covariates. See lavaan::standardizedsolution details. component type links return. Can \"\" c(\"regression\", \"correlation\", \"loading\", \"variance\", \"mean\"). keep Character containing regular expression pattern describes parameters included (keep) excluded (drop) returned data frame. keep may also named list regular expressions. non-matching parameters removed output. keep character vector, every parameter name \"Parameter\" column matches regular expression keep selected returned data frame (vice versa, parameter names matching drop excluded). Furthermore, keep one element, merged operator regular expression pattern like : \"(one|two|three)\". keep named list regular expression patterns, names list-element equal column name selection applied. useful model objects model_parameters() returns multiple columns parameter components, like model_parameters.lavaan(). Note regular expression pattern match parameter names stored returned data frame, can different printed. Inspect $Parameter column parameters table get exact parameter names. drop See keep. verbose Toggle warnings. ... Arguments passed methods. sort Sort loadings. threshold value 0 1 indicates (absolute) values loadings removed. integer higher 1 indicates n strongest loadings retain. Can also \"max\", case display maximum loading per variable (simple structure). labels character vector containing labels added loadings data. Usually, question related item.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.principal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parameters from PCA, FA, CFA, SEM — model_parameters.lavaan","text":"data frame indices loadings.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.principal.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Parameters from PCA, FA, CFA, SEM — model_parameters.lavaan","text":"structural models obtained psych, following indices present: Complexity (Hoffman's, 1978; Pettersson Turkheimer, 2010) represents number latent components needed account observed variables. Whereas perfect simple structure solution complexity 1 item load one factor, solution evenly distributed items complexity greater 1. Uniqueness represents variance 'unique' variable shared variables. equal 1 – communality (variance shared variables). uniqueness 0.20 suggests 20% variable's variance shared variables overall factor model. greater 'uniqueness' lower relevance variable factor model. MSA represents Kaiser-Meyer-Olkin Measure Sampling Adequacy (Kaiser Rice, 1974) item. indicates whether enough data factor give reliable results PCA. value > 0.6, desirable values > 0.8 (Tabachnick Fidell, 2013).","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.principal.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Parameters from PCA, FA, CFA, SEM — model_parameters.lavaan","text":"also plot()-method lavaan models implemented see-package.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.principal.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Parameters from PCA, FA, CFA, SEM — model_parameters.lavaan","text":"Kaiser, H.F. Rice. J. (1974). Little jiffy, mark iv. Educational Psychological Measurement, 34(1):111–117 Pettersson, E., Turkheimer, E. (2010). Item selection, evaluation, simple structure personality data. Journal research personality, 44(4), 407-420. Revelle, W. (2016). : Use psych package Factor Analysis data reduction. Tabachnick, B. G., Fidell, L. S. (2013). Using multivariate statistics (6th ed.). Boston: Pearson Education. Rosseel Y (2012). lavaan: R Package Structural Equation Modeling. Journal Statistical Software, 48(2), 1-36. Merkle EC , Rosseel Y (2018). blavaan: Bayesian Structural Equation Models via Parameter Expansion. Journal Statistical Software, 85(4), 1-30. http://www.jstatsoft.org/v85/i04/","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.principal.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parameters from PCA, FA, CFA, SEM — model_parameters.lavaan","text":"","code":"# \\donttest{ library(parameters) if (require(\"psych\", quietly = TRUE)) {   # Principal Component Analysis (PCA) ---------   pca <- psych::principal(attitude)   model_parameters(pca)    pca <- psych::principal(attitude, nfactors = 3, rotate = \"none\")   model_parameters(pca, sort = TRUE, threshold = 0.2)    principal_components(attitude, n = 3, sort = TRUE, threshold = 0.2)     # Exploratory Factor Analysis (EFA) ---------   efa <- psych::fa(attitude, nfactors = 3)   model_parameters(efa,     threshold = \"max\", sort = TRUE,     labels = as.character(1:ncol(attitude))   )     # Omega ---------   omega <- psych::omega(mtcars, nfactors = 3)   params <- model_parameters(omega)   params   summary(params) }  #> Composite | Total Variance (%) | Variance due to General Factor (%) | Variance due to Group Factor (%) #> ------------------------------------------------------------------------------------------------------ #> g         |              97.28 |                              56.64 |                            26.42 #> F1*       |              90.12 |                              31.07 |                            59.05 #> F2*       |              91.37 |                              69.32 |                            22.04 #> F3*       |              87.36 |                              59.65 |                            27.71 # }  # lavaan  library(parameters)  # lavaan ------------------------------------- if (require(\"lavaan\", quietly = TRUE)) {   # Confirmatory Factor Analysis (CFA) ---------    structure <- \" visual  =~ x1 + x2 + x3                  textual =~ x4 + x5 + x6                  speed   =~ x7 + x8 + x9 \"   model <- lavaan::cfa(structure, data = HolzingerSwineford1939)   model_parameters(model)   model_parameters(model, standardize = TRUE)    # filter parameters   model_parameters(     model,     parameters = list(       To = \"^(?!visual)\",       From = \"^(?!(x7|x8))\"     )   )    # Structural Equation Model (SEM) ------------    structure <- \"     # latent variable definitions       ind60 =~ x1 + x2 + x3       dem60 =~ y1 + a*y2 + b*y3 + c*y4       dem65 =~ y5 + a*y6 + b*y7 + c*y8     # regressions       dem60 ~ ind60       dem65 ~ ind60 + dem60     # residual correlations       y1 ~~ y5       y2 ~~ y4 + y6       y3 ~~ y7       y4 ~~ y8       y6 ~~ y8   \"   model <- lavaan::sem(structure, data = PoliticalDemocracy)   model_parameters(model)   model_parameters(model, standardize = TRUE) } #> # Loading  #>  #> Link            | Coefficient |   SE |       95% CI |     z |      p #> -------------------------------------------------------------------- #> ind60 =~ x1     |        0.92 | 0.02 | [0.88, 0.97] | 40.08 | < .001 #> ind60 =~ x2     |        0.97 | 0.02 | [0.94, 1.01] | 59.14 | < .001 #> ind60 =~ x3     |        0.87 | 0.03 | [0.81, 0.93] | 28.09 | < .001 #> dem60 =~ y1     |        0.85 | 0.04 | [0.77, 0.93] | 20.92 | < .001 #> dem60 =~ y2 (a) |        0.69 | 0.06 | [0.57, 0.81] | 11.58 | < .001 #> dem60 =~ y3 (b) |        0.76 | 0.05 | [0.66, 0.86] | 14.70 | < .001 #> dem60 =~ y4 (c) |        0.84 | 0.04 | [0.76, 0.92] | 20.12 | < .001 #> dem65 =~ y5     |        0.82 | 0.04 | [0.73, 0.90] | 18.52 | < .001 #> dem65 =~ y6 (a) |        0.75 | 0.05 | [0.65, 0.86] | 14.01 | < .001 #> dem65 =~ y7 (b) |        0.80 | 0.05 | [0.71, 0.89] | 17.40 | < .001 #> dem65 =~ y8 (c) |        0.83 | 0.04 | [0.75, 0.91] | 19.79 | < .001 #>  #> # Regression  #>  #> Link          | Coefficient |   SE |       95% CI |     z |      p #> ------------------------------------------------------------------ #> dem60 ~ ind60 |        0.45 | 0.10 | [0.25, 0.65] |  4.33 | < .001 #> dem65 ~ ind60 |        0.19 | 0.07 | [0.05, 0.33] |  2.64 | 0.008  #> dem65 ~ dem60 |        0.88 | 0.05 | [0.78, 0.98] | 17.24 | < .001 #>  #> # Correlation  #>  #> Link     | Coefficient |   SE |        95% CI |    z |      p #> ------------------------------------------------------------- #> y1 ~~ y5 |        0.28 | 0.14 | [ 0.00, 0.56] | 1.97 | 0.049  #> y2 ~~ y4 |        0.29 | 0.11 | [ 0.07, 0.52] | 2.55 | 0.011  #> y2 ~~ y6 |        0.36 | 0.10 | [ 0.17, 0.54] | 3.71 | < .001 #> y3 ~~ y7 |        0.17 | 0.13 | [-0.09, 0.43] | 1.26 | 0.208  #> y4 ~~ y8 |        0.11 | 0.13 | [-0.14, 0.36] | 0.86 | 0.388  #> y6 ~~ y8 |        0.34 | 0.11 | [ 0.12, 0.55] | 3.08 | 0.002"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.rma.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameters from Meta-Analysis — model_parameters.rma","title":"Parameters from Meta-Analysis — model_parameters.rma","text":"Extract compute indices measures describe parameters meta-analysis models.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.rma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parameters from Meta-Analysis — model_parameters.rma","text":"","code":"# S3 method for class 'rma' model_parameters(   model,   ci = 0.95,   bootstrap = FALSE,   iterations = 1000,   standardize = NULL,   exponentiate = FALSE,   include_studies = TRUE,   keep = NULL,   drop = NULL,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.rma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameters from Meta-Analysis — model_parameters.rma","text":"model Model object. ci Confidence Interval (CI) level. Default 0.95 (95%). bootstrap estimates based bootstrapped model? TRUE, arguments Bayesian regressions apply (see also bootstrap_parameters()). iterations number bootstrap replicates. apply case bootstrapped frequentist models. standardize method used standardizing parameters. Can NULL (default; standardization), \"refit\" (re-fitting model standardized data) one \"basic\", \"posthoc\", \"smart\", \"pseudo\". See 'Details' standardize_parameters(). Importantly: \"refit\" method standardize categorical predictors (.e. factors), may different behaviour compared R packages (lm.beta) software packages (like SPSS). mimic behaviours, either use standardize=\"basic\" standardize data datawizard::standardize(force=TRUE) fitting model. mixed models, using methods \"refit\", fixed effects standardized. Robust estimation (.e., vcov set value NULL) standardized parameters works standardize=\"refit\". exponentiate Logical, indicating whether exponentiate coefficients (related confidence intervals). typical logistic regression, generally speaking, models log logit links. also recommended use exponentiate = TRUE models log-transformed response values. models log-transformed response variable, exponentiate = TRUE, one-unit increase predictor associated multiplying outcome predictor's coefficient. Note: Delta-method standard errors also computed (multiplying standard errors transformed coefficients). mimic behaviour software packages, Stata, standard errors poorly estimate uncertainty transformed coefficient. transformed confidence interval clearly captures uncertainty. compare_parameters(), exponentiate = \"nongaussian\" exponentiate coefficients non-Gaussian families. include_studies Logical, TRUE (default), includes parameters studies. Else, parameters overall-effects shown. keep Character containing regular expression pattern describes parameters included (keep) excluded (drop) returned data frame. keep may also named list regular expressions. non-matching parameters removed output. keep character vector, every parameter name \"Parameter\" column matches regular expression keep selected returned data frame (vice versa, parameter names matching drop excluded). Furthermore, keep one element, merged operator regular expression pattern like : \"(one|two|three)\". keep named list regular expression patterns, names list-element equal column name selection applied. useful model objects model_parameters() returns multiple columns parameter components, like model_parameters.lavaan(). Note regular expression pattern match parameter names stored returned data frame, can different printed. Inspect $Parameter column parameters table get exact parameter names. drop See keep. verbose Toggle warnings messages. ... Arguments passed methods. instance, bootstrap = TRUE, arguments like type parallel passed bootstrap_model(). non-documented arguments : digits, p_digits, ci_digits footer_digits set number digits output. groups can used group coefficients. arguments passed print-method, can directly used print(), see documentation print.parameters_model(). s_value = TRUE, p-value replaced S-value output (cf. Rafi Greenland 2020). pd adds additional column probability direction (see bayestestR::p_direction() details). Furthermore, see 'Examples' function. developers, whose interest mainly get \"tidy\" data frame model summaries, recommended set pretty_names = FALSE speed computation summary table.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.rma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parameters from Meta-Analysis — model_parameters.rma","text":"data frame indices related model's parameters.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.rma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parameters from Meta-Analysis — model_parameters.rma","text":"","code":"library(parameters) mydat <<- data.frame(   effectsize = c(-0.393, 0.675, 0.282, -1.398),   stderr = c(0.317, 0.317, 0.13, 0.36) ) if (require(\"metafor\", quietly = TRUE)) {   model <- rma(yi = effectsize, sei = stderr, method = \"REML\", data = mydat)   model_parameters(model) } #>  #> Loading the 'metafor' package (version 4.6-0). For an #> introduction to the package please type: help(metafor) #>  #> Attaching package: ‘metafor’ #> The following object is masked from ‘package:mclust’: #>  #>     hc #> Meta-analysis using 'metafor' #>  #> Parameter | Coefficient |   SE |         95% CI |     z |      p | Weight #> ------------------------------------------------------------------------- #> Study 1   |       -0.39 | 0.32 | [-1.01,  0.23] | -1.24 | 0.215  |   9.95 #> Study 2   |        0.68 | 0.32 | [ 0.05,  1.30] |  2.13 | 0.033  |   9.95 #> Study 3   |        0.28 | 0.13 | [ 0.03,  0.54] |  2.17 | 0.030  |  59.17 #> Study 4   |       -1.40 | 0.36 | [-2.10, -0.69] | -3.88 | < .001 |   7.72 #> Overall   |       -0.18 | 0.44 | [-1.05,  0.68] | -0.42 | 0.676  |        #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) #>   computed using a Wald z-distribution approximation. # \\donttest{ # with subgroups if (require(\"metafor\", quietly = TRUE)) {   data(dat.bcg)   dat <- escalc(     measure = \"RR\",     ai = tpos,     bi = tneg,     ci = cpos,     di = cneg,     data = dat.bcg   )   dat$alloc <- ifelse(dat$alloc == \"random\", \"random\", \"other\")   d <<- dat   model <- rma(yi, vi, mods = ~alloc, data = d, digits = 3, slab = author)   model_parameters(model) } #> # Random Effects  #>  #> Parameter         | Coefficient |   SE |         95% CI |      z |      p | Weight #> ---------------------------------------------------------------------------------- #> Aronson           |       -0.89 | 0.57 | [-2.01,  0.23] |  -1.56 | 0.119  |   3.07 #> Ferguson & Simes  |       -1.59 | 0.44 | [-2.45, -0.72] |  -3.59 | < .001 |   5.14 #> Rosenthal et al.1 |       -1.35 | 0.64 | [-2.61, -0.08] |  -2.09 | 0.036  |   2.41 #> Hart & Sutherland |       -1.44 | 0.14 | [-1.72, -1.16] | -10.19 | < .001 |  49.97 #> Vandiviere et al  |       -1.62 | 0.47 | [-2.55, -0.70] |  -3.43 | < .001 |   4.48 #> TPT Madras        |        0.01 | 0.06 | [-0.11,  0.14] |   0.19 | 0.849  | 252.42 #> Coetzee & Berjak  |       -0.47 | 0.24 | [-0.94,  0.00] |  -1.98 | 0.048  |  17.72 #> Overall           |       -0.49 | 0.36 | [-1.20,  0.22] |  -1.35 | 0.176  |        #>  #> # other  #>  #> Parameter            | Coefficient |   SE |         95% CI |     z |      p | Weight #> ------------------------------------------------------------------------------------ #> Frimodt-Moller et al |       -0.22 | 0.23 | [-0.66,  0.23] | -0.96 | 0.336  |  19.53 #> Stein & Aronson      |       -0.79 | 0.08 | [-0.95, -0.62] | -9.46 | < .001 | 144.81 #> Rosenthal et al.2    |       -1.37 | 0.27 | [-1.90, -0.84] | -5.07 | < .001 |  13.69 #> Comstock et al.1     |       -0.34 | 0.11 | [-0.56, -0.12] | -3.05 | 0.002  |  80.57 #> Comstock & Webster   |        0.45 | 0.73 | [-0.98,  1.88] |  0.61 | 0.541  |   1.88 #> Comstock et al.2     |       -0.02 | 0.27 | [-0.54,  0.51] | -0.06 | 0.948  |  14.00 #> Overall              |       -0.47 | 0.26 | [-0.97,  0.04] | -1.82 | 0.069  |        #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) #>   computed using a Wald z-distribution approximation.  if (require(\"metaBMA\", quietly = TRUE)) {   data(towels)   m <- suppressWarnings(meta_random(logOR, SE, study, data = towels))   model_parameters(m) } #> This is metaBMA version 0.6.9 #> - Default priors were changed in version 0.6.6. #> - Since default priors may change again, it is safest to specify priors (even when using the defaults). #> # Studies  #>  #> Parameter                                           | Coefficient |   SE #> ------------------------------------------------------------------------ #> Goldstein, Cialdini, & Griskevicius (2008), Exp. 1  |        0.38 | 0.20 #> Goldstein, Cialdini, & Griskevicius  (2008), Exp. 2 |        0.30 | 0.14 #> Schultz, Khazian, & Zaleski (2008), Exp. 2          |        0.21 | 0.19 #> Schultz, Khazian, & Zaleski (2008), Exp. 3          |        0.25 | 0.17 #> Mair & Bergin-Seers (2010), Exp. 1                  |        0.29 | 0.82 #> Bohner & Schluter (2014), Exp. 1                    |       -0.12 | 0.25 #> Bohner & Schluter (2014), Exp. 2                    |       -1.46 | 0.76 #>  #> Parameter                                           |        95% CI | Weight |                                 Method #> --------------------------------------------------------------------------------------------------------------------- #> Goldstein, Cialdini, & Griskevicius (2008), Exp. 1  | [-0.01, 0.77] |  25.59 | Bayesian meta-analysis using 'metaBMA' #> Goldstein, Cialdini, & Griskevicius  (2008), Exp. 2 | [ 0.04, 0.57] |  53.97 | Bayesian meta-analysis using 'metaBMA' #> Schultz, Khazian, & Zaleski (2008), Exp. 2          | [-0.17, 0.58] |  27.24 | Bayesian meta-analysis using 'metaBMA' #> Schultz, Khazian, & Zaleski (2008), Exp. 3          | [-0.08, 0.58] |  34.57 | Bayesian meta-analysis using 'metaBMA' #> Mair & Bergin-Seers (2010), Exp. 1                  | [-1.33, 1.90] |   1.47 | Bayesian meta-analysis using 'metaBMA' #> Bohner & Schluter (2014), Exp. 1                    | [-0.61, 0.36] |  16.25 | Bayesian meta-analysis using 'metaBMA' #> Bohner & Schluter (2014), Exp. 2                    | [-2.95, 0.03] |   1.73 | Bayesian meta-analysis using 'metaBMA' #>  #> # Meta-Parameters  #>  #> Parameter | Coefficient |   SE |        95% CI |    BF |  Rhat |     ESS #> ------------------------------------------------------------------------ #> Overall   |        0.19 | 0.11 | [-0.04, 0.39] | 0.804 | 1.002 | 3380.00 #> tau       |        0.14 | 0.10 | [ 0.03, 0.41] |       | 1.002 | 2388.00 #>  #> Parameter |                     Prior |                                 Method #> ------------------------------------------------------------------------------ #> Overall   |   Student's t (0 +- 0.71) | Bayesian meta-analysis using 'metaBMA' #> tau       | Inverse gamma (1 +- 0.15) | Bayesian meta-analysis using 'metaBMA' #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) #>   computed using a MCMC distribution approximation. # }"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.t1way.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameters from robust statistical objects in WRS2 — model_parameters.t1way","title":"Parameters from robust statistical objects in WRS2 — model_parameters.t1way","text":"Parameters robust statistical objects WRS2","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.t1way.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parameters from robust statistical objects in WRS2 — model_parameters.t1way","text":"","code":"# S3 method for class 't1way' model_parameters(model, keep = NULL, verbose = TRUE, ...)"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.t1way.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameters from robust statistical objects in WRS2 — model_parameters.t1way","text":"model Object WRS2 package. keep Character containing regular expression pattern describes parameters included (keep) excluded (drop) returned data frame. keep may also named list regular expressions. non-matching parameters removed output. keep character vector, every parameter name \"Parameter\" column matches regular expression keep selected returned data frame (vice versa, parameter names matching drop excluded). Furthermore, keep one element, merged operator regular expression pattern like : \"(one|two|three)\". keep named list regular expression patterns, names list-element equal column name selection applied. useful model objects model_parameters() returns multiple columns parameter components, like model_parameters.lavaan(). Note regular expression pattern match parameter names stored returned data frame, can different printed. Inspect $Parameter column parameters table get exact parameter names. verbose Toggle warnings messages. ... Arguments passed methods.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.t1way.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parameters from robust statistical objects in WRS2 — model_parameters.t1way","text":"data frame indices related model's parameters.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.t1way.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parameters from robust statistical objects in WRS2 — model_parameters.t1way","text":"","code":"if (require(\"WRS2\") && packageVersion(\"WRS2\") >= \"1.1.3\") {   model <- t1way(libido ~ dose, data = viagra)   model_parameters(model) } #> Loading required package: WRS2 #> A heteroscedastic one-way ANOVA for trimmed means #>  #> F    | df | df (error) |     p | Estimate |       95% CI |                         Effectsize #> --------------------------------------------------------------------------------------------- #> 3.00 |  2 |          4 | 0.160 |     0.79 | [0.36, 1.95] | Explanatory measure of effect size"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.zcpglm.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameters from Zero-Inflated Models — model_parameters.zcpglm","title":"Parameters from Zero-Inflated Models — model_parameters.zcpglm","text":"Parameters zero-inflated models (packages like pscl, cplm countreg).","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.zcpglm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parameters from Zero-Inflated Models — model_parameters.zcpglm","text":"","code":"# S3 method for class 'zcpglm' model_parameters(   model,   ci = 0.95,   bootstrap = FALSE,   iterations = 1000,   component = \"all\",   standardize = NULL,   exponentiate = FALSE,   p_adjust = NULL,   summary = getOption(\"parameters_summary\", FALSE),   include_info = getOption(\"parameters_info\", FALSE),   keep = NULL,   drop = NULL,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/parameters/reference/model_parameters.zcpglm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameters from Zero-Inflated Models — model_parameters.zcpglm","text":"model model zero-inflation component. ci Confidence Interval (CI) level. Default 0.95 (95%). bootstrap estimates based bootstrapped model? TRUE, arguments Bayesian regressions apply (see also bootstrap_parameters()). iterations number bootstrap replicates. apply case bootstrapped frequentist models. component parameters, parameters conditional model, zero-inflation part model, dispersion model returned? Applies models zero-inflation /dispersion component. component may one \"conditional\", \"zi\", \"zero-inflated\", \"dispersion\" \"\" (default). May abbreviated. standardize method used standardizing parameters. Can NULL (default; standardization), \"refit\" (re-fitting model standardized data) one \"basic\", \"posthoc\", \"smart\", \"pseudo\". See 'Details' standardize_parameters(). Importantly: \"refit\" method standardize categorical predictors (.e. factors), may different behaviour compared R packages (lm.beta) software packages (like SPSS). mimic behaviours, either use standardize=\"basic\" standardize data datawizard::standardize(force=TRUE) fitting model. mixed models, using methods \"refit\", fixed effects standardized. Robust estimation (.e., vcov set value NULL) standardized parameters works standardize=\"refit\". exponentiate Logical, indicating whether exponentiate coefficients (related confidence intervals). typical logistic regression, generally speaking, models log logit links. also recommended use exponentiate = TRUE models log-transformed response values. models log-transformed response variable, exponentiate = TRUE, one-unit increase predictor associated multiplying outcome predictor's coefficient. Note: Delta-method standard errors also computed (multiplying standard errors transformed coefficients). mimic behaviour software packages, Stata, standard errors poorly estimate uncertainty transformed coefficient. transformed confidence interval clearly captures uncertainty. compare_parameters(), exponentiate = \"nongaussian\" exponentiate coefficients non-Gaussian families. p_adjust Character vector, NULL, indicates method adjust p-values. See stats::p.adjust() details. possible adjustment methods \"tukey\", \"scheffe\", \"sidak\" \"none\" explicitly disable adjustment emmGrid objects (emmeans). summary Deprecated, please use info instead. include_info Logical, TRUE, prints summary information model (model formula, number observations, residual standard deviation ). keep Character containing regular expression pattern describes parameters included (keep) excluded (drop) returned data frame. keep may also named list regular expressions. non-matching parameters removed output. keep character vector, every parameter name \"Parameter\" column matches regular expression keep selected returned data frame (vice versa, parameter names matching drop excluded). Furthermore, keep one element, merged operator regular expression pattern like : \"(one|two|three)\". keep named list regular expression patterns, names list-element equal column name selection applied. useful model objects model_parameters() returns multiple columns parameter components, like model_parameters.lavaan(). Note regular expression pattern match parameter names stored returned data frame, can different printed. Inspect $Parameter column parameters table get exact parameter names. drop See keep. verbose Toggle warnings messages. ... Arguments passed methods. instance, bootstrap = TRUE, arguments like type parallel passed bootstrap_model(). non-documented arguments : digits, p_digits, ci_digits footer_digits set number digits output. groups can used group coefficients. arguments passed print-method, can directly used print(), see documentation print.parameters_model(). s_value = TRUE, p-value replaced S-value output (cf. Rafi Greenland 2020). pd adds additional column probability direction (see bayestestR::p_direction() details). Furthermore, see 'Examples' function. developers, whose interest mainly get \"tidy\" data frame model summaries, recommended set pretty_names = FALSE speed computation summary table.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.zcpglm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parameters from Zero-Inflated Models — model_parameters.zcpglm","text":"data frame indices related model's parameters.","code":""},{"path":"https://easystats.github.io/parameters/reference/model_parameters.zcpglm.html","id":"model-components","dir":"Reference","previous_headings":"","what":"Model components","title":"Parameters from Zero-Inflated Models — model_parameters.zcpglm","text":"Possible values component argument depend model class. Following valid options: \"\": returns model components, applies models, effect models just conditional model component. \"conditional\": returns conditional component, .e. \"fixed effects\" terms model. effect models just conditional model component. \"smooth_terms\": returns smooth terms, applies GAMs (similar models may contain smooth terms). \"zero_inflated\" (\"zi\"): returns zero-inflation component. \"dispersion\": returns dispersion model component. common models zero-inflation can model dispersion parameter. \"instruments\": instrumental-variable fixed effects regression, returns instruments. \"nonlinear\": non-linear models (like models class nlmerMod nls), returns staring estimates nonlinear parameters. \"correlation\": models correlation-component, like gls, variables used describe correlation structure returned. Special models model classes also allow rather uncommon options. : mhurdle: \"infrequent_purchase\", \"ip\", \"auxiliary\" BGGM: \"correlation\" \"intercept\" BFBayesFactor, glmx: \"extra\" averaging:\"conditional\" \"full\" mjoint: \"survival\" mfx: \"precision\", \"marginal\" betareg, DirichletRegModel: \"precision\" mvord: \"thresholds\" \"correlation\" clm2: \"scale\" selection: \"selection\", \"outcome\", \"auxiliary\" lavaan: One \"regression\", \"correlation\", \"loading\", \"variance\", \"defined\", \"mean\". Can also \"\" include components. models class brmsfit (package brms), even options possible component argument, documented detail .","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/model_parameters.zcpglm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parameters from Zero-Inflated Models — model_parameters.zcpglm","text":"","code":"data(\"bioChemists\", package = \"pscl\") model <- pscl::zeroinfl(   art ~ fem + mar + kid5 + ment | kid5 + phd,   data = bioChemists ) model_parameters(model) #> # Fixed Effects  #>  #> Parameter     | Log-Mean |       SE |         95% CI |     z |      p #> --------------------------------------------------------------------- #> (Intercept)   |     0.56 |     0.07 | [ 0.43,  0.69] |  8.26 | < .001 #> fem [Women]   |    -0.23 |     0.06 | [-0.34, -0.11] | -3.91 | < .001 #> mar [Married] |     0.14 |     0.07 | [ 0.01,  0.27] |  2.07 | 0.038  #> kid5          |    -0.17 |     0.05 | [-0.26, -0.07] | -3.43 | < .001 #> ment          |     0.02 | 2.12e-03 | [ 0.02,  0.03] | 10.05 | < .001 #>  #> # Zero-Inflation  #>  #> Parameter   | Log-Odds |   SE |         95% CI |     z |     p #> -------------------------------------------------------------- #> (Intercept) |    -0.93 | 0.43 | [-1.78, -0.08] | -2.14 | 0.032 #> kid5        |     0.05 | 0.22 | [-0.38,  0.47] |  0.21 | 0.831 #> phd         |    -0.25 | 0.14 | [-0.51,  0.02] | -1.84 | 0.065"},{"path":"https://easystats.github.io/parameters/reference/n_clusters.html","id":null,"dir":"Reference","previous_headings":"","what":"Find number of clusters in your data — n_clusters","title":"Find number of clusters in your data — n_clusters","text":"Similarly n_factors() factor / principal component analysis, n_clusters() main function find optimal numbers clusters present data based maximum consensus large number methods. Essentially, exist many methods determine optimal number clusters, pros cons, benefits limitations. main n_clusters function proposes run , find number clusters suggested majority methods (case ties, select parsimonious solution fewer clusters). Note also implement specific, commonly used methods, like Elbow Gap method, visualization functionalities. See examples details.","code":""},{"path":"https://easystats.github.io/parameters/reference/n_clusters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find number of clusters in your data — n_clusters","text":"","code":"n_clusters(   x,   standardize = TRUE,   include_factors = FALSE,   package = c(\"easystats\", \"NbClust\", \"mclust\"),   fast = TRUE,   nbclust_method = \"kmeans\",   n_max = 10,   ... )  n_clusters_elbow(   x,   standardize = TRUE,   include_factors = FALSE,   clustering_function = stats::kmeans,   n_max = 10,   ... )  n_clusters_gap(   x,   standardize = TRUE,   include_factors = FALSE,   clustering_function = stats::kmeans,   n_max = 10,   gap_method = \"firstSEmax\",   ... )  n_clusters_silhouette(   x,   standardize = TRUE,   include_factors = FALSE,   clustering_function = stats::kmeans,   n_max = 10,   ... )  n_clusters_dbscan(   x,   standardize = TRUE,   include_factors = FALSE,   method = c(\"kNN\", \"SS\"),   min_size = 0.1,   eps_n = 50,   eps_range = c(0.1, 3),   ... )  n_clusters_hclust(   x,   standardize = TRUE,   include_factors = FALSE,   distance_method = \"correlation\",   hclust_method = \"average\",   ci = 0.95,   iterations = 100,   ... )"},{"path":"https://easystats.github.io/parameters/reference/n_clusters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find number of clusters in your data — n_clusters","text":"x data frame. standardize Standardize dataframe clustering (default). include_factors Logical, TRUE, factors converted numerical values order included data determining number clusters. default, factors removed, methods determine number clusters need numeric input . package Package methods called determine number clusters. Can \"\" vector containing \"easystats\", \"NbClust\", \"mclust\", \"M3C\". fast FALSE, compute 4 indices (sets index = \"allong\" NbClust). deactivated default computationally heavy. nbclust_method clustering method (passed NbClust::NbClust() method). n_max Maximal number clusters test. ... Arguments passed methods. instance, bootstrap = TRUE, arguments like type parallel passed bootstrap_model(). non-documented arguments : digits, p_digits, ci_digits footer_digits set number digits output. groups can used group coefficients. arguments passed print-method, can directly used print(), see documentation print.parameters_model(). s_value = TRUE, p-value replaced S-value output (cf. Rafi Greenland 2020). pd adds additional column probability direction (see bayestestR::p_direction() details). Furthermore, see 'Examples' function. developers, whose interest mainly get \"tidy\" data frame model summaries, recommended set pretty_names = FALSE speed computation summary table. clustering_function, gap_method arguments passed functions. clustering_function used fviz_nbclust() can kmeans, cluster::pam, cluster::clara, cluster::fanny, . gap_method used cluster::maxSE extract optimal numbers clusters (see method argument). method, min_size, eps_n, eps_range Arguments DBSCAN algorithm. distance_method distance method (passed dist()). Used algorithms relying distance matrix, hclust dbscan. hclust_method hierarchical clustering method (passed hclust()). ci Confidence Interval (CI) level. Default 0.95 (95%). iterations number bootstrap replicates. apply case bootstrapped frequentist models.","code":""},{"path":"https://easystats.github.io/parameters/reference/n_clusters.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Find number of clusters in your data — n_clusters","text":"also plot()-method implemented see-package.","code":""},{"path":"https://easystats.github.io/parameters/reference/n_clusters.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find number of clusters in your data — n_clusters","text":"","code":"# \\donttest{ library(parameters)  # The main 'n_clusters' function =============================== if (require(\"mclust\", quietly = TRUE) && require(\"NbClust\", quietly = TRUE) &&   require(\"cluster\", quietly = TRUE) && require(\"see\", quietly = TRUE)) {   n <- n_clusters(iris[, 1:4], package = c(\"NbClust\", \"mclust\")) # package can be \"all\"   n   summary(n)   as.data.frame(n) # Duration is the time elapsed for each method in seconds   plot(n)    # The following runs all the method but it significantly slower   # n_clusters(iris[1:4], standardize = FALSE, package = \"all\", fast = FALSE) }  # } # \\donttest{ x <- n_clusters_elbow(iris[1:4]) x #> The Elbow method, that aims at minimizing the total intra-cluster variation (i.e., the total within-cluster sum of square), suggests that the optimal number of clusters is 2. as.data.frame(x) #>    n_Clusters       WSS #> 1           1 596.00000 #> 2           2 220.87929 #> 3           3 138.88836 #> 4           4 113.64981 #> 5           5  90.22782 #> 6           6  95.25396 #> 7           7  72.75296 #> 8           8  64.61603 #> 9           9  59.48502 #> 10         10  59.10865 plot(x)  # } # \\donttest{ # # Gap method -------------------- if (require(\"see\", quietly = TRUE) &&   require(\"cluster\", quietly = TRUE) &&   require(\"factoextra\", quietly = TRUE)) {   x <- n_clusters_gap(iris[1:4])   x   as.data.frame(x)   plot(x) }  # } # \\donttest{ # # Silhouette method -------------------------- if (require(\"factoextra\", quietly = TRUE)) {   x <- n_clusters_silhouette(iris[1:4])   x   as.data.frame(x)   plot(x) }  # } # \\donttest{ # if (require(\"dbscan\", quietly = TRUE)) {   # DBSCAN method -------------------------   # NOTE: This actually primarily estimates the 'eps' parameter, the number of   # clusters is a side effect (it's the number of clusters corresponding to   # this 'optimal' EPS parameter).   x <- n_clusters_dbscan(iris[1:4], method = \"kNN\", min_size = 0.05) # 5 percent   x   head(as.data.frame(x))   plot(x)    x <- n_clusters_dbscan(iris[1:4], method = \"SS\", eps_n = 100, eps_range = c(0.1, 2))   x   head(as.data.frame(x))   plot(x) }  # } # \\donttest{ # # hclust method ------------------------------- if (require(\"pvclust\", quietly = TRUE)) {   # iterations should be higher for real analyses   x <- n_clusters_hclust(iris[1:4], iterations = 50, ci = 0.90)   x   head(as.data.frame(x), n = 10) # Print 10 first rows   plot(x) }  # }"},{"path":"https://easystats.github.io/parameters/reference/n_factors.html","id":null,"dir":"Reference","previous_headings":"","what":"Number of components/factors to retain in PCA/FA — n_factors","title":"Number of components/factors to retain in PCA/FA — n_factors","text":"function runs many existing procedures determining many factors retain/extract factor analysis (FA) dimension reduction (PCA). returns number factors based maximum consensus methods. case ties, keep simplest model select solution fewer factors.","code":""},{"path":"https://easystats.github.io/parameters/reference/n_factors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Number of components/factors to retain in PCA/FA — n_factors","text":"","code":"n_factors(   x,   type = \"FA\",   rotation = \"varimax\",   algorithm = \"default\",   package = c(\"nFactors\", \"psych\"),   cor = NULL,   safe = TRUE,   n_max = NULL,   ... )  n_components(   x,   type = \"PCA\",   rotation = \"varimax\",   algorithm = \"default\",   package = c(\"nFactors\", \"psych\"),   cor = NULL,   safe = TRUE,   ... )"},{"path":"https://easystats.github.io/parameters/reference/n_factors.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Number of components/factors to retain in PCA/FA — n_factors","text":"x data frame. type Can \"FA\" \"PCA\", depending want . rotation used VSS (Simple Structure criterion, see psych::VSS()). rotation apply. Can \"none\", \"varimax\", \"quartimax\", \"bentlerT\", \"equamax\", \"varimin\", \"geominT\" \"bifactor\" orthogonal rotations, \"promax\", \"oblimin\", \"simplimax\", \"bentlerQ\", \"geominQ\", \"biquartimin\" \"cluster\" oblique transformations. algorithm Factoring method used VSS. Can \"pa\" Principal Axis Factor Analysis, \"minres\" minimum residual (OLS) factoring, \"mle\" Maximum Likelihood FA \"pc\" Principal Components. \"default\" select \"minres\" type = \"FA\" \"pc\" type = \"PCA\". package Package respective methods used. Can \"\" vector containing \"nFactors\", \"psych\", \"PCDimension\", \"fit\" \"EGAnet\". Note \"fit\" (actually also relies psych package) \"EGAnet\" can slow bigger datasets. Thus, default c(\"nFactors\", \"psych\"). must respective packages installed methods used. cor optional correlation matrix can used (note data must still passed first argument). NULL, compute running cor() passed data. safe TRUE, function run procedures try blocks, return work silently skip ones may fail. n_max set value (e.g., 10), drop results methods suggest higher number components. interpretation becomes 'methods suggested number lower n_max, results ...'. ... Arguments passed methods.","code":""},{"path":"https://easystats.github.io/parameters/reference/n_factors.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Number of components/factors to retain in PCA/FA — n_factors","text":"data frame.","code":""},{"path":"https://easystats.github.io/parameters/reference/n_factors.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Number of components/factors to retain in PCA/FA — n_factors","text":"n_components() actually alias n_factors(), different defaults function arguments.","code":""},{"path":"https://easystats.github.io/parameters/reference/n_factors.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Number of components/factors to retain in PCA/FA — n_factors","text":"also plot()-method implemented see-package. n_components() convenient short-cut  n_factors(type = \"PCA\").","code":""},{"path":"https://easystats.github.io/parameters/reference/n_factors.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Number of components/factors to retain in PCA/FA — n_factors","text":"Bartlett, M. S. (1950). Tests significance factor analysis. British Journal statistical psychology, 3(2), 77-85. Bentler, P. M., & Yuan, K. H. (1996). Test linear trend eigenvalues covariance matrix application data analysis. British Journal Mathematical Statistical Psychology, 49(2), 299-312. Cattell, R. B. (1966). scree test number factors. Multivariate behavioral research, 1(2), 245-276. Finch, W. H. (2019). Using Fit Statistic Differences Determine Optimal Number Factors Retain Exploratory Factor Analysis. Educational Psychological Measurement. Zoski, K. W., & Jurs, S. (1996). objective counterpart visual scree test factor analysis: standard error scree. Educational Psychological Measurement, 56(3), 443-451. Zoski, K., & Jurs, S. (1993). Using multiple regression determine number factors retain factor analysis. Multiple Linear Regression Viewpoints, 20(1), 5-9. Nasser, F., Benson, J., & Wisenbaker, J. (2002). performance regression-based variations visual scree determining number common factors. Educational psychological measurement, 62(3), 397-419. Golino, H., Shi, D., Garrido, L. E., Christensen, . P., Nieto, M. D., Sadana, R., & Thiyagarajan, J. . (2018). Investigating performance Exploratory Graph Analysis traditional techniques identify number latent factors: simulation tutorial. Golino, H. F., & Epskamp, S. (2017). Exploratory graph analysis: new approach estimating number dimensions psychological research. PloS one, 12(6), e0174035. Revelle, W., & Rocklin, T. (1979). simple structure: alternative procedure estimating optimal number interpretable factors. Multivariate Behavioral Research, 14(4), 403-414. Velicer, W. F. (1976). Determining number components matrix partial correlations. Psychometrika, 41(3), 321-327.","code":""},{"path":"https://easystats.github.io/parameters/reference/n_factors.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Number of components/factors to retain in PCA/FA — n_factors","text":"","code":"library(parameters) n_factors(mtcars, type = \"PCA\") #> # Method Agreement Procedure: #>  #> The choice of 3 dimensions is supported by 5 (29.41%) methods out of 17 (Bartlett, CNG, Scree (SE), Scree (R2), Velicer's MAP).  result <- n_factors(mtcars[1:5], type = \"FA\") as.data.frame(result) #>    n_Factors              Method       Family #> 1          1             Bentler      Bentler #> 2          1 Optimal coordinates        Scree #> 3          1 Acceleration factor        Scree #> 4          1   Parallel analysis        Scree #> 5          1    Kaiser criterion        Scree #> 6          1          Scree (SE)     Scree_SE #> 7          1    VSS complexity 1          VSS #> 8          1       Velicer's MAP Velicers_MAP #> 9          1                 BIC          BIC #> 10         2            Bartlett      Barlett #> 11         2            Anderson      Barlett #> 12         2              Lawley      Barlett #> 13         2          Scree (R2)     Scree_SE #> 14         2      BIC (adjusted)          BIC #> 15         3    VSS complexity 2          VSS summary(result) #>   n_Factors n_Methods Variance_Cumulative #> 1         1         9           0.7824146 #> 2         2         5           0.8583921 #> 3         3         1           0.8661856 # \\donttest{ # Setting package = 'all' will increase the number of methods (but is slow) n_factors(mtcars, type = \"PCA\", package = \"all\") #> # Method Agreement Procedure: #>  #> The choice of 3 dimensions is supported by 7 (33.33%) methods out of 21 (Bartlett, CNG, Scree (SE), Scree (R2), EGA (glasso), EGA (TMFG), Velicer's MAP). n_factors(mtcars, type = \"FA\", algorithm = \"mle\", package = \"all\") #> # Method Agreement Procedure: #>  #> The choice of 3 dimensions is supported by 11 (40.74%) methods out of 27 (Bartlett, CNG, Scree (SE), Scree (R2), EGA (glasso), EGA (TMFG), Velicer's MAP, BIC, RMSR, CRMS, BIC). # }"},{"path":"https://easystats.github.io/parameters/reference/p_calibrate.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate calibrated p-values. — p_calibrate","title":"Calculate calibrated p-values. — p_calibrate","text":"Compute calibrated p-values can interpreted probabilistically, .e. posterior probability H0 (given H0 H1 equal prior probabilities).","code":""},{"path":"https://easystats.github.io/parameters/reference/p_calibrate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate calibrated p-values. — p_calibrate","text":"","code":"p_calibrate(x, ...)  # Default S3 method p_calibrate(x, type = \"frequentist\", verbose = TRUE, ...)"},{"path":"https://easystats.github.io/parameters/reference/p_calibrate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate calibrated p-values. — p_calibrate","text":"x numeric vector p-values, regression model object. ... Currently used. type Type calibration. Can \"frequentist\" \"bayesian\". See 'Details'. verbose Toggle warnings.","code":""},{"path":"https://easystats.github.io/parameters/reference/p_calibrate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate calibrated p-values. — p_calibrate","text":"data frame p-values calibrated p-values.","code":""},{"path":"https://easystats.github.io/parameters/reference/p_calibrate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate calibrated p-values. — p_calibrate","text":"Bayesian calibration, .e. type = \"bayesian\", can interpreted lower bound Bayes factor H0 H1, based data. full Bayes factor require multiplying prior odds H0 H1. frequentist calibration also Bayesian interpretation; posterior probability H0, assuming H0 H1 equal prior probabilities 0.5 (Sellke et al. 2001). calibration works p-values lower equal 1/e.","code":""},{"path":"https://easystats.github.io/parameters/reference/p_calibrate.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Calculate calibrated p-values. — p_calibrate","text":"Thomas Sellke, M. J Bayarri James O Berger (2001) Calibration p Values Testing Precise Null Hypotheses, American Statistician, 55:1, 62-71, doi:10.1198/000313001300339950","code":""},{"path":"https://easystats.github.io/parameters/reference/p_calibrate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate calibrated p-values. — p_calibrate","text":"","code":"model <- lm(mpg ~ wt + as.factor(gear) + am, data = mtcars) p_calibrate(model, verbose = FALSE) #> Parameter        |      p | p (calibrated) #> ------------------------------------------ #> (Intercept)      | < .001 |         < .001 #> wt               | < .001 |         < .001 #> as.factor(gear)4 | 0.242  |         0.483  #> as.factor(gear)5 | 0.660  |                #> am               | 0.925  |                #> Calibrated p-values indicate the posterior probability of H0. #>"},{"path":"https://easystats.github.io/parameters/reference/p_direction.lm.html","id":null,"dir":"Reference","previous_headings":"","what":"Probability of Direction (pd) — p_direction.lm","title":"Probability of Direction (pd) — p_direction.lm","text":"Compute Probability Direction (pd, also known Maximum Probability Effect - MPE). can interpreted probability parameter (described full confidence, \"compatibility\" interval) strictly positive negative (whichever probable). Although differently expressed, index fairly similar (.e., strongly correlated) frequentist p-value (see 'Details').","code":""},{"path":"https://easystats.github.io/parameters/reference/p_direction.lm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Probability of Direction (pd) — p_direction.lm","text":"","code":"# S3 method for class 'lm' p_direction(   x,   ci = 0.95,   method = \"direct\",   null = 0,   vcov = NULL,   vcov_args = NULL,   ... )"},{"path":"https://easystats.github.io/parameters/reference/p_direction.lm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Probability of Direction (pd) — p_direction.lm","text":"x statistical model. ci Confidence Interval (CI) level. Default 0.95 (95%). method Can \"direct\" one methods estimate_density(), \"kernel\", \"logspline\" \"KernSmooth\". See details. null value considered \"null\" effect. Traditionally 0, also 1 case ratios change (, IRR, ...). vcov Variance-covariance matrix used compute uncertainty estimates (e.g., robust standard errors). argument accepts covariance matrix, function returns covariance matrix, string identifies function used compute covariance matrix. covariance matrix function returns covariance matrix (e.g., stats::vcov()) string indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC Cluster-robust: \"CR\", \"CR0\", \"CR1\", \"CR1p\", \"CR1S\", \"CR2\", \"CR3\". See ?clubSandwich::vcovCR Bootstrap: \"BS\", \"xy\", \"residual\", \"wild\", \"mammen\", \"fractional\", \"jackknife\", \"norm\", \"webb\". See ?sandwich::vcovBS sandwich package functions: \"HAC\", \"PC\", \"CL\", \"OPG\", \"PL\". vcov_args List arguments passed function identified vcov argument. function typically supplied sandwich clubSandwich packages. Please refer documentation (e.g., ?sandwich::vcovHAC) see list available arguments. estimation type (argument type) given, default type \"HC\" equals default sandwich package; type \"CR\", default set \"CR3\". ... Arguments passed methods, e.g. ci(). Arguments like vcov vcov_args can used compute confidence intervals using specific variance-covariance matrix standard errors.","code":""},{"path":"https://easystats.github.io/parameters/reference/p_direction.lm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Probability of Direction (pd) — p_direction.lm","text":"data frame.","code":""},{"path":"https://easystats.github.io/parameters/reference/p_direction.lm.html","id":"what-is-the-pd-","dir":"Reference","previous_headings":"","what":"What is the pd?","title":"Probability of Direction (pd) — p_direction.lm","text":"Probability Direction (pd) index effect existence, representing certainty effect goes particular direction (.e., positive negative / sign), typically ranging 0.5 1 (see next section cases can range 0 1). Beyond simplicity interpretation, understanding computation, index also presents interesting properties: Like posterior-based indices, pd solely based posterior distributions require additional information data model (e.g., priors, case Bayes factors). robust scale response variable predictors. strongly correlated frequentist p-value, can thus used draw parallels give reference readers non-familiar Bayesian statistics (Makowski et al., 2019).","code":""},{"path":"https://easystats.github.io/parameters/reference/p_direction.lm.html","id":"relationship-with-the-p-value","dir":"Reference","previous_headings":"","what":"Relationship with the p-value","title":"Probability of Direction (pd) — p_direction.lm","text":"cases, seems pd direct correspondence frequentist one-sided p-value formula (two-sided p): p = 2 * (1 - pd) Thus, two-sided p-value respectively .1, .05, .01 .001 correspond approximately pd 95%, 97.5%, 99.5% 99.95%. See pd_to_p() details.","code":""},{"path":"https://easystats.github.io/parameters/reference/p_direction.lm.html","id":"possible-range-of-values","dir":"Reference","previous_headings":"","what":"Possible Range of Values","title":"Probability of Direction (pd) — p_direction.lm","text":"largest value pd can take 1 - posterior strictly directional. However, smallest value pd can take depends parameter space represented posterior. continuous parameter space, exact values 0 (point null value) possible, 100% posterior sign, positive, negative. Therefore, smallest pd can 0.5 - equal posterior mass positive negative values. Values close 0.5 used support null hypothesis (parameter direction) similar large p-values used support null hypothesis (see pd_to_p(); Makowski et al., 2019). discrete parameter space parameter space mixture discrete continuous spaces, exact values 0 (point null value) possible! Therefore, smallest pd can 0 - 100% posterior mass 0. Thus values close 0 can used support null hypothesis (see van den Bergh et al., 2021). Examples posteriors representing discrete parameter space: parameter can take discrete values. mixture prior/posterior used (spike--slab prior; see van den Bergh et al., 2021). conducting Bayesian model averaging (e.g., weighted_posteriors() brms::posterior_average).","code":""},{"path":"https://easystats.github.io/parameters/reference/p_direction.lm.html","id":"statistical-inference-how-to-quantify-evidence","dir":"Reference","previous_headings":"","what":"Statistical inference - how to quantify evidence","title":"Probability of Direction (pd) — p_direction.lm","text":"standardized approach drawing conclusions based available data statistical models. frequently chosen also much criticized approach evaluate results based statistical significance (Amrhein et al. 2017). sophisticated way test whether estimated effects exceed \"smallest effect size interest\", avoid even smallest effects considered relevant simply statistically significant, clinically practically irrelevant (Lakens et al. 2018, Lakens 2024). rather unconventional approach, nevertheless advocated various authors, interpret results classical regression models either terms probabilities, similar usual approach Bayesian statistics (Schweder 2018; Schweder Hjort 2003; Vos 2022) terms relative measure \"evidence\" \"compatibility\" data (Greenland et al. 2022; Rafi Greenland 2020), nevertheless comes close probabilistic interpretation. detailed discussion topic found documentation p_function(). parameters package provides several options functions aid statistical inference. , example: equivalence_test(), compute (conditional) equivalence test frequentist models p_significance(), compute probability practical significance, can conceptualized unidirectional equivalence test p_function(), consonance function, compute p-values compatibility (confidence) intervals statistical models pd argument (setting pd = TRUE) model_parameters() includes column probability direction, .e. probability parameter strictly positive negative. See bayestestR::p_direction() details. plotting desired, p_direction() function can used, together plot(). s_value argument (setting s_value = TRUE) model_parameters() replaces p-values related S-values (Rafi Greenland 2020) finally, possible generate distributions model coefficients generating bootstrap-samples (setting bootstrap = TRUE) simulating draws model coefficients using simulate_model(). samples can treated \"posterior samples\" used many functions bayestestR package. shown options functions derive methods originally implemented Bayesian models (Makowski et al. 2019). However, assuming model assumptions met (means, model fits well data, correct model chosen reflects data generating process (distributional model family) etc.), seems appropriate interpret results classical frequentist models \"Bayesian way\" (details: documentation p_function()).","code":""},{"path":"https://easystats.github.io/parameters/reference/p_direction.lm.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Probability of Direction (pd) — p_direction.lm","text":"Amrhein, V., Korner-Nievergelt, F., Roth, T. (2017). earth flat (p > 0.05): Significance thresholds crisis unreplicable research. PeerJ, 5, e3544. doi:10.7717/peerj.3544 Greenland S, Rafi Z, Matthews R, Higgs M. Aid Scientific Inference, Emphasize Unconditional Compatibility Descriptions Statistics. (2022) https://arxiv.org/abs/1909.08583v7 (Accessed November 10, 2022) Lakens, D. (2024). Improving Statistical Inferences (Version v1.5.1). Retrieved https://lakens.github.io/statistical_inferences/. doi:10.5281/ZENODO.6409077 Lakens, D., Scheel, . M., Isager, P. M. (2018). Equivalence Testing Psychological Research: Tutorial. Advances Methods Practices Psychological Science, 1(2), 259–269. doi:10.1177/2515245918770963 Makowski, D., Ben-Shachar, M. S., Chen, S. H. ., Lüdecke, D. (2019). Indices Effect Existence Significance Bayesian Framework. Frontiers Psychology, 10, 2767. doi:10.3389/fpsyg.2019.02767 Rafi Z, Greenland S. Semantic cognitive tools aid statistical science: replace confidence significance compatibility surprise. BMC Medical Research Methodology (2020) 20:244. Schweder T. Confidence epistemic probability empirical science. Journal Statistical Planning Inference (2018) 195:116–125. doi:10.1016/j.jspi.2017.09.016 Schweder T, Hjort NL. Frequentist analogues priors posteriors. Stigum, B. (ed.), Econometrics Philosophy Economics: Theory Data Confrontation Economics, pp. 285-217. Princeton University Press, Princeton, NJ, 2003 Vos P, Holbert D. Frequentist statistical inference without repeated sampling. Synthese 200, 89 (2022). doi:10.1007/s11229-022-03560-x","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/p_direction.lm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Probability of Direction (pd) — p_direction.lm","text":"","code":"data(qol_cancer) model <- lm(QoL ~ time + age + education, data = qol_cancer) p_direction(model) #> Probability of Direction (null: 0) #>  #> Parameter     |         95% CI |     pd #> --------------------------------------- #> (Intercept)   | [58.46, 69.28] |   100% #> time          | [-1.07,  2.85] | 81.47% #> age           | [-0.32,  0.37] | 55.91% #> educationmid  | [ 4.43, 13.09] | 99.99% #> educationhigh | [ 9.33, 19.38] |   100%  # based on heteroscedasticity-robust standard errors p_direction(model, vcov = \"HC3\") #> Probability of Direction (null: 0) #>  #> Parameter     |         95% CI |     pd #> --------------------------------------- #> (Intercept)   | [58.33, 69.41] |   100% #> time          | [-1.13,  2.90] | 80.70% #> age           | [-0.33,  0.38] | 55.35% #> educationmid  | [ 4.21, 13.31] |   100% #> educationhigh | [ 9.37, 19.34] |   100%  result <- p_direction(model) plot(result)"},{"path":"https://easystats.github.io/parameters/reference/p_function.html","id":null,"dir":"Reference","previous_headings":"","what":"p-value or consonance function — p_function","title":"p-value or consonance function — p_function","text":"Compute p-values compatibility (confidence) intervals statistical models, different levels. function also called consonance function. allows see estimates compatible model various compatibility levels. Use plot() generate plots p resp. consonance function compatibility intervals different levels.","code":""},{"path":"https://easystats.github.io/parameters/reference/p_function.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"p-value or consonance function — p_function","text":"","code":"p_function(   model,   ci_levels = c(0.25, 0.5, 0.75, emph = 0.95),   exponentiate = FALSE,   effects = \"fixed\",   component = \"all\",   vcov = NULL,   vcov_args = NULL,   keep = NULL,   drop = NULL,   verbose = TRUE,   ... )  consonance_function(   model,   ci_levels = c(0.25, 0.5, 0.75, emph = 0.95),   exponentiate = FALSE,   effects = \"fixed\",   component = \"all\",   vcov = NULL,   vcov_args = NULL,   keep = NULL,   drop = NULL,   verbose = TRUE,   ... )  confidence_curve(   model,   ci_levels = c(0.25, 0.5, 0.75, emph = 0.95),   exponentiate = FALSE,   effects = \"fixed\",   component = \"all\",   vcov = NULL,   vcov_args = NULL,   keep = NULL,   drop = NULL,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/parameters/reference/p_function.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"p-value or consonance function — p_function","text":"model Statistical Model. ci_levels Vector scalars, indicating different levels compatibility intervals printed plotted. plots, levels highlighted vertical lines. possible increase thickness one lines providing names vector, highlighted values named \"emph\", e.g ci_levels = c(0.25, 0.5, emph = 0.95). exponentiate Logical, indicating whether exponentiate coefficients (related confidence intervals). typical logistic regression, generally speaking, models log logit links. also recommended use exponentiate = TRUE models log-transformed response values. models log-transformed response variable, exponentiate = TRUE, one-unit increase predictor associated multiplying outcome predictor's coefficient. Note: Delta-method standard errors also computed (multiplying standard errors transformed coefficients). mimic behaviour software packages, Stata, standard errors poorly estimate uncertainty transformed coefficient. transformed confidence interval clearly captures uncertainty. compare_parameters(), exponentiate = \"nongaussian\" exponentiate coefficients non-Gaussian families. effects parameters fixed effects (\"fixed\"), random effects (\"random\"), (\"\") returned? applies mixed models. May abbreviated. calculation random effects parameters takes long, may use effects = \"fixed\". component type parameters return, parameters conditional model, zero-inflation part model, dispersion term, auxiliary parameters returned? Applies models zero-inflation /dispersion formula, parameters sigma included. May abbreviated. Note conditional component also called count mean component, depending model. three convenient shortcuts: component = \"\" returns possible parameters. component = \"location\", location parameters conditional, zero_inflated, smooth_terms, returned (everything fixed random effects - depending effects argument - auxiliary parameters). component = \"distributional\" (\"auxiliary\"), components like sigma, dispersion, beta (auxiliary parameters) returned. vcov Variance-covariance matrix used compute uncertainty estimates (e.g., robust standard errors). argument accepts covariance matrix, function returns covariance matrix, string identifies function used compute covariance matrix. covariance matrix function returns covariance matrix (e.g., stats::vcov()) string indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC Cluster-robust: \"CR\", \"CR0\", \"CR1\", \"CR1p\", \"CR1S\", \"CR2\", \"CR3\". See ?clubSandwich::vcovCR Bootstrap: \"BS\", \"xy\", \"residual\", \"wild\", \"mammen\", \"fractional\", \"jackknife\", \"norm\", \"webb\". See ?sandwich::vcovBS sandwich package functions: \"HAC\", \"PC\", \"CL\", \"OPG\", \"PL\". vcov_args List arguments passed function identified vcov argument. function typically supplied sandwich clubSandwich packages. Please refer documentation (e.g., ?sandwich::vcovHAC) see list available arguments. estimation type (argument type) given, default type \"HC\" equals default sandwich package; type \"CR\", default set \"CR3\". keep Character containing regular expression pattern describes parameters included (keep) excluded (drop) returned data frame. keep may also named list regular expressions. non-matching parameters removed output. keep character vector, every parameter name \"Parameter\" column matches regular expression keep selected returned data frame (vice versa, parameter names matching drop excluded). Furthermore, keep one element, merged operator regular expression pattern like : \"(one|two|three)\". keep named list regular expression patterns, names list-element equal column name selection applied. useful model objects model_parameters() returns multiple columns parameter components, like model_parameters.lavaan(). Note regular expression pattern match parameter names stored returned data frame, can different printed. Inspect $Parameter column parameters table get exact parameter names. drop See keep. verbose Toggle warnings messages. ... Arguments passed methods. Non-documented arguments digits, p_digits, ci_digits footer_digits set number digits output. groups can used group coefficients. arguments passed print-method, can directly used print(), see documentation print.parameters_model(). s_value = TRUE, p-value replaced S-value output (cf. Rafi Greenland 2020). pd adds additional column probability direction (see bayestestR::p_direction() details). Furthermore, see 'Examples' model_parameters.default(). developers, whose interest mainly get \"tidy\" data frame model summaries, recommended set pretty_names = FALSE speed computation summary table.","code":""},{"path":"https://easystats.github.io/parameters/reference/p_function.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"p-value or consonance function — p_function","text":"data frame p-values compatibility intervals.","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/p_function.html","id":"compatibility-intervals-and-continuous-p-values-for-different-estimate-values","dir":"Reference","previous_headings":"","what":"Compatibility intervals and continuous p-values for different estimate values","title":"p-value or consonance function — p_function","text":"p_function() returns compatibility interval estimates, related p-values. reason p-value given estimate value just 1 - CI_level. values indicating lower upper limits intervals related estimates associated p-value. E.g., parameter x 75% compatibility interval (0.81, 1.05), p-value estimate value 0.81 1 - 0.75, 0.25. relationship intuitive better understand looking plots (using plot()).","code":""},{"path":"https://easystats.github.io/parameters/reference/p_function.html","id":"conditional-versus-unconditional-interpretation-of-p-values-and-intervals","dir":"Reference","previous_headings":"","what":"Conditional versus unconditional interpretation of p-values and intervals","title":"p-value or consonance function — p_function","text":"p_function(), particular plot() method, aims re-interpreting p-values confidence intervals (better named: compatibility intervals) unconditional terms. Instead referring long-term property repeated trials interpreting interval estimates (-called \"aleatory probability\", Schweder 2018), assuming underlying assumptions correct met, p_function() interprets p-values Fisherian way \"continuous measure evidence test hypothesis entire model (assumptions) used compute \" (P-Values Tough S-Values Can Help, lesslikely.com/statistics/s-values; see also Amrhein Greenland 2022). interpretation continuous measure evidence test hypothesis entire model used compute can seen figure (taken P-Values Tough S-Values Can Help, lesslikely.com/statistics/s-values). \"conditional\" interpretation p-values interval estimates () implicitly assumes certain assumptions true, thus interpretation \"conditioned\" assumptions (.e. assumptions taken given). unconditional interpretation (B), however, questions assumptions.  \"Emphasizing unconditional interpretations helps avoid overconfident misleading inferences light uncertainties assumptions used arrive statistical results.\" (Greenland et al. 2022). Note: term \"conditional\" used Rafi Greenland probably slightly different meaning normally. \"Conditional\" notion means model assumptions taken given - confused terms like \"conditional probability\". See also Greenland et al. 2022 detailed elaboration issue. words, term compatibility interval emphasizes \"dependence p-value assumptions well data, recognizing p<0.05 can arise assumption violations even effect study null\" (Gelman/Greenland 2019).","code":""},{"path":"https://easystats.github.io/parameters/reference/p_function.html","id":"probabilistic-interpretation-of-p-values-and-compatibility-intervals","dir":"Reference","previous_headings":"","what":"Probabilistic interpretation of p-values and compatibility intervals","title":"p-value or consonance function — p_function","text":"Schweder (2018) resp. Schweder Hjort (2016) (others) argue confidence curves (produced p_function()) valid probabilistic interpretation. distinguish aleatory probability, describes aleatory stochastic element distribution ex ante, .e. data obtained. classical interpretation confidence intervals following Neyman-Pearson school statistics. However, also ex post probability, called epistemic probability, confidence curves. shift terminology confidence intervals compatibility intervals may help emphasizing interpretation. sense, probabilistic interpretation p-values compatibility intervals \"conditional\" - data model assumptions (line \"unconditional\" interpretation sense Rafi Greenland). Ascribing probabilistic interpretation one realized confidence interval possible without repeated sampling specific experiment. Important assumption sampling distribution good description variability parameter (Vos Holbert 2022). core, interpretation confidence interval \"assume sampling distribution good description uncertainty parameter. good assumption, values interval plausible compatible data\". source confidence probability statements assumption selected sampling distribution appropriate. \"realized confidence distribution clearly epistemic probability distribution\" (Schweder 2018). Bayesian words, compatibility intervals (confidence distributons, consonance curves) \"posteriors without priors\" (Schweder, Hjort, 2003). p-value indicates degree compatibility endpoints interval given confidence level (1) observed data (2) model assumptions. observed point estimate (p-value = 1) value estimated compatible data model assumptions, whereas values values far observed point estimate (p approaches 0) least compatible data model assumptions (Schweder Hjort 2016, pp. 60-61; Amrhein Greenland 2022). regards, p-values statements confidence compatibility: p-value absolute measure evidence model (null/alternative model), continuous measure compatibility observed data model used compute (Greenland et al. 2016, Greenland 2023). Going one step , following Schweder, p-values can considered epistemic probability - \"necessarily hypothesis true, possibly true\" (Schweder 2018). Hence, interpretation p-values might guided using bayestestR::p_to_pd().","code":""},{"path":"https://easystats.github.io/parameters/reference/p_function.html","id":"probability-or-compatibility-","dir":"Reference","previous_headings":"","what":"Probability or compatibility?","title":"p-value or consonance function — p_function","text":"presented discussion p-values confidence intervals perspective two paradigms, one saying probability statements can made, one saying interpretation guided terms \"compatibility\". Cox Hinkley say, \"interval estimates taken probability statements\" (Cox Hinkley 1979: 208), conflicts Schweder Hjort confidence distribution school. However, view interval estimates intervals values consistent data, comes close idea (epistemic) probability. believe two paradigms contradict exclude . Rather, aim emphasize one point view , .e. place linguistic nuances either 'compatibility' 'probability'. main take-away interpret p-values dichotomous decisions distinguish \"found effect\" (statistically significant)\" vs. \"found effect\" (statistically significant) (Altman Bland 1995).","code":""},{"path":"https://easystats.github.io/parameters/reference/p_function.html","id":"compatibility-intervals-is-their-interpretation-conditional-or-not-","dir":"Reference","previous_headings":"","what":"Compatibility intervals - is their interpretation \"conditional\" or not?","title":"p-value or consonance function — p_function","text":"fact term \"conditional\" used different meanings statistics, confusing unfortunate. Thus, summarize (probabilistic) interpretation compatibility intervals follows: intervals built data modeling assumptions. accuracy intervals depends model assumptions. value outside interval, might (1) parameter value supported data, (2) modeling assumptions poor fit situation. make bad assumptions, compatibility interval might wide (commonly seriously) narrow, making us think know parameter warranted. say \"95% chance true value interval\", statement epistemic probability (.e. description uncertainty related knowledge belief). talk repeated samples sampling distributions, referring aleatoric (physical properties) probability. Frequentist inference built defining estimators known aleatoric probability properties, can draw epistemic probabilistic statements uncertainty (Schweder Hjort 2016).","code":""},{"path":"https://easystats.github.io/parameters/reference/p_function.html","id":"functions-in-the-parameters-package-to-check-for-effect-existence-and-significance","dir":"Reference","previous_headings":"","what":"Functions in the parameters package to check for effect existence and significance","title":"p-value or consonance function — p_function","text":"parameters package provides several options functions aid statistical inference. Beyond p_function(), , example: equivalence_test(), compute (conditional) equivalence test frequentist models p_significance(), compute probability practical significance, can conceptualized unidirectional equivalence test pd argument (setting pd = TRUE) model_parameters() includes column probability direction, .e. probability parameter strictly positive negative. See bayestestR::p_direction() details. plotting desired, p_direction() function can used, together plot(). s_value argument (setting s_value = TRUE) model_parameters() replaces p-values related S-values (Rafi Greenland 2020) finally, possible generate distributions model coefficients generating bootstrap-samples (setting bootstrap = TRUE) simulating draws model coefficients using simulate_model(). samples can treated \"posterior samples\" used many functions bayestestR package.","code":""},{"path":"https://easystats.github.io/parameters/reference/p_function.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"p-value or consonance function — p_function","text":"Curently, p_function() computes intervals based Wald t- z-statistic. certain models (like mixed models), profiled intervals may accurate, however, currently supported.","code":""},{"path":"https://easystats.github.io/parameters/reference/p_function.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"p-value or consonance function — p_function","text":"Altman DG, Bland JM. Absence evidence evidence absence. BMJ. 1995;311(7003):485. doi:10.1136/bmj.311.7003.485 Amrhein V, Greenland S. Discuss practical importance results based interval estimates p-value functions, point estimates null p-values. Journal Information Technology 2022;37:316–20. doi:10.1177/02683962221105904 Cox DR, Hinkley DV. 1979. Theoretical Statistics. 6th edition. Chapman Hall/CRC Fraser DAS. P-value function statistical inference. American Statistician. 2019;73(sup1):135-147. doi:10.1080/00031305.2018.1556735 Gelman , Greenland S. confidence intervals better termed \"uncertainty intervals\"? BMJ (2019)l5381. doi:10.1136/bmj.l5381 Greenland S, Rafi Z, Matthews R, Higgs M. Aid Scientific Inference, Emphasize Unconditional Compatibility Descriptions Statistics. (2022) https://arxiv.org/abs/1909.08583v7 (Accessed November 10, 2022) Greenland S, Senn SJ, Rothman KJ, Carlin JB, Poole C, Goodman SN, et al. (2016). Statistical tests, P values, confidence intervals, power: guide misinterpretations. European Journal Epidemiology. 31:337-350. doi:10.1007/s10654-016-0149-3 Greenland S (2023). Divergence versus decision P-values: distinction worth making theory keeping practice: , divergence P-values measure evidence even decision P-values . Scand J Statist, 50(1), 54-88. Rafi Z, Greenland S. Semantic cognitive tools aid statistical science: Replace confidence significance compatibility surprise. BMC Medical Research Methodology. 2020;20(1):244. doi:10.1186/s12874-020-01105-9 Schweder T. Confidence epistemic probability empirical science. Journal Statistical Planning Inference (2018) 195:116–125. doi:10.1016/j.jspi.2017.09.016 Schweder T, Hjort NL. Confidence Likelihood. Scandinavian Journal Statistics. 2002;29(2):309-332. doi:10.1111/1467-9469.00285 Schweder T, Hjort NL. Frequentist analogues priors posteriors. Stigum, B. (ed.), Econometrics Philosophy Economics: Theory Data Confrontation Economics, pp. 285-217. Princeton University Press, Princeton, NJ, 2003 Schweder T, Hjort NL. Confidence, Likelihood, Probability: Statistical inference confidence distributions. Cambridge University Press, 2016. Vos P, Holbert D. Frequentist statistical inference without repeated sampling. Synthese 200, 89 (2022). doi:10.1007/s11229-022-03560-x","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/p_function.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"p-value or consonance function — p_function","text":"","code":"model <- lm(Sepal.Length ~ Species, data = iris) p_function(model) #> Consonance Function #>  #> Parameter            |       25% CI |       50% CI |       75% CI |       95% CI #> -------------------------------------------------------------------------------- #> (Intercept)          | [4.98, 5.03] | [4.96, 5.06] | [4.92, 5.09] | [4.86, 5.15] #> Species [versicolor] | [0.90, 0.96] | [0.86, 1.00] | [0.81, 1.05] | [0.73, 1.13] #> Species [virginica]  | [1.55, 1.61] | [1.51, 1.65] | [1.46, 1.70] | [1.38, 1.79]  model <- lm(mpg ~ wt + as.factor(gear) + am, data = mtcars) result <- p_function(model)  # single panels plot(result, n_columns = 2)   # integrated plot, the default plot(result)"},{"path":"https://easystats.github.io/parameters/reference/p_significance.lm.html","id":null,"dir":"Reference","previous_headings":"","what":"Practical Significance (ps) — p_significance.lm","title":"Practical Significance (ps) — p_significance.lm","text":"Compute probability Practical Significance (ps), can conceptualized unidirectional equivalence test. returns probability effect given threshold corresponding negligible effect median's direction, considering parameter's full confidence interval. words, returns probability clear direction effect, larger smallest effect size interest (e.g., minimal important difference). theoretical range zero one, ps typically larger 0.5 (indicate practical significance). comparison equivalence_test() function, SGPV (second generation p-value) describes proportion full confidence interval inside ROPE, value returned p_significance() describes larger proportion full confidence interval outside ROPE. makes p_significance() comparable bayestestR::p_direction(), however, p_direction() compares point-null default, p_significance() compares range-null.","code":""},{"path":"https://easystats.github.io/parameters/reference/p_significance.lm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Practical Significance (ps) — p_significance.lm","text":"","code":"# S3 method for class 'lm' p_significance(   x,   threshold = \"default\",   ci = 0.95,   vcov = NULL,   vcov_args = NULL,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/parameters/reference/p_significance.lm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Practical Significance (ps) — p_significance.lm","text":"x statistical model. threshold threshold value separates significant negligible effect, can following possible values: \"default\", case range set 0.1 input vector, based rope_range() (Bayesian) model provided. single numeric value (e.g., 0.1), used range around zero (.e. threshold range set -0.1 0.1, .e. reflects symmetric interval) numeric vector length two (e.g., c(-0.2, 0.1)), useful asymmetric intervals list numeric vectors, vector corresponds parameter list named numeric vectors, names correspond parameter names. case, parameters matching name threshold set \"default\". ci Confidence Interval (CI) level. Default 0.95 (95%). vcov Variance-covariance matrix used compute uncertainty estimates (e.g., robust standard errors). argument accepts covariance matrix, function returns covariance matrix, string identifies function used compute covariance matrix. covariance matrix function returns covariance matrix (e.g., stats::vcov()) string indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC Cluster-robust: \"CR\", \"CR0\", \"CR1\", \"CR1p\", \"CR1S\", \"CR2\", \"CR3\". See ?clubSandwich::vcovCR Bootstrap: \"BS\", \"xy\", \"residual\", \"wild\", \"mammen\", \"fractional\", \"jackknife\", \"norm\", \"webb\". See ?sandwich::vcovBS sandwich package functions: \"HAC\", \"PC\", \"CL\", \"OPG\", \"PL\". vcov_args List arguments passed function identified vcov argument. function typically supplied sandwich clubSandwich packages. Please refer documentation (e.g., ?sandwich::vcovHAC) see list available arguments. estimation type (argument type) given, default type \"HC\" equals default sandwich package; type \"CR\", default set \"CR3\". verbose Toggle warnings messages. ... Arguments passed methods.","code":""},{"path":"https://easystats.github.io/parameters/reference/p_significance.lm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Practical Significance (ps) — p_significance.lm","text":"data frame columns parameter names, confidence intervals values practical significance. Higher values indicate practical significance (upper bound one).","code":""},{"path":"https://easystats.github.io/parameters/reference/p_significance.lm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Practical Significance (ps) — p_significance.lm","text":"p_significance() returns proportion full confidence interval range (assuming normally t-distributed, equal-tailed interval, based model) outside certain range (negligible effect, ROPE, see argument threshold). values distribution ROPE, p_significance() returns higher probability value outside ROPE. Typically, value larger 0.5 indicate practical significance. However, range negligible effect rather large compared range confidence interval, p_significance() less 0.5, indicates clear practical significance. Note assumed interval, used calculate practical significance, estimation full interval based chosen confidence level. example, 95% confidence interval coefficient ranges -1 1, underlying full (normally t-distributed) interval approximately ranges -1.9 1.9, see also following code:   ensures practical significance always refers general compatible parameter space coefficients. Therefore, full interval similar Bayesian posterior distribution equivalent Bayesian model, see following code:","code":"# simulate full normal distribution out <- bayestestR::distribution_normal(10000, 0, 0.5) # range of \"full\" distribution range(out) # range of 95% CI round(quantile(out, probs = c(0.025, 0.975)), 2) library(bayestestR) library(brms) m <- lm(mpg ~ gear + wt + cyl + hp, data = mtcars) m2 <- brm(mpg ~ gear + wt + cyl + hp, data = mtcars) # probability of significance (ps) for frequentist model p_significance(m) # similar to ps of Bayesian models p_significance(m2) # similar to ps of simulated draws / bootstrap samples p_significance(simulate_model(m))"},{"path":"https://easystats.github.io/parameters/reference/p_significance.lm.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Practical Significance (ps) — p_significance.lm","text":"also plot()-method implemented see-package.","code":""},{"path":"https://easystats.github.io/parameters/reference/p_significance.lm.html","id":"statistical-inference-how-to-quantify-evidence","dir":"Reference","previous_headings":"","what":"Statistical inference - how to quantify evidence","title":"Practical Significance (ps) — p_significance.lm","text":"standardized approach drawing conclusions based available data statistical models. frequently chosen also much criticized approach evaluate results based statistical significance (Amrhein et al. 2017). sophisticated way test whether estimated effects exceed \"smallest effect size interest\", avoid even smallest effects considered relevant simply statistically significant, clinically practically irrelevant (Lakens et al. 2018, Lakens 2024). rather unconventional approach, nevertheless advocated various authors, interpret results classical regression models either terms probabilities, similar usual approach Bayesian statistics (Schweder 2018; Schweder Hjort 2003; Vos 2022) terms relative measure \"evidence\" \"compatibility\" data (Greenland et al. 2022; Rafi Greenland 2020), nevertheless comes close probabilistic interpretation. detailed discussion topic found documentation p_function(). parameters package provides several options functions aid statistical inference. , example: equivalence_test(), compute (conditional) equivalence test frequentist models p_significance(), compute probability practical significance, can conceptualized unidirectional equivalence test p_function(), consonance function, compute p-values compatibility (confidence) intervals statistical models pd argument (setting pd = TRUE) model_parameters() includes column probability direction, .e. probability parameter strictly positive negative. See bayestestR::p_direction() details. plotting desired, p_direction() function can used, together plot(). s_value argument (setting s_value = TRUE) model_parameters() replaces p-values related S-values (Rafi Greenland 2020) finally, possible generate distributions model coefficients generating bootstrap-samples (setting bootstrap = TRUE) simulating draws model coefficients using simulate_model(). samples can treated \"posterior samples\" used many functions bayestestR package. shown options functions derive methods originally implemented Bayesian models (Makowski et al. 2019). However, assuming model assumptions met (means, model fits well data, correct model chosen reflects data generating process (distributional model family) etc.), seems appropriate interpret results classical frequentist models \"Bayesian way\" (details: documentation p_function()).","code":""},{"path":"https://easystats.github.io/parameters/reference/p_significance.lm.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Practical Significance (ps) — p_significance.lm","text":"Amrhein, V., Korner-Nievergelt, F., Roth, T. (2017). earth flat (p > 0.05): Significance thresholds crisis unreplicable research. PeerJ, 5, e3544. doi:10.7717/peerj.3544 Greenland S, Rafi Z, Matthews R, Higgs M. Aid Scientific Inference, Emphasize Unconditional Compatibility Descriptions Statistics. (2022) https://arxiv.org/abs/1909.08583v7 (Accessed November 10, 2022) Lakens, D. (2024). Improving Statistical Inferences (Version v1.5.1). Retrieved https://lakens.github.io/statistical_inferences/. doi:10.5281/ZENODO.6409077 Lakens, D., Scheel, . M., Isager, P. M. (2018). Equivalence Testing Psychological Research: Tutorial. Advances Methods Practices Psychological Science, 1(2), 259–269. doi:10.1177/2515245918770963 Makowski, D., Ben-Shachar, M. S., Chen, S. H. ., Lüdecke, D. (2019). Indices Effect Existence Significance Bayesian Framework. Frontiers Psychology, 10, 2767. doi:10.3389/fpsyg.2019.02767 Rafi Z, Greenland S. Semantic cognitive tools aid statistical science: replace confidence significance compatibility surprise. BMC Medical Research Methodology (2020) 20:244. Schweder T. Confidence epistemic probability empirical science. Journal Statistical Planning Inference (2018) 195:116–125. doi:10.1016/j.jspi.2017.09.016 Schweder T, Hjort NL. Frequentist analogues priors posteriors. Stigum, B. (ed.), Econometrics Philosophy Economics: Theory Data Confrontation Economics, pp. 285-217. Princeton University Press, Princeton, NJ, 2003 Vos P, Holbert D. Frequentist statistical inference without repeated sampling. Synthese 200, 89 (2022). doi:10.1007/s11229-022-03560-x","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/p_significance.lm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Practical Significance (ps) — p_significance.lm","text":"","code":"data(qol_cancer) model <- lm(QoL ~ time + age + education, data = qol_cancer)  p_significance(model) #> Practical Significance (threshold: -1.99, 1.99) #>  #> Parameter     |         95% CI |     ps #> --------------------------------------- #> (Intercept)   | [58.46, 69.28] |   100% #> time          | [-1.07,  2.85] | 13.59% #> age           | [-0.32,  0.37] |  0.00% #> educationmid  | [ 4.43, 13.09] | 99.94% #> educationhigh | [ 9.33, 19.38] |   100% p_significance(model, threshold = c(-0.5, 1.5)) #> Practical Significance (threshold: -0.50, 1.50) #>  #> Parameter     |         95% CI |     ps #> --------------------------------------- #> (Intercept)   | [58.46, 69.28] |   100% #> time          | [-1.07,  2.85] | 26.63% #> age           | [-0.32,  0.37] |  0.20% #> educationmid  | [ 4.43, 13.09] | 99.96% #> educationhigh | [ 9.33, 19.38] |   100%  # based on heteroscedasticity-robust standard errors p_significance(model, vcov = \"HC3\") #> Practical Significance (threshold: -1.99, 1.99) #>  #> Parameter     |         95% CI |     ps #> --------------------------------------- #> (Intercept)   | [58.33, 69.41] |   100% #> time          | [-1.13,  2.90] | 14.24% #> age           | [-0.33,  0.38] |  0.00% #> educationmid  | [ 4.21, 13.31] | 99.87% #> educationhigh | [ 9.37, 19.34] |   100%  if (require(\"see\", quietly = TRUE)) {   result <- p_significance(model)   plot(result) }"},{"path":"https://easystats.github.io/parameters/reference/p_value.html","id":null,"dir":"Reference","previous_headings":"","what":"p-values — p_value","title":"p-values — p_value","text":"function attempts return, compute, p-values model's parameters.","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"p-values — p_value","text":"","code":"p_value(model, ...)  # Default S3 method p_value(   model,   dof = NULL,   method = NULL,   component = \"all\",   vcov = NULL,   vcov_args = NULL,   verbose = TRUE,   ... )  # S3 method for class 'emmGrid' p_value(model, ci = 0.95, adjust = \"none\", ...)"},{"path":"https://easystats.github.io/parameters/reference/p_value.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"p-values — p_value","text":"model statistical model. ... Additional arguments dof Number degrees freedom used calculating confidence intervals. NULL (default), degrees freedom retrieved calling insight::get_df() approximation method defined method. NULL, use argument override default degrees freedom used compute confidence intervals. method Method computing degrees freedom confidence intervals (CI) related p-values. Allowed following options (vary depending model class): \"residual\", \"normal\", \"likelihood\", \"satterthwaite\", \"kenward\", \"wald\", \"profile\", \"boot\", \"uniroot\", \"ml1\", \"betwithin\", \"hdi\", \"quantile\", \"ci\", \"eti\", \"si\", \"bci\", \"bcai\". See section Confidence intervals approximation degrees freedom model_parameters() details. component Model component parameters shown. See documentation object's class model_parameters() p_value() details, see section Model components. vcov Variance-covariance matrix used compute uncertainty estimates (e.g., robust standard errors). argument accepts covariance matrix, function returns covariance matrix, string identifies function used compute covariance matrix. covariance matrix function returns covariance matrix (e.g., stats::vcov()) string indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC Cluster-robust: \"CR\", \"CR0\", \"CR1\", \"CR1p\", \"CR1S\", \"CR2\", \"CR3\". See ?clubSandwich::vcovCR Bootstrap: \"BS\", \"xy\", \"residual\", \"wild\", \"mammen\", \"fractional\", \"jackknife\", \"norm\", \"webb\". See ?sandwich::vcovBS sandwich package functions: \"HAC\", \"PC\", \"CL\", \"OPG\", \"PL\". vcov_args List arguments passed function identified vcov argument. function typically supplied sandwich clubSandwich packages. Please refer documentation (e.g., ?sandwich::vcovHAC) see list available arguments. estimation type (argument type) given, default type \"HC\" equals default sandwich package; type \"CR\", default set \"CR3\". verbose Toggle warnings messages. ci Confidence Interval (CI) level. Default 0.95 (95%). adjust Character value naming method used adjust p-values confidence intervals. See ?emmeans::summary.emmGrid details.","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"p-values — p_value","text":"data frame least two columns: parameter names p-values. Depending model, may also include columns model components etc.","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"p-values — p_value","text":"Bayesian models, p-values corresponds probability direction (bayestestR::p_direction()), converted p-value using bayestestR::convert_pd_to_p().","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value.html","id":"confidence-intervals-and-approximation-of-degrees-of-freedom","dir":"Reference","previous_headings":"","what":"Confidence intervals and approximation of degrees of freedom","title":"p-values — p_value","text":"different ways approximating degrees freedom depending different assumptions nature model sampling distribution. ci_method argument modulates method computing degrees freedom (df) used calculate confidence intervals (CI) related p-values. Following options allowed, depending model class: Classical methods: Classical inference generally based Wald method. Wald approach inference computes test statistic dividing parameter estimate standard error (Coefficient / SE), comparing statistic t- normal distribution. approach can used compute CIs p-values. \"wald\": Applies non-Bayesian models. linear models, CIs computed using Wald method (SE t-distribution residual df); p-values computed using Wald method t-distribution residual df. models, CIs computed using Wald method (SE normal distribution); p-values computed using Wald method normal distribution. \"normal\" Applies non-Bayesian models. Compute Wald CIs p-values, always use normal distribution. \"residual\" Applies non-Bayesian models. Compute Wald CIs p-values, always use t-distribution residual df possible. residual df model determined, normal distribution used instead. Methods mixed models: Compared fixed effects (single-level) models, determining appropriate df Wald-based inference mixed models difficult. See R GLMM FAQ discussion. Several approximate methods computing df available, also consider instead using profile likelihood (\"profile\") bootstrap (\"boot\") CIs p-values instead. \"satterthwaite\" Applies linear mixed models. CIs computed using Wald method (SE t-distribution Satterthwaite df); p-values computed using Wald method t-distribution Satterthwaite df. \"kenward\" Applies linear mixed models. CIs computed using Wald method (Kenward-Roger SE t-distribution Kenward-Roger df); p-values computed using Wald method Kenward-Roger SE t-distribution Kenward-Roger df. \"ml1\" Applies linear mixed models. CIs computed using Wald method (SE t-distribution m-l-1 approximated df); p-values computed using Wald method t-distribution m-l-1 approximated df. See ci_ml1(). \"betwithin\" Applies linear mixed models generalized linear mixed models. CIs computed using Wald method (SE t-distribution -within df); p-values computed using Wald method t-distribution -within df. See ci_betwithin(). Likelihood-based methods: Likelihood-based inference based comparing likelihood maximum-likelihood estimate likelihood models one parameter values changed (e.g., set zero range alternative values). Likelihood ratios maximum-likelihood alternative models compared \\(\\chi\\)-squared distribution compute CIs p-values. \"profile\" Applies non-Bayesian models class glm, polr, merMod glmmTMB. CIs computed profiling likelihood curve parameter, using linear interpolation find likelihood ratio equals critical value; p-values computed using Wald method normal-distribution (note: might change future update!) \"uniroot\" Applies non-Bayesian models class glmmTMB. CIs computed profiling likelihood curve parameter, using root finding find likelihood ratio equals critical value; p-values computed using Wald method normal-distribution (note: might change future update!) Methods bootstrapped Bayesian models: Bootstrap-based inference based resampling refitting model resampled datasets. distribution parameter estimates across resampled datasets used approximate parameter's sampling distribution. Depending type model, several different methods bootstrapping constructing CIs p-values bootstrap distribution available. Bayesian models, inference based drawing samples model posterior distribution. \"quantile\" (\"eti\") Applies models (including Bayesian models). non-Bayesian models, applies bootstrap = TRUE. CIs computed equal tailed intervals using quantiles bootstrap posterior samples; p-values based probability direction. See bayestestR::eti(). \"hdi\" Applies models (including Bayesian models). non-Bayesian models, applies bootstrap = TRUE. CIs computed highest density intervals bootstrap posterior samples; p-values based probability direction. See bayestestR::hdi(). \"bci\" (\"bcai\") Applies models (including Bayesian models). non-Bayesian models, applies bootstrap = TRUE. CIs computed bias corrected accelerated intervals bootstrap posterior samples; p-values based probability direction. See bayestestR::bci(). \"si\" Applies Bayesian models proper priors. CIs computed support intervals comparing posterior samples prior samples; p-values based probability direction. See bayestestR::si(). \"boot\" Applies non-Bayesian models class merMod. CIs computed using parametric bootstrapping (simulating data fitted model); p-values computed using Wald method normal-distribution) (note: might change future update!). iteration-based methods \"boot\" (\"hdi\", \"quantile\", \"ci\", \"eti\", \"si\", \"bci\", \"bcai\"), p-values based probability direction (bayestestR::p_direction()), converted p-value using bayestestR::pd_to_p().","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value.html","id":"model-components","dir":"Reference","previous_headings":"","what":"Model components","title":"p-values — p_value","text":"Possible values component argument depend model class. Following valid options: \"\": returns model components, applies models, effect models just conditional model component. \"conditional\": returns conditional component, .e. \"fixed effects\" terms model. effect models just conditional model component. \"smooth_terms\": returns smooth terms, applies GAMs (similar models may contain smooth terms). \"zero_inflated\" (\"zi\"): returns zero-inflation component. \"dispersion\": returns dispersion model component. common models zero-inflation can model dispersion parameter. \"instruments\": instrumental-variable fixed effects regression, returns instruments. \"nonlinear\": non-linear models (like models class nlmerMod nls), returns staring estimates nonlinear parameters. \"correlation\": models correlation-component, like gls, variables used describe correlation structure returned. Special models model classes also allow rather uncommon options. : mhurdle: \"infrequent_purchase\", \"ip\", \"auxiliary\" BGGM: \"correlation\" \"intercept\" BFBayesFactor, glmx: \"extra\" averaging:\"conditional\" \"full\" mjoint: \"survival\" mfx: \"precision\", \"marginal\" betareg, DirichletRegModel: \"precision\" mvord: \"thresholds\" \"correlation\" clm2: \"scale\" selection: \"selection\", \"outcome\", \"auxiliary\" lavaan: One \"regression\", \"correlation\", \"loading\", \"variance\", \"defined\", \"mean\". Can also \"\" include components. models class brmsfit (package brms), even options possible component argument, documented detail .","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"p-values — p_value","text":"","code":"data(iris) model <- lm(Petal.Length ~ Sepal.Length + Species, data = iris) p_value(model) #>           Parameter            p #> 1       (Intercept) 1.005180e-11 #> 2      Sepal.Length 1.121002e-28 #> 3 Speciesversicolor 9.645641e-67 #> 4  Speciesvirginica 4.917626e-71  data(\"bioChemists\", package = \"pscl\") model <- pscl::zeroinfl(   art ~ fem + mar + kid5 | kid5 + phd,   data = bioChemists ) p_value(model) #>           Parameter            p     Component #> 1 count_(Intercept) 3.069445e-43   conditional #> 2    count_femWomen 5.108245e-06   conditional #> 3  count_marMarried 9.587350e-02   conditional #> 4        count_kid5 8.174027e-03   conditional #> 5  zero_(Intercept) 4.463504e-02 zero_inflated #> 6         zero_kid5 4.146225e-01 zero_inflated #> 7          zero_phd 2.485159e-02 zero_inflated p_value(model, component = \"zi\") #>          Parameter          p     Component #> 5 zero_(Intercept) 0.04463504 zero_inflated #> 6        zero_kid5 0.41462254 zero_inflated #> 7         zero_phd 0.02485159 zero_inflated"},{"path":"https://easystats.github.io/parameters/reference/p_value_betwithin.html","id":null,"dir":"Reference","previous_headings":"","what":"Between-within approximation for SEs, CIs and p-values — ci_betwithin","title":"Between-within approximation for SEs, CIs and p-values — ci_betwithin","text":"Approximation degrees freedom based \"-within\" heuristic.","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value_betwithin.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Between-within approximation for SEs, CIs and p-values — ci_betwithin","text":"","code":"ci_betwithin(model, ci = 0.95, ...)  dof_betwithin(model)  p_value_betwithin(model, dof = NULL, ...)"},{"path":"https://easystats.github.io/parameters/reference/p_value_betwithin.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Between-within approximation for SEs, CIs and p-values — ci_betwithin","text":"model mixed model. ci Confidence Interval (CI) level. Default 0.95 (95%). ... Additional arguments passed underlying functions. E.g., arguments like vcov vcov_args can used compute confidence intervals using specific variance-covariance matrix standard errors. dof Degrees Freedom.","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value_betwithin.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Between-within approximation for SEs, CIs and p-values — ci_betwithin","text":"data frame.","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/p_value_betwithin.html","id":"small-sample-cluster-corrected-degrees-of-freedom","dir":"Reference","previous_headings":"","what":"Small Sample Cluster corrected Degrees of Freedom","title":"Between-within approximation for SEs, CIs and p-values — ci_betwithin","text":"Inferential statistics (like p-values, confidence intervals standard errors) may biased mixed models number clusters small (even sample size level-1 units high). cases recommended approximate accurate number degrees freedom inferential statistics (see Li Redden 2015). -within denominator degrees freedom approximation recommended particular (generalized) linear mixed models repeated measurements (longitudinal design). dof_betwithin() implements heuristic based -within approach. Note implementation return exactly results shown Li Redden 2015, similar.","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value_betwithin.html","id":"degrees-of-freedom-for-longitudinal-designs-repeated-measures-","dir":"Reference","previous_headings":"","what":"Degrees of Freedom for Longitudinal Designs (Repeated Measures)","title":"Between-within approximation for SEs, CIs and p-values — ci_betwithin","text":"particular repeated measure designs (longitudinal data analysis), -within heuristic likely accurate simply using residual infinite degrees freedom, dof_betwithin() returns different degrees freedom within-cluster -cluster effects.","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value_betwithin.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Between-within approximation for SEs, CIs and p-values — ci_betwithin","text":"Elff, M.; Heisig, J.P.; Schaeffer, M.; Shikano, S. (2019). Multilevel Analysis Clusters: Improving Likelihood-based Methods Provide Unbiased Estimates Accurate Inference, British Journal Political Science. Li, P., Redden, D. T. (2015). Comparing denominator degrees freedom approximations generalized linear mixed model analyzing binary outcome small sample cluster-randomized trials. BMC Medical Research Methodology, 15(1), 38. doi:10.1186/s12874-015-0026-x","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/p_value_betwithin.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Between-within approximation for SEs, CIs and p-values — ci_betwithin","text":"","code":"# \\donttest{ if (require(\"lme4\")) {   data(sleepstudy)   model <- lmer(Reaction ~ Days + (1 + Days | Subject), data = sleepstudy)   dof_betwithin(model)   p_value_betwithin(model) } #>     Parameter            p #> 1 (Intercept) 9.306054e-80 #> 2        Days 6.290140e-06 # }"},{"path":"https://easystats.github.io/parameters/reference/p_value_kenward.html","id":null,"dir":"Reference","previous_headings":"","what":"Kenward-Roger approximation for SEs, CIs and p-values — ci_kenward","title":"Kenward-Roger approximation for SEs, CIs and p-values — ci_kenward","text":"approximate F-test based Kenward-Roger (1997) approach.","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value_kenward.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Kenward-Roger approximation for SEs, CIs and p-values — ci_kenward","text":"","code":"ci_kenward(model, ci = 0.95)  dof_kenward(model)  p_value_kenward(model, dof = NULL)  se_kenward(model)"},{"path":"https://easystats.github.io/parameters/reference/p_value_kenward.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Kenward-Roger approximation for SEs, CIs and p-values — ci_kenward","text":"model statistical model. ci Confidence Interval (CI) level. Default 0.95 (95%). dof Degrees Freedom.","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value_kenward.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Kenward-Roger approximation for SEs, CIs and p-values — ci_kenward","text":"data frame.","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value_kenward.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Kenward-Roger approximation for SEs, CIs and p-values — ci_kenward","text":"Inferential statistics (like p-values, confidence intervals standard errors) may biased mixed models number clusters small (even sample size level-1 units high). cases recommended approximate accurate number degrees freedom inferential statistics. Unlike simpler approximation heuristics like \"m-l-1\" rule (dof_ml1), Kenward-Roger approximation also applicable complex multilevel designs, e.g. cross-classified clusters. However, \"m-l-1\" heuristic also applies generalized mixed models, approaches like Kenward-Roger Satterthwaite limited linear mixed models .","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value_kenward.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Kenward-Roger approximation for SEs, CIs and p-values — ci_kenward","text":"Kenward, M. G., & Roger, J. H. (1997). Small sample inference fixed effects restricted maximum likelihood. Biometrics, 983-997.","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/p_value_kenward.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Kenward-Roger approximation for SEs, CIs and p-values — ci_kenward","text":"","code":"# \\donttest{ if (require(\"lme4\", quietly = TRUE)) {   model <- lmer(Petal.Length ~ Sepal.Length + (1 | Species), data = iris)   p_value_kenward(model) } #>      Parameter            p #> 1  (Intercept) 9.605137e-01 #> 2 Sepal.Length 8.598429e-29 # }"},{"path":"https://easystats.github.io/parameters/reference/p_value_ml1.html","id":null,"dir":"Reference","previous_headings":"","what":"","title":"","text":"Approximation degrees freedom based \"m-l-1\" heuristic suggested Elff et al. (2019).","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value_ml1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"","text":"","code":"ci_ml1(model, ci = 0.95, ...)  dof_ml1(model)  p_value_ml1(model, dof = NULL, ...)"},{"path":"https://easystats.github.io/parameters/reference/p_value_ml1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"","text":"model mixed model. ci Confidence Interval (CI) level. Default 0.95 (95%). ... Additional arguments passed underlying functions. E.g., arguments like vcov vcov_args can used compute confidence intervals using specific variance-covariance matrix standard errors. dof Degrees Freedom.","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value_ml1.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"","text":"data frame.","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/p_value_ml1.html","id":"small-sample-cluster-corrected-degrees-of-freedom","dir":"Reference","previous_headings":"","what":"Small Sample Cluster corrected Degrees of Freedom","title":"","text":"Inferential statistics (like p-values, confidence intervals standard errors) may biased mixed models number clusters small (even sample size level-1 units high). cases recommended approximate accurate number degrees freedom inferential statistics (see Li Redden 2015). m-l-1 heuristic approach uses t-distribution fewer degrees freedom (dof_ml1()) calculate p-values (p_value_ml1()) confidence intervals (ci(method = \"ml1\")).","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value_ml1.html","id":"degrees-of-freedom-for-longitudinal-designs-repeated-measures-","dir":"Reference","previous_headings":"","what":"Degrees of Freedom for Longitudinal Designs (Repeated Measures)","title":"","text":"particular repeated measure designs (longitudinal data analysis), m-l-1 heuristic likely accurate simply using residual infinite degrees freedom, dof_ml1() returns different degrees freedom within-cluster -cluster effects.","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value_ml1.html","id":"limitations-of-the-m-l-heuristic","dir":"Reference","previous_headings":"","what":"Limitations of the \"m-l-1\" Heuristic","title":"","text":"Note \"m-l-1\" heuristic applicable (least less accurate) complex multilevel designs, e.g. cross-classified clusters. cases, accurate approaches like Kenward-Roger approximation (dof_kenward()) recommended. However, \"m-l-1\" heuristic also applies generalized mixed models, approaches like Kenward-Roger Satterthwaite limited linear mixed models .","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value_ml1.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"","text":"Elff, M.; Heisig, J.P.; Schaeffer, M.; Shikano, S. (2019). Multilevel Analysis Clusters: Improving Likelihood-based Methods Provide Unbiased Estimates Accurate Inference, British Journal Political Science. Li, P., Redden, D. T. (2015). Comparing denominator degrees freedom approximations generalized linear mixed model analyzing binary outcome small sample cluster-randomized trials. BMC Medical Research Methodology, 15(1), 38. doi:10.1186/s12874-015-0026-x","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/p_value_ml1.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"","text":"","code":"# \\donttest{ if (require(\"lme4\")) {   model <- lmer(Petal.Length ~ Sepal.Length + (1 | Species), data = iris)   p_value_ml1(model) } #>      Parameter          p #> 1  (Intercept) 0.96504927 #> 2 Sepal.Length 0.04534945 # }"},{"path":"https://easystats.github.io/parameters/reference/p_value_satterthwaite.html","id":null,"dir":"Reference","previous_headings":"","what":"Satterthwaite approximation for SEs, CIs and p-values — ci_satterthwaite","title":"Satterthwaite approximation for SEs, CIs and p-values — ci_satterthwaite","text":"approximate F-test based Satterthwaite (1946) approach.","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value_satterthwaite.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Satterthwaite approximation for SEs, CIs and p-values — ci_satterthwaite","text":"","code":"ci_satterthwaite(model, ci = 0.95, ...)  dof_satterthwaite(model)  p_value_satterthwaite(model, dof = NULL, ...)  se_satterthwaite(model)"},{"path":"https://easystats.github.io/parameters/reference/p_value_satterthwaite.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Satterthwaite approximation for SEs, CIs and p-values — ci_satterthwaite","text":"model statistical model. ci Confidence Interval (CI) level. Default 0.95 (95%). ... Additional arguments passed underlying functions. E.g., arguments like vcov vcov_args can used compute confidence intervals using specific variance-covariance matrix standard errors. dof Degrees Freedom.","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value_satterthwaite.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Satterthwaite approximation for SEs, CIs and p-values — ci_satterthwaite","text":"data frame.","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value_satterthwaite.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Satterthwaite approximation for SEs, CIs and p-values — ci_satterthwaite","text":"Inferential statistics (like p-values, confidence intervals standard errors) may biased mixed models number clusters small (even sample size level-1 units high). cases recommended approximate accurate number degrees freedom inferential statistics. Unlike simpler approximation heuristics like \"m-l-1\" rule (dof_ml1), Satterthwaite approximation also applicable complex multilevel designs. However, \"m-l-1\" heuristic also applies generalized mixed models, approaches like Kenward-Roger Satterthwaite limited linear mixed models .","code":""},{"path":"https://easystats.github.io/parameters/reference/p_value_satterthwaite.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Satterthwaite approximation for SEs, CIs and p-values — ci_satterthwaite","text":"Satterthwaite FE (1946) approximate distribution estimates variance components. Biometrics Bulletin 2 (6):110–4.","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/p_value_satterthwaite.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Satterthwaite approximation for SEs, CIs and p-values — ci_satterthwaite","text":"","code":"# \\donttest{ if (require(\"lme4\", quietly = TRUE)) {   model <- lmer(Petal.Length ~ Sepal.Length + (1 | Species), data = iris)   p_value_satterthwaite(model) } #>      Parameter            p #> 1  (Intercept) 9.605145e-01 #> 2 Sepal.Length 7.882014e-29 # }"},{"path":"https://easystats.github.io/parameters/reference/parameters-package.html","id":null,"dir":"Reference","previous_headings":"","what":"parameters: Extracting, Computing and Exploring the Parameters of Statistical Models using R — parameters-package","title":"parameters: Extracting, Computing and Exploring the Parameters of Statistical Models using R — parameters-package","text":"parameters' primary goal provide utilities processing parameters various statistical models (see list supported models). Beyond computing p-values, CIs, Bayesian indices measures wide variety models, package implements features like bootstrapping parameters models, feature reduction (feature extraction variable selection), tools data reduction like functions perform cluster, factor principal component analysis. Another important goal parameters package facilitate streamline process reporting results statistical models, includes easy intuitive calculation standardized estimates robust standard errors p-values. parameters therefor offers simple unified syntax process large variety (model) objects many different packages. References: Lüdecke et al. (2020) doi:10.21105/joss.02445","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/parameters-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"parameters: Extracting, Computing and Exploring the Parameters of Statistical Models using R — parameters-package","text":"Maintainer: Daniel Lüdecke d.luedecke@uke.de (ORCID) Authors: Dominique Makowski dom.makowski@gmail.com (ORCID) Mattan S. Ben-Shachar matanshm@post.bgu.ac.il (ORCID) Indrajeet Patil patilindrajeet.science@gmail.com (ORCID) Søren Højsgaard sorenh@math.aau.dk Brenton M. Wiernik brenton@wiernik.org (ORCID) contributors: Zen J. Lau zenjuen.lau@ntu.edu.sg [contributor] Vincent Arel-Bundock vincent.arel-bundock@umontreal.ca (ORCID) [contributor] Jeffrey Girard @jmgirard.com (ORCID) [contributor] Christina Maimone christina.maimone@northwestern.edu [reviewer] Niels Ohlsen [reviewer] Douglas Ezra Morrison dmorrison01@ucla.edu (ORCID) [contributor] Joseph Luchman jluchman@gmail.com (ORCID) [contributor]","code":""},{"path":"https://easystats.github.io/parameters/reference/parameters_type.html","id":null,"dir":"Reference","previous_headings":"","what":"Type of model parameters — parameters_type","title":"Type of model parameters — parameters_type","text":"regression model, parameters meaning. instance, intercept interpreted theoretical outcome value conditions (predictors set 0), whereas coefficients interpreted amounts change. Others, interactions, represent changes another parameter. parameters_type function attempts retrieve information meaning parameters. outputs dataframe information parameters, Type (whether parameter corresponds factor numeric predictor, whether (regular) interaction nested one), Link (whether parameter can interpreted mean value, slope association difference two levels) , case interactions, parameters impacted parameter.","code":""},{"path":"https://easystats.github.io/parameters/reference/parameters_type.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Type of model parameters — parameters_type","text":"","code":"parameters_type(model, ...)"},{"path":"https://easystats.github.io/parameters/reference/parameters_type.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Type of model parameters — parameters_type","text":"model statistical model. ... Arguments passed methods.","code":""},{"path":"https://easystats.github.io/parameters/reference/parameters_type.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Type of model parameters — parameters_type","text":"data frame.","code":""},{"path":"https://easystats.github.io/parameters/reference/parameters_type.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Type of model parameters — parameters_type","text":"","code":"library(parameters)  model <- lm(Sepal.Length ~ Petal.Length + Species, data = iris) parameters_type(model) #>           Parameter      Type        Link              Term     Variable #> 1       (Intercept) intercept        Mean       (Intercept)         <NA> #> 2      Petal.Length   numeric Association      Petal.Length Petal.Length #> 3 Speciesversicolor    factor  Difference Speciesversicolor      Species #> 4  Speciesvirginica    factor  Difference  Speciesvirginica      Species #>        Level Secondary_Parameter Secondary_Type Secondary_Link Secondary_Term #> 1       <NA>                <NA>             NA             NA             NA #> 2       <NA>                <NA>             NA             NA             NA #> 3 versicolor                <NA>             NA             NA             NA #> 4  virginica                <NA>             NA             NA             NA #>   Secondary_Variable Secondary_Level Tertiary_Parameter #> 1                 NA              NA                 NA #> 2                 NA              NA                 NA #> 3                 NA              NA                 NA #> 4                 NA              NA                 NA  model <- lm(Sepal.Length ~ Species + poly(Sepal.Width, 2), data = iris) parameters_type(model) #>               Parameter      Type        Link                  Term    Variable #> 1           (Intercept) intercept        Mean           (Intercept)        <NA> #> 2     Speciesversicolor    factor  Difference     Speciesversicolor     Species #> 3      Speciesvirginica    factor  Difference      Speciesvirginica     Species #> 4 poly(Sepal.Width, 2)1      poly Association poly(Sepal.Width, 2)1 Sepal.Width #> 5 poly(Sepal.Width, 2)2      poly Association poly(Sepal.Width, 2)2 Sepal.Width #>        Level Secondary_Parameter Secondary_Type Secondary_Link Secondary_Term #> 1       <NA>                <NA>             NA             NA             NA #> 2 versicolor                <NA>             NA             NA             NA #> 3  virginica                <NA>             NA             NA             NA #> 4          1                <NA>             NA             NA             NA #> 5          2                <NA>             NA             NA             NA #>   Secondary_Variable Secondary_Level Tertiary_Parameter #> 1                 NA              NA                 NA #> 2                 NA              NA                 NA #> 3                 NA              NA                 NA #> 4                 NA              NA                 NA #> 5                 NA              NA                 NA  model <- lm(Sepal.Length ~ Species + poly(Sepal.Width, 2, raw = TRUE), data = iris) parameters_type(model) #>                           Parameter      Type        Link                  Term #> 1                       (Intercept) intercept        Mean           (Intercept) #> 2                 Speciesversicolor    factor  Difference     Speciesversicolor #> 3                  Speciesvirginica    factor  Difference      Speciesvirginica #> 4 poly(Sepal.Width, 2, raw = TRUE)1  poly_raw Association poly(Sepal.Width, 2)1 #> 5 poly(Sepal.Width, 2, raw = TRUE)2  poly_raw Association poly(Sepal.Width, 2)2 #>      Variable      Level Secondary_Parameter Secondary_Type Secondary_Link #> 1        <NA>       <NA>                <NA>             NA             NA #> 2     Species versicolor                <NA>             NA             NA #> 3     Species  virginica                <NA>             NA             NA #> 4 Sepal.Width          1                <NA>             NA             NA #> 5 Sepal.Width          2                <NA>             NA             NA #>   Secondary_Term Secondary_Variable Secondary_Level Tertiary_Parameter #> 1             NA                 NA              NA                 NA #> 2             NA                 NA              NA                 NA #> 3             NA                 NA              NA                 NA #> 4             NA                 NA              NA                 NA #> 5             NA                 NA              NA                 NA  # Interactions model <- lm(Sepal.Length ~ Sepal.Width * Species, data = iris) parameters_type(model) #>                       Parameter        Type        Link              Term #> 1                   (Intercept)   intercept        Mean       (Intercept) #> 2                   Sepal.Width     numeric Association       Sepal.Width #> 3             Speciesversicolor      factor  Difference Speciesversicolor #> 4              Speciesvirginica      factor  Difference  Speciesvirginica #> 5 Sepal.Width:Speciesversicolor interaction  Difference Speciesversicolor #> 6  Sepal.Width:Speciesvirginica interaction  Difference  Speciesvirginica #>      Variable      Level Secondary_Parameter Secondary_Type Secondary_Link #> 1        <NA>       <NA>                <NA>           <NA>           <NA> #> 2 Sepal.Width       <NA>                <NA>           <NA>           <NA> #> 3     Species versicolor                <NA>           <NA>           <NA> #> 4     Species  virginica                <NA>           <NA>           <NA> #> 5     Species versicolor         Sepal.Width        numeric    Association #> 6     Species  virginica         Sepal.Width        numeric    Association #>   Secondary_Term Secondary_Variable Secondary_Level Tertiary_Parameter #> 1           <NA>               <NA>            <NA>               <NA> #> 2           <NA>               <NA>            <NA>               <NA> #> 3           <NA>               <NA>            <NA>               <NA> #> 4           <NA>               <NA>            <NA>               <NA> #> 5    Sepal.Width        Sepal.Width            <NA>               <NA> #> 6    Sepal.Width        Sepal.Width            <NA>               <NA>  model <- lm(Sepal.Length ~ Sepal.Width * Species * Petal.Length, data = iris) parameters_type(model) #>                                     Parameter        Type        Link #> 1                                 (Intercept)   intercept        Mean #> 2                                 Sepal.Width     numeric Association #> 3                           Speciesversicolor      factor  Difference #> 4                            Speciesvirginica      factor  Difference #> 5                                Petal.Length     numeric Association #> 6               Sepal.Width:Speciesversicolor interaction  Difference #> 7                Sepal.Width:Speciesvirginica interaction  Difference #> 8                    Sepal.Width:Petal.Length interaction Association #> 9              Speciesversicolor:Petal.Length interaction  Difference #> 10              Speciesvirginica:Petal.Length interaction  Difference #> 11 Sepal.Width:Speciesversicolor:Petal.Length interaction Association #> 12  Sepal.Width:Speciesvirginica:Petal.Length interaction Association #>                 Term     Variable      Level           Secondary_Parameter #> 1        (Intercept)         <NA>       <NA>                          <NA> #> 2        Sepal.Width  Sepal.Width       <NA>                          <NA> #> 3  Speciesversicolor      Species versicolor                          <NA> #> 4   Speciesvirginica      Species  virginica                          <NA> #> 5       Petal.Length Petal.Length       <NA>                          <NA> #> 6  Speciesversicolor      Species versicolor                   Sepal.Width #> 7   Speciesvirginica      Species  virginica                   Sepal.Width #> 8       Petal.Length Petal.Length       <NA>                   Sepal.Width #> 9       Petal.Length Petal.Length       <NA>             Speciesversicolor #> 10      Petal.Length Petal.Length       <NA>              Speciesvirginica #> 11      Petal.Length Petal.Length       <NA> Sepal.Width:Speciesversicolor #> 12      Petal.Length Petal.Length       <NA>  Sepal.Width:Speciesvirginica #>    Secondary_Type Secondary_Link    Secondary_Term Secondary_Variable #> 1            <NA>           <NA>              <NA>               <NA> #> 2            <NA>           <NA>              <NA>               <NA> #> 3            <NA>           <NA>              <NA>               <NA> #> 4            <NA>           <NA>              <NA>               <NA> #> 5            <NA>           <NA>              <NA>               <NA> #> 6         numeric    Association       Sepal.Width        Sepal.Width #> 7         numeric    Association       Sepal.Width        Sepal.Width #> 8         numeric    Association       Sepal.Width        Sepal.Width #> 9          factor     Difference Speciesversicolor            Species #> 10         factor     Difference  Speciesvirginica            Species #> 11    interaction     Difference Speciesversicolor            Species #> 12    interaction     Difference  Speciesvirginica            Species #>    Secondary_Level Tertiary_Parameter #> 1             <NA>               <NA> #> 2             <NA>               <NA> #> 3             <NA>               <NA> #> 4             <NA>               <NA> #> 5             <NA>               <NA> #> 6             <NA>               <NA> #> 7             <NA>               <NA> #> 8             <NA>               <NA> #> 9       versicolor               <NA> #> 10       virginica               <NA> #> 11      versicolor        Sepal.Width #> 12       virginica        Sepal.Width  model <- lm(Sepal.Length ~ Species * Sepal.Width, data = iris) parameters_type(model) #>                       Parameter        Type        Link              Term #> 1                   (Intercept)   intercept        Mean       (Intercept) #> 2             Speciesversicolor      factor  Difference Speciesversicolor #> 3              Speciesvirginica      factor  Difference  Speciesvirginica #> 4                   Sepal.Width     numeric Association       Sepal.Width #> 5 Speciesversicolor:Sepal.Width interaction  Difference       Sepal.Width #> 6  Speciesvirginica:Sepal.Width interaction  Difference       Sepal.Width #>      Variable      Level Secondary_Parameter Secondary_Type Secondary_Link #> 1        <NA>       <NA>                <NA>           <NA>           <NA> #> 2     Species versicolor                <NA>           <NA>           <NA> #> 3     Species  virginica                <NA>           <NA>           <NA> #> 4 Sepal.Width       <NA>                <NA>           <NA>           <NA> #> 5 Sepal.Width       <NA>   Speciesversicolor         factor     Difference #> 6 Sepal.Width       <NA>    Speciesvirginica         factor     Difference #>      Secondary_Term Secondary_Variable Secondary_Level Tertiary_Parameter #> 1              <NA>               <NA>            <NA>               <NA> #> 2              <NA>               <NA>            <NA>               <NA> #> 3              <NA>               <NA>            <NA>               <NA> #> 4              <NA>               <NA>            <NA>               <NA> #> 5 Speciesversicolor            Species      versicolor               <NA> #> 6  Speciesvirginica            Species       virginica               <NA>  model <- lm(Sepal.Length ~ Species / Sepal.Width, data = iris) parameters_type(model) #>                       Parameter      Type       Link              Term #> 1                   (Intercept) intercept       Mean       (Intercept) #> 2             Speciesversicolor    factor Difference Speciesversicolor #> 3              Speciesvirginica    factor Difference  Speciesvirginica #> 4     Speciessetosa:Sepal.Width    nested Difference       Sepal.Width #> 5 Speciesversicolor:Sepal.Width    nested Difference       Sepal.Width #> 6  Speciesvirginica:Sepal.Width    nested Difference       Sepal.Width #>      Variable      Level Secondary_Parameter Secondary_Type Secondary_Link #> 1        <NA>       <NA>                <NA>           <NA>           <NA> #> 2     Species versicolor                <NA>           <NA>           <NA> #> 3     Species  virginica                <NA>           <NA>           <NA> #> 4 Sepal.Width       <NA>       Speciessetosa         factor     Difference #> 5 Sepal.Width       <NA>   Speciesversicolor         factor     Difference #> 6 Sepal.Width       <NA>    Speciesvirginica         factor     Difference #>      Secondary_Term Secondary_Variable Secondary_Level Tertiary_Parameter #> 1              <NA>               <NA>            <NA>               <NA> #> 2              <NA>               <NA>            <NA>               <NA> #> 3              <NA>               <NA>            <NA>               <NA> #> 4     Speciessetosa            Species          setosa               <NA> #> 5 Speciesversicolor            Species      versicolor               <NA> #> 6  Speciesvirginica            Species       virginica               <NA>   # Complex interactions data <- iris data$fac2 <- ifelse(data$Sepal.Width > mean(data$Sepal.Width), \"A\", \"B\") model <- lm(Sepal.Length ~ Species / fac2 / Petal.Length, data = data) parameters_type(model) #>                               Parameter      Type        Link              Term #> 1                           (Intercept) intercept        Mean       (Intercept) #> 2                     Speciesversicolor    factor  Difference Speciesversicolor #> 3                      Speciesvirginica    factor  Difference  Speciesvirginica #> 4                   Speciessetosa:fac2B    nested  Difference             fac2B #> 5               Speciesversicolor:fac2B    nested  Difference             fac2B #> 6                Speciesvirginica:fac2B    nested  Difference             fac2B #> 7      Speciessetosa:fac2A:Petal.Length    nested Association      Petal.Length #> 8  Speciesversicolor:fac2A:Petal.Length    nested Association      Petal.Length #> 9   Speciesvirginica:fac2A:Petal.Length    nested Association      Petal.Length #> 10     Speciessetosa:fac2B:Petal.Length    nested Association      Petal.Length #> 11 Speciesversicolor:fac2B:Petal.Length    nested Association      Petal.Length #> 12  Speciesvirginica:fac2B:Petal.Length    nested Association      Petal.Length #>        Variable      Level     Secondary_Parameter Secondary_Type #> 1          <NA>       <NA>                    <NA>           <NA> #> 2       Species versicolor                    <NA>           <NA> #> 3       Species  virginica                    <NA>           <NA> #> 4          fac2          B           Speciessetosa         factor #> 5          fac2          B       Speciesversicolor         factor #> 6          fac2          B        Speciesvirginica         factor #> 7  Petal.Length       <NA>     Speciessetosa:fac2A    interaction #> 8  Petal.Length       <NA> Speciesversicolor:fac2A    interaction #> 9  Petal.Length       <NA>  Speciesvirginica:fac2A    interaction #> 10 Petal.Length       <NA>     Speciessetosa:fac2B         nested #> 11 Petal.Length       <NA> Speciesversicolor:fac2B         nested #> 12 Petal.Length       <NA>  Speciesvirginica:fac2B         nested #>    Secondary_Link    Secondary_Term Secondary_Variable Secondary_Level #> 1            <NA>              <NA>               <NA>            <NA> #> 2            <NA>              <NA>               <NA>            <NA> #> 3            <NA>              <NA>               <NA>            <NA> #> 4      Difference     Speciessetosa            Species          setosa #> 5      Difference Speciesversicolor            Species      versicolor #> 6      Difference  Speciesvirginica            Species       virginica #> 7      Difference             fac2A               fac2               A #> 8      Difference             fac2A               fac2               A #> 9      Difference             fac2A               fac2               A #> 10     Difference             fac2B               fac2               B #> 11     Difference             fac2B               fac2               B #> 12     Difference             fac2B               fac2               B #>    Tertiary_Parameter #> 1                <NA> #> 2                <NA> #> 3                <NA> #> 4                <NA> #> 5                <NA> #> 6                <NA> #> 7       Speciessetosa #> 8   Speciesversicolor #> 9    Speciesvirginica #> 10      Speciessetosa #> 11  Speciesversicolor #> 12   Speciesvirginica  model <- lm(Sepal.Length ~ Species / fac2 * Petal.Length, data = data) parameters_type(model) #>                               Parameter        Type        Link #> 1                           (Intercept)   intercept        Mean #> 2                     Speciesversicolor      factor  Difference #> 3                      Speciesvirginica      factor  Difference #> 4                          Petal.Length     numeric Association #> 5                   Speciessetosa:fac2B      nested  Difference #> 6               Speciesversicolor:fac2B      nested  Difference #> 7                Speciesvirginica:fac2B      nested  Difference #> 8        Speciesversicolor:Petal.Length interaction  Difference #> 9         Speciesvirginica:Petal.Length interaction  Difference #> 10     Speciessetosa:fac2B:Petal.Length      simple Association #> 11 Speciesversicolor:fac2B:Petal.Length      simple Association #> 12  Speciesvirginica:fac2B:Petal.Length      simple Association #>                 Term     Variable      Level     Secondary_Parameter #> 1        (Intercept)         <NA>       <NA>                    <NA> #> 2  Speciesversicolor      Species versicolor                    <NA> #> 3   Speciesvirginica      Species  virginica                    <NA> #> 4       Petal.Length Petal.Length       <NA>                    <NA> #> 5              fac2B         fac2          B           Speciessetosa #> 6              fac2B         fac2          B       Speciesversicolor #> 7              fac2B         fac2          B        Speciesvirginica #> 8       Petal.Length Petal.Length       <NA>       Speciesversicolor #> 9       Petal.Length Petal.Length       <NA>        Speciesvirginica #> 10      Petal.Length Petal.Length       <NA>     Speciessetosa:fac2B #> 11      Petal.Length Petal.Length       <NA> Speciesversicolor:fac2B #> 12      Petal.Length Petal.Length       <NA>  Speciesvirginica:fac2B #>    Secondary_Type Secondary_Link    Secondary_Term Secondary_Variable #> 1            <NA>           <NA>              <NA>               <NA> #> 2            <NA>           <NA>              <NA>               <NA> #> 3            <NA>           <NA>              <NA>               <NA> #> 4            <NA>           <NA>              <NA>               <NA> #> 5          factor     Difference     Speciessetosa            Species #> 6          factor     Difference Speciesversicolor            Species #> 7          factor     Difference  Speciesvirginica            Species #> 8          factor     Difference Speciesversicolor            Species #> 9          factor     Difference  Speciesvirginica            Species #> 10         nested     Difference             fac2B               fac2 #> 11         nested     Difference             fac2B               fac2 #> 12         nested     Difference             fac2B               fac2 #>    Secondary_Level Tertiary_Parameter #> 1             <NA>               <NA> #> 2             <NA>               <NA> #> 3             <NA>               <NA> #> 4             <NA>               <NA> #> 5           setosa               <NA> #> 6       versicolor               <NA> #> 7        virginica               <NA> #> 8       versicolor               <NA> #> 9        virginica               <NA> #> 10               B      Speciessetosa #> 11               B  Speciesversicolor #> 12               B   Speciesvirginica"},{"path":"https://easystats.github.io/parameters/reference/pool_parameters.html","id":null,"dir":"Reference","previous_headings":"","what":"Pool Model Parameters — pool_parameters","title":"Pool Model Parameters — pool_parameters","text":"function \"pools\" (.e. combines) model parameters similar fashion mice::pool(). However, function pools parameters parameters_model objects, returned model_parameters().","code":""},{"path":"https://easystats.github.io/parameters/reference/pool_parameters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pool Model Parameters — pool_parameters","text":"","code":"pool_parameters(   x,   exponentiate = FALSE,   effects = \"fixed\",   component = \"all\",   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/parameters/reference/pool_parameters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pool Model Parameters — pool_parameters","text":"x list parameters_model objects, returned model_parameters(), list model-objects supported model_parameters(). exponentiate Logical, indicating whether exponentiate coefficients (related confidence intervals). typical logistic regression, generally speaking, models log logit links. also recommended use exponentiate = TRUE models log-transformed response values. models log-transformed response variable, exponentiate = TRUE, one-unit increase predictor associated multiplying outcome predictor's coefficient. Note: Delta-method standard errors also computed (multiplying standard errors transformed coefficients). mimic behaviour software packages, Stata, standard errors poorly estimate uncertainty transformed coefficient. transformed confidence interval clearly captures uncertainty. compare_parameters(), exponentiate = \"nongaussian\" exponentiate coefficients non-Gaussian families. effects parameters fixed effects (\"fixed\"), random effects (\"random\"), (\"\") returned? applies mixed models. May abbreviated. calculation random effects parameters takes long, may use effects = \"fixed\". component type parameters return, parameters conditional model, zero-inflation part model, dispersion term, auxiliary parameters returned? Applies models zero-inflation /dispersion formula, parameters sigma included. May abbreviated. Note conditional component also called count mean component, depending model. three convenient shortcuts: component = \"\" returns possible parameters. component = \"location\", location parameters conditional, zero_inflated, smooth_terms, returned (everything fixed random effects - depending effects argument - auxiliary parameters). component = \"distributional\" (\"auxiliary\"), components like sigma, dispersion, beta (auxiliary parameters) returned. verbose Toggle warnings messages. ... Arguments passed model_parameters(), x list model-objects. Can used, instance, specify arguments like ci ci_method etc.","code":""},{"path":"https://easystats.github.io/parameters/reference/pool_parameters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pool Model Parameters — pool_parameters","text":"data frame indices related model's parameters.","code":""},{"path":"https://easystats.github.io/parameters/reference/pool_parameters.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Pool Model Parameters — pool_parameters","text":"Averaging parameters follows Rubin's rules (Rubin, 1987, p. 76). pooled degrees freedom based Barnard-Rubin adjustment small samples (Barnard Rubin, 1999).","code":""},{"path":"https://easystats.github.io/parameters/reference/pool_parameters.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Pool Model Parameters — pool_parameters","text":"Models multiple components, (instance, models zero-inflation, predictors appear count zero-inflation part, models dispersion component) may fail rare situations. case, compute pooled parameters components separately, using component argument. model objects return standard errors (e.g. objects class htest). models, pooled confidence intervals p-values returned.","code":""},{"path":"https://easystats.github.io/parameters/reference/pool_parameters.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Pool Model Parameters — pool_parameters","text":"Barnard, J. Rubin, D.B. (1999). Small sample degrees freedom multiple imputation. Biometrika, 86, 948-955. Rubin, D.B. (1987). Multiple Imputation Nonresponse Surveys. New York: John Wiley Sons.","code":""},{"path":"https://easystats.github.io/parameters/reference/pool_parameters.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Pool Model Parameters — pool_parameters","text":"","code":"# example for multiple imputed datasets data(\"nhanes2\", package = \"mice\") imp <- mice::mice(nhanes2, printFlag = FALSE) models <- lapply(1:5, function(i) {   lm(bmi ~ age + hyp + chl, data = mice::complete(imp, action = i)) }) pool_parameters(models) #> # Fixed Effects #>  #> Parameter   | Coefficient |   SE |          95% CI | Statistic |    df |      p #> ------------------------------------------------------------------------------- #> (Intercept) |       18.85 | 3.53 | [ 10.94, 26.77] |      5.34 |  9.64 | < .001 #> age [40-59] |       -5.62 | 2.00 | [-10.04, -1.21] |     -2.81 | 10.73 | 0.017  #> age [60-99] |       -7.05 | 2.50 | [-12.72, -1.37] |     -2.82 |  8.69 | 0.021  #> hyp [yes]   |        2.23 | 2.13 | [ -2.54,  6.99] |      1.05 |  9.72 | 0.321  #> chl         |        0.05 | 0.02 | [  0.01,  0.10] |      2.63 |  8.20 | 0.029  #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) #>   computed using a Wald distribution approximation.  # should be identical to: m <- with(data = imp, exp = lm(bmi ~ age + hyp + chl)) summary(mice::pool(m)) #>          term   estimate std.error statistic        df      p.value #> 1 (Intercept) 18.8529658 3.5332535  5.335866  9.637102 0.0003741459 #> 2    age40-59 -5.6214485 2.0001740 -2.810480 10.729821 0.0173287192 #> 3    age60-99 -7.0451215 2.4952100 -2.823458  8.693991 0.0206115436 #> 4      hypyes  2.2276804 2.1295899  1.046061  9.722954 0.3208412270 #> 5         chl  0.0531414 0.0201819  2.633122  8.195111 0.0294228344  # For glm, mice used residual df, while `pool_parameters()` uses `Inf` nhanes2$hyp <- datawizard::slide(as.numeric(nhanes2$hyp)) imp <- mice::mice(nhanes2, printFlag = FALSE) models <- lapply(1:5, function(i) {   glm(hyp ~ age + chl, family = binomial, data = mice::complete(imp, action = i)) }) m <- with(data = imp, exp = glm(hyp ~ age + chl, family = binomial)) # residual df summary(mice::pool(m))$df #> [1] 19.248074 19.248074 19.248074  5.431369 # df = Inf pool_parameters(models)$df_error #> [1] Inf Inf Inf Inf # use residual df instead pool_parameters(models, ci_method = \"residual\")$df_error #> [1] 19.248074 19.248074 19.248074  5.431369"},{"path":"https://easystats.github.io/parameters/reference/predict.parameters_clusters.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict method for parameters_clusters objects — predict.parameters_clusters","title":"Predict method for parameters_clusters objects — predict.parameters_clusters","text":"Predict method parameters_clusters objects","code":""},{"path":"https://easystats.github.io/parameters/reference/predict.parameters_clusters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict method for parameters_clusters objects — predict.parameters_clusters","text":"","code":"# S3 method for class 'parameters_clusters' predict(object, newdata = NULL, names = NULL, ...)"},{"path":"https://easystats.github.io/parameters/reference/predict.parameters_clusters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict method for parameters_clusters objects — predict.parameters_clusters","text":"object model object prediction desired. newdata data.frame names character vector list ... additional arguments affecting predictions produced.","code":""},{"path":"https://easystats.github.io/parameters/reference/principal_components.html","id":null,"dir":"Reference","previous_headings":"","what":"Principal Component Analysis (PCA) and Factor Analysis (FA) — factor_analysis","title":"Principal Component Analysis (PCA) and Factor Analysis (FA) — factor_analysis","text":"functions principal_components() factor_analysis() can used perform principal component analysis (PCA) factor analysis (FA). return loadings data frame, various methods functions available access / display information (see Details section).","code":""},{"path":"https://easystats.github.io/parameters/reference/principal_components.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Principal Component Analysis (PCA) and Factor Analysis (FA) — factor_analysis","text":"","code":"factor_analysis(   x,   n = \"auto\",   rotation = \"none\",   sort = FALSE,   threshold = NULL,   standardize = TRUE,   cor = NULL,   ... )  principal_components(   x,   n = \"auto\",   rotation = \"none\",   sparse = FALSE,   sort = FALSE,   threshold = NULL,   standardize = TRUE,   ... )  rotated_data(pca_results, verbose = TRUE)  # S3 method for class 'parameters_efa' predict(   object,   newdata = NULL,   names = NULL,   keep_na = TRUE,   verbose = TRUE,   ... )  # S3 method for class 'parameters_efa' print(x, digits = 2, sort = FALSE, threshold = NULL, labels = NULL, ...)  # S3 method for class 'parameters_efa' sort(x, ...)  closest_component(pca_results)"},{"path":"https://easystats.github.io/parameters/reference/principal_components.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Principal Component Analysis (PCA) and Factor Analysis (FA) — factor_analysis","text":"x data frame statistical model. n Number components extract. n=\"\", n set number variables minus 1 (ncol(x)-1). n=\"auto\" (default) n=NULL, number components selected n_factors() resp. n_components(). Else, n number, n components extracted. n exceeds number variables data, automatically set maximum number (.e. ncol(x)). reduce_parameters(), can also \"max\", case select components maximally pseudo-loaded (.e., correlated) least one variable. rotation \"none\", PCA / FA computed using psych package. Possible options include \"varimax\", \"quartimax\", \"promax\", \"oblimin\", \"simplimax\", \"cluster\" (). See psych::fa() details. sort Sort loadings. threshold value 0 1 indicates (absolute) values loadings removed. integer higher 1 indicates n strongest loadings retain. Can also \"max\", case display maximum loading per variable (simple structure). standardize logical value indicating whether variables standardized (centered scaled) unit variance analysis (general, scaling advisable). cor optional correlation matrix can used (note data must still passed first argument). NULL, compute running cor() passed data. ... Arguments passed methods. sparse Whether compute sparse PCA (SPCA, using sparsepca::spca()). SPCA attempts find sparse loadings (nonzero values), improves interpretability avoids overfitting. Can TRUE \"robust\" (see sparsepca::robspca()). pca_results output principal_components() function. verbose Toggle warnings. object object class parameters_pca parameters_efa newdata optional data frame look variables predict. omitted, fitted values used. names Optional character vector name columns returned data frame. keep_na Logical, TRUE, predictions also return observations missing values original data, hence number rows predicted data original data equal. digits Argument print(), indicates number digits (rounding) used. labels Argument print(), character vector length columns x. provided, adds additional column labels.","code":""},{"path":"https://easystats.github.io/parameters/reference/principal_components.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Principal Component Analysis (PCA) and Factor Analysis (FA) — factor_analysis","text":"data frame loadings.","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/principal_components.html","id":"methods-and-utilities","dir":"Reference","previous_headings":"","what":"Methods and Utilities","title":"Principal Component Analysis (PCA) and Factor Analysis (FA) — factor_analysis","text":"n_components() n_factors() automatically estimates optimal number dimensions retain. performance::check_factorstructure() checks suitability data factor analysis using sphericity (see performance::check_sphericity_bartlett()) KMO (see performance::check_kmo()) measure. performance::check_itemscale() computes various measures internal consistencies applied (sub)scales (.e., components) extracted PCA. Running summary() returns information related component/factor, explained variance Eivenvalues. Running get_scores() computes scores subscale. Running closest_component() return numeric vector assigned component index column original data frame. Running rotated_data() return rotated data, including missing values, matches original data frame. Running plot() visually displays loadings (requires see-package work).","code":""},{"path":"https://easystats.github.io/parameters/reference/principal_components.html","id":"complexity","dir":"Reference","previous_headings":"","what":"Complexity","title":"Principal Component Analysis (PCA) and Factor Analysis (FA) — factor_analysis","text":"Complexity represents number latent components needed account observed variables. Whereas perfect simple structure solution complexity 1 item load one factor, solution evenly distributed items complexity greater 1 (Hofman, 1978; Pettersson Turkheimer, 2010).","code":""},{"path":"https://easystats.github.io/parameters/reference/principal_components.html","id":"uniqueness","dir":"Reference","previous_headings":"","what":"Uniqueness","title":"Principal Component Analysis (PCA) and Factor Analysis (FA) — factor_analysis","text":"Uniqueness represents variance 'unique' variable shared variables. equal 1 – communality (variance shared variables). uniqueness 0.20 suggests 20% variable's variance shared variables overall factor model. greater 'uniqueness' lower relevance variable factor model.","code":""},{"path":"https://easystats.github.io/parameters/reference/principal_components.html","id":"msa","dir":"Reference","previous_headings":"","what":"MSA","title":"Principal Component Analysis (PCA) and Factor Analysis (FA) — factor_analysis","text":"MSA represents Kaiser-Meyer-Olkin Measure Sampling Adequacy (Kaiser Rice, 1974) item. indicates whether enough data factor give reliable results PCA. value > 0.6, desirable values > 0.8 (Tabachnick Fidell, 2013).","code":""},{"path":"https://easystats.github.io/parameters/reference/principal_components.html","id":"pca-or-fa-","dir":"Reference","previous_headings":"","what":"PCA or FA?","title":"Principal Component Analysis (PCA) and Factor Analysis (FA) — factor_analysis","text":"simplified rule thumb may help decide whether run factor analysis principal component analysis: Run factor analysis assume wish test theoretical model latent factors causing observed variables. Run principal component analysis want simply reduce correlated observed variables smaller set important independent composite variables. (Source: CrossValidated)","code":""},{"path":"https://easystats.github.io/parameters/reference/principal_components.html","id":"computing-item-scores","dir":"Reference","previous_headings":"","what":"Computing Item Scores","title":"Principal Component Analysis (PCA) and Factor Analysis (FA) — factor_analysis","text":"Use get_scores() compute scores \"subscales\" represented extracted principal components. get_scores() takes results principal_components() extracts variables component found PCA. , \"subscales\", raw means calculated (equals adding single items dividing number items). results sum score component PCA, scale original, single items used compute PCA. One can also use predict() back-predict scores component, one can provide newdata vector names components.","code":""},{"path":"https://easystats.github.io/parameters/reference/principal_components.html","id":"explained-variance-and-eingenvalues","dir":"Reference","previous_headings":"","what":"Explained Variance and Eingenvalues","title":"Principal Component Analysis (PCA) and Factor Analysis (FA) — factor_analysis","text":"Use summary() get Eigenvalues explained variance extracted component. eigenvectors eigenvalues represent \"core\" PCA: eigenvectors (principal components) determine directions new feature space, eigenvalues determine magnitude. words, eigenvalues explain variance data along new feature axes.","code":""},{"path":"https://easystats.github.io/parameters/reference/principal_components.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Principal Component Analysis (PCA) and Factor Analysis (FA) — factor_analysis","text":"Kaiser, H.F. Rice. J. (1974). Little jiffy, mark iv. Educational Psychological Measurement, 34(1):111–117 Hofmann, R. (1978). Complexity simplicity objective indices descriptive factor solutions. Multivariate Behavioral Research, 13:2, 247-250, doi:10.1207/s15327906mbr1302_9 Pettersson, E., & Turkheimer, E. (2010). Item selection, evaluation, simple structure personality data. Journal research personality, 44(4), 407-420, doi:10.1016/j.jrp.2010.03.002 Tabachnick, B. G., Fidell, L. S. (2013). Using multivariate statistics (6th ed.). Boston: Pearson Education.","code":""},{"path":"https://easystats.github.io/parameters/reference/principal_components.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Principal Component Analysis (PCA) and Factor Analysis (FA) — factor_analysis","text":"","code":"library(parameters)  # \\donttest{ # Principal Component Analysis (PCA) ------------------- principal_components(mtcars[, 1:7], n = \"all\", threshold = 0.2) #> # Loadings from Principal Component Analysis (no rotation) #>  #> Variable |   PC1 |   PC2 |  PC3 |   PC4 |  PC5 |   PC6 | Complexity #> ------------------------------------------------------------------- #> mpg      | -0.93 |       |      | -0.30 |      |       |       1.30 #> cyl      |  0.96 |       |      |       |      | -0.21 |       1.18 #> disp     |  0.95 |       |      | -0.23 |      |       |       1.16 #> hp       |  0.87 |  0.36 |      |       | 0.30 |       |       1.64 #> drat     | -0.75 |  0.48 | 0.44 |       |      |       |       2.47 #> wt       |  0.88 | -0.35 | 0.26 |       |      |       |       1.54 #> qsec     | -0.54 | -0.81 |      |       |      |       |       1.96 #>  #> The 6 principal components accounted for 99.30% of the total variance of the original data (PC1 = 72.66%, PC2 = 16.52%, PC3 = 4.93%, PC4 = 2.26%, PC5 = 1.85%, PC6 = 1.08%). #>   # Automated number of components principal_components(mtcars[, 1:4], n = \"auto\") #> # Loadings from Principal Component Analysis (no rotation) #>  #> Variable |   PC1 | Complexity #> ----------------------------- #> mpg      | -0.93 |       1.00 #> cyl      |  0.96 |       1.00 #> disp     |  0.95 |       1.00 #> hp       |  0.91 |       1.00 #>  #> The unique principal component accounted for 87.55% of the total variance of the original data. #>   # labels can be useful if variable names are not self-explanatory print(   principal_components(mtcars[, 1:4], n = \"auto\"),   labels = c(     \"Miles/(US) gallon\",     \"Number of cylinders\",     \"Displacement (cu.in.)\",     \"Gross horsepower\"   ) ) #> # Loadings from Principal Component Analysis (no rotation) #>  #> Variable | Label                 |   PC1 | Complexity #> ----------------------------------------------------- #> mpg      | Miles/(US) gallon     | -0.93 |       1.00 #> cyl      | Number of cylinders   |  0.96 |       1.00 #> disp     | Displacement (cu.in.) |  0.95 |       1.00 #> hp       | Gross horsepower      |  0.91 |       1.00  # Sparse PCA principal_components(mtcars[, 1:7], n = 4, sparse = TRUE) #> # Loadings from Principal Component Analysis (no rotation) #>  #> Variable |   PC1 |   PC2 |   PC3 |   PC4 | Complexity #> ----------------------------------------------------- #> mpg      | -0.92 |  0.03 | -0.11 | -0.31 |       1.27 #> cyl      |  1.00 |  0.07 | -0.07 | -0.05 |       1.03 #> disp     |  0.96 | -0.06 |  0.08 | -0.23 |       1.14 #> hp       |  0.74 |  0.32 |  0.07 |  0.00 |       1.38 #> drat     | -0.68 |  0.46 |  0.47 | -0.03 |       2.62 #> wt       |  1.03 | -0.32 |  0.24 | -0.03 |       1.31 #> qsec     | -0.49 | -0.85 |  0.17 |  0.00 |       1.69 #>  #> The 4 principal components accounted for 96.42% of the total variance of the original data (PC1 = 72.75%, PC2 = 16.53%, PC3 = 4.91%, PC4 = 2.24%). #>  principal_components(mtcars[, 1:7], n = 4, sparse = \"robust\") #> # Loadings from Principal Component Analysis (no rotation) #>  #> Variable |   PC1 |   PC2 |   PC3 |   PC4 | Complexity #> ----------------------------------------------------- #> mpg      | -0.92 |  0.03 | -0.11 | -0.31 |       1.27 #> cyl      |  1.00 |  0.07 | -0.07 | -0.05 |       1.03 #> disp     |  0.96 | -0.06 |  0.08 | -0.23 |       1.14 #> hp       |  0.74 |  0.32 |  0.07 |  0.00 |       1.38 #> drat     | -0.68 |  0.46 |  0.47 | -0.03 |       2.62 #> wt       |  1.03 | -0.32 |  0.24 | -0.03 |       1.31 #> qsec     | -0.49 | -0.85 |  0.17 |  0.00 |       1.69 #>  #> The 4 principal components accounted for 96.42% of the total variance of the original data (PC1 = 72.75%, PC2 = 16.53%, PC3 = 4.91%, PC4 = 2.24%). #>   # Rotated PCA principal_components(mtcars[, 1:7],   n = 2, rotation = \"oblimin\",   threshold = \"max\", sort = TRUE ) #> # Rotated loadings from Principal Component Analysis (oblimin-rotation) #>  #> Variable |   TC1 |   TC2 | Complexity | Uniqueness |  MSA #> --------------------------------------------------------- #> wt       |  0.98 |       |       1.03 |       0.10 | 0.77 #> drat     | -0.95 |       |       1.19 |       0.21 | 0.85 #> disp     |  0.89 |       |       1.07 |       0.08 | 0.85 #> mpg      | -0.87 |       |       1.07 |       0.13 | 0.87 #> cyl      |  0.78 |       |       1.38 |       0.08 | 0.87 #> qsec     |       | -0.98 |       1.00 |       0.06 | 0.61 #> hp       |       |  0.61 |       1.97 |       0.10 | 0.90 #>  #> The 2 principal components (oblimin rotation) accounted for 89.18% of the total variance of the original data (TC1 = 63.90%, TC2 = 25.28%). #>  principal_components(mtcars[, 1:7], n = 2, threshold = 2, sort = TRUE) #> # Loadings from Principal Component Analysis (no rotation) #>  #> Variable |  PC1 |   PC2 | Complexity #> ------------------------------------ #> cyl      | 0.96 |       |       1.02 #> disp     | 0.95 |       |       1.02 #> mpg      |      |       |       1.02 #> wt       |      |       |       1.30 #> hp       |      |       |       1.33 #> drat     |      |  0.48 |       1.71 #> qsec     |      | -0.81 |       1.75 #>  #> The 2 principal components accounted for 89.18% of the total variance of the original data (PC1 = 72.66%, PC2 = 16.52%). #>   pca <- principal_components(mtcars[, 1:5], n = 2, rotation = \"varimax\") pca # Print loadings #> # Rotated loadings from Principal Component Analysis (varimax-rotation) #>  #> Variable |   RC1 |   RC2 | Complexity | Uniqueness |  MSA #> --------------------------------------------------------- #> mpg      | -0.77 |  0.53 |       1.77 |       0.14 | 0.92 #> cyl      |  0.81 | -0.52 |       1.70 |       0.08 | 0.84 #> disp     |  0.77 | -0.56 |       1.82 |       0.10 | 0.88 #> hp       |  0.95 | -0.16 |       1.05 |       0.06 | 0.81 #> drat     | -0.27 |  0.95 |       1.16 |       0.03 | 0.80 #>  #> The 2 principal components (varimax rotation) accounted for 92.00% of the total variance of the original data (RC1 = 56.46%, RC2 = 35.54%). #>  summary(pca) # Print information about the factors #> # (Explained) Variance of Components #>  #> Parameter                       |   RC1 |   RC2 #> ----------------------------------------------- #> Eigenvalues                     | 4.038 | 0.562 #> Variance Explained              | 0.565 | 0.355 #> Variance Explained (Cumulative) | 0.565 | 0.920 #> Variance Explained (Proportion) | 0.614 | 0.386 predict(pca, names = c(\"Component1\", \"Component2\")) # Back-predict scores #>     Component1  Component2 #> 1  -0.23906186  0.38058456 #> 2  -0.23906186  0.38058456 #> 3  -0.87523403  0.30496365 #> 4  -0.83256507 -1.21853890 #> 5   0.37716377 -0.82007976 #> 6  -1.10127278 -1.86114104 #> 7   1.23453249 -0.26702364 #> 8  -1.30024506 -0.23007562 #> 9  -0.74129623  0.41446358 #> 10 -0.02461777  0.47612740 #> 11  0.02534454  0.45386195 #> 12  0.29853804 -0.88051969 #> 13  0.26641941 -0.86620618 #> 14  0.34136287 -0.89960437 #> 15  0.93247714 -1.25088059 #> 16  1.06844670 -1.03682781 #> 17  1.22799380 -0.41588998 #> 18 -1.30762202  0.71198099 #> 19 -0.60701035  2.14073148 #> 20 -1.25685030  0.99325379 #> 21 -0.90720118  0.02588588 #> 22 -0.15711335 -1.72688554 #> 23  0.18137850 -1.00150788 #> 24  1.72116683  0.68171810 #> 25  0.36060813 -0.98161661 #> 26 -1.12513535  0.63056351 #> 27 -0.46730967  1.39310467 #> 28 -1.05428733  0.43877634 #> 29  2.24906373  1.75900256 #> 30  0.13210722  0.33766027 #> 31  2.24244855  1.06973229 #> 32 -0.42316749  0.86380202  # which variables from the original data belong to which extracted component? closest_component(pca) #>  mpg  cyl disp   hp drat  #>    1    1    1    1    2  # }  # Factor Analysis (FA) ------------------------  factor_analysis(mtcars[, 1:7], n = \"all\", threshold = 0.2) #> # Loadings from Factor Analysis (no rotation) #>  #> Variable |   MR1 |   MR2 |  MR3 |  MR4 | MR5 | MR6 | Complexity | Uniqueness #> ---------------------------------------------------------------------------- #> mpg      | -0.92 |       |      | 0.22 |     |     |       1.16 |       0.08 #> cyl      |  0.96 |       |      |      |     |     |       1.14 |       0.01 #> disp     |  0.95 |       |      | 0.20 |     |     |       1.13 |       0.03 #> hp       |  0.86 | -0.35 |      |      |     |     |       1.38 |       0.12 #> drat     | -0.72 | -0.40 | 0.29 |      |     |     |       1.96 |       0.24 #> wt       |  0.89 |  0.38 | 0.24 |      |     |     |       1.53 |   5.00e-03 #> qsec     | -0.53 |  0.76 |      |      |     |     |       1.81 |       0.14 #>  #> The 6 latent factors accounted for 90.99% of the total variance of the original data (MR1 = 71.60%, MR2 = 14.55%, MR3 = 2.91%, MR4 = 1.35%, MR5 = 0.45%, MR6 = 0.12%). #>  factor_analysis(mtcars[, 1:7], n = 2, rotation = \"oblimin\", threshold = \"max\", sort = TRUE) #> # Rotated loadings from Factor Analysis (oblimin-rotation) #>  #> Variable |   MR1 |  MR2 | Complexity | Uniqueness #> ------------------------------------------------- #> wt       |  1.00 |      |       1.07 |       0.10 #> disp     |  0.92 |      |       1.02 |       0.09 #> mpg      | -0.88 |      |       1.02 |       0.15 #> drat     | -0.84 |      |       1.14 |       0.39 #> cyl      |  0.82 |      |       1.23 |       0.08 #> hp       |  0.60 |      |       1.94 |       0.18 #> qsec     |       | 1.00 |       1.00 |   4.75e-03 #>  #> The 2 latent factors (oblimin rotation) accounted for 85.83% of the total variance of the original data (MR1 = 63.85%, MR2 = 21.99%). #>  factor_analysis(mtcars[, 1:7], n = 2, threshold = 2, sort = TRUE) #> # Loadings from Factor Analysis (no rotation) #>  #> Variable |  MR1 |  MR2 | Complexity | Uniqueness #> ------------------------------------------------ #> cyl      | 0.96 |      |       1.01 |       0.08 #> disp     | 0.95 |      |       1.03 |       0.09 #> mpg      |      |      |       1.03 |       0.15 #> wt       |      | 0.36 |       1.33 |       0.10 #> hp       |      |      |       1.23 |       0.18 #> drat     |      |      |       1.49 |       0.39 #> qsec     |      | 0.83 |       1.74 |   4.75e-03 #>  #> The 2 latent factors accounted for 85.83% of the total variance of the original data (MR1 = 70.67%, MR2 = 15.16%). #>   efa <- factor_analysis(mtcars[, 1:5], n = 2) summary(efa) #> # (Explained) Variance of Components #>  #> Parameter                       |   MR1 |   MR2 #> ----------------------------------------------- #> Eigenvalues                     | 3.908 | 0.398 #> Variance Explained              | 0.782 | 0.080 #> Variance Explained (Cumulative) | 0.782 | 0.861 #> Variance Explained (Proportion) | 0.908 | 0.092 predict(efa, verbose = FALSE) #>            MR1         MR2 #> 1  -0.41953471 -0.35544083 #> 2  -0.41953471 -0.35544083 #> 3  -0.93451791  0.05188420 #> 4  -0.02247401 -1.06704187 #> 5   0.80423811 -0.57723722 #> 6   0.05132529 -1.40382795 #> 7   1.17796287  0.82565287 #> 8  -0.97981546 -0.77961043 #> 9  -0.87835186  0.02703875 #> 10 -0.31368972 -0.16476124 #> 11 -0.28032337 -0.23570818 #> 12  0.73053450 -0.34851886 #> 13  0.70908470 -0.30291012 #> 14  0.75913424 -0.40933052 #> 15  1.40523363 -0.78714835 #> 16  1.40381792 -0.48501471 #> 17  1.26324243  0.25588537 #> 18 -1.39062136  0.13411535 #> 19 -1.62307787  0.15402661 #> 20 -1.48149201  0.28280884 #> 21 -0.82463188 -0.03789222 #> 22  0.79425443 -1.37121293 #> 23  0.67357950 -1.14361360 #> 24  1.04878537  1.07073183 #> 25  0.89062471 -0.71650907 #> 26 -1.26846941 -0.12530276 #> 27 -1.14242028  0.42262235 #> 28 -1.03993655  0.89398689 #> 29  0.94311149  1.87551864 #> 30 -0.08324543  0.96674422 #> 31  1.32372015  3.27012728 #> 32 -0.87651282  0.43537850  # \\donttest{ # Automated number of components factor_analysis(mtcars[, 1:4], n = \"auto\") #> # Loadings from Factor Analysis (no rotation) #>  #> Variable |   MR1 | Complexity | Uniqueness #> ------------------------------------------ #> mpg      | -0.90 |       1.00 |       0.19 #> cyl      |  0.96 |       1.00 |       0.08 #> disp     |  0.93 |       1.00 |       0.13 #> hp       |  0.86 |       1.00 |       0.26 #>  #> The unique latent factor accounted for 83.55% of the total variance of the original data. #>  # }"},{"path":"https://easystats.github.io/parameters/reference/print.compare_parameters.html","id":null,"dir":"Reference","previous_headings":"","what":"Print comparisons of model parameters — format.compare_parameters","title":"Print comparisons of model parameters — format.compare_parameters","text":"print()-method objects compare_parameters().","code":""},{"path":"https://easystats.github.io/parameters/reference/print.compare_parameters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print comparisons of model parameters — format.compare_parameters","text":"","code":"# S3 method for class 'compare_parameters' format(   x,   split_components = TRUE,   select = NULL,   digits = 2,   ci_digits = digits,   p_digits = 3,   ci_width = NULL,   ci_brackets = NULL,   zap_small = FALSE,   format = NULL,   groups = NULL,   engine = NULL,   ... )  # S3 method for class 'compare_parameters' print(   x,   split_components = TRUE,   caption = NULL,   subtitle = NULL,   footer = NULL,   digits = 2,   ci_digits = digits,   p_digits = 3,   zap_small = FALSE,   groups = NULL,   column_width = NULL,   ci_brackets = c(\"[\", \"]\"),   select = NULL,   ... )  # S3 method for class 'compare_parameters' print_html(   x,   caption = NULL,   subtitle = NULL,   footer = NULL,   digits = 2,   ci_digits = digits,   p_digits = 3,   zap_small = FALSE,   groups = NULL,   select = NULL,   ci_brackets = c(\"(\", \")\"),   font_size = \"100%\",   line_padding = 4,   column_labels = NULL,   engine = \"gt\",   ... )  # S3 method for class 'compare_parameters' print_md(   x,   digits = 2,   ci_digits = digits,   p_digits = 3,   caption = NULL,   subtitle = NULL,   footer = NULL,   select = NULL,   split_components = TRUE,   ci_brackets = c(\"(\", \")\"),   zap_small = FALSE,   groups = NULL,   engine = \"tt\",   ... )"},{"path":"https://easystats.github.io/parameters/reference/print.compare_parameters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print comparisons of model parameters — format.compare_parameters","text":"x object returned compare_parameters(). split_components Logical, TRUE (default), models multiple components (zero-inflation, smooth terms, ...), component printed separate table. FALSE, model parameters printed single table Component column added output. select Determines columns layout columns printed. three options argument: Selecting columns name index select can character vector (numeric index) column names printed, columns extracted data frame returned model_parameters() related functions. two pre-defined options selecting columns: select = \"minimal\" prints coefficients, confidence intervals p-values, select = \"short\" prints coefficients, standard errors p-values. string expression layout pattern select string \"tokens\" enclosed braces. tokens replaced associated columns, selected columns collapsed one column. Following tokens replaced related coefficients statistics: {estimate}, {se}, {ci} ({ci_low} {ci_high}), {p} {stars}. token {ci} replaced {ci_low}, {ci_high}. Example: select = \"{estimate}{stars} ({ci})\" possible create multiple columns well. | separates values new cells/columns. Example: select = \"{estimate} ({ci})|{p}\". format = \"html\", <br> inserts line break inside cell. See 'Examples'. *. string indicating pre-defined layout select can one following string values, create one following pre-defined column layouts: \"ci\": Estimates confidence intervals, asterisks p-values. equivalent select = \"{estimate} ({ci})\". \"se\": Estimates standard errors, asterisks p-values. equivalent select = \"{estimate} ({se})\". \"ci_p\": Estimates, confidence intervals asterisks p-values. equivalent select = \"{estimate}{stars} ({ci})\". \"se_p\": Estimates, standard errors asterisks p-values. equivalent select = \"{estimate}{stars} ({se})\".. \"ci_p2\": Estimates, confidence intervals numeric p-values, two columns. equivalent select = \"{estimate} ({ci})|{p}\". \"se_p2\": Estimate, standard errors numeric p-values, two columns. equivalent select = \"{estimate} ({se})|{p}\". model_parameters(), glue-like syntax still experimental case complex models (like mixed models) may return expected results. digits, ci_digits, p_digits Number digits rounding significant figures. May also \"signif\" return significant figures \"scientific\" return scientific notation. Control number digits adding value suffix, e.g. digits = \"scientific4\" scientific notation 4 decimal places, digits = \"signif5\" 5 significant figures (see also signif()). ci_width Minimum width returned string confidence intervals. NULL width larger string's length, leading whitespaces added string. width=\"auto\", width set length longest string. ci_brackets Logical, TRUE (default), CI-values encompassed square brackets (else parentheses). zap_small Logical, TRUE, small values rounded digits decimal places. FALSE, values decimal places digits printed scientific notation. format String, indicating output format. Can \"markdown\" \"html\". groups Named list, can used group parameters printed output. List elements may either character vectors match name parameters belong one group, list elements can row numbers parameter rows belong one group. names list elements used group names, inserted \"header row\". possible use case might emphasize focal predictors control variables, see 'Examples'. Parameters re-ordered according order used groups, non-matching parameters added end. engine Character string, naming package engine used printing HTML markdown format. Currently supported \"gt\" (\"default\") use gt package print HTML default easystats engine create markdown tables. engine = \"tt\", tinytable package used printing HTML markdown. print() methods support \"tt\" engine yet. specific print() method engine argument, insight::export_table() used, uses gt HTML printing. ... Arguments passed format.parameters_model(), insight::format_table() insight::export_table() caption Table caption string. NULL, depending model, either default caption table caption printed. Use caption = \"\" suppress table caption. subtitle Table title (caption) subtitle, strings. NULL, title subtitle printed, unless stored attributes (table_title, alias table_caption, table_subtitle). x list data frames, caption may list table captions, one table. footer Can either FALSE empty string (.e. \"\") suppress footer, NULL print default footer, string. latter combine string value default footer. column_width Width table columns. Can either NULL, named numeric vector, \"fixed\". NULL, width table column adjusted minimum required width. named numeric vector, value names matched column names, match, specified width used. \"fixed\", table split multiple components, columns across table components adjusted width. font_size HTML tables, font size. line_padding HTML tables, distance (pixel) lines. column_labels Labels columns HTML tables. NULL, automatic column names generated. See 'Examples'.","code":""},{"path":"https://easystats.github.io/parameters/reference/print.compare_parameters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print comparisons of model parameters — format.compare_parameters","text":"Invisibly returns original input object.","code":""},{"path":"https://easystats.github.io/parameters/reference/print.compare_parameters.html","id":"global-options-to-customize-messages-and-tables-when-printing","dir":"Reference","previous_headings":"","what":"Global Options to Customize Messages and Tables when Printing","title":"Print comparisons of model parameters — format.compare_parameters","text":"verbose argument can used display silence messages warnings different functions parameters package. However, messages providing additional information can displayed suppressed using options(): parameters_info: options(parameters_info = TRUE) override include_info argument model_parameters() always show model summary non-mixed models. parameters_mixed_info: options(parameters_mixed_info = TRUE) override include_info argument model_parameters() mixed models, always show model summary. parameters_cimethod: options(parameters_cimethod = TRUE) show additional information approximation method used calculate confidence intervals p-values. Set FALSE hide message printing model_parameters() objects. parameters_exponentiate: options(parameters_exponentiate = TRUE) show additional information interpret coefficients models log-transformed response variables log-/logit-links exponentiate argument model_parameters() TRUE. Set option FALSE hide message printing model_parameters() objects. options can used modify default behaviour printed outputs: parameters_labels: options(parameters_labels = TRUE) use variable value labels pretty names, data labelled. labels available, default pretty names used. parameters_interaction: options(parameters_interaction = <character>) replace interaction mark (default, *) related character. parameters_select: options(parameters_select = <value>) set default select argument. See argument's documentation available options. easystats_table_width: options(easystats_table_width = <value>) set default width tables text-format, .e. outputs printed console. specified, tables adjusted current available width, e.g. console (source textual output, like markdown files). argument table_width can also used print() methods specify table width desired. easystats_html_engine: options(easystats_html_engine = \"gt\") set default HTML engine tables gt, .e. gt package used create HTML tables. set tt, tinytable package used. insight_use_symbols: options(insight_use_symbols = TRUE) try print unicode-chars symbols column names, wherever possible (e.g., ω instead Omega).","code":""},{"path":"https://easystats.github.io/parameters/reference/print.compare_parameters.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print comparisons of model parameters — format.compare_parameters","text":"","code":"# \\donttest{ data(iris) lm1 <- lm(Sepal.Length ~ Species, data = iris) lm2 <- lm(Sepal.Length ~ Species + Petal.Length, data = iris)  # custom style result <- compare_parameters(lm1, lm2, select = \"{estimate}{stars} ({se})\") print(result) #> Parameter            |            lm1 |             lm2 #> ------------------------------------------------------- #> (Intercept)          | 5.01*** (0.07) |  3.68*** (0.11) #> Species [versicolor] | 0.93*** (0.10) | -1.60*** (0.19) #> Species [virginica]  | 1.58*** (0.10) | -2.12*** (0.27) #> Petal Length         |                |  0.90*** (0.06) #> ------------------------------------------------------- #> Observations         |            150 |             150  # custom style, in HTML result <- compare_parameters(lm1, lm2, select = \"{estimate}<br>({se})|{p}\") print_html(result)     Parameter                lm1                       lm2            Estimate(SE)       p       Estimate(SE)       p     (Intercept) 5.01(0.07) <0.001 3.68(0.11) <0.001Species (versicolor) 0.93(0.10) <0.001 -1.60(0.19) <0.001Species (virginica) 1.58(0.10) <0.001 -2.12(0.27) <0.001Petal Length   0.90(0.06) <0.001    Observations 150  150      # }"},{"path":"https://easystats.github.io/parameters/reference/print.parameters_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Print model parameters — format.parameters_model","title":"Print model parameters — format.parameters_model","text":"print()-method objects model_parameters().","code":""},{"path":"https://easystats.github.io/parameters/reference/print.parameters_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print model parameters — format.parameters_model","text":"","code":"# S3 method for class 'parameters_model' format(   x,   pretty_names = TRUE,   split_components = TRUE,   select = NULL,   digits = 2,   ci_digits = digits,   p_digits = 3,   ci_width = NULL,   ci_brackets = NULL,   zap_small = FALSE,   format = NULL,   groups = NULL,   include_reference = FALSE,   ... )  # S3 method for class 'parameters_model' print(   x,   pretty_names = TRUE,   split_components = TRUE,   select = NULL,   caption = NULL,   footer = NULL,   digits = 2,   ci_digits = digits,   p_digits = 3,   footer_digits = 3,   show_sigma = FALSE,   show_formula = FALSE,   zap_small = FALSE,   groups = NULL,   column_width = NULL,   ci_brackets = c(\"[\", \"]\"),   include_reference = FALSE,   ... )  # S3 method for class 'parameters_model' summary(object, ...)  # S3 method for class 'parameters_model' print_html(   x,   pretty_names = TRUE,   split_components = TRUE,   select = NULL,   caption = NULL,   subtitle = NULL,   footer = NULL,   align = NULL,   digits = 2,   ci_digits = digits,   p_digits = 3,   footer_digits = 3,   ci_brackets = c(\"(\", \")\"),   show_sigma = FALSE,   show_formula = FALSE,   zap_small = FALSE,   groups = NULL,   font_size = \"100%\",   line_padding = 4,   column_labels = NULL,   include_reference = FALSE,   verbose = TRUE,   ... )  # S3 method for class 'parameters_model' print_md(   x,   pretty_names = TRUE,   split_components = TRUE,   select = NULL,   caption = NULL,   subtitle = NULL,   footer = NULL,   align = NULL,   digits = 2,   ci_digits = digits,   p_digits = 3,   footer_digits = 3,   ci_brackets = c(\"(\", \")\"),   show_sigma = FALSE,   show_formula = FALSE,   zap_small = FALSE,   groups = NULL,   include_reference = FALSE,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/parameters/reference/print.parameters_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print model parameters — format.parameters_model","text":"x, object object returned model_parameters(). pretty_names Can TRUE, return \"pretty\" (.e. human readable) parameter names. \"labels\", case value variable labels used parameters names. latter works \"labelled\" data, .e. data used fit model \"label\" \"labels\" attributes. See also section Global Options Customize Messages Printing. split_components Logical, TRUE (default), models multiple components (zero-inflation, smooth terms, ...), component printed separate table. FALSE, model parameters printed single table Component column added output. select Determines columns layout columns printed. three options argument: Selecting columns name index select can character vector (numeric index) column names printed, columns extracted data frame returned model_parameters() related functions. two pre-defined options selecting columns: select = \"minimal\" prints coefficients, confidence intervals p-values, select = \"short\" prints coefficients, standard errors p-values. string expression layout pattern select string \"tokens\" enclosed braces. tokens replaced associated columns, selected columns collapsed one column. Following tokens replaced related coefficients statistics: {estimate}, {se}, {ci} ({ci_low} {ci_high}), {p} {stars}. token {ci} replaced {ci_low}, {ci_high}. Example: select = \"{estimate}{stars} ({ci})\" possible create multiple columns well. | separates values new cells/columns. Example: select = \"{estimate} ({ci})|{p}\". format = \"html\", <br> inserts line break inside cell. See 'Examples'. *. string indicating pre-defined layout select can one following string values, create one following pre-defined column layouts: \"ci\": Estimates confidence intervals, asterisks p-values. equivalent select = \"{estimate} ({ci})\". \"se\": Estimates standard errors, asterisks p-values. equivalent select = \"{estimate} ({se})\". \"ci_p\": Estimates, confidence intervals asterisks p-values. equivalent select = \"{estimate}{stars} ({ci})\". \"se_p\": Estimates, standard errors asterisks p-values. equivalent select = \"{estimate}{stars} ({se})\".. \"ci_p2\": Estimates, confidence intervals numeric p-values, two columns. equivalent select = \"{estimate} ({ci})|{p}\". \"se_p2\": Estimate, standard errors numeric p-values, two columns. equivalent select = \"{estimate} ({se})|{p}\". model_parameters(), glue-like syntax still experimental case complex models (like mixed models) may return expected results. digits, ci_digits, p_digits Number digits rounding significant figures. May also \"signif\" return significant figures \"scientific\" return scientific notation. Control number digits adding value suffix, e.g. digits = \"scientific4\" scientific notation 4 decimal places, digits = \"signif5\" 5 significant figures (see also signif()). ci_width Minimum width returned string confidence intervals. NULL width larger string's length, leading whitespaces added string. width=\"auto\", width set length longest string. ci_brackets Logical, TRUE (default), CI-values encompassed square brackets (else parentheses). zap_small Logical, TRUE, small values rounded digits decimal places. FALSE, values decimal places digits printed scientific notation. format String, indicating output format. Can \"markdown\" \"html\". groups Named list, can used group parameters printed output. List elements may either character vectors match name parameters belong one group, list elements can row numbers parameter rows belong one group. names list elements used group names, inserted \"header row\". possible use case might emphasize focal predictors control variables, see 'Examples'. Parameters re-ordered according order used groups, non-matching parameters added end. include_reference Logical, TRUE, reference level factors added parameters table. relevant models categorical predictors. coefficient reference level always 0 (except exponentiate = TRUE, coefficient 1), just completeness. ... Arguments passed format.parameters_model(), insight::format_table() insight::export_table() caption Table caption string. NULL, depending model, either default caption table caption printed. Use caption = \"\" suppress table caption. footer Can either FALSE empty string (.e. \"\") suppress footer, NULL print default footer, string. latter combine string value default footer. footer_digits Number decimal places values footer summary. show_sigma Logical, TRUE, adds information residual standard deviation. show_formula Logical, TRUE, adds model formula output. column_width Width table columns. Can either NULL, named numeric vector, \"fixed\". NULL, width table column adjusted minimum required width. named numeric vector, value names matched column names, match, specified width used. \"fixed\", table split multiple components, columns across table components adjusted width. subtitle Table title (caption) subtitle, strings. NULL, title subtitle printed, unless stored attributes (table_title, alias table_caption, table_subtitle). x list data frames, caption may list table captions, one table. align applies HTML tables. May one \"left\", \"right\" \"center\". font_size HTML tables, font size. line_padding HTML tables, distance (pixel) lines. column_labels Labels columns HTML tables. NULL, automatic column names generated. See 'Examples'. verbose Toggle messages warnings.","code":""},{"path":"https://easystats.github.io/parameters/reference/print.parameters_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print model parameters — format.parameters_model","text":"Invisibly returns original input object.","code":""},{"path":"https://easystats.github.io/parameters/reference/print.parameters_model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Print model parameters — format.parameters_model","text":"summary() convenient shortcut print(object, select = \"minimal\", show_sigma = TRUE, show_formula = TRUE).","code":""},{"path":"https://easystats.github.io/parameters/reference/print.parameters_model.html","id":"global-options-to-customize-messages-and-tables-when-printing","dir":"Reference","previous_headings":"","what":"Global Options to Customize Messages and Tables when Printing","title":"Print model parameters — format.parameters_model","text":"verbose argument can used display silence messages warnings different functions parameters package. However, messages providing additional information can displayed suppressed using options(): parameters_info: options(parameters_info = TRUE) override include_info argument model_parameters() always show model summary non-mixed models. parameters_mixed_info: options(parameters_mixed_info = TRUE) override include_info argument model_parameters() mixed models, always show model summary. parameters_cimethod: options(parameters_cimethod = TRUE) show additional information approximation method used calculate confidence intervals p-values. Set FALSE hide message printing model_parameters() objects. parameters_exponentiate: options(parameters_exponentiate = TRUE) show additional information interpret coefficients models log-transformed response variables log-/logit-links exponentiate argument model_parameters() TRUE. Set option FALSE hide message printing model_parameters() objects. options can used modify default behaviour printed outputs: parameters_labels: options(parameters_labels = TRUE) use variable value labels pretty names, data labelled. labels available, default pretty names used. parameters_interaction: options(parameters_interaction = <character>) replace interaction mark (default, *) related character. parameters_select: options(parameters_select = <value>) set default select argument. See argument's documentation available options. easystats_table_width: options(easystats_table_width = <value>) set default width tables text-format, .e. outputs printed console. specified, tables adjusted current available width, e.g. console (source textual output, like markdown files). argument table_width can also used print() methods specify table width desired. easystats_html_engine: options(easystats_html_engine = \"gt\") set default HTML engine tables gt, .e. gt package used create HTML tables. set tt, tinytable package used. insight_use_symbols: options(insight_use_symbols = TRUE) try print unicode-chars symbols column names, wherever possible (e.g., ω instead Omega).","code":""},{"path":"https://easystats.github.io/parameters/reference/print.parameters_model.html","id":"interpretation-of-interaction-terms","dir":"Reference","previous_headings":"","what":"Interpretation of Interaction Terms","title":"Print model parameters — format.parameters_model","text":"Note interpretation interaction terms depends many characteristics model. number parameters, overall performance model, can differ * b, : b, / b, suggesting sometimes interaction terms give different parameterizations model, times gives completely different models (depending b factors covariates, included main effects , etc.). interpretation depends full context model, inferred parameters table alone - rather, recommend use packages calculate estimated marginal means marginal effects, modelbased, emmeans, ggeffects, marginaleffects. raise awareness issue, may use print(...,show_formula=TRUE) add model-specification output print() method model_parameters().","code":""},{"path":"https://easystats.github.io/parameters/reference/print.parameters_model.html","id":"labeling-the-degrees-of-freedom","dir":"Reference","previous_headings":"","what":"Labeling the Degrees of Freedom","title":"Print model parameters — format.parameters_model","text":"Throughout parameters package, decided label residual degrees freedom df_error. reason degrees freedom always refer residuals. certain models, refer estimate error - linear model , - instance - mixed effects model, strictly true. Hence, think df_error generic label degrees freedom.","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/print.parameters_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print model parameters — format.parameters_model","text":"","code":"# \\donttest{ library(parameters) model <- glmmTMB::glmmTMB(   count ~ spp + mined + (1 | site),   ziformula = ~mined,   family = poisson(),   data = Salamanders ) mp <- model_parameters(model)  print(mp, pretty_names = FALSE) #> # Fixed Effects (Count Model)  #>  #> Parameter   | Log-Mean |   SE |         95% CI |     z |      p #> --------------------------------------------------------------- #> (Intercept) |    -0.36 | 0.28 | [-0.90,  0.18] | -1.30 | 0.194  #> sppPR       |    -1.27 | 0.24 | [-1.74, -0.80] | -5.27 | < .001 #> sppDM       |     0.27 | 0.14 | [ 0.00,  0.54] |  1.95 | 0.051  #> sppEC-A     |    -0.57 | 0.21 | [-0.97, -0.16] | -2.75 | 0.006  #> sppEC-L     |     0.67 | 0.13 | [ 0.41,  0.92] |  5.20 | < .001 #> sppDES-L    |     0.63 | 0.13 | [ 0.38,  0.87] |  4.96 | < .001 #> sppDF       |     0.12 | 0.15 | [-0.17,  0.40] |  0.78 | 0.435  #> minedno     |     1.27 | 0.27 | [ 0.74,  1.80] |  4.72 | < .001 #>  #> # Fixed Effects (Zero-Inflation Component)  #>  #> Parameter   | Log-Odds |   SE |         95% CI |     z |      p #> --------------------------------------------------------------- #> (Intercept) |     0.79 | 0.27 | [ 0.26,  1.32] |  2.90 | 0.004  #> minedno     |    -1.84 | 0.31 | [-2.46, -1.23] | -5.87 | < .001 #>  #> # Random Effects Variances  #>  #> Parameter            | Coefficient |       95% CI #> ------------------------------------------------- #> SD (Intercept: site) |        0.33 | [0.18, 0.63] #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) #>   computed using a Wald z-distribution approximation.  print(mp, split_components = FALSE) #> # Fixed Effects #>  #> Parameter            | Coefficient |   SE |         95% CI |     z |      p #> --------------------------------------------------------------------------- #> (Intercept)          |       -0.36 | 0.28 | [-0.90,  0.18] | -1.30 | 0.194  #> spp [PR]             |       -1.27 | 0.24 | [-1.74, -0.80] | -5.27 | < .001 #> spp [DM]             |        0.27 | 0.14 | [ 0.00,  0.54] |  1.95 | 0.051  #> spp [EC-A]           |       -0.57 | 0.21 | [-0.97, -0.16] | -2.75 | 0.006  #> spp [EC-L]           |        0.67 | 0.13 | [ 0.41,  0.92] |  5.20 | < .001 #> spp [DES-L]          |        0.63 | 0.13 | [ 0.38,  0.87] |  4.96 | < .001 #> spp [DF]             |        0.12 | 0.15 | [-0.17,  0.40] |  0.78 | 0.435  #> mined [no]           |        1.27 | 0.27 | [ 0.74,  1.80] |  4.72 | < .001 #> (Intercept)          |        0.79 | 0.27 | [ 0.26,  1.32] |  2.90 | 0.004  #> minedno              |       -1.84 | 0.31 | [-2.46, -1.23] | -5.87 | < .001 #> SD (Intercept: site) |        0.33 |      | [ 0.18,  0.63] |       |        #>  #> Parameter            | Effects |     Component #> ---------------------------------------------- #> (Intercept)          |   fixed |   conditional #> spp [PR]             |   fixed |   conditional #> spp [DM]             |   fixed |   conditional #> spp [EC-A]           |   fixed |   conditional #> spp [EC-L]           |   fixed |   conditional #> spp [DES-L]          |   fixed |   conditional #> spp [DF]             |   fixed |   conditional #> mined [no]           |   fixed |   conditional #> (Intercept)          |   fixed | zero_inflated #> minedno              |   fixed | zero_inflated #> SD (Intercept: site) |  random |   conditional #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) #>   computed using a Wald z-distribution approximation.  print(mp, select = c(\"Parameter\", \"Coefficient\", \"SE\")) #> # Fixed Effects (Count Model)  #>  #> Parameter   | Log-Mean |   SE #> ----------------------------- #> (Intercept) |    -0.36 | 0.28 #> spp [PR]    |    -1.27 | 0.24 #> spp [DM]    |     0.27 | 0.14 #> spp [EC-A]  |    -0.57 | 0.21 #> spp [EC-L]  |     0.67 | 0.13 #> spp [DES-L] |     0.63 | 0.13 #> spp [DF]    |     0.12 | 0.15 #> mined [no]  |     1.27 | 0.27 #>  #> # Fixed Effects (Zero-Inflation Component)  #>  #> Parameter   | Log-Odds |   SE #> ----------------------------- #> (Intercept) |     0.79 | 0.27 #> mined [no]  |    -1.84 | 0.31 #>  #> # Random Effects Variances  #>  #> Parameter            | Coefficient #> ---------------------------------- #> SD (Intercept: site) |        0.33 #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) #>   computed using a Wald z-distribution approximation.  print(mp, select = \"minimal\") #> # Fixed Effects (Count Model)  #>  #> Parameter   | Log-Mean |         95% CI |      p #> ------------------------------------------------ #> (Intercept) |    -0.36 | [-0.90,  0.18] | 0.194  #> spp [PR]    |    -1.27 | [-1.74, -0.80] | < .001 #> spp [DM]    |     0.27 | [ 0.00,  0.54] | 0.051  #> spp [EC-A]  |    -0.57 | [-0.97, -0.16] | 0.006  #> spp [EC-L]  |     0.67 | [ 0.41,  0.92] | < .001 #> spp [DES-L] |     0.63 | [ 0.38,  0.87] | < .001 #> spp [DF]    |     0.12 | [-0.17,  0.40] | 0.435  #> mined [no]  |     1.27 | [ 0.74,  1.80] | < .001 #>  #> # Fixed Effects (Zero-Inflation Component)  #>  #> Parameter   | Log-Odds |         95% CI |      p #> ------------------------------------------------ #> (Intercept) |     0.79 | [ 0.26,  1.32] | 0.004  #> mined [no]  |    -1.84 | [-2.46, -1.23] | < .001 #>  #> # Random Effects Variances  #>  #> Parameter            | Coefficient |       95% CI #> ------------------------------------------------- #> SD (Intercept: site) |        0.33 | [0.18, 0.63] #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) #>   computed using a Wald z-distribution approximation.   # group parameters ------  data(iris) model <- lm(   Sepal.Width ~ Sepal.Length + Species + Petal.Length,   data = iris ) # don't select \"Intercept\" parameter mp <- model_parameters(model, parameters = \"^(?!\\\\(Intercept)\") groups <- list(   \"Focal Predictors\" = c(\"Speciesversicolor\", \"Speciesvirginica\"),   \"Controls\" = c(\"Sepal.Length\", \"Petal.Length\") ) print(mp, groups = groups) #> Parameter              | Coefficient |   SE |         95% CI | t(145) |      p #> ------------------------------------------------------------------------------ #> Focal Predictors       |             |      |                |        |        #>   Species [versicolor] |       -0.89 | 0.20 | [-1.29, -0.49] |  -4.43 | < .001 #>   Species [virginica]  |       -0.88 | 0.28 | [-1.43, -0.33] |  -3.15 | 0.002  #> Controls               |             |      |                |        |        #>   Sepal Length         |        0.38 | 0.07 | [ 0.24,  0.52] |   5.31 | < .001 #>   Petal Length         |       -0.04 | 0.08 | [-0.21,  0.13] |  -0.50 | 0.618  #> (Intercept)            |        1.60 | 0.28 | [ 1.06,  2.15] |   5.80 | < .001 #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) #>   computed using a Wald t-distribution approximation.  # or use row indices print(mp, groups = list(   \"Focal Predictors\" = c(1, 4),   \"Controls\" = c(2, 3) )) #> Parameter              | Coefficient |   SE |         95% CI | t(145) |      p #> ------------------------------------------------------------------------------ #> Focal Predictors       |             |      |                |        |        #>   (Intercept)          |        1.60 | 0.28 | [ 1.06,  2.15] |   5.80 | < .001 #>   Species [virginica]  |       -0.88 | 0.28 | [-1.43, -0.33] |  -3.15 | 0.002  #> Controls               |             |      |                |        |        #>   Sepal Length         |        0.38 | 0.07 | [ 0.24,  0.52] |   5.31 | < .001 #>   Species [versicolor] |       -0.89 | 0.20 | [-1.29, -0.49] |  -4.43 | < .001 #> Petal Length           |       -0.04 | 0.08 | [-0.21,  0.13] |  -0.50 | 0.618  #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) #>   computed using a Wald t-distribution approximation.  # only show coefficients, CI and p, # put non-matched parameters to the end  data(mtcars) mtcars$cyl <- as.factor(mtcars$cyl) mtcars$gear <- as.factor(mtcars$gear) model <- lm(mpg ~ hp + gear * vs + cyl + drat, data = mtcars)  # don't select \"Intercept\" parameter mp <- model_parameters(model, parameters = \"^(?!\\\\(Intercept)\") print(mp, groups = list(   \"Engine\" = c(\"cyl6\", \"cyl8\", \"vs\", \"hp\"),   \"Interactions\" = c(\"gear4:vs\", \"gear5:vs\") )) #> Parameter        | Coefficient |   SE |          95% CI | t(22) |     p #> ----------------------------------------------------------------------- #> Engine           |             |      |                 |       |       #>   cyl [6]        |       -2.47 | 2.21 | [ -7.05,  2.12] | -1.12 | 0.276 #>   cyl [8]        |        1.97 | 5.11 | [ -8.63, 12.58] |  0.39 | 0.703 #>   vs             |        3.18 | 3.79 | [ -4.68, 11.04] |  0.84 | 0.410 #>   hp             |       -0.06 | 0.02 | [ -0.11, -0.02] | -2.91 | 0.008 #> Interactions     |             |      |                 |       |       #>   gear [4] × vs  |       -2.90 | 4.67 | [-12.57,  6.78] | -0.62 | 0.541 #>   gear [5] × vs  |        2.59 | 4.54 | [ -6.82, 12.00] |  0.57 | 0.574 #> (Intercept)      |       16.63 | 7.77 | [  0.53, 32.74] |  2.14 | 0.044 #> gear [4]         |        3.10 | 4.34 | [ -5.90, 12.10] |  0.71 | 0.482 #> gear [5]         |        4.80 | 3.48 | [ -2.42, 12.01] |  1.38 | 0.182 #> drat             |        2.70 | 2.03 | [ -1.52,  6.91] |  1.33 | 0.198 #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) #>   computed using a Wald t-distribution approximation. # }   # custom column layouts ------  data(iris) lm1 <- lm(Sepal.Length ~ Species, data = iris) lm2 <- lm(Sepal.Length ~ Species + Petal.Length, data = iris)  # custom style result <- compare_parameters(lm1, lm2, select = \"{estimate}{stars} ({se})\") print(result) #> Parameter            |            lm1 |             lm2 #> ------------------------------------------------------- #> (Intercept)          | 5.01*** (0.07) |  3.68*** (0.11) #> Species [versicolor] | 0.93*** (0.10) | -1.60*** (0.19) #> Species [virginica]  | 1.58*** (0.10) | -2.12*** (0.27) #> Petal Length         |                |  0.90*** (0.06) #> ------------------------------------------------------- #> Observations         |            150 |             150  # \\donttest{ # custom style, in HTML result <- compare_parameters(lm1, lm2, select = \"{estimate}<br>({se})|{p}\") print_html(result)     Parameter                lm1                       lm2            Estimate(SE)       p       Estimate(SE)       p     (Intercept) 5.01(0.07) <0.001 3.68(0.11) <0.001Species (versicolor) 0.93(0.10) <0.001 -1.60(0.19) <0.001Species (virginica) 1.58(0.10) <0.001 -2.12(0.27) <0.001Petal Length   0.90(0.06) <0.001    Observations 150  150      # }"},{"path":"https://easystats.github.io/parameters/reference/qol_cancer.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample data set — qol_cancer","title":"Sample data set — qol_cancer","text":"sample data set longitudinal data, used vignette describing datawizard::demean() function. Health-related quality life cancer-patients measured three time points (pre-surgery, 6 12 months surgery).","code":""},{"path":"https://easystats.github.io/parameters/reference/qol_cancer.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Sample data set — qol_cancer","text":"data frame 564 rows 7 variables: ID Patient ID QoL Quality Life Score time Timepoint measurement age Age years phq4 Patients' Health Questionnaire, 4-item version hospital Hospital ID, patient treated education Patients' educational level","code":""},{"path":"https://easystats.github.io/parameters/reference/random_parameters.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary information from random effects — random_parameters","title":"Summary information from random effects — random_parameters","text":"function extracts different variance components mixed model returns result data frame.","code":""},{"path":"https://easystats.github.io/parameters/reference/random_parameters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary information from random effects — random_parameters","text":"","code":"random_parameters(model, component = \"conditional\")"},{"path":"https://easystats.github.io/parameters/reference/random_parameters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary information from random effects — random_parameters","text":"model mixed effects model (including stanreg models). component parameters, parameters conditional model, zero-inflation part model, dispersion model returned? Applies models zero-inflation /dispersion component. component may one \"conditional\", \"zi\", \"zero-inflated\", \"dispersion\" \"\" (default). May abbreviated.","code":""},{"path":"https://easystats.github.io/parameters/reference/random_parameters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary information from random effects — random_parameters","text":"data frame random effects statistics variance components, including number levels per random effect group, well complete observations model.","code":""},{"path":"https://easystats.github.io/parameters/reference/random_parameters.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summary information from random effects — random_parameters","text":"variance components obtained insight::get_variance() denoted following:","code":""},{"path":"https://easystats.github.io/parameters/reference/random_parameters.html","id":"within-group-or-residual-variance","dir":"Reference","previous_headings":"","what":"Within-group (or residual) variance","title":"Summary information from random effects — random_parameters","text":"residual variance, σ2ε, sum distribution-specific variance variance due additive dispersion. indicates within-group variance.","code":""},{"path":"https://easystats.github.io/parameters/reference/random_parameters.html","id":"between-group-random-intercept-variance","dir":"Reference","previous_headings":"","what":"Between-group random intercept variance","title":"Summary information from random effects — random_parameters","text":"random intercept variance, -group variance intercept (τ00), obtained VarCorr(). indicates much groups subjects differ .","code":""},{"path":"https://easystats.github.io/parameters/reference/random_parameters.html","id":"between-group-random-slope-variance","dir":"Reference","previous_headings":"","what":"Between-group random slope variance","title":"Summary information from random effects — random_parameters","text":"random slope variance, -group variance slopes (τ11) obtained VarCorr(). measure available mixed models random slopes. indicates much groups subjects differ according slopes.","code":""},{"path":"https://easystats.github.io/parameters/reference/random_parameters.html","id":"random-slope-intercept-correlation","dir":"Reference","previous_headings":"","what":"Random slope-intercept correlation","title":"Summary information from random effects — random_parameters","text":"random slope-intercept correlation (ρ01) obtained VarCorr(). measure available mixed models random intercepts slopes. Note: within-group -group variance, variance standard deviations (simply square root variance) shown.","code":""},{"path":"https://easystats.github.io/parameters/reference/random_parameters.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary information from random effects — random_parameters","text":"","code":"if (require(\"lme4\")) {   data(sleepstudy)   model <- lmer(Reaction ~ Days + (1 + Days | Subject), data = sleepstudy)   random_parameters(model) } #> # Random Effects #>  #> Within-Group Variance          654.94 (25.59) #> Between-Group Variance #>   Random Intercept (Subject)    612.1 (24.74) #>   Random Slope (Subject.Days)   35.07  (5.92) #> Correlations #>   Subject.Days                   0.07 #> N (groups per factor) #>   Subject                          18 #> Observations                      180"},{"path":"https://easystats.github.io/parameters/reference/reduce_parameters.html","id":null,"dir":"Reference","previous_headings":"","what":"Dimensionality reduction (DR) / Features Reduction — reduce_parameters","title":"Dimensionality reduction (DR) / Features Reduction — reduce_parameters","text":"function performs reduction parameter space (number variables). starts creating new set variables, based given method (default method \"PCA\", available via method argument, \"cMDS\", \"DRR\" \"ICA\"). , names new dimensions using original variables correlates . instance, variable named 'V1_0.97/V4_-0.88' means V1 V4 variables correlate maximally (respective coefficients .97 -.88) dimension. Although function can useful exploratory data analysis, best perform dimension reduction step separate dedicated stage, important process data analysis workflow. reduce_data() alias reduce_parameters.data.frame().","code":""},{"path":"https://easystats.github.io/parameters/reference/reduce_parameters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dimensionality reduction (DR) / Features Reduction — reduce_parameters","text":"","code":"reduce_parameters(x, method = \"PCA\", n = \"max\", distance = \"euclidean\", ...)  reduce_data(x, method = \"PCA\", n = \"max\", distance = \"euclidean\", ...)"},{"path":"https://easystats.github.io/parameters/reference/reduce_parameters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Dimensionality reduction (DR) / Features Reduction — reduce_parameters","text":"x data frame statistical model. method feature reduction method. Can one \"PCA\", \"cMDS\", \"DRR\", \"ICA\" (see 'Details' section). n Number components extract. n=\"\", n set number variables minus 1 (ncol(x)-1). n=\"auto\" (default) n=NULL, number components selected n_factors() resp. n_components(). Else, n number, n components extracted. n exceeds number variables data, automatically set maximum number (.e. ncol(x)). reduce_parameters(), can also \"max\", case select components maximally pseudo-loaded (.e., correlated) least one variable. distance distance measure used. applies method = \"cMDS\". must one \"euclidean\", \"maximum\", \"manhattan\", \"canberra\", \"binary\" \"minkowski\". unambiguous substring can given. ... Arguments passed methods.","code":""},{"path":"https://easystats.github.io/parameters/reference/reduce_parameters.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Dimensionality reduction (DR) / Features Reduction — reduce_parameters","text":"different methods available described :","code":""},{"path":"https://easystats.github.io/parameters/reference/reduce_parameters.html","id":"supervised-methods","dir":"Reference","previous_headings":"","what":"Supervised Methods","title":"Dimensionality reduction (DR) / Features Reduction — reduce_parameters","text":"PCA: See principal_components(). cMDS / PCoA: Classical Multidimensional Scaling (cMDS) takes set dissimilarities (.e., distance matrix) returns set points distances points approximately equal dissimilarities. DRR: Dimensionality Reduction via Regression (DRR) recent technique extending PCA (Laparra et al., 2015). Starting rotated PCA, predicts redundant information remaining components using non-linear regression. notable advantages performing DRR avoidance multicollinearity predictors overfitting mitigation. DRR tends perform well first principal component enough explain variation predictors. Requires DRR package installed. ICA: Performs Independent Component Analysis using FastICA algorithm. Contrary PCA, attempts find uncorrelated sources (least squares minimization), ICA attempts find independent sources, .e., source space maximizes \"non-gaussianity\" sources. Contrary PCA, ICA rank source, makes poor tool dimensionality reduction. Requires fastICA package installed. See also package vignette.","code":""},{"path":"https://easystats.github.io/parameters/reference/reduce_parameters.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Dimensionality reduction (DR) / Features Reduction — reduce_parameters","text":"Nguyen, L. H., Holmes, S. (2019). Ten quick tips effective dimensionality reduction. PLOS Computational Biology, 15(6). Laparra, V., Malo, J., Camps-Valls, G. (2015). Dimensionality reduction via regression hyperspectral imagery. IEEE Journal Selected Topics Signal Processing, 9(6), 1026-1036.","code":""},{"path":"https://easystats.github.io/parameters/reference/reduce_parameters.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Dimensionality reduction (DR) / Features Reduction — reduce_parameters","text":"","code":"data(iris) model <- lm(Sepal.Width ~ Species * Sepal.Length + Petal.Width, data = iris) model #>  #> Call: #> lm(formula = Sepal.Width ~ Species * Sepal.Length + Petal.Width,  #>     data = iris) #>  #> Coefficients: #>                    (Intercept)               Speciesversicolor   #>                        -0.4731                          1.2981   #>               Speciesvirginica                    Sepal.Length   #>                         1.2252                          0.7515   #>                    Petal.Width  Speciesversicolor:Sepal.Length   #>                         0.5662                         -0.5503   #>  Speciesvirginica:Sepal.Length   #>                        -0.5883   #>  reduce_parameters(model) #>  #> Call: #> lm(formula = Sepal.Width ~ `Petal.Width_0.98/Species.setosa_-0.90/Sepal.Length_0.89/Species.virginica_0.78` +  #>     `Species.versicolor_-0.99`, data = cbind(model_data, y)) #>  #> Coefficients: #>                                                                      (Intercept)   #>                                                                          3.05733   #> `Petal.Width_0.98/Species.setosa_-0.90/Sepal.Length_0.89/Species.virginica_0.78`   #>                                                                         -0.08903   #>                                                       `Species.versicolor_-0.99`   #>                                                                          0.14879   #>   out <- reduce_data(iris, method = \"PCA\", n = \"max\") head(out) #>   Petal.Length_0.99/Petal.Width_0.97/Species.setosa_-0.94/Sepal.Length_0.86/Species.virginica_0.73 #> 1                                                                                        -2.803852 #> 2                                                                                        -2.633035 #> 3                                                                                        -2.866923 #> 4                                                                                        -2.808656 #> 5                                                                                        -2.907343 #> 6                                                                                        -2.668523 #>   Species.versicolor_0.93 Sepal.Width_0.62 #> 1             -0.65195900        0.1365792 #> 2             -0.09924539       -0.8296167 #> 3             -0.26560467       -0.5984029 #> 4             -0.14622405       -0.8154592 #> 5             -0.73579102        0.2543209 #> 6             -1.14741717        1.0076406"},{"path":"https://easystats.github.io/parameters/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. bayestestR ci, equivalence_test, p_direction, p_significance datawizard demean, describe_distribution, kurtosis, rescale_weights, skewness, visualisation_recipe insight display, n_parameters, print_html, print_md, standardize_names, supported_models","code":""},{"path":"https://easystats.github.io/parameters/reference/reshape_loadings.html","id":null,"dir":"Reference","previous_headings":"","what":"Reshape loadings between wide/long formats — reshape_loadings","title":"Reshape loadings between wide/long formats — reshape_loadings","text":"Reshape loadings wide/long formats.","code":""},{"path":"https://easystats.github.io/parameters/reference/reshape_loadings.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reshape loadings between wide/long formats — reshape_loadings","text":"","code":"reshape_loadings(x, ...)  # S3 method for class 'parameters_efa' reshape_loadings(x, threshold = NULL, ...)  # S3 method for class 'data.frame' reshape_loadings(x, threshold = NULL, loadings_columns = NULL, ...)"},{"path":"https://easystats.github.io/parameters/reference/reshape_loadings.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reshape loadings between wide/long formats — reshape_loadings","text":"x data frame statistical model. ... Arguments passed methods. threshold value 0 1 indicates (absolute) values loadings removed. integer higher 1 indicates n strongest loadings retain. Can also \"max\", case display maximum loading per variable (simple structure). loadings_columns Vector indicating columns corresponding loadings.","code":""},{"path":"https://easystats.github.io/parameters/reference/reshape_loadings.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reshape loadings between wide/long formats — reshape_loadings","text":"","code":"if (require(\"psych\")) {   pca <- model_parameters(psych::fa(attitude, nfactors = 3))   loadings <- reshape_loadings(pca)    loadings   reshape_loadings(loadings) } #> Variable   |   MR1 |   MR2 |   MR3 | Complexity | Uniqueness #> ------------------------------------------------------------ #> rating     |  0.90 | -0.07 | -0.05 |       1.02 |       0.23 #> complaints |  0.97 | -0.06 |  0.04 |       1.01 |       0.10 #> privileges |  0.44 |  0.25 | -0.05 |       1.64 |       0.65 #> learning   |  0.47 |  0.54 | -0.28 |       2.51 |       0.24 #> raises     |  0.55 |  0.43 |  0.25 |       2.35 |       0.23 #> critical   |  0.16 |  0.17 |  0.48 |       1.46 |       0.67 #> advance    | -0.11 |  0.91 |  0.07 |       1.04 |       0.22"},{"path":"https://easystats.github.io/parameters/reference/select_parameters.html","id":null,"dir":"Reference","previous_headings":"","what":"Automated selection of model parameters — select_parameters","title":"Automated selection of model parameters — select_parameters","text":"function performs automated selection 'best' parameters, updating returning \"best\" model.","code":""},{"path":"https://easystats.github.io/parameters/reference/select_parameters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Automated selection of model parameters — select_parameters","text":"","code":"select_parameters(model, ...)  # S3 method for class 'lm' select_parameters(model, direction = \"both\", steps = 1000, k = 2, ...)  # S3 method for class 'merMod' select_parameters(model, direction = \"backward\", steps = 1000, ...)"},{"path":"https://easystats.github.io/parameters/reference/select_parameters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Automated selection of model parameters — select_parameters","text":"model statistical model (class lm, glm, merMod). ... Arguments passed methods. direction mode stepwise search, can one \"\",     \"backward\", \"forward\", default \"\".     scope argument missing default     direction \"backward\".  Values can abbreviated. steps maximum number steps considered.  default 1000     (essentially many required).  typically used stop     process early. k multiple number degrees freedom used penalty. k = 2 gives genuine AIC: k = log(n) sometimes referred BIC SBC.","code":""},{"path":"https://easystats.github.io/parameters/reference/select_parameters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Automated selection of model parameters — select_parameters","text":"model refitted optimal number parameters.","code":""},{"path":"https://easystats.github.io/parameters/reference/select_parameters.html","id":"classical-lm-and-glm","dir":"Reference","previous_headings":"","what":"Classical lm and glm","title":"Automated selection of model parameters — select_parameters","text":"frequentist GLMs, select_parameters() performs AIC-based stepwise selection.","code":""},{"path":"https://easystats.github.io/parameters/reference/select_parameters.html","id":"mixed-models","dir":"Reference","previous_headings":"","what":"Mixed models","title":"Automated selection of model parameters — select_parameters","text":"mixed-effects models class merMod, stepwise selection based cAIC4::stepcAIC(). step function searches \"best\" model based random-effects structure, .e. select_parameters() adds excludes random-effects cAIC improved .","code":""},{"path":"https://easystats.github.io/parameters/reference/select_parameters.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Automated selection of model parameters — select_parameters","text":"","code":"model <- lm(mpg ~ ., data = mtcars) select_parameters(model) #>  #> Call: #> lm(formula = mpg ~ wt + qsec + am, data = mtcars) #>  #> Coefficients: #> (Intercept)           wt         qsec           am   #>       9.618       -3.917        1.226        2.936   #>   model <- lm(mpg ~ cyl * disp * hp * wt, data = mtcars) select_parameters(model) #>  #> Call: #> lm(formula = mpg ~ cyl + disp + hp + wt + cyl:disp + cyl:hp +  #>     disp:hp + cyl:wt + disp:wt + hp:wt + cyl:disp:hp + cyl:hp:wt,  #>     data = mtcars) #>  #> Coefficients: #> (Intercept)          cyl         disp           hp           wt     cyl:disp   #>  49.1436077   -3.6167276   -1.2955318   -0.0004854   58.8328841    0.1704703   #>      cyl:hp      disp:hp       cyl:wt      disp:wt        hp:wt  cyl:disp:hp   #>  -0.0134573    0.0132124   -7.4915051   -0.0167172   -0.6524341   -0.0016542   #>   cyl:hp:wt   #>   0.0850798   #>  # \\donttest{ # lme4 ------------------------------------------- model <- lme4::lmer(   Sepal.Width ~ Sepal.Length * Petal.Width * Petal.Length + (1 | Species),   data = iris ) select_parameters(model) #> Linear mixed model fit by REML ['lmerMod'] #> Formula: Sepal.Width ~ Sepal.Length * Petal.Width * Petal.Length + (1 |   #>     Species) #>    Data: iris #> REML criterion at convergence: 50.9896 #> Random effects: #>  Groups   Name        Std.Dev. #>  Species  (Intercept) 0.8259   #>  Residual             0.2536   #> Number of obs: 150, groups:  Species, 3 #> Fixed Effects: #>                           (Intercept)                           Sepal.Length   #>                             -2.000229                               0.936730   #>                           Petal.Width                           Petal.Length   #>                              1.575526                               0.265556   #>              Sepal.Length:Petal.Width              Sepal.Length:Petal.Length   #>                             -0.282960                              -0.088409   #>              Petal.Width:Petal.Length  Sepal.Length:Petal.Width:Petal.Length   #>                              0.001866                               0.023319   # }"},{"path":"https://easystats.github.io/parameters/reference/simulate_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulated draws from model coefficients — simulate_model","title":"Simulated draws from model coefficients — simulate_model","text":"Simulate draws statistical model return data frame estimates.","code":""},{"path":"https://easystats.github.io/parameters/reference/simulate_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulated draws from model coefficients — simulate_model","text":"","code":"simulate_model(model, iterations = 1000, ...)  # Default S3 method simulate_model(model, iterations = 1000, component = \"all\", ...)"},{"path":"https://easystats.github.io/parameters/reference/simulate_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulated draws from model coefficients — simulate_model","text":"model Statistical model (Bayesian models). iterations number draws simulate/bootstrap. ... Arguments passed insight::get_varcov(), e.g. allow simulated draws based heteroscedasticity consistent variance covariance matrices. component parameters, parameters conditional model, zero-inflation part model, dispersion model returned? Applies models zero-inflation /dispersion component. component may one \"conditional\", \"zi\", \"zero-inflated\", \"dispersion\" \"\" (default). May abbreviated.","code":""},{"path":"https://easystats.github.io/parameters/reference/simulate_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulated draws from model coefficients — simulate_model","text":"data frame.","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/simulate_model.html","id":"technical-details","dir":"Reference","previous_headings":"","what":"Technical Details","title":"Simulated draws from model coefficients — simulate_model","text":"simulate_model() computationally faster alternative bootstrap_model(). Simulated draws coefficients based multivariate normal distribution (MASS::mvrnorm()) mean mu = coef(model) variance Sigma = vcov(model).","code":""},{"path":"https://easystats.github.io/parameters/reference/simulate_model.html","id":"models-with-zero-inflation-component","dir":"Reference","previous_headings":"","what":"Models with Zero-Inflation Component","title":"Simulated draws from model coefficients — simulate_model","text":"models packages glmmTMB, pscl, GLMMadaptive countreg, component argument can used specify parameters simulated. models, parameters conditional component (fixed effects) simulated. may include smooth terms, random effects.","code":""},{"path":"https://easystats.github.io/parameters/reference/simulate_model.html","id":"model-components","dir":"Reference","previous_headings":"","what":"Model components","title":"Simulated draws from model coefficients — simulate_model","text":"Possible values component argument depend model class. Following valid options: \"\": returns model components, applies models, effect models just conditional model component. \"conditional\": returns conditional component, .e. \"fixed effects\" terms model. effect models just conditional model component. \"smooth_terms\": returns smooth terms, applies GAMs (similar models may contain smooth terms). \"zero_inflated\" (\"zi\"): returns zero-inflation component. \"dispersion\": returns dispersion model component. common models zero-inflation can model dispersion parameter. \"instruments\": instrumental-variable fixed effects regression, returns instruments. \"nonlinear\": non-linear models (like models class nlmerMod nls), returns staring estimates nonlinear parameters. \"correlation\": models correlation-component, like gls, variables used describe correlation structure returned. Special models model classes also allow rather uncommon options. : mhurdle: \"infrequent_purchase\", \"ip\", \"auxiliary\" BGGM: \"correlation\" \"intercept\" BFBayesFactor, glmx: \"extra\" averaging:\"conditional\" \"full\" mjoint: \"survival\" mfx: \"precision\", \"marginal\" betareg, DirichletRegModel: \"precision\" mvord: \"thresholds\" \"correlation\" clm2: \"scale\" selection: \"selection\", \"outcome\", \"auxiliary\" lavaan: One \"regression\", \"correlation\", \"loading\", \"variance\", \"defined\", \"mean\". Can also \"\" include components. models class brmsfit (package brms), even options possible component argument, documented detail .","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/simulate_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulated draws from model coefficients — simulate_model","text":"","code":"model <- lm(Sepal.Length ~ Species * Petal.Width + Petal.Length, data = iris) head(simulate_model(model)) #>   (Intercept) Speciesversicolor Speciesvirginica Petal.Width Petal.Length #> 1    3.436303        -0.7644174        -1.921772  0.81511491    0.8968868 #> 2    3.352833        -1.3050538        -2.057244  0.58321747    1.0497614 #> 3    3.724642        -0.7274907        -1.377786  0.65939731    0.7937357 #> 4    3.368219        -1.2476274        -2.599220  0.33148979    1.0075941 #> 5    3.383443        -1.5451483        -2.851981 -0.08413517    1.0958122 #> 6    3.591734        -1.2903453        -2.781200  0.32582409    0.9524036 #>   Speciesversicolor:Petal.Width Speciesvirginica:Petal.Width #> 1                    -1.1498087                   -0.7648875 #> 2                    -1.0266680                   -0.8025617 #> 3                    -0.9864884                   -0.7338618 #> 4                    -0.6499459                   -0.2341848 #> 5                    -0.3796449                    0.1095252 #> 6                    -0.6257724                   -0.0805681 # \\donttest{ if (require(\"glmmTMB\", quietly = TRUE)) {   model <- glmmTMB(     count ~ spp + mined + (1 | site),     ziformula = ~mined,     family = poisson(),     data = Salamanders   )   head(simulate_model(model))   head(simulate_model(model, component = \"zero_inflated\")) } #>   (Intercept)   minedno #> 1   1.0070148 -2.037876 #> 2   0.6898270 -1.774201 #> 3   0.7126957 -1.687886 #> 4   0.8666444 -1.847277 #> 5   0.9512715 -1.788466 #> 6   0.6543926 -1.515102 # }"},{"path":"https://easystats.github.io/parameters/reference/simulate_parameters.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate Model Parameters — simulate_parameters","title":"Simulate Model Parameters — simulate_parameters","text":"Compute simulated draws parameters related indices Confidence Intervals (CI) p-values. Simulating parameter draws can seen (computationally faster) alternative bootstrapping.","code":""},{"path":"https://easystats.github.io/parameters/reference/simulate_parameters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate Model Parameters — simulate_parameters","text":"","code":"simulate_parameters(model, ...)  # Default S3 method simulate_parameters(   model,   iterations = 1000,   centrality = \"median\",   ci = 0.95,   ci_method = \"quantile\",   test = \"p-value\",   ... )"},{"path":"https://easystats.github.io/parameters/reference/simulate_parameters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate Model Parameters — simulate_parameters","text":"model Statistical model (Bayesian models). ... Arguments passed insight::get_varcov(), e.g. allow simulated draws based heteroscedasticity consistent variance covariance matrices. iterations number draws simulate/bootstrap. centrality point-estimates (centrality indices) compute. Character (vector) list one options: \"median\", \"mean\", \"MAP\" (see map_estimate()), \"trimmed\" (just mean(x, trim = threshold)), \"mode\" \"\". ci Value vector probability CI (0 1) estimated. Default 0.95 (95%). ci_method type index used Credible Interval. Can \"ETI\" (default, see eti()), \"HDI\" (see hdi()), \"BCI\" (see bci()), \"SPI\" (see spi()), \"SI\" (see si()). test indices effect existence compute. Character (vector) list one options: \"p_direction\" (\"pd\"), \"rope\", \"p_map\", \"equivalence_test\" (\"equitest\"), \"bayesfactor\" (\"bf\") \"\" compute tests. \"test\", corresponding bayestestR function called (e.g. rope() p_direction()) results included summary output.","code":""},{"path":"https://easystats.github.io/parameters/reference/simulate_parameters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate Model Parameters — simulate_parameters","text":"data frame simulated parameters.","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/simulate_parameters.html","id":"technical-details","dir":"Reference","previous_headings":"","what":"Technical Details","title":"Simulate Model Parameters — simulate_parameters","text":"simulate_parameters() computationally faster alternative bootstrap_parameters(). Simulated draws coefficients based multivariate normal distribution (MASS::mvrnorm()) mean mu = coef(model) variance Sigma = vcov(model).","code":""},{"path":"https://easystats.github.io/parameters/reference/simulate_parameters.html","id":"models-with-zero-inflation-component","dir":"Reference","previous_headings":"","what":"Models with Zero-Inflation Component","title":"Simulate Model Parameters — simulate_parameters","text":"models packages glmmTMB, pscl, GLMMadaptive countreg, component argument can used specify parameters simulated. models, parameters conditional component (fixed effects) simulated. may include smooth terms, random effects.","code":""},{"path":"https://easystats.github.io/parameters/reference/simulate_parameters.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Simulate Model Parameters — simulate_parameters","text":"also plot()-method implemented see-package.","code":""},{"path":"https://easystats.github.io/parameters/reference/simulate_parameters.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Simulate Model Parameters — simulate_parameters","text":"Gelman , Hill J. Data analysis using regression multilevel/hierarchical models. Cambridge; New York: Cambridge University Press 2007: 140-143","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/simulate_parameters.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate Model Parameters — simulate_parameters","text":"","code":"model <- lm(Sepal.Length ~ Species * Petal.Width + Petal.Length, data = iris) simulate_parameters(model) #> # Fixed Effects #>  #> Parameter                     | Coefficient |         95% CI |      p #> --------------------------------------------------------------------- #> (Intercept)                   |        3.53 | [ 3.21,  3.84] | < .001 #> Speciesversicolor             |       -1.15 | [-1.85, -0.46] | < .001 #> Speciesvirginica              |       -2.26 | [-3.13, -1.44] | < .001 #> Petal.Width                   |        0.40 | [-0.40,  1.34] | 0.358  #> Petal.Length                  |        0.94 | [ 0.79,  1.09] | < .001 #> Speciesversicolor:Petal.Width |       -0.75 | [-1.82,  0.25] | 0.142  #> Speciesvirginica:Petal.Width  |       -0.34 | [-1.36,  0.47] | 0.436  #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) #>   computed using a simulated multivariate normal distribution #>   approximation.  # \\donttest{ if (require(\"glmmTMB\", quietly = TRUE)) {   model <- glmmTMB(     count ~ spp + mined + (1 | site),     ziformula = ~mined,     family = poisson(),     data = Salamanders   )   simulate_parameters(model, centrality = \"mean\")   simulate_parameters(model, ci = c(.8, .95), component = \"zero_inflated\") } #> # Fixed Effects #>  #> Parameter   | Coefficient |         80% CI |         95% CI |      p #> -------------------------------------------------------------------- #> (Intercept) |        0.81 | [ 0.44,  1.16] | [ 0.25,  1.35] | 0.006  #> minedno     |       -1.85 | [-2.27, -1.43] | [-2.45, -1.23] | < .001 #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) #>   computed using a MCMC distribution approximation. # }"},{"path":"https://easystats.github.io/parameters/reference/sort_parameters.html","id":null,"dir":"Reference","previous_headings":"","what":"Sort parameters by coefficient values — sort_parameters","title":"Sort parameters by coefficient values — sort_parameters","text":"Sort parameters coefficient values","code":""},{"path":"https://easystats.github.io/parameters/reference/sort_parameters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sort parameters by coefficient values — sort_parameters","text":"","code":"sort_parameters(x, ...)  # Default S3 method sort_parameters(x, sort = \"none\", column = \"Coefficient\", ...)"},{"path":"https://easystats.github.io/parameters/reference/sort_parameters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sort parameters by coefficient values — sort_parameters","text":"x data frame parameters_model object. ... Arguments passed methods. sort \"none\" (default) sort, \"ascending\" sort increasing coefficient value, \"descending\" sort decreasing coefficient value. column column containing model parameter estimates. \"Coefficient\" (default) easystats packages, \"estimate\" broom package, etc.","code":""},{"path":"https://easystats.github.io/parameters/reference/sort_parameters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sort parameters by coefficient values — sort_parameters","text":"sorted data frame original object.","code":""},{"path":"https://easystats.github.io/parameters/reference/sort_parameters.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sort parameters by coefficient values — sort_parameters","text":"","code":"# creating object to sort (can also be a regular data frame) mod <- model_parameters(stats::lm(wt ~ am * cyl, data = mtcars))  # original output mod #> Parameter   | Coefficient |   SE |        95% CI | t(28) |      p #> ----------------------------------------------------------------- #> (Intercept) |        1.66 | 0.59 | [ 0.46, 2.86] |  2.82 | 0.009  #> am          |       -0.96 | 0.79 | [-2.58, 0.67] | -1.21 | 0.238  #> cyl         |        0.30 | 0.08 | [ 0.13, 0.47] |  3.68 | < .001 #> am × cyl    |        0.03 | 0.13 | [-0.23, 0.30] |  0.25 | 0.803  #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) #>   computed using a Wald t-distribution approximation.  # sorted outputs sort_parameters(mod, sort = \"ascending\") #> Parameter   | Coefficient |   SE |        95% CI | t(28) |      p #> ----------------------------------------------------------------- #> am          |       -0.96 | 0.79 | [-2.58, 0.67] | -1.21 | 0.238  #> am × cyl    |        0.03 | 0.13 | [-0.23, 0.30] |  0.25 | 0.803  #> cyl         |        0.30 | 0.08 | [ 0.13, 0.47] |  3.68 | < .001 #> (Intercept) |        1.66 | 0.59 | [ 0.46, 2.86] |  2.82 | 0.009  #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) #>   computed using a Wald t-distribution approximation. sort_parameters(mod, sort = \"descending\") #> Parameter   | Coefficient |   SE |        95% CI | t(28) |      p #> ----------------------------------------------------------------- #> (Intercept) |        1.66 | 0.59 | [ 0.46, 2.86] |  2.82 | 0.009  #> cyl         |        0.30 | 0.08 | [ 0.13, 0.47] |  3.68 | < .001 #> am × cyl    |        0.03 | 0.13 | [-0.23, 0.30] |  0.25 | 0.803  #> am          |       -0.96 | 0.79 | [-2.58, 0.67] | -1.21 | 0.238  #>  #> Uncertainty intervals (equal-tailed) and p-values (two-tailed) #>   computed using a Wald t-distribution approximation."},{"path":"https://easystats.github.io/parameters/reference/standard_error.html","id":null,"dir":"Reference","previous_headings":"","what":"Standard Errors — standard_error","title":"Standard Errors — standard_error","text":"standard_error() attempts return standard errors model parameters.","code":""},{"path":"https://easystats.github.io/parameters/reference/standard_error.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Standard Errors — standard_error","text":"","code":"standard_error(model, ...)  # Default S3 method standard_error(   model,   effects = \"fixed\",   component = \"all\",   vcov = NULL,   vcov_args = NULL,   verbose = TRUE,   ... )  # S3 method for class 'factor' standard_error(model, force = FALSE, verbose = TRUE, ...)"},{"path":"https://easystats.github.io/parameters/reference/standard_error.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Standard Errors — standard_error","text":"model model. ... Arguments passed methods. effects standard errors fixed effects (\"fixed\"), random effects (\"random\"), (\"\") returned? applies mixed models. May abbreviated. standard errors random effects requested, grouping factor list standard errors (per group level) random intercepts slopes returned. component Model component standard errors shown. See documentation object's class model_parameters() p_value() details. vcov Variance-covariance matrix used compute uncertainty estimates (e.g., robust standard errors). argument accepts covariance matrix, function returns covariance matrix, string identifies function used compute covariance matrix. covariance matrix function returns covariance matrix (e.g., stats::vcov()) string indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC Cluster-robust: \"CR\", \"CR0\", \"CR1\", \"CR1p\", \"CR1S\", \"CR2\", \"CR3\". See ?clubSandwich::vcovCR Bootstrap: \"BS\", \"xy\", \"residual\", \"wild\", \"mammen\", \"fractional\", \"jackknife\", \"norm\", \"webb\". See ?sandwich::vcovBS sandwich package functions: \"HAC\", \"PC\", \"CL\", \"OPG\", \"PL\". vcov_args List arguments passed function identified vcov argument. function typically supplied sandwich clubSandwich packages. Please refer documentation (e.g., ?sandwich::vcovHAC) see list available arguments. estimation type (argument type) given, default type \"HC\" equals default sandwich package; type \"CR\", default set \"CR3\". verbose Toggle warnings messages. force Logical, TRUE, factors converted numerical values calculate standard error, lowest level value 1 (unless factor numeric levels, converted corresponding numeric value). default, NA returned factors character vectors.","code":""},{"path":"https://easystats.github.io/parameters/reference/standard_error.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Standard Errors — standard_error","text":"data frame least two columns: parameter names standard errors. Depending model, may also include columns model components etc.","code":""},{"path":"https://easystats.github.io/parameters/reference/standard_error.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Standard Errors — standard_error","text":"Bayesian models (rstanarm brms), standard error SD posterior samples.","code":""},{"path":"https://easystats.github.io/parameters/reference/standard_error.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Standard Errors — standard_error","text":"","code":"model <- lm(Petal.Length ~ Sepal.Length * Species, data = iris) standard_error(model) #>                        Parameter        SE #> 1                    (Intercept) 0.5310388 #> 2                   Sepal.Length 0.1058237 #> 3              Speciesversicolor 0.6836543 #> 4               Speciesvirginica 0.6578142 #> 5 Sepal.Length:Speciesversicolor 0.1281447 #> 6  Sepal.Length:Speciesvirginica 0.1209952  # robust standard errors standard_error(model, vcov = \"HC3\") #>                        Parameter         SE #> 1                    (Intercept) 0.42486667 #> 2                   Sepal.Length 0.08504442 #> 3              Speciesversicolor 0.67252996 #> 4               Speciesvirginica 0.58942889 #> 5 Sepal.Length:Speciesversicolor 0.12045791 #> 6  Sepal.Length:Speciesvirginica 0.10558799  # cluster-robust standard errors standard_error(model,   vcov = \"vcovCL\",   vcov_args = list(cluster = iris$Species) ) #>                        Parameter           SE #> 1                    (Intercept) 2.505042e-15 #> 2                   Sepal.Length 5.010641e-16 #> 3              Speciesversicolor 2.569665e-15 #> 4               Speciesvirginica 6.109570e-15 #> 5 Sepal.Length:Speciesversicolor 5.104241e-16 #> 6  Sepal.Length:Speciesvirginica 9.830228e-16"},{"path":"https://easystats.github.io/parameters/reference/standardize_info.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Standardization Information — standardize_info","title":"Get Standardization Information — standardize_info","text":"function extracts information, deviations (SD MAD) parent variables, necessary post-hoc standardization parameters. function gives window standardized obtained, .e., divided. \"basic\" method standardization uses.","code":""},{"path":"https://easystats.github.io/parameters/reference/standardize_info.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Standardization Information — standardize_info","text":"","code":"standardize_info(model, ...)  # Default S3 method standardize_info(   model,   robust = FALSE,   two_sd = FALSE,   include_pseudo = FALSE,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/parameters/reference/standardize_info.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Standardization Information — standardize_info","text":"model statistical model. ... Arguments passed methods. robust Logical, TRUE, centering done subtracting median variables dividing median absolute deviation (MAD). FALSE, variables standardized subtracting mean dividing standard deviation (SD). two_sd TRUE, variables scaled two times deviation (SD MAD depending robust). method can useful obtain model coefficients continuous parameters comparable coefficients related binary predictors, applied predictors (outcome) (Gelman, 2008). include_pseudo ((G)LMMs) Pseudo-standardized information included? verbose Toggle warnings messages .","code":""},{"path":"https://easystats.github.io/parameters/reference/standardize_info.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Standardization Information — standardize_info","text":"data frame information parameter (see parameters_type()), various standardization coefficients post-hoc methods (see standardize_parameters()) predictor response.","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/standardize_info.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Standardization Information — standardize_info","text":"","code":"model <- lm(mpg ~ ., data = mtcars) standardize_info(model) #>      Parameter      Type        Link Secondary_Parameter EffectSize_Type #> 1  (Intercept) intercept        Mean                <NA>            <NA> #> 2          cyl   numeric Association                <NA>               r #> 3         disp   numeric Association                <NA>               r #> 4           hp   numeric Association                <NA>               r #> 5         drat   numeric Association                <NA>               r #> 6           wt   numeric Association                <NA>               r #> 7         qsec   numeric Association                <NA>               r #> 8           vs   numeric Association                <NA>               r #> 9           am   numeric Association                <NA>               r #> 10        gear   numeric Association                <NA>               r #> 11        carb   numeric Association                <NA>               r #>    Deviation_Response_Basic Deviation_Response_Smart Deviation_Basic #> 1                  6.026948                 6.026948       0.0000000 #> 2                  6.026948                 6.026948       1.7859216 #> 3                  6.026948                 6.026948     123.9386938 #> 4                  6.026948                 6.026948      68.5628685 #> 5                  6.026948                 6.026948       0.5346787 #> 6                  6.026948                 6.026948       0.9784574 #> 7                  6.026948                 6.026948       1.7869432 #> 8                  6.026948                 6.026948       0.5040161 #> 9                  6.026948                 6.026948       0.4989909 #> 10                 6.026948                 6.026948       0.7378041 #> 11                 6.026948                 6.026948       1.6152000 #>    Deviation_Smart Deviation_SDy #> 1        0.0000000       0.13455 #> 2        1.7859216       0.13455 #> 3      123.9386938       0.13455 #> 4       68.5628685       0.13455 #> 5        0.5346787       0.13455 #> 6        0.9784574       0.13455 #> 7        1.7869432       0.13455 #> 8        0.5040161       0.13455 #> 9        0.4989909       0.13455 #> 10       0.7378041       0.13455 #> 11       1.6152000       0.13455 standardize_info(model, robust = TRUE) #>      Parameter      Type        Link Secondary_Parameter EffectSize_Type #> 1  (Intercept) intercept        Mean                <NA>            <NA> #> 2          cyl   numeric Association                <NA>               r #> 3         disp   numeric Association                <NA>               r #> 4           hp   numeric Association                <NA>               r #> 5         drat   numeric Association                <NA>               r #> 6           wt   numeric Association                <NA>               r #> 7         qsec   numeric Association                <NA>               r #> 8           vs   numeric Association                <NA>               r #> 9           am   numeric Association                <NA>               r #> 10        gear   numeric Association                <NA>               r #> 11        carb   numeric Association                <NA>               r #>    Deviation_Response_Basic Deviation_Response_Smart Deviation_Basic #> 1                   5.41149                  5.41149       0.0000000 #> 2                   5.41149                  5.41149       2.9652000 #> 3                   5.41149                  5.41149     140.4763500 #> 4                   5.41149                  5.41149      77.0952000 #> 5                   5.41149                  5.41149       0.7042350 #> 6                   5.41149                  5.41149       0.7672455 #> 7                   5.41149                  5.41149       1.4158830 #> 8                   5.41149                  5.41149       0.0000000 #> 9                   5.41149                  5.41149       0.0000000 #> 10                  5.41149                  5.41149       1.4826000 #> 11                  5.41149                  5.41149       1.4826000 #>    Deviation_Smart Deviation_SDy #> 1        0.0000000       0.13455 #> 2        2.9652000       0.13455 #> 3      140.4763500       0.13455 #> 4       77.0952000       0.13455 #> 5        0.7042350       0.13455 #> 6        0.7672455       0.13455 #> 7        1.4158830       0.13455 #> 8        0.0000000       0.13455 #> 9        0.0000000       0.13455 #> 10       1.4826000       0.13455 #> 11       1.4826000       0.13455 standardize_info(model, two_sd = TRUE) #>      Parameter      Type        Link Secondary_Parameter EffectSize_Type #> 1  (Intercept) intercept        Mean                <NA>            <NA> #> 2          cyl   numeric Association                <NA>               r #> 3         disp   numeric Association                <NA>               r #> 4           hp   numeric Association                <NA>               r #> 5         drat   numeric Association                <NA>               r #> 6           wt   numeric Association                <NA>               r #> 7         qsec   numeric Association                <NA>               r #> 8           vs   numeric Association                <NA>               r #> 9           am   numeric Association                <NA>               r #> 10        gear   numeric Association                <NA>               r #> 11        carb   numeric Association                <NA>               r #>    Deviation_Response_Basic Deviation_Response_Smart Deviation_Basic #> 1                  6.026948                 6.026948       0.0000000 #> 2                  6.026948                 6.026948       3.5718433 #> 3                  6.026948                 6.026948     247.8773877 #> 4                  6.026948                 6.026948     137.1257370 #> 5                  6.026948                 6.026948       1.0693575 #> 6                  6.026948                 6.026948       1.9569149 #> 7                  6.026948                 6.026948       3.5738865 #> 8                  6.026948                 6.026948       1.0080323 #> 9                  6.026948                 6.026948       0.9979818 #> 10                 6.026948                 6.026948       1.4756081 #> 11                 6.026948                 6.026948       3.2304000 #>    Deviation_Smart Deviation_SDy #> 1        0.0000000       0.13455 #> 2        3.5718433       0.13455 #> 3      247.8773877       0.13455 #> 4      137.1257370       0.13455 #> 5        1.0693575       0.13455 #> 6        1.9569149       0.13455 #> 7        3.5738865       0.13455 #> 8        1.0080323       0.13455 #> 9        0.9979818       0.13455 #> 10       1.4756081       0.13455 #> 11       3.2304000       0.13455"},{"path":"https://easystats.github.io/parameters/reference/standardize_parameters.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameters standardization — standardize_parameters","title":"Parameters standardization — standardize_parameters","text":"Compute standardized model parameters (coefficients).","code":""},{"path":"https://easystats.github.io/parameters/reference/standardize_parameters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parameters standardization — standardize_parameters","text":"","code":"standardize_parameters(   model,   method = \"refit\",   ci = 0.95,   robust = FALSE,   two_sd = FALSE,   include_response = TRUE,   verbose = TRUE,   ... )  standardize_posteriors(   model,   method = \"refit\",   robust = FALSE,   two_sd = FALSE,   include_response = TRUE,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/parameters/reference/standardize_parameters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameters standardization — standardize_parameters","text":"model statistical model. method method used standardizing parameters. Can \"refit\" (default), \"posthoc\", \"smart\", \"basic\", \"pseudo\" \"sdy\". See Details'. ci Confidence Interval (CI) level robust Logical, TRUE, centering done subtracting median variables dividing median absolute deviation (MAD). FALSE, variables standardized subtracting mean dividing standard deviation (SD). two_sd TRUE, variables scaled two times deviation (SD MAD depending robust). method can useful obtain model coefficients continuous parameters comparable coefficients related binary predictors, applied predictors (outcome) (Gelman, 2008). include_response TRUE (default), response value also standardized. FALSE, predictors standardized. GLMs response value never standardized (see Generalized Linear Models section). verbose Toggle warnings messages . ... standardize_parameters(), arguments passed model_parameters(), : ci_method, centrality Mixed models Bayesian models... exponentiate, ... etc.","code":""},{"path":"https://easystats.github.io/parameters/reference/standardize_parameters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parameters standardization — standardize_parameters","text":"data frame standardized parameters (Std_*, depending model type) CIs (CI_low CI_high). applicable, standard errors (SEs) returned attribute (attr(x, \"standard_error\")).","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/standardize_parameters.html","id":"standardization-methods","dir":"Reference","previous_headings":"","what":"Standardization Methods","title":"Parameters standardization — standardize_parameters","text":"refit: method based complete model re-fit standardized version data. Hence, method equal standardizing variables fitting model. \"purest\" accurate (Neter et al., 1989), also computationally costly long (especially heavy models Bayesian models). method particularly recommended complex models include interactions transformations (e.g., polynomial spline terms). robust (default FALSE) argument enables robust standardization data, .e., based median MAD instead mean SD. See datawizard::standardize() details. Note standardize_parameters(method = \"refit\") may return results fitting model data standardized standardize(); standardize_parameters() used data used model fitting function, might data missing values. see remove_na argument standardize(). posthoc: Post-hoc standardization parameters, aiming emulating results obtained \"refit\" without refitting model. coefficients divided standard deviation (MAD robust) outcome (becomes expression 'unit'). , coefficients related numeric variables additionally multiplied standard deviation (MAD robust) related terms, correspond changes 1 SD predictor (e.g., \"change 1 SD x related change 0.24 SD y). apply binary variables factors, coefficients still related changes levels. method accurate tend give aberrant results interactions specified. basic: method similar method = \"posthoc\", treats variables continuous: also scales coefficient standard deviation model's matrix' parameter factors levels (transformed integers) binary predictors. Although inappropriate cases, method one implemented default software packages, lm.beta::lm.beta(). smart (Standardization Model's parameters Adjustment, Reconnaissance Transformation - experimental): Similar method = \"posthoc\" involve model refitting. difference SD (MAD robust) response computed relevant section data. instance, factor 3 levels (intercept), B C entered predictor, effect corresponding B vs. scaled variance response intercept . results, coefficients effects factors similar Glass' delta. pseudo (2-level (G)LMMs ): (post-hoc) method, response predictor standardized based level prediction (levels detected performance::check_heterogeneity_bias()): Predictors standardized based SD level prediction (see also datawizard::demean()); outcome (linear LMMs) standardized based fitted random-intercept-model, sqrt(random-intercept-variance) used level 2 predictors, sqrt(residual-variance) used level 1 predictors (Hoffman 2015, page 342). warning given within-group variable found access -group variance. sdy (logistic regression models ): y-standardization useful comparing coefficients logistic regression models across models sample. Unobserved heterogeneity varies across models different independent variables, thus, odds ratios predictor different models compared directly. y-standardization makes coefficients \"comparable across models dividing estimated standard deviation latent variable model\" (Mood 2010). Thus, whenever one multiple logistic regression models fit data share certain predictors (e.g. nested models), can useful use standardization approach make log-odds odds ratios comparable.","code":""},{"path":"https://easystats.github.io/parameters/reference/standardize_parameters.html","id":"transformed-variables","dir":"Reference","previous_headings":"","what":"Transformed Variables","title":"Parameters standardization — standardize_parameters","text":"model's formula contains transformations (e.g. y ~ exp(X)) method = \"refit\" give different results compared method = \"basic\" (\"posthoc\" \"smart\" support transformations): \"refit\" standardizes data prior transformation (e.g. equivalent exp(scale(X))), \"basic\" method standardizes transformed data (e.g. equivalent scale(exp(X))).  See Transformed Variables section datawizard::standardize.default() details different transformations dealt method = \"refit\".","code":""},{"path":"https://easystats.github.io/parameters/reference/standardize_parameters.html","id":"confidence-intervals","dir":"Reference","previous_headings":"","what":"Confidence Intervals","title":"Parameters standardization — standardize_parameters","text":"returned confidence intervals re-scaled versions unstandardized confidence intervals, \"true\" confidence intervals standardized coefficients (cf. Jones & Waller, 2015).","code":""},{"path":"https://easystats.github.io/parameters/reference/standardize_parameters.html","id":"generalized-linear-models","dir":"Reference","previous_headings":"","what":"Generalized Linear Models","title":"Parameters standardization — standardize_parameters","text":"Standardization generalized linear models (GLM, GLMM, etc) done respect predictors (outcome remains -, unstandardized) - maintaining interpretability coefficients (e.g., binomial model: exponent standardized parameter change 1 SD predictor, etc.)","code":""},{"path":"https://easystats.github.io/parameters/reference/standardize_parameters.html","id":"dealing-with-factors","dir":"Reference","previous_headings":"","what":"Dealing with Factors","title":"Parameters standardization — standardize_parameters","text":"standardize(model) standardize_parameters(model, method = \"refit\") standardize categorical predictors (.e. factors) / dummy-variables, may different behaviour compared R packages (lm.beta) software packages (like SPSS). mimic behaviours, either use standardize_parameters(model, method = \"basic\") obtain post-hoc standardized parameters, standardize data datawizard::standardize(data, force = TRUE) fitting model.","code":""},{"path":"https://easystats.github.io/parameters/reference/standardize_parameters.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Parameters standardization — standardize_parameters","text":"Hoffman, L. (2015). Longitudinal analysis: Modeling within-person fluctuation change. Routledge. Jones, J. ., & Waller, N. G. (2015). normal-theory asymptotic distribution-free (ADF) covariance matrix standardized regression coefficients: theoretical extensions finite sample behavior. Psychometrika, 80(2), 365-378. Neter, J., Wasserman, W., & Kutner, M. H. (1989). Applied linear regression models. Gelman, . (2008). Scaling regression inputs dividing two standard deviations. Statistics medicine, 27(15), 2865-2873. Mood C. Logistic Regression: Think Can , Can . European Sociological Review (2010) 26:67–82.","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/reference/standardize_parameters.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parameters standardization — standardize_parameters","text":"","code":"model <- lm(len ~ supp * dose, data = ToothGrowth) standardize_parameters(model, method = \"refit\") #> # Standardization method: refit #>  #> Parameter        | Std. Coef. |         95% CI #> ---------------------------------------------- #> (Intercept)      |       0.24 | [ 0.05,  0.44] #> supp [VC]        |      -0.48 | [-0.76, -0.21] #> dose             |       0.64 | [ 0.45,  0.84] #> supp [VC] × dose |       0.32 | [ 0.04,  0.60] # \\donttest{ standardize_parameters(model, method = \"posthoc\") #> # Standardization method: posthoc #>  #> Parameter        | Std. Coef. |         95% CI #> ---------------------------------------------- #> (Intercept)      |       0.00 | [ 0.00,  0.00] #> supp [VC]        |      -1.08 | [-1.66, -0.49] #> dose             |       0.64 | [ 0.45,  0.84] #> supp [VC] × dose |       0.32 | [ 0.04,  0.60] standardize_parameters(model, method = \"smart\") #> # Standardization method: smart #>  #> Parameter        | Std. Coef. |         95% CI #> ---------------------------------------------- #> (Intercept)      |       0.00 | [ 0.00,  0.00] #> supp [VC]        |      -1.00 | [-1.54, -0.46] #> dose             |       0.64 | [ 0.45,  0.84] #> supp [VC] × dose |       0.55 | [ 0.07,  1.02] standardize_parameters(model, method = \"basic\") #> # Standardization method: basic #>  #> Parameter        | Std. Coef. |         95% CI #> ---------------------------------------------- #> (Intercept)      |       0.00 | [ 0.00,  0.00] #> supp [VC]        |      -0.54 | [-0.84, -0.25] #> dose             |       0.64 | [ 0.45,  0.84] #> supp [VC] × dose |       0.38 | [ 0.05,  0.70]  # Robust and 2 SD standardize_parameters(model, robust = TRUE) #> # Standardization method: refit #>  #> Parameter        | Std. Coef. |         95% CI #> ---------------------------------------------- #> (Intercept)      |       0.01 | [-0.16,  0.18] #> supp [VC]        |      -0.48 | [-0.72, -0.24] #> dose             |       0.64 | [ 0.44,  0.84] #> supp [VC] × dose |       0.32 | [ 0.04,  0.60] #>  #> - Scaled by one MAD from the median. standardize_parameters(model, two_sd = TRUE) #> # Standardization method: refit #>  #> Parameter        | Std. Coef. |         95% CI #> ---------------------------------------------- #> (Intercept)      |       0.24 | [ 0.05,  0.44] #> supp [VC]        |      -0.48 | [-0.76, -0.21] #> dose             |       1.28 | [ 0.89,  1.68] #> supp [VC] × dose |       0.64 | [ 0.09,  1.20] #>  #> - Scaled by two SDs from the mean.  model <- glm(am ~ cyl * mpg, data = mtcars, family = \"binomial\") standardize_parameters(model, method = \"refit\") #> # Standardization method: refit #>  #> Parameter   | Std. Coef. |        95% CI #> ---------------------------------------- #> (Intercept) |      -0.58 | [-1.98, 0.70] #> cyl         |       0.25 | [-1.54, 2.10] #> mpg         |       2.10 | [-0.19, 5.28] #> cyl × mpg   |      -0.36 | [-2.57, 1.54] #>  #> - Response is unstandardized. standardize_parameters(model, method = \"posthoc\") #> # Standardization method: posthoc #>  #> Parameter   | Std. Coef. |         95% CI #> ----------------------------------------- #> (Intercept) |       0.00 | [ 0.00,  0.00] #> cyl         |       1.46 | [-4.63,  9.37] #> mpg         |       3.36 | [-2.31, 12.59] #> cyl × mpg   |      -0.20 | [-1.44,  0.86] #>  #> - Response is unstandardized. standardize_parameters(model, method = \"basic\", exponentiate = TRUE) #> # Standardization method: basic #>  #> Parameter   | Std_Odds_Ratio |           95% CI #> ----------------------------------------------- #> (Intercept) |           1.00 | [1.00,     1.00] #> cyl         |           4.32 | [0.01, 11681.98] #> mpg         |          28.80 | [0.10, 2.92e+05] #> cyl × mpg   |           0.54 | [0.01,    13.94] #>  #> - Response is unstandardized. # }  # \\donttest{ m <- lme4::lmer(mpg ~ cyl + am + vs + (1 | cyl), mtcars) #> boundary (singular) fit: see help('isSingular') standardize_parameters(m, method = \"pseudo\", ci_method = \"satterthwaite\") #> The following within-group terms have between-group variance: #>   am, vs #>   This can inflate standardized within-group parameters associated with #>   these terms. #>   See `help(\"demean\", package = \"datawizard\")` for modeling between- and #>   within-subject effects. #> # Standardization method: pseudo #>  #> Parameter   | Std. Coef. |         95% CI #> ----------------------------------------- #> (Intercept) |       0.00 | [ 0.00,  0.00] #> cyl         |      -0.74 | [-1.25, -0.23] #> am          |       0.47 | [-0.01,  0.95] #> vs          |       0.20 | [-0.50,  0.90] # } # \\donttest{ model <- rstanarm::stan_glm(rating ~ critical + privileges, data = attitude, refresh = 0) standardize_posteriors(model, method = \"refit\", verbose = FALSE) #> # Standardization method: refit #>  #> (Intercept) |  critical | privileges #> ------------------------------------ #> 0.05        |      0.26 |       0.56 #> -0.18       |      0.20 |       0.44 #> 0.02        |      0.03 |       0.34 #> -0.03       |  9.56e-03 |       0.35 #> -0.03       |      0.05 |       0.42 #> 0.05        |      0.74 |       0.35 #> 0.15        |     -0.22 |       0.42 #> -0.24       |      0.05 |       0.37 #> 0.14        |      0.13 |       0.37 #> -0.14       |      0.44 |       0.22 #> 0.25        |  9.29e-03 |       0.49 #> 0.33        |     -0.07 |       0.57 #> -0.31       |      0.17 |       0.45 #> 0.15        |     -0.03 |       0.30 #> -0.16       |      0.26 |       0.50 #> 0.25        |      0.05 |       0.36 #> 0.13        |      0.09 |       0.27 #> -0.17       |      0.16 |       0.58 #> -0.09       |     -0.17 |       0.64 #> 0.14        |      0.16 |       0.15 #> -0.06       |      0.17 |       0.57 #> -0.21       |      0.18 |       0.33 #> 0.22        |  3.06e-03 |       0.50 #> -0.12       |      0.19 |       0.41 #> -0.34       |      0.16 |       0.47 #> 0.26        |      0.08 |       0.20 #> -0.20       |      0.34 |       0.88 #> -0.23       |      0.47 |       0.95 #> 0.15        |      0.17 |       0.05 #> -0.07       |      0.13 |       0.48 #> 0.03        |      0.13 |       0.29 #> 0.04        |      0.12 |       0.43 #> -0.25       |      0.09 |       0.25 #> -0.28       |     -0.02 |       0.35 #> 0.27        |      0.11 |       0.55 #> -0.27       |      0.07 |       0.25 #> 0.35        |      0.27 |       0.44 #> -0.05       |     -0.09 |       0.21 #> 0.12        |      0.17 |       0.53 #> 0.04        |      0.14 |       0.45 #> 0.27        |      0.22 |       0.44 #> 2.32e-03    |      0.10 |       0.54 #> -0.13       |      0.07 |       0.35 #> -0.32       |      0.20 |       0.51 #> -0.03       |     -0.13 |       0.30 #> 0.02        |      0.37 |       0.48 #> -0.04       |      0.49 |       0.45 #> 0.10        |     -0.43 |       0.53 #> -0.09       |      0.52 |       0.32 #> -0.11       |     -0.55 |       0.43 #> 0.16        |     -0.04 |       0.34 #> -0.16       |      0.24 |       0.46 #> 0.21        |     -0.14 |       0.47 #> 0.13        |      0.08 |       0.36 #> -0.12       |      0.17 |       0.42 #> -0.10       |      0.16 |       0.27 #> -0.09       |      0.09 |       0.26 #> 0.03        |      0.06 |       0.68 #> 0.08        |     -0.09 |       0.77 #> -0.03       |     -0.15 |       0.41 #> 0.05        |     -0.32 |       0.38 #> -0.07       |      0.07 |       0.38 #> 0.07        |      0.01 |       0.23 #> -0.11       |      0.24 |       0.46 #> -0.15       |      0.24 |       0.32 #> 0.21        |     -0.11 |       0.64 #> -0.14       |      0.17 |       0.30 #> 0.09        | -9.56e-03 |       0.26 #> -0.15       |      0.12 |       0.63 #> 0.18        |      0.10 |       0.12 #> 0.11        |      0.11 |       0.23 #> 0.22        |     -0.13 |       0.48 #> -0.27       |     -0.30 |       0.49 #> -0.30       |     -0.30 |       0.48 #> 0.31        |      0.24 |       0.67 #> -0.07       |      0.27 |       0.68 #> -0.12       |      0.09 |       0.55 #> -0.02       |      0.09 |       0.50 #> -0.01       |      0.08 |       0.43 #> 0.10        |     -0.08 |       0.36 #> 0.11        |     -0.20 |       0.45 #> 0.16        |      0.25 |       0.67 #> -5.36e-03   |     -0.42 |       0.47 #> -0.05       |      0.51 |       0.36 #> -0.09       |      0.52 |       0.45 #> 0.13        |     -0.44 |       0.32 #> -0.14       |      0.52 |       0.59 #> 0.12        |     -0.09 |       0.07 #> 0.22        |     -0.43 |       0.04 #> 0.18        |     -0.29 |       0.07 #> -0.12       |      0.08 |       0.39 #> -0.11       | -5.35e-03 |       0.08 #> 0.08        |      0.22 |       0.72 #> 0.23        |      0.24 |       0.81 #> 0.19        |      0.23 |       0.77 #> 0.05        |     -0.03 |       0.27 #> -0.07       |      0.21 |       0.43 #> 0.06        | -1.05e-03 |       0.52 #> -0.08       |     -0.03 |       0.21 #> -0.10       |     -0.16 |       0.03 #> 0.33        |      0.16 |       0.41 #> -0.14       |  6.17e-03 |       0.35 #> 0.15        |      0.21 |       0.42 #> -0.14       |      0.01 |       0.61 #> 0.08        |      0.26 |       0.13 #> -0.02       |      0.28 |       0.37 #> 9.94e-03    |     -0.12 |       0.46 #> 0.26        |      0.14 |       0.77 #> 0.02        |      0.15 |       0.70 #> -0.15       |      0.13 |       0.38 #> 0.05        |     -0.05 |       0.45 #> 0.09        |     -0.05 |       0.28 #> -0.13       |      0.37 |       0.48 #> 0.09        |      0.11 |       0.48 #> -0.12       |      0.07 |       0.33 #> 0.09        |      0.11 |       0.46 #> -0.02       |      0.05 |       0.32 #> -0.18       |      0.39 |       0.20 #> 0.03        |     -0.04 |       0.51 #> 0.13        |      0.10 |       0.36 #> -0.19       |      0.05 |       0.60 #> 0.18        |      0.14 |       0.25 #> 0.10        |      0.35 |       0.35 #> -0.09       |      0.26 |       0.47 #> 0.12        | -9.35e-03 |       0.39 #> 0.10        |      0.26 |       0.50 #> -0.16       |      0.03 |       0.35 #> -0.28       |      0.06 |       0.36 #> 0.22        |     -0.06 |       0.50 #> -0.23       |      0.21 |       0.35 #> 0.14        |      0.48 |       0.04 #> -0.15       |     -0.20 |       0.69 #> -0.15       |      0.05 |       0.64 #> 0.03        |      0.12 |       0.11 #> 0.28        |      0.25 |       0.28 #> -0.35       |     -0.14 |       0.59 #> -0.19       |     -0.05 |       0.70 #> 0.22        |      0.24 |      -0.07 #> -0.08       |     -0.11 |       0.19 #> -6.76e-03   |      0.49 |       0.60 #> 0.07        |      0.06 |       0.04 #> 0.23        |      0.27 |       0.48 #> -0.21       |     -0.04 |       0.34 #> -0.03       |      0.06 |       0.67 #> 0.21        |      0.12 |       0.41 #> 0.10        |      0.16 |       0.43 #> -0.14       |     -0.07 |       0.50 #> 0.15        |      0.07 |       0.51 #> 0.12        |      0.06 |       0.30 #> 0.03        |      0.18 |       0.45 #> -0.02       |      0.12 |       0.35 #> 0.07        |      0.12 |       0.66 #> -0.16       |     -0.27 |       0.34 #> 0.17        |      0.40 |       0.48 #> 0.29        |      0.24 |       0.50 #> 0.21        |      0.15 |       0.42 #> -0.19       |     -0.08 |       0.42 #> 4.27e-04    |     -0.11 |       0.98 #> 0.18        |     -0.22 |       0.85 #> 0.08        |     -0.15 |       0.73 #> -0.09       |      0.12 |       0.55 #> -0.02       |  1.49e-03 |       0.72 #> 0.16        |      0.13 |       0.46 #> -0.02       |      0.02 |       0.46 #> 6.31e-03    |     -0.14 |       0.30 #> 0.23        |     -0.14 |       0.55 #> -0.25       |      0.15 |       0.38 #> 0.18        |     -0.12 |       0.34 #> 0.30        |     -0.21 |       0.06 #> -0.11       |      0.45 |       0.63 #> 0.07        |     -0.12 |       0.22 #> 0.03        |     -0.04 |       0.33 #> -0.23       |      0.02 |       0.39 #> -0.19       |     -0.19 |       0.59 #> 0.14        |      0.07 |       0.46 #> -0.21       |      0.23 |       0.39 #> 0.22        |     -0.02 |       0.38 #> -0.09       |      0.24 |       0.45 #> 0.09        |  4.18e-03 |       0.39 #> 0.02        |      0.04 |       0.48 #> 2.61e-03    |      0.18 |       0.42 #> 0.10        | -8.30e-03 |       0.35 #> 0.20        |     -0.07 |       0.23 #> 0.05        |     -0.07 |       0.26 #> 0.03        |      0.06 |       0.42 #> -9.40e-04   |      0.14 |       0.32 #> 0.03        |     -0.04 |       0.38 #> -0.16       |      0.20 |       0.54 #> 0.03        |     -0.18 |       0.39 #> 0.02        |     -0.34 |       0.40 #> 0.02        |      0.30 |       0.41 #> 9.40e-03    |      0.24 |       0.29 #> 0.05        |      0.03 |       0.41 #> -0.04       |      0.29 |       0.42 #> 0.02        |      0.36 |       0.33 #> -0.10       |      0.53 |       0.22 #> 0.08        |     -0.23 |       0.45 #> 0.04        |      0.55 |       0.36 #> -0.27       |      0.22 |      -0.04 #> -0.08       |      0.14 |       0.29 #> -1.00e-02   |      0.12 |       0.45 #> 0.06        |      0.09 |       0.40 #> 0.22        |      0.48 |       0.23 #> -0.13       |      0.29 |       0.72 #> 0.05        |     -0.12 |       0.15 #> 0.03        |      0.30 |       0.30 #> 0.08        |      0.09 |       0.62 #> -0.31       |     -0.06 |       0.51 #> -0.26       |      0.12 |       0.40 #> 0.20        |      0.03 |       0.50 #> -0.10       |      0.49 |       0.46 #> 0.02        |  2.13e-03 |       0.03 #> 0.24        |      0.05 |       0.66 #> -0.35       |      0.07 |       0.62 #> 0.25        |      0.17 |       0.16 #> -0.07       |      0.33 |       0.41 #> -0.27       |      0.26 |       0.27 #> -0.07       |      0.17 |       0.53 #> 0.20        |     -0.10 |       0.11 #> -0.13       |      0.38 |       0.61 #> 0.25        |      0.12 |       0.19 #> -0.22       |      0.18 |       0.27 #> -0.01       |      0.32 |       0.53 #> -0.16       |      0.32 |       0.41 #> -0.15       |     -0.08 |       0.12 #> -0.26       |      0.04 |       0.36 #> 0.27        |      0.21 |       0.40 #> -0.28       |      0.12 |       0.25 #> 8.64e-03    |     -0.42 |       0.68 #> 0.05        |      0.33 |       0.46 #> 0.09        |      0.26 |       0.23 #> -0.62       |      0.48 |       0.32 #> -0.03       |     -0.37 |       0.49 #> 0.02        |     -0.03 |       0.61 #> 0.19        |     -0.01 |       0.40 #> 0.22        |     -0.07 |       0.80 #> -0.04       |      0.34 |       0.07 #> 0.14        |     -0.20 |       0.80 #> 0.26        | -4.89e-03 |       0.69 #> -0.13       |      0.30 |       0.39 #> -0.26       |      0.09 |       0.53 #> -0.27       |     -0.20 |       0.62 #> -0.11       |     -0.17 |       0.56 #> -0.06       |      0.42 |       0.23 #> 5.89e-03    |     -0.15 |       0.50 #> 0.02        |      0.34 |       0.30 #> -0.02       |      0.21 |       0.09 #> -0.11       |     -0.05 |       0.11 #> 0.02        |     -0.25 |       0.56 #> 0.12        |      0.37 |       0.23 #> -0.13       |     -0.06 |       0.46 #> 0.04        |      0.13 |       0.34 #> -0.17       |      0.02 |       0.41 #> 0.15        |      0.09 |       0.49 #> 0.16        |      0.15 |       0.61 #> -0.16       |      0.07 |       0.20 #> -0.14       |     -0.04 |       0.14 #> -0.04       |      0.29 |       0.22 #> 0.05        |      0.34 |       0.47 #> 0.07        |      0.16 |       0.29 #> -0.15       |     -0.04 |       0.60 #> -0.23       |     -0.03 |       0.30 #> -0.09       |     -0.05 |       0.50 #> 0.02        |     -0.19 |       0.33 #> 0.04        |      0.16 |       0.63 #> -0.05       |      0.03 |       0.16 #> -0.15       |      0.03 |       0.35 #> 0.10        |      0.12 |       0.45 #> -0.18       |      0.12 |       0.36 #> -0.24       |      0.19 |       0.40 #> -0.31       |      0.17 |       0.43 #> 0.17        |  4.33e-04 |       0.24 #> -0.13       |      0.43 |       0.42 #> -0.50       |     -0.02 |       0.04 #> 0.44        |      0.27 |       0.77 #> -0.33       |      0.04 |       0.50 #> -0.01       |      0.16 |       0.65 #> -0.11       |      0.11 |       0.53 #> 0.08        |      0.16 |       0.08 #> -0.02       |      0.05 |       0.67 #> 0.04        |      0.11 |       0.18 #> -0.07       |      0.18 |       0.33 #> -0.32       |      0.27 |       0.28 #> 0.30        |     -0.12 |       0.56 #> 0.28        |     -0.03 |       0.43 #> -0.27       |      0.32 |       0.34 #> -0.06       |      0.34 |       0.59 #> 0.19        |      0.09 |       0.18 #> -0.12       |      0.14 |       0.43 #> -0.08       |     -0.10 |       0.44 #> 0.02        |     -0.13 |       0.45 #> -0.04       |     -0.12 |       0.50 #> 0.01        |      0.08 |       0.43 #> 0.04        |  9.24e-03 |       0.27 #> -5.85e-03   |      0.17 |       0.35 #> -0.20       |     -0.09 |       0.47 #> -0.15       |      0.03 |       0.34 #> -0.09       |      0.03 |       0.34 #> 0.03        |      0.08 |       0.54 #> 0.04        |      0.09 |       0.48 #> 0.06        |     -0.03 |       0.26 #> -0.09       |      0.16 |       0.49 #> -0.18       |      0.24 |       0.26 #> 0.11        |     -0.06 |       0.56 #> -0.22       |      0.30 |       0.31 #> 0.25        |      0.13 |       0.48 #> 6.38e-03    |      0.11 |       0.45 #> 0.11        |      0.04 |       0.32 #> 0.25        |     -0.25 |       0.65 #> -0.13       |      0.06 |       0.17 #> -0.18       |     -0.43 |       0.34 #> 0.06        |      0.25 |       0.64 #> -0.04       |     -0.08 |       0.24 #> -8.49e-03   | -5.45e-04 |       0.20 #> -0.06       |      0.12 |       0.23 #> 0.04        |      0.05 |  -6.90e-03 #> 0.08        |      0.34 |       0.44 #> 0.22        |      0.06 |       0.34 #> 0.12        |      0.03 |       0.45 #> 0.06        |      0.24 |      -0.03 #> -0.07       |      0.16 |       0.54 #> -0.02       |      0.03 |       0.55 #> 9.86e-03    |      0.10 |       0.21 #> 0.07        |      0.11 |       0.54 #> -0.03       |      0.14 |       0.20 #> 0.16        |      0.02 |       0.30 #> -0.20       |      0.26 |       0.49 #> 8.30e-04    |     -0.06 |       0.52 #> -2.62e-03   |     -0.23 |       0.44 #> 9.39e-03    |      0.34 |       0.43 #> -0.13       |     -0.01 |       0.27 #> -0.08       |      0.03 |       0.57 #> 0.14        |      0.23 |       0.29 #> 0.21        |      0.34 |       0.23 #> 0.04        |      0.13 |       0.68 #> -0.16       |     -0.06 |       0.55 #> -0.06       |     -0.03 |       0.70 #> -0.10       |      0.26 |       0.26 #> -7.88e-03   |      0.23 |       0.37 #> -0.16       |      0.30 |       0.26 #> 0.10        |      0.43 |       0.14 #> -0.21       |      0.59 |       0.22 #> -0.12       |      0.51 |       0.18 #> -3.96e-03   |     -0.18 |       0.19 #> 0.08        |      0.22 |      -0.05 #> -0.04       |     -0.02 |       0.79 #> 0.13        |      0.32 |       0.14 #> -0.13       |     -0.15 |       0.73 #> -0.32       |      0.19 |       0.80 #> -0.29       |      0.08 |       0.57 #> 0.10        |      0.11 |       0.56 #> 0.04        |      0.12 |       0.11 #> 0.02        |      0.10 |       0.16 #> 0.17        |      0.45 |       0.31 #> -0.06       |     -0.15 |       0.41 #> 0.16        |      0.24 |       0.67 #> -0.02       |      0.15 |       0.61 #> -0.11       |      0.31 |       0.33 #> -8.93e-03   |      0.30 |       0.40 #> 0.01        |     -0.04 |       0.31 #> 0.05        |      0.16 |       0.09 #> 0.14        |      0.16 |       0.09 #> 0.35        |      0.26 |       0.36 #> -0.33       |      0.15 |       0.26 #> -0.43       |      0.06 |       0.37 #> 0.15        |      0.11 |       0.69 #> 0.02        |      0.08 |       0.09 #> -0.09       |      0.18 |       0.30 #> -0.25       |      0.14 |       0.42 #> 0.25        |     -0.06 |       0.30 #> 0.20        |      0.03 |       0.50 #> 0.23        | -4.95e-03 |       0.52 #> 0.32        |      0.04 |       0.08 #> -0.28       |      0.15 |       0.76 #> -0.05       |     -0.24 |       0.26 #> 0.22        |     -0.16 |       0.51 #> -0.02       |      0.34 |       0.52 #> -0.04       |     -0.10 |       0.32 #> -0.12       |      0.35 |       0.52 #> 0.03        |      0.16 |       0.37 #> 9.25e-03    |      0.06 |       0.55 #> 0.01        |     -0.04 |       0.27 #> 0.11        |     -0.14 |       0.64 #> 0.03        |     -0.15 |       0.60 #> -0.29       |      0.15 |       0.63 #> -0.14       |      0.06 |       0.60 #> 0.22        |      0.10 |       0.16 #> -0.07       |      0.46 |       0.16 #> -0.11       |      0.20 |       0.39 #> 0.02        | -8.01e-03 |       0.42 #> -0.02       |      0.19 |       0.43 #> 0.31        |      0.05 |       0.55 #> -0.31       |      0.09 |       0.42 #> -0.20       |      0.06 |       0.52 #> -0.22       |      0.15 |       0.64 #> -0.37       | -1.58e-04 |       0.54 #> 0.32        |      0.17 |       0.18 #> 0.11        |      0.37 |       0.47 #> 0.03        |      0.15 |       0.36 #> 0.02        |      0.38 |       0.24 #> -0.08       |     -0.15 |       0.49 #> 0.04        |      0.02 |       0.48 #> -0.03       |      0.20 |       0.34 #> 0.06        |      0.18 |       0.45 #> -0.16       |      0.21 |       0.43 #> -0.07       |     -0.20 |       0.48 #> -0.09       |      0.18 |       0.68 #> 0.08        |     -0.03 |       0.18 #> -8.44e-03   |     -0.28 |       0.14 #> -0.40       |      0.18 |       0.63 #> -0.17       |      0.29 |       0.52 #> -0.14       |      0.27 |       0.51 #> 0.10        |      0.02 |       0.30 #> -0.11       |      0.29 |       0.33 #> -0.35       |      0.66 |       0.18 #> -0.10       |      0.36 |       0.65 #> -0.13       |      0.09 |       0.21 #> -0.29       |      0.04 |       0.46 #> 0.02        |      0.28 |       0.45 #> 0.04        |  9.84e-03 |       0.44 #> -0.05       |     -0.02 |       0.48 #> 0.03        |      0.22 |       0.33 #> -0.05       |     -0.04 |       0.52 #> 0.01        |      0.23 |       0.28 #> 0.30        |      0.03 |       0.20 #> 0.32        |      0.16 |       0.76 #> -0.71       |      0.14 |       0.47 #> -0.65       |      0.30 |       0.37 #> 0.04        |     -0.16 |       0.60 #> 0.20        |      0.04 |       0.52 #> 0.09        |      0.04 |       0.59 #> 0.08        |     -0.29 |       0.40 #> 0.15        |     -0.14 |       0.35 #> 0.16        |     -0.44 |       0.06 #> 0.18        |     -0.48 |       0.05 #> 0.44        |     -0.21 |       0.45 #> 0.29        |     -0.05 |       0.39 #> -0.16       |      0.15 |       0.49 #> 0.07        |      0.30 |       0.36 #> -0.07       |     -0.09 |       0.44 #> 0.04        |      0.32 |       0.44 #> 0.11        |     -0.10 |       0.18 #> 0.12        |     -0.07 |       0.30 #> -0.03       |      0.18 |       0.55 #> 0.19        |      0.07 |       0.28 #> 0.34        |      0.10 |       0.36 #> -0.13       |      0.10 |       0.18 #> -0.44       |      0.30 |       0.14 #> 0.47        |      0.14 |       0.48 #> -0.27       |      0.21 |       0.24 #> -0.15       |      0.18 |       0.26 #> -0.11       |      0.09 |       0.44 #> -0.08       |      0.07 |       0.26 #> -0.18       | -9.96e-03 |       0.28 #> 0.10        |      0.30 |       0.29 #> 0.14        |      0.38 |       0.22 #> -0.19       |     -0.22 |       0.50 #> -0.13       |      0.41 |       0.34 #> -0.17       |      0.19 |       0.29 #> -0.45       |      0.21 |       0.20 #> -0.09       |      0.39 |       0.22 #> -0.06       |      0.28 |       0.26 #> -0.03       |      0.14 |       0.49 #> 0.02        |  9.41e-03 |       0.34 #> -0.09       |     -0.09 |       0.48 #> -0.16       |     -0.04 |       0.55 #> 0.18        |      0.17 |       0.27 #> -0.17       |     -0.12 |       0.46 #> -0.19       |     -0.14 |       0.30 #> -0.07       |      0.02 |       0.42 #> 0.01        |      0.25 |       0.60 #> 0.02        |      0.24 |       0.59 #> 8.10e-04    |     -0.12 |       0.49 #> 0.02        |      0.35 |       0.30 #> -0.01       |      0.11 |  -6.14e-03 #> 0.17        |      0.16 |       0.71 #> 0.20        |     -0.11 |       0.43 #> -0.16       |      0.22 |       0.46 #> 0.14        |      0.09 |       0.27 #> -0.08       |     -0.08 |       0.39 #> -0.09       |     -0.06 |       0.35 #> 0.09        |      0.27 |       0.47 #> 0.05        |     -0.15 |       0.22 #> 0.02        |     -0.03 |       0.04 #> -0.07       |      0.18 |       0.71 #> 0.08        |      0.05 |      -0.02 #> 0.25        |      0.18 |       0.75 #> 0.22        |      0.14 |       0.60 #> 0.14        |      0.36 |       0.21 #> -0.12       |     -0.05 |       0.42 #> 0.11        |      0.11 |       0.36 #> -0.18       |      0.25 |       0.05 #> 0.27        | -4.18e-03 |       0.83 #> 0.12        |      0.19 |       0.28 #> -0.12       |      0.05 |       0.57 #> 0.10        |     -0.33 |       0.42 #> 0.20        |  2.58e-03 |       0.43 #> 0.05        | -1.35e-05 |       0.13 #> -0.22       |      0.11 |       0.34 #> -0.03       |     -0.04 |       0.59 #> -0.05       |      0.19 |       0.25 #> 0.22        |     -0.09 |       0.50 #> 0.04        |      0.05 |       0.53 #> 0.11        |     -0.04 |       0.32 #> 0.11        |     -0.04 |       0.32 #> -0.05       |      0.52 |       0.18 #> 0.09        |      0.22 |       0.31 #> -0.32       |      0.30 |       0.10 #> 0.05        | -4.17e-04 |       0.26 #> -0.06       |      0.14 |       0.61 #> -0.03       |     -0.04 |       0.42 #> -0.03       |      0.18 |       0.48 #> -0.08       |     -0.14 |       0.44 #> 0.14        |      0.40 |       0.38 #> -0.12       |     -0.16 |       0.42 #> -0.03       |     -0.17 |       0.36 #> -0.21       |      0.17 |       0.49 #> -0.13       |      0.12 |       0.24 #> -0.16       |     -0.02 |       0.43 #> -7.85e-03   |      0.14 |       0.44 #> 0.05        |      0.02 |       0.33 #> 0.02        |      0.18 |       0.50 #> -0.04       |  8.42e-03 |       0.34 #> 0.05        |      0.11 |       0.44 #> 0.05        |      0.29 |       0.37 #> 0.21        |     -0.12 |       0.43 #> -8.09e-03   |      0.14 |       0.52 #> 5.91e-03    |      0.02 |       0.34 #> -8.72e-03   |      0.11 |       0.47 #> -0.05       |      0.21 |       0.17 #> -0.06       |      0.25 |       0.14 #> -0.25       |  6.08e-03 |       0.33 #> 0.12        |      0.05 |       0.58 #> -0.09       |      0.10 |       0.33 #> -0.15       |      0.09 |       0.33 #> -0.04       |      0.05 |       0.52 #> -0.16       |      0.23 |       0.31 #> 0.22        |     -0.03 |       0.52 #> -0.05       |     -0.15 |       0.56 #> 0.03        |      0.11 |       0.48 #> -0.09       |     -0.12 |       0.48 #> -0.04       |     -0.29 |       0.50 #> 0.12        |  7.87e-03 |      -0.09 #> -0.02       |      0.18 |       0.44 #> 0.07        |      0.15 |       0.54 #> -0.04       |      0.09 |       0.34 #> -0.02       |      0.28 |       0.43 #> 0.02        |     -0.06 |       0.42 #> 0.12        | -2.65e-03 |       0.37 #> 0.16        |      0.08 |       0.50 #> -0.15       |      0.08 |       0.33 #> -0.10       |      0.19 |       0.40 #> -0.17       |     -0.10 |       0.30 #> 0.10        |     -0.21 |       0.54 #> -0.10       |      0.36 |       0.31 #> 0.18        |      0.15 |       0.50 #> 0.07        |      0.10 |       0.38 #> -0.05       |      0.09 |       0.40 #> -0.17       |     -0.18 |       0.23 #> -0.04       |     -0.17 |       0.39 #> -3.51e-03   |     -0.02 |       0.34 #> -0.05       |      0.16 |       0.58 #> 0.04        |      0.04 |       0.28 #> -7.06e-04   |      0.10 |       0.30 #> -0.10       |      0.25 |       0.50 #> 6.05e-03    |     -0.13 |       0.36 #> 0.06        |     -0.18 |       0.37 #> -0.06       |     -0.10 |       0.39 #> 0.07        |     -0.06 |       0.37 #> -0.07       |      0.23 |       0.38 #> 0.07        |     -0.08 |       0.44 #> -0.19       |      0.12 |       0.52 #> 0.19        |      0.16 |       0.21 #> -0.18       |      0.24 |       0.49 #> 0.02        |      0.09 |       0.50 #> 0.07        |      0.18 |       0.55 #> 0.06        |      0.30 |       0.57 #> 0.09        |      0.06 |       0.25 #> 0.07        |      0.22 |       0.10 #> 0.21        |      0.22 |       0.34 #> 0.23        |      0.14 |       0.49 #> 0.29        |      0.24 |       0.54 #> 0.50        |     -0.16 |       0.09 #> 0.62        |     -0.11 |       0.10 #> 0.19        |      0.02 |       0.28 #> 0.24        |      0.12 |       0.31 #> -0.08       |      0.14 |       0.53 #> 0.20        |      0.08 |       0.42 #> 0.37        |      0.07 |       0.45 #> 0.11        |      0.07 |       0.44 #> 0.06        |      0.27 |       0.46 #> 0.03        |      0.22 |       0.47 #> 0.01        |      0.05 |  -4.79e-03 #> 0.03        |      0.03 |      -0.01 #> -0.14       |      0.24 |       0.24 #> 0.16        |      0.07 |       0.44 #> -0.06       |      0.27 |       0.52 #> 0.06        |      0.18 |       0.09 #> -0.07       |     -0.12 |       0.40 #> 0.01        |     -0.13 |       0.52 #> 0.12        |      0.03 |       0.46 #> -0.17       |     -0.04 |       0.34 #> 0.39        |      0.20 |       0.22 #> -0.04       |     -0.19 |       0.45 #> -0.07       |      0.10 |       0.49 #> -0.10       |      0.14 |       0.42 #> -0.02       |      0.10 |       0.51 #> 0.28        |      0.17 |       0.48 #> 0.24        |      0.13 |       0.40 #> 0.05        |      0.16 |       0.31 #> -2.83e-03   | -6.12e-04 |       0.33 #> -0.02       |     -0.02 |       0.29 #> 0.14        |      0.02 |       0.37 #> -0.20       |      0.29 |       0.42 #> 0.39        |      0.23 |       0.40 #> -0.20       |     -0.10 |       0.52 #> 0.04        |      0.24 |       0.59 #> 0.27        |      0.47 |       0.60 #> -0.30       |     -0.05 |       0.23 #> -0.26       |     -0.15 |       0.59 #> 0.13        |      0.17 |       0.25 #> 0.15        |  2.19e-04 |       0.43 #> 0.04        |     -0.02 |       0.50 #> -0.15       |      0.10 |       0.44 #> -0.26       |     -0.09 |       0.49 #> 0.06        |      0.30 |       0.48 #> 0.03        |      0.42 |       0.48 #> 0.27        |      0.10 |       0.15 #> -0.15       |      0.33 |       0.42 #> -0.17       |      0.28 |       0.35 #> 0.13        |      0.02 |       0.35 #> -0.07       |      0.17 |       0.44 #> 0.03        |     -0.09 |       0.35 #> 0.01        |      0.23 |       0.37 #> -0.07       |      0.50 |       0.39 #> 0.13        |      0.19 |       0.38 #> -0.07       |     -0.07 |       0.47 #> 0.12        |     -0.25 |       0.46 #> -0.36       |      0.21 |       0.40 #> 0.19        |      0.37 |       0.24 #> -0.21       |      0.57 |       0.26 #> -0.36       |      0.26 |       0.42 #> 0.25        |     -0.22 |       0.41 #> -0.34       |      0.51 |       0.43 #> -0.07       |      0.04 |       0.25 #> -0.02       |      0.43 |       0.43 #> -0.13       |  4.30e-03 |       0.58 #> -0.45       |     -0.11 |       0.46 #> 0.42        |      0.06 |       0.18 #> 0.11        |      0.23 |       0.61 #> 0.10        |      0.05 |       0.24 #> 0.12        |      0.20 |       0.41 #> -0.14       |     -0.06 |       0.46 #> 0.16        |      0.17 |       0.44 #> -0.22       |      0.04 |       0.47 #> -0.14       |      0.06 |       0.53 #> 0.16        |      0.08 |       0.38 #> -0.09       |      0.13 |       0.68 #> -0.10       |      0.23 |       0.37 #> -0.06       |     -0.30 |      -0.04 #> 0.05        |     -0.15 |       0.15 #> 0.05        |     -0.19 |       0.19 #> 0.29        |      0.05 |       0.52 #> -0.02       |      0.11 |       0.11 #> 0.03        |      0.07 |       0.71 #> -0.06       |      0.23 |       0.27 #> -0.07       |     -0.20 |       0.45 #> -0.16       |     -0.18 |       0.28 #> 0.21        |     -0.17 |       0.24 #> 0.24        |      0.16 |       0.44 #> -0.04       |  2.35e-03 |       0.50 #> -0.22       |      0.29 |       0.35 #> 0.14        |     -0.01 |       0.42 #> -0.16       |      0.10 |       0.43 #> -0.24       |      0.15 |       0.63 #> -0.07       |      0.11 |       0.47 #> 0.07        |      0.14 |       0.40 #> -0.09       |     -0.04 |       0.53 #> 0.17        |      0.18 |       0.35 #> 0.21        |      0.28 |       0.36 #> -0.07       |     -0.17 |       0.80 #> -0.30       |     -0.30 |       0.32 #> 0.03        |      0.26 |       0.32 #> -0.08       |      0.09 |       0.38 #> 0.08        |      0.06 |       0.52 #> 0.07        |     -0.06 |       0.39 #> 0.20        |     -0.04 |       0.66 #> -0.13       |      0.22 |       0.17 #> -0.12       |      0.21 |       0.18 #> -0.05       |     -0.01 |       0.16 #> -0.04       |      0.02 |       0.24 #> -2.94e-03   |      0.22 |       0.23 #> 0.10        |      0.28 |       0.23 #> 0.16        |      0.35 |       0.69 #> 0.08        |     -0.22 |       0.41 #> -0.29       |      0.13 |       0.60 #> 0.08        |      0.20 |       0.22 #> 0.12        |      0.12 |       0.70 #> -0.36       |     -0.26 |       0.65 #> 0.17        |      0.23 |       0.68 #> -0.05       |     -0.05 |       0.46 #> 0.03        |      0.29 |       0.35 #> -0.16       |     -0.04 |       0.52 #> 0.18        |      0.27 |       0.25 #> 0.04        |      0.08 |       0.43 #> 0.03        |      0.25 |       0.27 #> -0.04       |      0.10 |       0.40 #> -0.22       |      0.12 |       0.32 #> -0.14       |      0.11 |       0.36 #> -0.07       |  7.22e-03 |       0.20 #> -0.08       |  5.93e-03 |       0.44 #> -0.28       |     -0.24 |       0.64 #> -0.09       |      0.16 |       0.20 #> 0.07        |      0.03 |       0.61 #> 0.33        |      0.16 |       0.58 #> 0.29        |      0.06 |       0.58 #> -0.25       |      0.01 |       0.12 #> 0.13        |      0.57 |       0.64 #> -0.07       |     -0.12 |       0.23 #> 0.04        |      0.33 |       0.54 #> 0.01        |      0.27 |       0.59 #> 0.04        |      0.25 |       0.52 #> -0.07       |     -0.06 |       0.33 #> 0.07        |      0.20 |       0.54 #> -0.02       |     -0.10 |       0.29 #> 0.29        |      0.42 |       0.09 #> -0.40       |     -0.22 |       0.58 #> 0.25        |     -0.33 |       0.46 #> -0.21       |      0.26 |       0.39 #> -0.25       |      0.21 |       0.08 #> 0.09        | -3.52e-03 |       0.83 #> 0.07        |      0.12 |       0.56 #> -0.12       |  5.13e-03 |       0.31 #> 0.15        |      0.26 |       0.48 #> 0.04        | -1.21e-03 |       0.39 #> -0.18       |      0.19 |       0.31 #> -0.04       |      0.33 |       0.12 #> 0.03        |     -0.12 |       0.64 #> -0.10       |      0.05 |       0.36 #> 0.10        |      0.15 |       0.43 #> -0.32       |     -0.14 |       0.33 #> -0.08       |     -0.36 |       0.39 #> 0.02        |      0.30 |       0.77 #> 0.03        |      0.13 |       0.26 #> -0.24       |      0.14 |       0.43 #> 0.23        |      0.08 |       0.32 #> -0.22       |      0.09 |       0.68 #> 0.04        | -4.80e-03 |       0.43 #> -0.08       |      0.05 |       0.48 #> -0.01       |      0.17 |       0.34 #> -0.12       |      0.19 |       0.29 #> 0.13        |     -0.07 |       0.55 #> 0.15        |      0.11 |       0.24 #> -0.28       |      0.22 |       0.10 #> 0.04        |      0.28 |       0.48 #> 0.07        |     -0.10 |       0.20 #> 0.07        |      0.08 |       0.32 #> -4.73e-03   |      0.11 |       0.22 #> 0.07        |     -0.14 |       0.07 #> 0.20        |      0.20 |      -0.23 #> -0.46       |      0.25 |       0.68 #> 0.40        |      0.05 |       0.43 #> 0.43        |      0.02 |       0.34 #> -0.42       |      0.14 |       0.59 #> -0.51       |      0.17 |       0.55 #> -0.36       |      0.08 |       0.46 #> -0.18       |      0.09 |       0.43 #> 0.14        |      0.18 |       0.35 #> -0.16       |      0.13 |       0.52 #> 0.05        |      0.09 |       0.28 #> -0.02       |      0.12 |       0.36 #> 0.08        |      0.04 |       0.38 #> -0.04       |     -0.05 |       0.38 #> -0.15       |     -0.15 |       0.55 #> 0.02        |      0.33 |       0.09 #> 6.04e-03    |      0.49 |      -0.04 #> 0.04        |      0.44 |       0.46 #> -0.35       |      0.11 |       0.32 #> 0.14        |      0.35 |       0.63 #> -0.05       |      0.25 |       0.54 #> 0.04        |      0.01 |       0.25 #> -0.06       |      0.06 |       0.44 #> 0.05        |      0.04 |       0.46 #> -0.06       |      0.03 |       0.61 #> -0.03       |     -0.08 |       0.24 #> 0.05        |      0.27 |       0.56 #> -0.05       |      0.43 |       0.47 #> 0.15        |     -0.13 |       0.29 #> -9.33e-03   |     -0.15 |       0.60 #> 0.06        |      0.30 |       0.27 #> 0.10        |      0.32 |       0.32 #> -0.13       |      0.20 |       0.04 #> 0.04        |      0.07 |      -0.04 #> 0.10        |  9.31e-03 |       0.09 #> -0.05       |      0.10 |       0.70 #> 0.06        |      0.04 |       0.63 #> -0.06       |      0.22 |       0.21 #> -0.01       |      0.03 |       0.49 #> 0.08        |      0.23 |       0.35 #> -0.17       |      0.23 |       0.34 #> 0.15        |     -0.09 |       0.53 #> 0.09        |      0.17 |       0.46 #> -0.17       |      0.19 |       0.52 #> 0.16        |      0.04 |       0.27 #> 0.25        |     -0.13 |       0.15 #> -0.02       |      0.37 |       0.69 #> -8.19e-03   |      0.47 |       0.79 #> 0.22        |     -0.14 |       0.25 #> 0.15        |      0.04 |       0.40 #> -0.11       |      0.18 |       0.47 #> 0.07        |      0.11 |       0.42 #> 0.13        |      0.44 |       0.25 #> -3.20e-03   |     -0.22 |       0.51 #> -0.23       |      0.43 |       0.20 #> -0.18       |      0.29 |       0.21 #> 0.25        |      0.31 |       0.51 #> 0.25        |      0.19 |       0.18 #> -0.03       |      0.17 |       0.47 #> -0.18       |      0.43 |       0.32 #> -0.21       |      0.36 |       0.30 #> -0.18       |      0.34 |       0.46 #> 0.10        |      0.07 |       0.56 #> 0.31        |      0.15 |       0.49 #> 0.03        |      0.40 |       0.46 #> -0.36       |      0.07 |       0.42 #> 0.35        |     -0.08 |       0.08 #> -0.30       |      0.28 |       0.72 #> -0.22       |      0.28 |       0.68 #> 0.29        | -1.56e-03 |       0.29 #> -0.29       |      0.32 |       0.47 #> 0.07        |      0.10 |       0.45 #> 0.25        |  3.04e-03 |       0.58 #> -0.09       |      0.60 |       0.56 #> -0.05       |      0.35 |       0.48 #> 0.02        |      0.35 |       0.34 #> -0.13       |     -0.26 |       0.49 #> 9.26e-03    |     -0.14 |       0.30 #> -0.09       |      0.36 |       0.49 #> -0.02       |      0.26 |       0.51 #> -0.26       |      0.15 |       0.20 #> -0.44       |      0.28 |       0.17 #> -0.44       |      0.30 |       0.20 #> -0.37       |      0.36 |       0.21 #> 0.44        |     -0.32 |       0.55 #> -0.55       |      0.23 |       0.04 #> 0.11        |     -0.09 |       0.28 #> 0.18        |     -0.39 |       0.43 #> -0.29       |      0.39 |       0.54 #> -0.34       |     -0.09 |       0.40 #> 0.38        |      0.26 |       0.14 #> -6.14e-03   |      0.18 |       0.13 #> -0.19       |     -0.18 |       0.67 #> -0.24       |     -0.15 |       0.70 #> -0.04       |     -0.12 |       0.19 #> 1.30e-03    |      0.30 |       0.41 #> 0.12        |      0.09 |       0.41 #> -0.08       |      0.12 |       0.54 #> 8.54e-03    |      0.21 |       0.46 #> -0.02       |      0.31 |       0.37 #> -0.12       |      0.33 |       0.43 #> 0.12        |      0.14 |       0.19 #> -0.12       |      0.08 |       0.10 #> 0.10        |      0.15 |       0.68 #> -0.13       |      0.19 |       0.32 #> 0.05        |      0.10 |       0.38 #> -0.20       |      0.37 |       0.48 #> -0.12       |     -0.09 |       0.36 #> -0.19       |     -0.30 |       0.37 #> -0.10       |      0.38 |       0.25 #> -0.21       |     -0.08 |       0.44 #> 6.71e-03    |      0.57 |       0.52 #> 0.04        |     -0.36 |       0.37 #> -0.05       |     -0.32 |       0.47 #> 9.27e-03    |      0.06 |       0.73 #> -0.17       |     -0.23 |       0.55 #> -0.28       |     -0.17 |       0.68 #> -0.35       |     -0.18 |       0.68 #> 0.52        |     -0.25 |       0.65 #> 0.47        |     -0.11 |       0.73 #> 4.85e-03    |     -0.17 |       0.51 #> 0.10        |     -0.09 |       0.69 #> -0.05       |      0.07 |       0.25 #> -0.04       |      0.03 |       0.66 #> -0.03       |      0.30 |       0.07 #> -0.01       |     -0.11 |       0.71 #> 0.15        |      0.12 |       0.47 #> -0.02       |      0.01 |       0.74 #> -0.07       |      0.02 |       0.18 #> -0.04       |      0.33 |      -0.06 #> -0.11       |      0.22 |       0.56 #> -0.01       |     -0.03 |       0.28 #> -0.25       |     -0.16 |       0.47 #> 0.15        |      0.41 |       0.46 #> -0.11       |      0.22 |       0.31 #> 0.20        |     -0.05 |       0.53 #> -0.49       |     -0.11 |       0.39 #> -0.35       |     -0.31 |       0.37 #> -0.16       |      0.71 |      -0.12 #> 0.05        |      0.43 |       0.20 #> 0.19        |      0.05 |       0.23 #> 0.03        |      0.11 |       0.19 #> 0.11        |      0.16 |       0.25 #> 0.21        |      0.16 |       0.10 #> -0.04       |      0.11 |       0.15 #> 0.25        |      0.37 |       0.03 #> -0.03       |      0.21 |       0.44 #> 0.05        |      0.28 |       0.34 #> 0.24        |     -0.10 |       0.22 #> 0.03        |      0.09 |       0.32 #> -0.02       |      0.14 |       0.39 #> 0.16        |      0.27 |       0.32 #> 2.62e-03    |      0.20 |       0.45 #> 0.04        |      0.08 |       0.40 #> 0.06        |      0.02 |       0.47 #> -0.28       |      0.22 |       0.39 #> 6.65e-03    |      0.20 |       0.36 #> -0.07       |      0.38 |       0.10 #> -0.06       |      0.08 |       0.85 #> 0.05        | -9.41e-03 |       0.71 #> -0.07       |      0.11 |       0.34 #> 0.06        |      0.20 |       0.55 #> 0.16        |      0.51 |       0.69 #> 0.11        |      0.27 |       0.66 #> 0.20        |     -0.15 |       0.48 #> 0.18        |     -0.40 |       0.42 #> -0.03       |     -0.14 |       0.34 #> 0.07        |      0.31 |       0.44 #> 0.15        |      0.10 |       0.28 #> 0.07        |      0.09 |       0.37 #> 5.08e-03    |      0.05 |       0.44 #> 0.10        |     -0.03 |       0.74 #> 0.11        |      0.08 |       0.22 #> -0.13       |      0.08 |       0.42 #> 0.25        |      0.50 |      -0.21 #> -0.25       |     -0.35 |       0.56 #> 0.23        |      0.48 |       0.39 #> -0.15       |     -0.10 |       0.18 #> 0.13        |      0.17 |       0.71 #> -0.12       |      0.01 |       0.14 #> -0.07       |      0.06 |      -0.02 #> 0.06        |      0.13 |       0.45 #> -0.04       |      0.26 |       0.37 #> 0.12        | -6.20e-03 |       0.61 #> 0.31        |      0.22 |       0.22 #> -0.23       |      0.34 |       0.57 #> -0.03       |     -0.08 |       0.40 #> 0.13        |      0.11 |       0.56 #> 0.49        |     -0.18 |       0.18 #> -0.13       |      0.08 |       0.25 #> 0.11        |     -0.05 |       0.31 #> 0.04        |      0.26 |       0.60 #> 0.48        |      0.20 |       0.45 #> -0.06       |      0.17 |       0.14 #> 0.06        |      0.09 |       0.62 #> -0.06       |      0.13 |       0.16 #> -0.28       |      0.20 |       0.26 #> 0.05        |     -0.10 |       0.47 #> 0.03        |      0.07 |       0.49 #> 0.08        |      0.10 |       0.24 #> -0.24       |      0.10 |       0.62 #> -0.27       |     -0.08 |       0.50 #> 0.22        |      0.29 |       0.42 #> 0.19        |     -0.13 |       0.81 #> -0.24       |     -0.05 |       0.73 #> -0.22       |  1.06e-03 |       0.66 #> 0.27        |      0.23 |       0.44 #> 0.25        |      0.23 |       0.54 #> -0.24       |     -0.08 |       0.27 #> 0.32        |      0.19 |       0.48 #> -0.04       |      0.17 |       0.46 #> 0.18        |      0.03 |       0.28 #> -0.16       |      0.10 |       0.52 #> 0.18        |      0.10 |       0.31 #> 0.38        |      0.10 |       0.42 #> 0.13        |      0.33 |       0.54 #> -0.11       |      0.20 |       0.70 #> 0.18        |     -0.01 |       0.09 #> 0.27        |     -0.06 |       0.11 #> 0.14        |     -0.13 |       0.38 #> -0.07       |      0.26 |       0.48 #> 0.17        |  2.65e-03 |       0.44 #> 0.10        |      0.04 |       0.33 #> -0.01       |     -0.03 |       0.29 #> 0.09        |     -0.18 |       0.32 #> 0.23        |      0.06 |       0.39 #> -0.12       |     -0.02 |       0.29 #> 0.15        |     -0.10 |       0.43 #> 0.19        |     -0.19 |       0.42 #> 0.29        |     -0.25 |       0.34 #> -0.32       |      0.29 |       0.49 #> -0.06       |      0.16 |       0.33 #> -0.05       |     -0.02 |       0.42 #> 0.12        |      0.05 |       0.33 #> 0.25        | -9.86e-03 |       0.37 #> -0.34       |      0.22 |       0.46 #> 0.03        |      0.26 |       0.45 #> 0.11        |     -0.05 |       0.34 #> 0.08        |     -0.11 |       0.34 #> -0.05       |     -0.04 |       0.42 #> 0.07        |     -0.03 |       0.61 #> 0.20        |      0.46 |      -0.03 #> 0.37        |      0.24 |       0.31 #> -0.33       |      0.10 |       0.29 #> -0.30       |      0.15 |       0.33 #> 0.30        |      0.10 |       0.44 #> 0.38        |      0.25 |       0.48 #> -0.03       |      0.26 |       0.35 #> -0.20       |      0.34 |       0.59 #> 0.01        | -2.23e-04 |       0.20 #> -0.10       |      0.16 |       0.50 #> 0.12        |      0.12 |       0.29 #> 0.09        |     -0.16 |       0.33 #> -0.03       |      0.25 |       0.45 #> -0.21       |      0.25 |       0.60 #> 0.25        |      0.29 |       0.15 #> -0.48       |     -0.02 |       0.05 #> -0.17       | -3.03e-03 |       0.44 #> -0.09       |      0.15 |       0.37 #> 0.09        |     -0.17 |       0.29 #> -0.03       |     -0.06 |       0.18 #> -0.27       |      0.28 |       0.78 #> 0.29        |      0.06 |       0.06 #> -0.38       |      0.11 |       0.80 #> 0.44        |      0.09 |       0.38 #> 0.18        |      0.24 |       0.36 #> 0.20        |      0.30 |       0.41 #> 0.04        |     -0.03 |       0.28 #> -0.10       |      0.20 |       0.53 #> -0.27       |      0.38 |       0.50 #> -0.34       |      0.25 |       0.74 #> -0.23       |      0.24 |       0.76 #> 5.89e-03    |      0.17 |       0.46 #> -0.09       |      0.28 |       0.36 #> -0.11       |      0.29 |       0.33 #> -0.07       |      0.07 |       0.37 #> 0.06        |      0.35 |       0.22 #> -0.07       |      0.02 |       0.07 #> -0.13       |     -0.05 |       0.45 #> 0.08        |      0.14 |       0.42 #> 0.13        | -2.77e-03 |       0.32 #> -0.10       |      0.26 |       0.39 #> -7.22e-05   |     -0.07 |       0.11 #> 0.36        |      0.04 |       0.86 #> -5.37e-03   |      0.36 |       0.23 #> 1.75e-03    |      0.45 |       0.25 #> -0.16       |      0.08 |       0.38 #> 0.19        |      0.22 |       0.14 #> -0.16       |     -0.05 |       0.53 #> 0.19        |      0.34 |       0.20 #> 0.12        |      0.01 |       0.74 #> -0.15       |      0.10 |       0.10 #> 0.14        |      0.08 |       0.43 #> -0.22       |      0.20 |       0.35 #> -0.08       |      0.42 |       0.24 #> -0.10       |      0.46 |       0.15 #> -0.21       |      0.58 |       0.19 #> 0.08        |     -0.18 |       0.76 #> 0.14        |     -0.07 |       0.56 #> 0.02        |      0.08 |       0.19 #> -0.26       |      0.08 |       0.59 #> 0.20        |     -0.22 |       0.94 #> 0.02        |      0.09 |       0.76 #> 0.03        |      0.27 |       0.08 #> 7.74e-04    |      0.06 |       0.74 #> -0.03       |      0.11 |       0.16 #> 0.12        |      0.14 |       0.49 #> 0.26        |      0.09 |       0.49 #> 0.13        |      0.21 |       0.45 #> 0.19        |      0.42 |       0.57 #> 0.04        |     -0.08 |       0.39 #> 0.20        |     -0.11 |       0.24 #> -0.30       |     -0.15 |       0.08 #> 0.16        |      0.17 |       0.71 #> -0.27       |      0.10 |       0.17 #> 0.04        |      0.18 |       0.19 #> 4.83e-03    |     -0.04 |       0.41 #> -0.16       |     -0.23 |       0.35 #> 0.02        |      0.15 |       0.86 #> -0.17       |     -0.17 |       0.15 #> 0.20        |      0.03 |       0.71 #> -0.12       |     -0.14 |       0.41 #> 0.25        |      0.19 |       0.37 #> -0.22       |     -0.15 |       0.54 #> 0.24        |      0.27 |       0.43 #> -0.32       |     -0.05 |       0.15 #> 0.22        |      0.48 |       0.39 #> 0.29        |      0.49 |       0.34 #> -0.45       |     -0.25 |       0.54 #> -0.08       |      0.03 |       0.40 #> 0.15        |      0.21 |       0.45 #> 0.18        |      0.37 |       0.49 #> -0.15       |      0.13 |       0.25 #> -0.04       |      0.32 |       0.04 #> 0.23        |      0.05 |       0.60 #> -0.13       |      0.32 |       0.50 #> -0.03       |      0.42 |       0.37 #> 0.09        |     -0.28 |       0.29 #> -0.09       |      0.53 |       0.50 #> 0.10        |      0.05 |       0.11 #> 0.14        |      0.04 |       0.64 #> 0.14        |      0.01 |       0.61 #> -0.15       |      0.21 |       0.16 #> 0.17        |      0.21 |       0.12 #> -0.06       |      0.06 |       0.44 #> -0.04       |     -0.05 |       0.41 #> 0.06        |      0.23 |       0.52 #> -0.07       |     -0.06 |       0.37 #> 0.11        |      0.45 |       0.47 #> 0.02        |      0.22 |       0.67 #> 0.10        |      0.25 |       0.57 #> 4.83e-03    |      0.15 |       0.44 #> 0.08        |      0.37 |       0.34 #> -0.06       |      0.37 |       0.30 #> 0.20        |      0.24 |       0.33 #> 0.23        |      0.26 |       0.36 #> -0.22       |     -0.14 |       0.56 #> 0.31        |      0.19 |       0.31 #> -0.26       |     -0.20 |       0.57 #> -0.18       |      0.13 |       0.57 #> 0.13        |     -0.02 |       0.32 #> -0.12       |      0.25 |       0.49 #> -3.53e-03   |     -0.12 |      -0.24 #> -0.03       |     -0.19 |      -0.30 #> 0.19        |      0.48 |       0.52 #> -0.21       |     -0.23 |       0.37 #> -0.06       |      0.02 |       0.57 #> 0.10        |      0.09 |       0.38 #> 0.27        |      0.01 |       0.16 #> -0.09       |      0.05 |       0.51 #> -2.43e-03   |     -0.10 |       0.48 #> -0.09       |     -0.01 |       0.37 #> 0.06        |      0.20 |       0.40 #> -0.17       |     -0.14 |       0.57 #> -0.09       |      0.01 |       0.55 #> 0.26        |      0.09 |       0.52 #> 0.25        |     -0.05 |       0.31 #> 0.22        |      0.25 |       0.24 #> -0.14       |     -0.19 |       0.56 #> 0.24        |      0.50 |       0.36 #> -0.24       |     -0.75 |       0.24 #> 0.06        |      0.76 |       0.44 #> 0.14        |     -0.07 |       0.34 #> -0.14       |      0.21 |       0.50 #> -0.05       |      0.35 |       0.56 #> 0.13        |     -0.19 |       0.37 #> 0.05        |      0.34 |       0.46 #> 0.06        |     -0.10 |       0.46 #> -0.02       |      0.37 |       0.45 #> -0.02       |      0.16 |       0.48 #> -0.17       |      0.12 |       0.46 #> 0.05        |  9.72e-04 |       0.51 #> 0.21        |     -0.14 |       0.50 #> 0.20        |      0.11 |       0.43 #> 5.15e-03    |     -0.11 |       0.36 #> 0.30        |     -0.36 |       0.54 #> 0.46        |     -0.31 |       0.26 #> 0.09        |      0.20 |       0.51 #> -0.08       |      0.13 |       0.33 #> 0.12        |      0.05 |       0.49 #> -0.01       |     -0.04 |       0.67 #> 0.10        |     -0.03 |       0.24 #> 0.03        |     -0.06 |       0.39 #> -0.20       |      0.15 |       0.32 #> 0.17        |     -0.31 |       0.52 #> -0.18       |      0.24 |       0.18 #> 0.26        |      0.10 |       0.55 #> -0.22       |      0.06 |       0.28 #> 0.15        |      0.26 |       0.54 #> -0.16       |     -0.11 |       0.37 #> 0.16        |      0.20 |       0.53 #> -0.10       |      0.13 |       0.25 #> 0.05        |     -0.07 |       0.59 #> -0.05       |      0.02 |       0.44 #> 0.35        |     -0.12 |       0.37 #> -0.23       |      0.12 |       0.39 #> -7.69e-03   |      0.11 |       0.39 #> -0.19       |     -0.03 |       0.57 #> 0.18        |      0.10 |       0.35 #> -0.10       |     -0.05 |       0.30 #> 0.13        |      0.33 |       0.43 #> 0.06        |      0.27 |       0.34 #> -0.08       |     -0.10 |       0.47 #> -0.37       |     -0.34 |       0.14 #> -0.31       |      0.30 |       0.48 #> -0.15       |      0.20 |       0.53 #> 0.16        |      0.27 |       0.35 #> -0.01       |      0.04 |       0.59 #> -0.01       |      0.04 |       0.14 #> 0.14        |      0.14 |       0.31 #> -0.15       |      0.24 |       0.40 #> 0.27        |     -0.03 |       0.39 #> -0.24       |      0.22 |       0.40 #> -0.19       |      0.15 |       0.48 #> -0.25       |     -0.08 |       0.41 #> -0.16       |      0.24 |       0.54 #> -0.16       |      0.26 |       0.56 #> 0.24        |     -0.01 |       0.37 #> -0.05       |      0.09 |       0.63 #> 0.07        |      0.07 |       0.19 #> -0.03       |      0.07 |       0.56 #> -0.09       | -5.36e-03 |       0.56 #> -0.11       |      0.32 |       0.58 #> 0.19        |     -0.33 |       0.50 #> 0.17        |     -0.09 |       0.70 #> 0.12        |      0.20 |       0.53 #> 0.12        |      0.07 |       0.78 #> -0.28       |      0.28 |       0.55 #> -0.31       |      0.49 |       0.42 #> -0.47       |      0.46 |       0.46 #> -0.21       |      0.34 |       0.38 #> -0.03       |      0.18 |       0.50 #> 0.02        |      0.05 |       0.30 #> 0.02        |      0.12 |       0.26 #> -0.06       |  1.38e-03 |       0.48 #> 0.21        |      0.16 |       0.59 #> -0.13       |     -0.11 |       0.31 #> 0.02        |     -0.03 |       0.45 #> -0.09       |      0.09 |       0.30 #> -0.12       |      0.02 |       0.45 #> -0.10       |      0.08 |       0.55 #> -0.47       |      0.16 |       0.18 #> -0.22       |      0.23 |       0.28 #> -5.22e-03   |      0.01 |       0.36 #> 0.14        | -6.28e-03 |       0.60 #> 0.16        |      0.19 |       0.63 #> -0.42       |     -0.04 |       0.33 #> -0.22       |     -0.16 |       0.44 #> 0.09        |     -0.37 |       0.41 #> -0.15       |      0.34 |       0.31 #> 0.19        |     -0.25 |       0.48 #> -0.15       |      0.23 |       0.18 #> -0.17       |      0.20 |       0.23 #> -0.14       |     -0.02 |       0.15 #> -0.18       |      0.10 |       0.28 #> 0.04        |      0.09 |       0.70 #> -6.28e-03   |     -0.08 |       0.82 #> -0.09       |      0.31 |      -0.09 #> -0.05       |      0.44 |   8.26e-03 #> 0.19        |      0.30 |       0.44 #> -0.02       |     -0.10 |       0.37 #> 0.20        |      0.07 |       0.40 #> 0.04        |      0.12 |       0.31 #> -0.04       |      0.03 |       0.60 #> 0.03        |      0.04 |       0.24 #> -0.13       |      0.26 |       0.56 #> 0.23        |      0.06 |       0.29 #> 0.21        |     -0.11 |       0.22 #> -0.13       |      0.18 |       0.60 #> 0.12        |     -0.04 |       0.29 #> -0.22       |      0.28 |       0.51 #> 0.16        |      0.03 |       0.20 #> -0.03       |      0.02 |       0.28 #> 0.04        |      0.04 |       0.70 #> 0.15        |      0.02 |       0.42 #> -0.02       | -4.77e-03 |       0.44 #> -0.11       |      0.19 |       0.42 #> 0.11        |     -0.07 |       0.72 #> -0.19       |     -0.17 |       0.59 #> -0.14       |     -0.05 |       0.70 #> 0.14        |      0.15 |       0.49 #> -0.41       |     -0.02 |       0.41 #> 0.08        |      0.31 |       0.50 #> 0.05        |      0.05 |       0.64 #> 0.13        |     -0.18 |       0.78 #> -0.12       |      0.39 |      -0.09 #> -0.04       |      0.34 |      -0.03 #> 0.07        |     -0.06 |       0.81 #> -0.11       |      0.24 |       0.05 #> -0.02       |      0.16 |      -0.03 #> 0.15        |     -0.20 |       0.28 #> -0.02       |     -0.02 |       0.48 #> 0.02        |      0.18 |       0.34 #> -0.06       |      0.12 |       0.33 #> -0.06       |      0.12 |       0.52 #> 0.07        |      0.09 |       0.66 #> -3.22e-03   |      0.08 |       0.38 #> 0.15        |     -0.13 |       0.35 #> 0.10        |     -0.24 |       0.35 #> 0.25        |      0.12 |       0.39 #> 0.12        |      0.12 |       0.44 #> -0.08       |      0.02 |       0.46 #> 0.15        |     -0.04 |       0.44 #> -0.15       |      0.18 |       0.46 #> 0.03        |     -0.06 |       0.18 #> -0.08       |     -0.09 |       0.13 #> 0.01        |      0.18 |       0.22 #> 0.16        |     -0.18 |       0.46 #> 0.05        |     -0.26 |       0.19 #> 0.02        |      0.27 |       0.52 #> -0.20       |      0.05 |       0.19 #> -0.09       |      0.03 |       0.22 #> 0.04        |      0.18 |       0.48 #> -0.30       |      0.02 |       0.46 #> 0.04        |      0.06 |       0.06 #> 0.06        |      0.24 |       0.73 #> 0.09        |      0.19 |       0.59 #> -0.09       |     -0.02 |       0.24 #> 0.26        |      0.01 |       0.29 #> 0.21        |      0.09 |       0.22 #> 0.02        |      0.16 |       0.58 #> -0.03       |      0.03 |       0.21 #> -0.11       |     -0.06 |       0.58 #> -0.24       |     -0.12 |       0.70 #> -0.20       |  1.30e-03 |       0.59 #> -0.23       |     -0.06 |       0.61 #> -4.03e-03   |      0.06 |       0.30 #> 0.04        |      0.03 |       0.45 #> -0.09       |      0.05 |       0.42 #> 0.27        |     -0.15 |       0.29 #> -0.05       |      0.27 |       0.68 #> -0.07       |      0.08 |       0.71 #> -0.03       |     -0.06 |       0.37 #> 0.05        |      0.07 |       0.34 #> 0.16        |      0.26 |       0.45 #> -0.23       |      0.08 |       0.21 #> 0.16        |      0.06 |       0.54 #> 0.11        |      0.04 |       0.46 #> -0.18       |      0.12 |       0.55 #> -0.36       |      0.12 |       0.90 #> -0.05       |      0.35 |       0.92 #> -0.09       |     -0.11 |       0.11 #> 0.06        |      0.34 |       0.62 #> 0.02        |      0.28 |       0.61 #> -0.06       | -3.23e-03 |       0.27 #> -0.09       |      0.13 |       0.73 #> 0.10        |     -0.32 |       0.71 #> -0.43       |      0.38 |       0.58 #> 0.33        |     -0.14 |       0.80 #> -0.38       |      0.27 |       0.43 #> 0.27        |      0.13 |       0.43 #> -0.14       |     -0.15 |       0.47 #> 0.02        |     -0.15 |       0.40 #> 0.15        |      0.05 |       0.17 #> -0.46       |     -0.07 |       0.44 #> 0.62        |      0.03 |       0.48 #> -0.45       |      0.38 |       0.40 #> 0.23        |     -0.16 |       0.34 #> -0.33       |      0.28 |       0.39 #> 0.07        |     -0.32 |       0.41 #> -0.08       |      0.56 |       0.40 #> -0.05       |     -0.04 |       0.44 #> -0.18       |     -0.06 |       0.36 #> -0.15       |      0.02 |       0.46 #> -0.28       |      0.29 |       0.18 #> 0.03        |      0.26 |       0.46 #> -0.27       |      0.11 |       0.16 #> 0.22        |      0.58 |       0.53 #> -0.24       |     -0.22 |       0.12 #> -0.25       |     -0.26 |       0.18 #> 0.11        |      0.47 |       0.12 #> 0.04        |     -0.14 |       0.17 #> -0.09       |      0.31 |       0.65 #> -0.11       |      0.27 |       0.61 #> 0.01        |     -0.05 |       0.51 #> 0.12        |      0.02 |       0.30 #> -0.32       |      0.05 |       0.17 #> 4.21e-03    |      0.01 |       0.47 #> -0.05       |     -0.10 |       0.41 #> -0.03       |      0.14 |       0.27 #> -0.13       |      0.02 |       0.47 #> -0.09       |      0.29 |       0.23 #> -0.28       |      0.19 |       0.50 #> -0.17       |      0.13 |       0.48 #> -0.10       |      0.08 |       0.42 #> 9.86e-03    |      0.14 |       0.67 #> -0.23       |      0.02 |       0.43 #> 0.22        |     -0.13 |       0.51 #> 0.07        |      0.20 |       0.44 #> -0.08       |      0.04 |       0.35 #> 0.10        |      0.13 |       0.46 #> 0.27        |      0.24 |       0.20 #> 0.26        |      0.25 |       0.08 #> -0.19       |     -0.05 |       0.52 #> -0.19       |      0.11 |       0.56 #> -0.20       |      0.20 |       0.39 #> 0.06        |      0.27 |      -0.05 #> 0.22        |      0.12 |       0.41 #> -0.21       |      0.07 |       0.46 #> 0.25        |      0.24 |       0.46 #> -0.27       |      0.40 |       0.63 #> -0.21       |      0.11 |       0.43 #> 0.08        |      0.12 |       0.48 #> -0.09       |      0.08 |       0.69 #> -0.17       |      0.10 |       0.86 #> 0.04        |      0.06 |       0.62 #> -9.54e-03   |      0.26 |       0.11 #> -0.12       |      0.02 |       0.48 #> 0.04        |     -0.04 |       0.57 #> 0.22        |     -0.02 |       0.47 #> -0.21       |      0.16 |       0.25 #> 0.04        |      0.12 |       0.43 #> 0.04        |      0.02 |       0.45 #> -2.26e-04   |      0.16 |       0.30 #> 0.10        |      0.11 |       0.52 #> -0.15       |      0.14 |       0.30 #> 0.04        |      0.05 |       0.13 #> -0.05       |      0.25 |       0.34 #> 0.07        |     -0.06 |       0.51 #> -0.10       |      0.31 |       0.36 #> -0.07       |      0.07 |       0.61 #> -0.18       |      0.51 |       0.32 #> 0.27        |     -0.17 |       0.41 #> -0.24       |      0.28 |       0.48 #> -0.22       |     -0.22 |       0.24 #> -0.17       |     -0.38 |       0.31 #> -0.16       |     -0.23 |       0.41 #> 0.23        |     -0.25 |       0.49 #> -0.11       |      0.53 |       0.33 #> -0.09       |     -0.01 |       0.34 #> -0.14       |      0.10 |       0.53 #> -0.10       |      0.50 |       0.68 #> 0.10        |     -0.39 |       0.22 #> -0.06       |      0.61 |       0.55 #> 0.03        |      0.31 |       0.32 #> -0.01       |     -0.06 |       0.43 #> -0.06       |      0.25 |       0.44 #> -0.02       | -1.12e-03 |       0.44 #> -0.04       |      0.12 |       0.11 #> 0.10        |      0.06 |       0.04 #> -0.09       |      0.17 |       0.62 #> 0.14        |     -0.02 |       0.33 #> -0.06       |      0.22 |       0.08 #> 0.01        |      0.02 |       0.62 #> -0.06       |      0.26 |       0.32 #> 0.04        |     -0.08 |       0.49 #> -0.16       |      0.05 |       0.45 #> 0.19        |      0.18 |       0.32 #> -0.05       |      0.35 |       0.48 #> -0.04       |     -0.21 |       0.21 #> 0.01        |      0.39 |       0.67 #> -0.14       |     -0.01 |       0.47 #> -0.19       |      0.11 |       0.37 #> -0.09       |      0.07 |       0.29 #> 0.04        |  3.19e-03 |       0.32 #> 0.02        |      0.03 |       0.65 #> 0.03        |     -0.01 |       0.04 #> -0.02       |      0.14 |       0.82 #> -0.02       |      0.01 |       0.07 #> 0.02        |     -0.04 |       0.47 #> 0.01        |      0.11 |       0.50 #> -0.16       |      0.21 |       0.24 #> 0.19        |     -0.13 |       0.59 #> -0.20       |      0.27 |       0.19 #> 0.06        |      0.09 |       0.56 #> -0.08       |      0.09 |       0.33 #> -0.18       |      0.20 |       0.36 #> 0.02        |      0.20 |       0.40 #> -0.10       |      0.18 |       0.27 #> -0.12       |  7.47e-03 |       0.34 #> -0.10       |      0.12 |       0.41 #> 0.05        |     -0.04 |       0.44 #> 0.19        |     -0.04 |       0.35 #> 0.23        |     -0.10 |       0.18 #> -0.03       |      0.24 |       0.44 #> 0.13        |     -0.07 |       0.48 #> 0.41        |     -0.15 |       0.48 #> -0.27       |      0.07 |       0.16 #> 0.20        |      0.21 |       0.28 #> 0.21        |      0.29 |       0.30 #> 0.03        |      0.24 |       0.48 #> 0.02        |     -0.01 |       0.39 #> -0.09       |      0.19 |       0.38 #> 0.26        |      0.12 |       0.35 #> 0.35        |      0.22 |       0.34 #> -0.08       |      0.33 |       0.27 #> 0.17        |     -0.17 |       0.35 #> 0.18        |      0.09 |       0.60 #> -0.13       |      0.41 |       0.23 #> 0.09        |     -0.15 |       0.47 #> 0.02        |      0.24 |       0.57 #> 0.09        | -9.34e-03 |       0.25 #> -0.07       |      0.02 |       0.18 #> -0.09       |      0.38 |       0.41 #> -0.09       |     -0.13 |       0.54 #> -0.02       |      0.37 |       0.53 #> 0.03        |     -0.01 |       0.12 #> 0.09        |      0.12 |       0.37 #> 0.07        |      0.22 |       0.36 #> -0.13       |     -0.01 |       0.51 #> 0.19        |      0.05 |       0.23 #> -0.40       |     -0.07 |       0.16 #> -0.16       |     -0.02 |       0.06 #> 0.11        |      0.36 |       0.74 #> -0.10       |     -0.05 |       0.49 #> 0.23        |      0.31 |       0.64 #> 0.12        |      0.19 |       0.58 #> 0.17        |      0.17 |       0.65 #> -0.23       |     -0.02 |       0.24 #> 0.20        |      0.16 |       0.41 #> -7.86e-03   |      0.14 |       0.40 #> -7.05e-03   |      0.09 |       0.35 #> -6.48e-03   |      0.10 |       0.03 #> 0.09        |      0.16 |       0.65 #> 0.10        |      0.09 |       0.61 #> -0.17       |     -0.11 |       0.40 #> -0.14       |      0.14 |       0.37 #> 0.17        |      0.02 |       0.56 #> -0.09       |      0.32 |       0.26 #> -0.06       |      0.34 |       0.23 #> -0.09       |      0.36 |       0.41 #> 0.05        |     -0.13 |       0.38 #> -0.39       |     -0.11 |       0.60 #> 0.35        |      0.36 |       0.37 #> 0.27        |      0.31 |       0.28 #> 0.23        |      0.22 |       0.24 #> -0.23       |     -0.01 |       0.44 #> -0.18       |     -0.09 |       0.39 #> 0.14        |      0.33 |       0.38 #> 5.55e-03    |      0.15 |       0.53 #> 8.28e-03    |      0.24 |       0.54 #> -0.04       |      0.35 |       0.57 #> 8.42e-03    |      0.46 |       0.58 #> 0.07        | -4.12e-03 |       0.41 #> -0.03       |      0.10 |       0.51 #> 0.10        |      0.15 |       0.30 #> -0.08       | -6.35e-03 |       0.42 #> 0.15        |     -0.04 |       0.55 #> -2.32e-03   |      0.05 |       0.47 #> 0.26        |      0.12 |       0.27 #> 0.32        |      0.12 |       0.34 #> -0.31       |      0.08 |       0.38 #> -0.13       |      0.10 |       0.23 #> 0.27        |      0.27 |       0.18 #> -0.26       |     -0.07 |       0.68 #> 0.23        |      0.25 |       0.20 #> 0.17        |      0.15 |       0.37 #> -0.18       |      0.13 |       0.45 #> 0.19        |      0.10 |       0.11 #> -0.37       |      0.48 |       0.41 #> -0.04       |     -0.09 |       0.43 #> -0.23       |      0.14 |       0.46 #> 0.23        |     -0.03 |       0.23 #> 0.16        | -7.88e-05 |       0.25 #> -0.04       |     -0.07 |       0.42 #> -0.01       |      0.18 |       0.39 #> 0.01        |     -0.08 |       0.38 #> -0.02       |      0.28 |       0.38 #> 0.20        |      0.16 |       0.32 #> -1.88e-03   |      0.11 |       0.29 #> 0.15        |      0.07 |       0.45 #> 0.03        |     -0.03 |       0.38 #> -0.07       |      0.18 |       0.53 #> -0.02       |      0.01 |       0.31 #> 0.02        |      0.13 |       0.44 #> 0.01        |     -0.02 |       0.48 #> -0.21       |      0.30 |       0.10 #> -0.08       | -5.46e-03 |       0.82 #> 0.09        |      0.19 |       0.01 #> -0.09       |     -0.03 |       0.70 #> -5.18e-03   |     -0.02 |       0.54 #> -0.19       |      0.08 |       0.35 #> 0.03        |      0.26 |       0.36 #> -0.10       |     -0.14 |       0.49 #> -0.13       |      0.36 |       0.45 #> 0.04        |     -0.21 |       0.39 #> 0.10        |      0.30 |       0.40 #> -0.10       |      0.26 |       0.36 #> -0.09       |      0.20 |       0.44 #> -0.23       |      0.16 |       0.65 #> 0.04        |      0.14 |       0.47 #> -0.02       |      0.27 |       0.50 #> 0.17        |      0.08 |       0.37 #> -0.10       |     -0.04 |       0.36 #> 0.08        |      0.21 |       0.38 #> -0.08       |     -0.02 |       0.49 #> -0.05       |      0.07 |       0.50 #> 0.24        |     -0.11 |       0.42 #> 0.19        |      0.05 |       0.14 #> 0.03        |     -0.02 |       0.49 #> 0.12        |      0.13 |       0.25 #> 0.02        |      0.02 |       0.34 #> -0.04       |      0.18 |       0.50 #> -0.09       |     -0.17 |       0.50 #> -0.08       |  2.51e-03 |       0.60 #> -0.12       |      0.30 |       0.31 #> 0.11        |      0.14 |       0.51 #> -0.14       | -3.62e-03 |       0.23 #> 0.12        |      0.11 |       0.51 #> 0.10        |      0.16 |       0.40 #> -0.13       |      0.09 |       0.44 #> -0.19       |      0.14 |       0.56 #> 0.06        |      0.06 |       0.42 #> 0.06        |      0.13 |       0.37 #> -0.08       |      0.06 |       0.46 #> 0.26        |      0.40 |       0.53 #> 0.04        |      0.13 |       0.47 #> 0.27        |      0.10 |       0.17 #> 0.06        |      0.15 |       0.61 #> 0.04        |      0.18 |      -0.18 #> 0.05        |     -0.14 |       0.85 #> -0.06       |     -0.03 |       0.60 #> -0.02       |     -0.06 |       0.61 #> 0.08        |      0.06 |       0.92 #> 0.01        |      0.04 |       0.66 #> 2.71e-03    |      0.02 |       0.45 #> 0.13        |      0.19 |       0.26 #> 0.05        |      0.17 |       0.68 #> -0.06       |     -0.03 |       0.13 #> -0.11       |      0.35 |       0.57 #> 0.07        |     -0.29 |       0.38 #> 0.10        |      0.15 |       0.26 #> -0.03       |      0.05 |       0.39 #> 0.21        |      0.16 |       0.49 #> 0.07        |      0.33 |       0.69 #> 4.91e-03    |      0.10 |       0.45 #> -0.05       |      0.11 |       0.61 #> 0.04        |  2.61e-03 |       0.82 #> 2.10e-04    |      0.08 |       0.12 #> 0.08        |      0.14 |       0.17 #> -0.23       |      0.30 |       0.37 #> -0.05       |  9.34e-03 |       0.48 #> -0.06       |      0.03 |       0.38 #> -0.14       |      0.25 |       0.29 #> 0.16        |     -0.02 |       0.51 #> -0.13       |      0.19 |       0.07 #> 0.02        |      0.05 |       0.87 #> -4.20e-03   |      0.14 |       0.03 #> 0.17        |     -0.31 |       0.87 #> 0.12        |     -0.24 |       0.84 #> -0.03       |      0.55 |       0.11 #> -0.10       |      0.55 |       0.27 #> -0.06       |      0.36 |       0.40 #> 0.18        |      0.09 |       0.33 #> 0.05        |      0.37 |       0.13 #> 0.04        |      0.03 |       0.17 #> 0.04        |      0.13 |       0.55 #> 0.18        |      0.22 |       0.57 #> -0.07       |  8.50e-04 |       0.35 #> -0.02       |     -0.12 |       0.46 #> 0.21        |     -0.04 |       0.94 #> 0.10        |     -0.09 |       0.48 #> 0.19        |  8.70e-03 |       0.42 #> -0.09       |     -0.03 |       0.41 #> 0.11        |     -0.06 |       0.34 #> 0.21        |     -0.03 |       0.54 #> -0.03       | -5.13e-03 |       0.51 #> -0.02       |      0.18 |       0.38 #> -0.20       |      0.29 |       0.63 #> 0.20        |      0.15 |       0.64 #> -0.32       |      0.08 |       0.20 #> 0.39        |      0.16 |       0.60 #> -0.30       |  9.65e-03 |       0.27 #> -0.30       |      0.15 |       0.23 #> 0.26        |     -0.16 |       0.75 #> -0.24       |      0.38 |      -0.10 #> 0.14        |      0.37 |       0.32 #> -0.25       |  2.82e-03 |       0.31 #> -0.21       |  7.21e-03 |       0.35 #> 0.16        |      0.06 |       0.39 #> -0.09       |      0.05 |       0.69 #> -0.06       |      0.05 |       0.52 #> -0.03       |     -0.09 |       0.49 #> 0.10        |      0.13 |       0.47 #> 0.16        |      0.07 |       0.44 #> 0.01        |      0.18 |       0.48 #> -0.07       |     -0.04 |       0.33 #> -0.08       |      0.11 |       0.38 #> 0.06        |      0.05 |       0.41 #> -0.03       |      0.17 |       0.23 #> -0.09       |     -0.03 |       0.52 #> -0.03       |      0.17 |       0.75 #> 0.17        |     -0.05 |       0.38 #> -0.23       |      0.10 |       0.39 #> -0.02       |      0.19 |       0.54 #> 1.18e-03    |      0.14 |       0.55 #> 0.03        |      0.35 |       0.24 #> -0.05       |     -0.04 |       0.16 #> 0.39        |      0.30 |       0.62 #> 0.33        |      0.22 |       0.62 #> 0.06        |      0.04 |       0.57 #> 0.07        |      0.07 |       0.50 #> 0.01        |     -0.06 |       0.29 #> -0.07       |      0.26 |       0.55 #> -0.05       |     -0.05 |       0.63 #> -0.07       |     -0.16 |       0.59 #> -0.03       |      0.49 |       0.20 #> 0.08        |      0.76 |       0.34 #> -0.16       |     -0.25 |       0.34 #> -0.15       |      0.18 |       0.55 #> 0.07        |      0.05 |       0.55 #> 0.08        |      0.28 |       0.36 #> 0.06        |      0.06 |       0.46 #> -0.04       |      0.17 |       0.55 #> 0.13        |     -0.19 |       0.48 #> 5.69e-03    |      0.08 |       0.79 #> -0.16       |      0.03 |       0.72 #> 3.43e-03    |     -0.18 |       0.57 #> 0.15        |     -0.06 |       0.41 #> -0.10       |      0.05 |       0.33 #> -0.16       |      0.29 |       0.33 #> 0.07        |     -0.07 |       0.56 #> 0.14        |     -0.10 |       0.50 #> -0.18       |      0.15 |       0.33 #> -0.23       |      0.09 |       0.20 #> 0.14        |     -0.10 |       0.53 #> -0.17       |     -0.04 |       0.39 #> -0.33       |     -0.32 |       0.32 #> 0.46        |     -0.03 |       1.00 #> 0.35        |     -0.02 |       0.49 #> 0.35        |      0.19 |       0.34 #> 0.03        |      0.15 |       0.38 #> 5.49e-03    |      0.24 |       0.21 #> 0.16        |      0.12 |       0.43 #> 0.13        |      0.09 |       0.47 #> -0.16       |      0.27 |       0.65 #> -0.05       |      0.29 |       0.59 #> 0.07        |     -0.11 |       0.35 #> -0.07       |      0.35 |       0.40 #> -0.06       |      0.39 |       0.37 #> 0.15        |      0.14 |       0.07 #> -0.17       |      0.08 |       0.73 #> 0.17        |      0.20 |      -0.02 #> -0.03       |      0.16 |       0.57 #> -0.24       |      0.43 |       0.47 #> 0.30        |     -0.02 |       0.51 #> 0.12        |      0.19 |       0.58 #> 0.08        |     -0.11 |       0.34 #> -0.08       |      0.22 |       0.32 #> -0.10       |      0.15 |       0.43 #> -0.04       |      0.25 |       0.43 #> -0.26       |     -0.17 |       0.54 #> 0.15        |      0.16 |  -8.54e-03 #> -0.10       |  5.80e-03 |       0.74 #> 0.09        |      0.22 |   5.64e-03 #> 0.02        |      0.16 |       0.45 #> 0.29        |     -0.02 |       0.27 #> -0.29       |      0.28 |       0.47 #> 0.24        |      0.01 |       0.29 #> 0.14        |      0.05 |       0.31 #> -0.02       |      0.07 |       0.27 #> 0.02        |      0.12 |       0.59 #> 0.12        |      0.11 |       0.25 #> 0.28        |      0.14 |       0.39 #> -0.22       |      0.34 |       0.35 #> -0.05       |     -0.08 |       0.45 #> 0.08        |      0.13 |       0.47 #> -0.11       |      0.28 |       0.46 #> 0.11        |     -0.02 |       0.27 #> 0.16        |      0.29 |       0.27 #> 0.17        |     -0.07 |       0.48 #> -0.22       |      0.26 |       0.39 #> -0.03       |      0.28 |       0.37 #> -3.92e-03   |      0.32 |       0.29 #> -0.27       |      0.42 |       0.10 #> 0.28        |     -0.25 |       0.62 #> 0.22        |     -0.16 |       0.57 #> 0.34        | -1.52e-03 |       0.40 #> 0.02        |      0.04 |       0.34 #> 0.13        |     -0.03 |       0.33 #> 0.04        |      0.41 |       0.27 #> -0.09       |     -0.12 |       0.43 #> -0.04       |      0.07 |       0.42 #> -0.05       |      0.11 |       0.58 #> -0.02       |     -0.05 |       0.38 #> 0.13        |  2.70e-05 |       0.79 #> -0.17       |      0.04 |       0.10 #> 0.16        |      0.36 |       0.48 #> -0.18       |     -0.04 |       0.35 #> -5.67e-03   |     -0.16 |       0.32 #> 0.05        |     -0.03 |       0.35 #> 0.20        |     -0.03 |       0.34 #> -0.19       |      0.19 |       0.51 #> 0.23        |      0.03 |       0.33 #> 0.24        |      0.08 |       0.49 #> -0.28       |      0.29 |       0.73 #> 0.25        |     -0.30 |       0.18 #> -0.08       |     -0.09 |       0.28 #> 0.05        |      0.05 |       0.69 #> -0.29       |     -0.07 |       0.72 #> 0.27        |      0.18 |       0.16 #> -0.34       |      0.33 |       0.31 #> 0.20        |      0.20 |       0.58 #> -0.16       |      0.03 |       0.19 #> -0.08       |      0.11 |       0.27 #> 0.06        |      0.11 |       0.56 #> -0.10       |      0.02 |       0.26 #> 0.13        |      0.28 |       0.39 #> 0.10        |      0.38 |       0.39 #> 0.05        |     -0.05 |       0.33 #> -0.14       |      0.07 |       0.42 #> 0.02        |     -0.20 |       0.56 #> 0.06        |      0.38 |       0.36 #> 0.11        |     -0.09 |       0.62 #> 0.06        |     -0.08 |       0.58 #> -0.27       |      0.34 |       0.07 #> -0.26       |      0.27 |       0.30 #> 0.04        |      0.13 |       0.45 #> 0.02        |      0.03 |       0.45 #> -0.03       |      0.13 |       0.42 #> 0.03        |     -0.13 |       0.66 #> 0.05        |     -0.12 |       0.63 #> 0.13        |     -0.02 |       0.49 #> -0.22       |      0.35 |       0.53 #> 0.22        |     -0.09 |       0.25 #> -0.20       |      0.29 |       0.66 #> -0.39       |      0.31 |       0.70 #> 0.22        |     -0.55 |       0.34 #> -0.26       |     -0.03 |       0.34 #> 0.16        |     -0.13 |       0.65 #> 0.12        | -8.94e-04 |       0.82 #> -0.11       |      0.09 |       0.16 #> -0.03       |      0.06 |       0.19 #> 0.04        |      0.11 |       0.70 #> 0.12        |      0.02 |       0.60 #> 0.02        |      0.07 |       0.28 #> -0.13       |      0.28 |       0.60 #> 0.24        |      0.12 |       0.26 #> 0.17        |      0.19 |      -0.01 #> 0.24        |      0.27 |      -0.10 #> 0.20        |      0.16 |  -7.38e-03 #> 0.20        |      0.13 |       0.14 #> 0.11        |      0.20 |       0.26 #> -0.18       |      0.16 |       0.73 #> -0.28       |     -0.08 |       0.74 #> 0.35        |     -0.09 |       0.57 #> -0.37       |     -0.14 |       0.23 #> -0.34       |      0.18 |       0.46 #> -0.27       |      0.11 |       0.40 #> 0.23        |      0.06 |       0.43 #> -0.17       |      0.21 |       0.18 #> 0.18        |  4.16e-03 |       0.52 #> 0.10        | -9.36e-03 |       0.41 #> 0.08        |     -0.13 |       0.36 #> 0.01        |      0.20 |       0.57 #> -0.01       |      0.24 |       0.47 #> 0.18        |      0.10 |       0.23 #> -0.21       |      0.10 |       0.40 #> 0.18        |      0.10 |       0.44 #> -0.05       |      0.21 |       0.30 #> 0.15        |      0.24 |       0.40 #> 0.20        |      0.28 |       0.25 #> -0.13       |      0.12 |       0.52 #> 0.15        |      0.16 |       0.17 #> 0.01        |      0.20 |       0.60 #> 0.12        |      0.26 |       0.85 #> 0.43        |      0.43 |       0.28 #> -0.29       |     -0.11 |       0.47 #> -0.10       |     -0.19 |       0.50 #> 0.12        |      0.41 |       0.36 #> 0.07        |      0.12 |       0.37 #> -0.11       |      0.10 |       0.50 #> -0.02       |     -0.07 |       0.56 #> -0.08       |     -0.10 |       0.20 #> 0.04        |     -0.11 |       0.56 #> 0.06        |     -0.24 |       0.48 #> -0.10       |     -0.21 |       0.57 #> -0.12       |     -0.15 |       0.63 #> 8.12e-03    |     -0.03 |       0.54 #> 1.89e-03    |      0.29 |       0.23 #> -0.07       |     -0.28 |       0.55 #> -0.07       |      0.01 |       0.60 #> -0.33       |      0.08 |       0.32 #> 0.33        |     -0.08 |       0.68 #> -0.28       |      0.22 |       0.14 #> -0.06       |      0.08 |       0.33 #> 0.03        |      0.19 |       0.11 #> 0.08        |     -0.02 |       0.67 #> -0.02       |      0.18 |       0.85 #> 0.02        |     -0.06 |       0.11 #> 0.11        |      0.14 |       0.41 #> 0.10        |      0.03 |       0.37 #> -0.37       |      0.20 |       0.64 #> -0.05       |      0.06 |       0.41 #> 0.07        |      0.12 |       0.40 #> -0.09       |      0.03 |       0.41 #> -0.07       |     -0.14 |       0.64 #> 0.09        |      0.23 |       0.23 #> 8.75e-03    |      0.28 |       0.27 #> -0.05       |      0.02 |       0.40 #> 0.11        |      0.23 |       0.41 #> 0.12        | -7.17e-03 |       0.55 #> -0.12       |      0.18 |       0.34 #> 0.08        |      0.08 |       0.53 #> -0.17       |      0.09 |       0.20 #> -0.21       |      0.07 |       0.27 #> 0.13        |     -0.21 |       0.59 #> -0.16       |      0.28 |       0.16 #> 0.10        |      0.13 |       0.40 #> 0.19        |      0.23 |       0.34 #> -0.15       |     -0.07 |       0.44 #> -0.20       |      0.04 |       0.13 #> 0.03        |      0.17 |       0.33 #> 0.01        |      0.38 |       0.57 #> -0.17       |     -0.03 |       0.53 #> 0.09        |      0.10 |       0.51 #> -0.02       |  9.66e-03 |       0.38 #> 0.19        |     -0.09 |       0.09 #> 0.26        |     -0.05 |       0.14 #> -0.11       |      0.23 |       0.55 #> -0.09       |      0.13 |       0.58 #> 0.21        |      0.26 |       0.44 #> -0.02       |      0.17 |       0.64 #> 0.08        |      0.08 |       0.28 #> -0.06       |      0.07 |       0.57 #> 1.80e-03    |      0.16 |       0.13 #> -0.05       |     -0.02 |       0.75 #> 0.12        |      0.27 |       0.10 #> 0.11        |      0.18 |       0.18 #> -0.15       |     -0.06 |       0.61 #> 0.05        |     -0.02 |       0.57 #> 0.09        |      0.31 |       0.39 #> -0.15       |     -0.08 |       0.36 #> 0.08        |      0.06 |       0.39 #> -0.11       |      0.06 |       0.50 #> 0.05        |      0.13 |       0.36 #> -1.86e-03   |     -0.04 |       0.31 #> -0.07       |      0.08 |       0.34 #> -0.01       |     -0.04 |       0.42 #> -0.24       | -8.31e-03 |       0.45 #> 0.16        |      0.14 |       0.38 #> -0.09       |      0.24 |       0.52 #> -0.12       |      0.23 |       0.54 #> -1.63e-03   |      0.24 |       0.42 #> 0.13        |     -0.13 |       0.39 #> -0.19       |      0.26 |       0.40 #> 0.15        |      0.05 |       0.69 #> -0.11       |     -0.04 |       0.77 #> -0.08       |     -0.02 |       0.46 #> -0.08       |      0.23 |       0.25 #> 0.20        |      0.12 |       0.37 #> 0.21        |      0.44 |       0.08 #> -0.10       |      0.56 |       0.21 #> 0.05        |     -0.24 |       0.54 #> -0.14       |  5.78e-03 |       0.39 #> 0.04        |     -0.03 |       0.26 #> -0.19       |      0.07 |       0.59 #> 0.05        |      0.03 |       0.57 #> -6.94e-03   |      0.36 |       0.41 #> -0.05       |      0.24 |       0.26 #> 0.02        |      0.24 |       0.48 #> -0.10       |      0.30 |       0.56 #> -0.03       |     -0.15 |       0.34 #> 0.03        |      0.16 |       0.54 #> 1.39e-03    |      0.02 |       0.25 #> -0.12       |      0.16 |       0.49 #> -0.12       |      0.40 |       0.59 #> 0.18        |     -0.34 |       0.27 #> -0.05       |     -0.10 |       0.32 #> -0.03       |      0.30 |       0.45 #> -4.39e-03   |     -0.09 |       0.35 #> 0.04        |      0.23 |       0.21 #> 0.15        |      0.09 |       0.28 #> -0.17       |      0.01 |       0.47 #> -0.30       |     -0.16 |       0.49 #> -0.30       |     -0.15 |       0.37 #> 0.20        |      0.40 |       0.29 #> -0.27       |     -0.05 |       0.33 #> 0.21        |      0.05 |       0.60 #> 0.27        |      0.11 |       0.74 #> -0.46       |      0.10 |      -0.02 #> 0.18        |      0.30 |       0.57 #> 0.52        |      0.14 |       0.65 #> -0.05       |     -0.05 |       0.37 #> -0.10       |     -0.14 |       0.58 #> -0.08       |     -0.27 |       0.43 #> -0.08       |      0.46 |       0.33 #> 0.03        |     -0.30 |       0.52 #> 0.22        |     -0.16 |       0.56 #> -0.38       |     -0.18 |       0.69 #> 0.30        |      0.24 |       0.27 #> 0.18        |      0.12 |       0.35 #> -0.11       |      0.33 |       0.48 #> 0.08        |     -0.02 |       0.29 #> -0.04       |      0.24 |       0.57 #> 0.01        |     -0.07 |       0.47 #> -0.11       |      0.09 |       0.60 #> 0.12        |  6.19e-03 |       0.46 #> -0.08       |     -0.02 |       0.54 #> 0.04        |      0.11 |       0.43 #> -0.02       |     -0.19 |       0.20 #> -0.01       |      0.34 |       0.56 #> 0.30        |      0.22 |       0.31 #> 0.13        |      0.12 |       0.46 #> 0.16        |  7.32e-03 |       0.35 #> -0.18       |      0.17 |       0.57 #> 0.12        |      0.10 |       0.29 #> -0.14       |     -0.05 |       0.65 #> 0.14        |      0.21 |       0.21 #> 0.11        |      0.07 |       0.21 #> 0.36        |      0.01 |       0.35 #> -0.34       |      0.16 |       0.41 #> 0.31        |      0.04 |       0.52 #> -0.08       |      0.06 |       0.22 #> -0.18       |      0.03 |       0.60 #> -0.06       |     -0.14 |       0.53 #> -0.07       |      0.43 |       0.13 #> 0.38        |      0.33 |       0.13 #> 0.05        |      0.03 |       0.29 #> 0.22        |      0.07 |       0.43 #> -0.02       |     -0.24 |       0.60 #> 0.06        |     -0.24 |       0.39 #> 0.07        |      0.05 |       0.37 #> -0.07       |      0.25 |       0.55 #> 0.09        |     -0.02 |       0.29 #> 0.11        |     -0.33 |       0.21 #> -0.11       |      0.52 |       0.61 #> -2.49e-03   |      0.55 |       0.53 #> 0.23        |     -0.12 |       0.32 #> -0.22       |      0.51 |       0.72 #> -7.83e-03   |      0.02 |       0.31 #> -0.02       |     -0.28 |       0.34 #> -0.17       |      0.12 |       0.14 #> -0.03       |      0.27 |       0.23 #> -0.05       |      0.18 |       0.25 #> 0.02        |     -0.15 |       0.59 #> -0.06       |     -0.11 |       0.49 #> -0.05       |      0.18 |       0.30 #> -0.02       |      0.19 |       0.50 #> 0.04        |  8.18e-03 |       0.30 #> 4.86e-03    |      0.17 |       0.46 #> -0.18       |      0.25 |       0.32 #> -0.22       |      0.16 |       0.27 #> 0.23        |     -0.04 |       0.67 #> -0.03       |  5.25e-03 |       0.48 #> 0.03        |      0.14 |       0.22 #> 0.02        |      0.16 |       0.17 #> -0.03       |      0.21 |       0.32 #> 0.21        |      0.09 |       0.90 #> 0.02        |      0.19 |       0.56 #> -0.24       |     -0.05 |       0.30 #> 0.12        |     -0.17 |       0.30 #> 2.36e-03    |      0.19 |       0.46 #> 0.03        | -4.38e-03 |       0.34 #> -0.03       |      0.19 |       0.43 #> 0.02        |      0.04 |       0.42 #> -0.06       |      0.04 |       0.23 #> 0.02        |      0.48 |       0.48 #> -0.02       |     -0.30 |       0.41 #> 0.15        |      0.13 |       0.69 #> -0.11       |      0.07 |       0.29 #> -0.27       |      0.31 |       0.27 #> 0.13        |     -0.17 |       0.51 #> -0.17       |      0.12 |       0.64 #> 0.06        |  6.60e-03 |       0.57 #> 0.16        |      0.28 |       0.08 #> -0.19       |      0.14 |       0.30 #> -0.03       |     -0.01 |       0.22 #> -0.22       |     -0.06 |       0.19 #> -0.27       |     -0.02 |       0.22 #> 0.21        |      0.16 |       0.45 #> 0.16        |     -0.08 |       0.35 #> 8.09e-03    | -3.45e-03 |       0.35 #> -2.85e-03   |      0.03 |       0.68 #> -0.08       |      0.06 |       0.18 #> -0.02       |      0.22 |       0.66 #> 0.02        |      0.04 |       0.31 #> 0.15        |      0.03 |       0.54 #> -0.12       |      0.11 |       0.26 #> 0.09        |      0.20 |       0.30 #> -0.47       |      0.18 |       0.13 #> -0.51       |      0.09 |       0.25 #> -0.48       |      0.09 |       0.13 #> 0.33        |      0.45 |       0.61 #> -0.24       |     -0.30 |       0.39 #> 0.12        |      0.21 |       0.48 #> 0.13        |      0.51 |       0.14 #> -0.07       |     -0.28 |       0.74 #> 0.14        |     -0.39 |       0.61 #> -0.18       |      0.42 |       0.16 #> -0.14       |      0.12 |       0.41 #> 0.27        |      0.13 |       0.36 #> -0.21       |      0.02 |       0.55 #> 0.17        |      0.21 |       0.30 #> -0.14       |      0.01 |       0.31 #> -0.05       |      0.07 |       0.40 #> 0.16        |     -0.02 |       0.66 #> -0.03       |      0.16 |       0.44 #> -0.01       |      0.24 |       0.34 #> 0.03        |     -0.15 |       0.62 #> 0.16        |      0.02 |       0.70 #> -0.17       |      0.14 |       0.17 #> 0.10        |      0.23 |       0.51 #> 0.03        |      0.11 |       0.53 #> -0.04       |      0.02 |       0.44 #> -0.02       |      0.15 |       0.36 #> 0.08        |      0.06 |       0.50 #> -0.09       |      0.27 |       0.32 #> -0.07       |      0.08 |      -0.22 #> 0.07        |      0.18 |       0.09 #> -0.07       |      0.10 |       0.57 #> 0.04        | -1.49e-03 |       0.34 #> 0.34        |     -0.04 |       0.38 #> 0.15        |      0.35 |       0.42 #> -0.03       |     -0.12 |       0.36 #> -0.02       |      0.15 |       0.56 #> -0.30       |      0.13 |       0.43 #> 0.34        |      0.11 |       0.27 #> 0.04        |      0.29 |       0.27 #> -0.29       |     -0.16 |       0.49 #> -0.15       |  8.34e-03 |       0.44 #> 0.11        |      0.13 |       0.44 #> 0.05        |      0.21 |       0.35 #> -0.12       |      0.02 |       0.52 #> 0.06        |     -0.11 |       0.47 #> -0.01       |      0.24 |       0.30 #> 0.04        | -9.57e-03 |       0.55 #> -0.05       |      0.11 |       0.35 #> 0.07        |      0.10 |       0.33 #> -0.09       |      0.02 |       0.63 #> 0.20        |      0.15 |       0.23 #> -0.19       |     -0.11 |       0.80 #> -0.23       |      0.10 |       0.21 #> 0.29        |      0.08 |       0.68 #> 0.15        |      0.14 |       0.37 #> 0.49        |      0.18 |       0.81 #> -0.33       |      0.23 |       0.24 #> 0.14        |      0.02 |       0.63 #> 0.11        |     -0.11 |       0.62 #> 0.10        |     -0.16 |       0.43 #> -0.11       |     -0.24 |       0.46 #> 0.06        |      0.22 |       0.73 #> 0.02        |     -0.15 |       0.26 #> -0.12       |     -0.04 |       0.15 #> -0.05       |      0.30 |       0.76 #> 0.36        |      0.20 |       0.22 #> 0.02        |      0.23 |       0.35 #> 0.02        |      0.04 |       0.28 #> 0.07        |      0.20 |       0.32 #> 0.15        |      0.12 |       0.44 #> 0.14        |     -0.10 |       0.39 #> -0.14       |      0.07 |       0.27 #> -0.14       |     -0.02 |       0.43 #> 0.04        |      0.21 |       0.29 #> -0.11       |      0.11 |       0.38 #> -0.30       |      0.19 |       0.38 #> 0.15        |     -0.10 |       0.40 #> 0.02        |      0.36 |       0.07 #> -0.08       |      0.27 |       0.32 #> -0.21       |      0.30 |       0.32 #> 0.23        |     -0.19 |       0.57 #> -0.18       |      0.32 |       0.34 #> 0.24        |      0.09 |       0.34 #> -0.03       |      0.42 |       0.43 #> -0.02       |      0.34 |       0.47 #> 0.04        |      0.08 |       0.22 #> 0.03        |      0.13 |       0.57 #> 0.15        |      0.05 |       0.28 #> -0.02       |     -0.07 |       0.34 #> -0.13       |      0.03 |       0.20 #> -0.18       |      0.12 |       0.43 #> -0.21       |      0.25 |       0.41 #> 0.03        |      0.08 |       0.50 #> 0.06        |      0.07 |       0.66 #> -0.36       |     -0.17 |       0.65 #> 0.18        |      0.38 |       0.20 #> 0.22        |      0.26 |       0.12 #> -0.19       |      0.06 |       0.64 #> -0.12       |      0.16 |       0.56 #> -0.02       |      0.31 |       0.49 #> 0.17        |      0.07 |       0.32 #> -0.08       |      0.13 |       0.55 #> -0.17       | -3.16e-03 |       0.43 #> -0.10       |      0.20 |       0.38 #> 0.29        |      0.17 |       0.51 #> 0.27        |      0.11 |       0.55 #> -0.35       |      0.30 |       0.20 #> 0.11        |     -0.15 |       0.56 #> -0.04       |      0.05 |      -0.01 #> 0.06        |      0.06 |       0.39 #> -0.30       |     -0.12 |       0.67 #> -0.06       |     -0.10 |       0.39 #> 0.02        |      0.21 |       0.59 #> -0.02       |      0.27 |       0.48 #> -0.17       |      0.31 |       0.35 #> -0.20       |      0.22 |       0.44 #> -0.29       |     -0.11 |       0.38 #> 0.24        |      0.34 |       0.32 #> -0.29       |     -0.13 |       0.46 #> 0.53        |      0.20 |       0.18 #> 0.20        |      0.16 |       0.22 #> -0.21       |      0.12 |       0.65 #> 0.09        |      0.12 |       0.06 #> 0.01        |      0.02 |       0.78 #> -0.05       |      0.21 |       0.10 #> 0.04        |      0.25 |       0.04 #> -0.12       |      0.10 |       0.31 #> 0.10        |      0.04 |       0.21 #> -0.05       |      0.06 |       0.55 #> -0.08       |     -0.03 |       0.48 #> 0.09        |      0.18 |       0.39 #> -0.15       |      0.05 |       0.08 #> 0.06        |      0.26 |       0.55 #> 0.06        |     -0.19 |       0.34 #> -0.08       |      0.32 |       0.42 #> 0.15        |     -0.12 |       0.42 #> -0.05       |      0.20 |       0.59 #> 0.06        |     -0.04 |       0.44 #> -0.08       |      0.06 |       0.39 #> -0.14       |      0.11 |       0.51 #> 0.03        |      0.06 |       0.36 #> -1.44e-03   |      0.23 |       0.45 #> -8.11e-03   |      0.07 |       0.26 #> -8.85e-03   |      0.03 |       0.48 #> -0.35       |     -0.24 |       0.58 #> 0.27        |      0.41 |       0.46 #> -0.32       |     -0.34 |       0.46 #> 0.31        |      0.54 |       0.33 #> -0.33       |     -0.14 |       0.05 #> 0.31        |      0.08 |       0.57 #> -0.33       |      0.04 |       0.33 #> 0.08        |      0.06 |       0.21 #> -0.25       |      0.17 |       0.58 #> 0.38        |      0.17 |       0.05 #> 0.17        |      0.04 |       0.13 #> 0.28        |      0.19 |       0.36 #> -0.30       |     -0.04 |       0.42 #> 0.36        |      0.24 |       0.39 #> -0.26       |      0.12 |       0.51 #> 0.10        |      0.15 |       0.28 #> 0.09        |     -0.09 |       0.06 #> 0.05        |     -0.12 |       0.50 #> 0.29        |     -0.23 |       0.35 #> -0.23       |      0.13 |       0.65 #> 0.26        |      0.10 |       0.16 #> 0.21        |      0.16 |       0.26 #> -0.22       |      0.12 |       0.47 #> 0.27        |      0.05 |       0.35 #> -0.15       |      0.13 |       0.70 #> 0.28        |      0.28 |       0.19 #> -0.43       |      0.06 |       0.62 #> 0.02        |      0.16 |      -0.02 #> 0.01        |      0.18 |       0.65 #> 0.06        |     -0.09 |       0.22 #> 0.13        |      0.19 |       0.28 #> -0.01       |      0.37 |       0.16 #> 0.12        |      0.09 |       0.50 #> -0.08       |      0.09 |       0.31 #> -0.10       |      0.08 |       0.54 #> 0.13        |      0.10 |       0.32 #> -0.06       |     -0.19 |       0.33 #> 6.21e-03    |      0.45 |       0.19 #> 0.04        |      0.35 |       0.34 #> 0.09        |      0.33 |       0.49 #> 0.02        |      0.21 |       0.45 #> -0.23       |     -0.03 |       0.40 #> -0.01       |      0.10 |       0.42 #> -0.03       |     -0.06 |       0.54 #> -9.43e-03   |  3.89e-03 |       0.45 #> -0.12       |      0.02 |       0.39 #> -0.12       |     -0.38 |       0.57 #> 0.06        |     -0.24 |       0.52 #> 0.13        |      0.11 |       0.24 #> 0.33        |      0.44 |       0.14 #> -0.11       |      0.16 |       0.37 #> 0.21        |      0.05 |       0.49 #> -0.11       |      0.15 |       0.59 #> 0.09        |      0.12 |       0.19 #> -0.06       |      0.13 |       0.61 #> 0.05        |      0.28 |       0.14 #> -0.01       |     -0.12 |       0.39 #> 0.09        |     -0.03 |       0.49 #> 0.05        |      0.16 |       0.42 #> 0.09        |      0.02 |       0.38 #> 0.24        |      0.13 |       0.46 #> 0.16        |      0.13 |       0.49 #> 0.09        |     -0.15 |       0.59 #> -0.14       |      0.29 |       0.25 #> -0.13       |      0.26 |       0.31 #> 0.11        |     -0.12 |       0.47 #> -0.11       |     -0.04 |       0.33 #> -0.08       | -7.28e-03 |       0.21 #> -0.19       |      0.26 |       0.59 #> 0.30        |      0.11 |      -0.03 #> -0.10       |      0.30 |       0.02 #> -0.24       |      0.16 |       0.16 #> 0.37        |      0.30 |       0.20 #> -0.25       |     -0.16 |       0.63 #> 0.02        |      0.20 |       0.42 #> 0.21        |     -0.02 |       0.24 #> -0.27       |      0.18 |       0.37 #> 0.08        |     -0.16 |       0.31 #> -0.07       |      0.40 |       0.45 #> -0.42       |     -0.29 |       0.61 #> 7.47e-03    |      0.02 |       0.59 #> -0.05       |      0.27 |       0.34 #> 4.15e-04    |      0.30 |       0.37 #> -0.01       |      0.03 |       0.39 #> -0.04       |  2.56e-03 |       0.31 #> 0.06        |      0.19 |       0.33 #> 0.02        |     -0.22 |       0.42 #> -0.05       |      0.40 |       0.36 #> 0.03        |     -0.24 |       0.49 #> -0.42       |      0.26 |       0.48 #> -0.04       |      0.22 |       0.39 #> 0.42        |      0.11 |       0.59 #> 6.14e-03    |      0.22 |       0.33 #> 0.03        |     -0.10 |       0.50 #> 0.23        |      0.19 |       0.09 #> 0.08        |      0.11 |       0.28 #> -7.03e-03   |      0.15 |       0.54 #> 0.20        |     -0.02 |       0.29 #> 0.06        |  6.78e-04 |       0.77 #> 0.17        |      0.06 |       0.02 #> -0.18       |      0.08 |       0.69 #> 0.04        |     -0.48 |       0.38 #> -0.06       |      0.41 |       0.55 #> -0.10       |      0.22 |       0.53 #> 0.02        |      0.28 |       0.30 #> 0.05        |      0.12 |       0.53 #> 0.15        |      0.03 |       0.29 #> 0.25        |      0.12 |       0.12 #> 0.30        |      0.18 |       0.16 #> -0.23       |      0.02 |       0.61 #> -0.06       |      0.11 |       0.49 #> 0.15        |      0.08 |       0.57 #> -0.19       |      0.13 |       0.29 #> 0.26        |      0.30 |       0.21 #> 0.27        |      0.42 |       0.33 #> -0.33       |     -0.24 |       0.51 #> 0.26        |      0.29 |       0.52 #> -0.13       |     -0.15 |       0.25 #> 0.29        |      0.18 |       0.82 #> -0.31       |     -0.08 |       0.21 #> 0.41        |      0.20 |       1.01 #> 0.22        |      0.15 |       1.01 #> 0.22        |      0.03 |       1.04 #> 0.14        | -8.50e-04 |       1.06 #> 0.18        |      0.08 |       0.85 #> -6.72e-03   |      0.05 |       0.52 #> 0.04        |      0.09 |       0.61 #> -0.13       |      0.21 |       0.31 #> 0.12        |     -0.15 |       0.52 #> -0.07       |     -0.14 |       0.43 #> 0.09        |      0.21 |       0.37 #> -0.15       |      0.07 |       0.46 #> -0.24       |      0.07 |       0.29 #> 0.35        |      0.24 |       0.22 #> 0.30        |      0.30 |       0.19 #> 0.17        |      0.17 |       0.27 #> 0.10        |      0.32 |       0.01 #> -0.03       |     -0.02 |       0.69 #> -0.20       |     -0.11 |       0.28 #> 0.18        |      0.27 |       0.52 #> -0.17       |     -0.06 |       0.34 #> 0.06        |     -0.16 |       0.44 #> 0.10        |     -0.05 |       0.53 #> 0.13        |     -0.07 |       0.65 #> -0.23       |      0.13 |       0.25 #> -0.19       |     -0.36 |       0.70 #> 0.18        |      0.50 |       0.18 #> 0.07        |      0.24 |       0.36 #> -0.12       |      0.06 |       0.25 #> 0.08        |      0.11 |       0.42 #> 0.15        |      0.17 |       0.41 #> -0.21       |      0.08 |       0.50 #> -0.32       |     -0.08 |       0.40 #> 0.33        |      0.36 |       0.40 #> -0.27       |     -0.19 |       0.48 #> 0.25        |      0.38 |       0.30 #> 0.03        |      0.18 |       0.28 #> 0.15        |     -0.04 |       0.71 #> -0.11       |      0.08 |       0.12 #> 0.06        |      0.13 |       0.20 #> -0.05       |     -0.08 |       0.31 #> -0.12       |      0.18 |       0.36 #> 0.09        |      0.09 |       0.50 #> 0.08        |  6.52e-03 |       0.57 #> -0.04       |      0.14 |       0.33 #> 0.12        |      0.16 |       0.17 #> -0.16       |      0.20 |       0.42 #> 0.24        |     -0.04 |       0.33 #> 0.13        |     -0.02 |       0.40 #> -0.11       |      0.48 |       0.21 #> -0.06       |      0.22 |       0.08 #> -0.13       |     -0.07 |       0.35 #> 0.14        |      0.22 |       0.53 #> -0.05       |      0.04 |       0.17 #> 0.09        |      0.32 |       0.54 #> 0.05        |      0.20 |       0.55 #> -0.31       |     -0.02 |       0.36 #> 0.27        |      0.18 |       0.54 #> -0.13       |      0.06 |       0.56 #> -3.70e-03   |      0.16 |       0.22 #> 0.08        |      0.22 |       0.82 #> 0.11        |     -0.17 |       0.65 #> -0.05       |      0.14 |       0.54 #> 0.06        |      0.07 |       0.24 #> 0.08        |      0.47 |       0.29 #> -0.11       |     -0.08 |       0.29 #> 0.19        |      0.09 |       0.51 #> -0.22       |      0.03 |       0.25 #> 0.09        |      0.11 |       0.41 #> 0.19        |      0.29 |       0.56 #> 0.06        |      0.17 |       0.33 #> -0.08       |     -0.30 |       0.49 #> 0.09        |     -0.17 |       0.47 #> -0.05       |  3.70e-03 |       0.54 #> 0.35        |      0.35 |       0.55 #> -0.12       |      0.35 |       0.24 #> -0.03       |      0.31 |       0.36 #> -0.05       |      0.42 |       0.43 #> 0.04        |     -0.22 |       0.45 #> 0.10        |     -0.31 |       0.46 #> -0.19       |      0.41 |       0.33 #> 0.18        |     -0.21 |       0.36 #> -0.21       |      0.32 |       0.51 #> -0.05       |      0.16 |       0.36 #> -0.17       |      0.15 |       0.61 #> -0.41       |      0.14 |       0.44 #> -0.53       |      0.17 |       0.35 #> -0.49       |      0.09 |       0.38 #> -0.63       |      0.22 |      -0.13 #> 0.25        |     -0.33 |       0.09 #> 0.40        |     -0.14 |       0.36 #> 0.32        |      0.13 |       0.05 #> -0.28       |      0.02 |       0.67 #> -0.30       |      0.23 |       0.67 #> -0.17       |      0.15 |       0.50 #> 0.14        |      0.03 |       0.38 #> 0.03        |      0.21 |       0.61 #> -9.16e-03   |     -0.02 |       0.21 #> 0.03        |      0.25 |       0.57 #> 0.08        |      0.14 |       0.72 #> 0.27        |      0.07 |      -0.02 #> 0.23        |      0.33 |       0.20 #> 0.12        |      0.39 |       0.20 #> 0.32        |      0.05 |       0.25 #> 0.02        |     -0.24 |       0.50 #> 0.13        |     -0.33 |       0.52 #> -0.05       |  8.27e-03 |       0.53 #> -0.06       |      0.35 |       0.36 #> 0.07        |      0.17 |       0.24 #> 0.04        |      0.13 |       0.44 #> 0.11        |      0.04 |       0.38 #> 0.21        |     -0.03 |       0.35 #> 0.16        |     -0.05 |       0.69 #> -0.03       |      0.14 |       0.42 #> 0.08        |      0.20 |       0.44 #> 0.46        |     -0.09 |       0.69 #> 0.42        |      0.05 |       0.61 #> -0.42       |     -0.05 |       0.33 #> -0.03       |      0.15 |       0.45 #> 0.02        |      0.08 |       0.39 #> 0.12        |     -0.23 |       0.27 #> 0.12        |     -0.18 |       0.39 #> -0.19       |      0.12 |       0.54 #> -0.11       |      0.07 |       0.09 #> -0.04       |      0.04 |       0.04 #> 0.03        |      0.03 |       0.41 #> -0.05       |     -0.02 |       0.39 #> 0.21        |      0.13 |       0.59 #> 0.30        |      0.27 |       0.46 #> 0.33        |      0.47 |       0.21 #> 0.05        |      0.24 |       0.65 #> 0.18        |     -0.09 |       0.25 #> -0.11       |      0.01 |       0.29 #> -0.28       |     -0.11 |      -0.11 #> -0.20       |     -0.24 |       0.14 #> 0.13        |      0.43 |       0.69 #> -0.05       |      0.12 |       0.54 #> 0.14        |      0.02 |       0.50 #> -0.07       |      0.13 |       0.45 #> 0.04        |      0.02 |       0.35 #> 0.08        |      0.18 |       0.41 #> 0.08        |      0.21 |       0.46 #> 0.13        |      0.46 |       0.49 #> -0.02       |      0.38 |       0.70 #> -0.10       | -3.65e-03 |       0.12 #> -0.10       |     -0.09 |      -0.02 #> 0.31        |      0.28 |       0.54 #> 0.36        |      0.49 |       0.70 #> -0.11       |     -0.31 |       0.53 #> -0.16       |      0.37 |       0.45 #> 0.13        |     -0.03 |       0.44 #> 0.20        |     -0.05 |       0.38 #> 0.57        |  1.32e-03 |       0.34 #> -0.07       |      0.39 |       0.75 #> 0.08        |      0.09 |       0.61 #> -0.10       |     -0.07 |       0.12 #> 0.09        |      0.10 |       0.66 #> -0.07       |      0.16 |       0.23 #> 0.27        |      0.12 |       0.64 #> 0.03        |      0.25 |       0.26 #> -0.20       |      0.30 |       0.22 #> -0.14       |      0.08 |       0.33 #> 0.03        |      0.34 |       0.46 #> -0.09       |      0.23 |       0.49 #> 0.13        |      0.14 |       0.24 #> -0.06       |      0.04 |       0.26 #> 1.23e-03    |      0.05 |       0.38 #> -0.19       |     -0.02 |       0.33 #> -0.22       |     -0.16 |       0.41 #> -0.01       |      0.23 |       0.43 #> 0.17        |      0.18 |   2.61e-03 #> -0.10       |      0.31 |       0.41 #> 0.09        |     -0.08 |       0.29 #> 0.11        |  7.67e-03 |       0.30 #> 0.05        |      0.48 |       0.45 #> 0.12        |      0.32 |       0.59 #> 0.05        |      0.09 |       0.35 #> 0.12        |     -0.05 |       0.34 #> -0.12       |      0.27 |       0.49 #> -0.12       |      0.11 |       0.14 #> 0.09        |      0.12 |       0.49 #> -0.08       |  2.87e-03 |       0.42 #> -0.32       | -9.69e-03 |       0.42 #> -0.03       |     -0.11 |       0.29 #> -0.07       |      0.09 |       0.49 #> 0.11        |     -0.06 |       0.51 #> 0.21        |      0.08 |       0.71 #> -0.34       |      0.12 |       0.32 #> 0.45        |  7.72e-03 |       0.47 #> 0.06        |      0.03 |       0.56 #> 0.10        |      0.08 |       0.21 #> -0.18       |     -0.05 |       0.72 #> 0.21        |      0.22 |       0.19 #> 0.23        |      0.20 |       0.14 #> 0.02        |      0.29 |       0.13 #> -0.21       |      0.33 |       0.28 #> 0.18        |     -0.04 |       0.61 #> 0.30        |      0.22 |       0.61 #> 0.03        |      0.15 |       0.51 #> -0.17       |     -0.02 |       0.27 #> -0.29       |     -0.19 |       0.32 #> -0.02       |      0.46 |      -0.05 #> -0.02       |      0.45 |       0.11 #> 0.02        |      0.51 |       0.08 #> 0.40        |     -0.14 |       0.55 #> 0.18        |     -0.34 |       0.53 #> 0.33        |     -0.33 |       0.64 #> 0.39        |     -0.22 |       0.67 #> 0.27        |      0.09 |       0.62 #> -0.21       |      0.12 |       0.20 #> 0.23        |      0.03 |       0.64 #> -0.09       |      0.40 |       0.45 #> -0.21       |     -0.13 |       0.32 #> 0.13        |      0.06 |       0.61 #> 0.06        |     -0.10 |       0.47 #> -0.06       |      0.21 |       0.46 #> 0.14        |     -0.09 |       0.34 #> -0.03       |      0.38 |      -0.02 #> -9.63e-03   |     -0.10 |       0.69 #> -0.06       |      0.17 |       0.60 #> 0.27        |      0.08 |       0.21 #> -0.46       |      0.54 |       0.40 #> -0.36       |      0.35 |       0.67 #> 0.25        |     -0.07 |       0.21 #> 0.13        |      0.23 |       0.22 #> -0.05       |     -0.01 |       0.47 #> -0.47       |      0.08 |       0.48 #> -0.21       |      0.03 |       0.52 #> 0.13        |      0.08 |       0.42 #> -0.07       |      0.03 |       0.46 #> -0.07       |      0.41 |       0.41 #> -0.08       |      0.17 |       0.55 #> 0.17        |      0.20 |       0.27 #> 0.03        |      0.17 |      -0.03 #> -5.38e-03   |      0.09 |       0.78 #> -0.14       |      0.12 |      -0.10 #> 0.12        |     -0.03 |       0.74 #> -0.06       |      0.34 |       0.21 #> 0.08        |     -0.14 |       0.57 #> 0.08        |      0.15 |       0.41 #> -0.13       |      0.14 |       0.36 #> 6.66e-03    |      0.14 |       0.35 #> -0.06       |      0.02 |       0.41 #> 0.24        |      0.15 |       0.59 #> 0.04        |      0.11 |       0.28 #> 0.05        |      0.12 |       0.59 #> -0.06       |      0.11 |       0.24 #> 0.07        |      0.04 |       0.69 #> 0.05        |      0.06 |       0.44 #> -0.03       |      0.17 |       0.41 #> -0.12       |      0.11 |       0.47 #> 0.13        |      0.06 |       0.37 #> -0.12       |      0.13 |       0.47 #> 0.04        |      0.02 |       0.35 #> 0.06        |      0.22 |       0.43 #> -4.97e-03   |      0.09 |       0.17 #> 0.32        |      0.03 |       0.39 #> -0.12       |     -0.06 |       0.65 #> 0.13        |      0.27 |       0.18 #> -0.12       |     -0.19 |       0.56 #> -0.08       |     -0.10 |       0.60 #> 0.04        |      0.26 |       0.64 #> 0.09        |      0.28 |       0.67 #> 0.14        |      0.20 |       0.51 #> -0.04       |     -0.04 |       0.50 #> 0.11        |     -0.12 |       0.68 #> 0.04        |      0.29 |       0.24 #> -0.14       |     -0.06 |       0.63 #> -0.22       |      0.10 |       0.85 #> 0.26        |      0.02 |       0.15 #> 0.26        |      0.02 |       0.15 #> -0.17       |      0.27 |       0.52 #> 0.04        |      0.22 |       0.01 #> 0.09        |     -0.03 |       0.37 #> -0.02       |      0.22 |       0.22 #> -0.18       |      0.36 |       0.29 #> 0.11        |      0.10 |       0.60 #> 0.03        |      0.03 |       0.36 #> -0.03       |     -0.03 |       0.50 #> -0.04       |      0.32 |       0.41 #> -0.22       |      0.26 |       0.48 #> 0.03        |      0.04 |       0.51 #> 0.05        |      0.10 |       0.35 #> 0.04        |      0.44 |       0.58 #> -0.07       |     -0.09 |       0.50 #> 8.61e-03    |  2.87e-03 |       0.27 #> 0.04        |      0.21 |       0.19 #> 0.02        |      0.20 |       0.37 #> 0.15        |      0.11 |       0.42 #> -0.18       |      0.01 |       0.40 #> 0.15        |      0.11 |       0.40 #> 0.14        |     -0.01 |       0.46 #> -0.13       |      0.21 |       0.34 #> 0.20        |      0.16 |       0.64 #> -0.26       |      0.08 |       0.06 #> 0.25        |      0.28 |       0.33 #> -0.19       |      0.03 |       0.40 #> 0.25        |      0.07 |       0.49 #> -0.29       |      0.08 |       0.40 #> -6.48e-03   |      0.02 |       0.37 #> -0.06       |      0.02 |       0.52 #> 0.08        |      0.11 |       0.34 #> -0.03       |     -0.07 |       0.62 #> 5.48e-03    |      0.04 |       0.59 #> 0.05        |      0.05 |       0.52 #> -0.12       |     -0.02 |       0.13 #> 0.02        |      0.26 |       0.44 #> 0.02        |      0.23 |       0.24 #> -0.32       |      0.29 |       0.33 #> 0.27        |     -0.01 |       0.39 #> -0.30       |      0.04 |       0.62 #> 0.16        |      0.06 |       0.39 #> -0.19       |      0.23 |       0.22 #> -0.07       |     -0.01 |       0.87 #> 0.01        |      0.08 |       0.16 #> -0.02       |      0.23 |       0.62 #> -0.33       |      0.40 |       0.34 #> -0.18       |      0.30 |       0.40 #> 0.02        |     -0.27 |       0.35 #> -0.06       |      0.27 |       0.58 #> 0.19        |      0.31 |       0.29 #> 0.26        |      0.13 |       0.43 #> 0.03        |     -0.08 |       0.43 #> -0.02       |      0.35 |       0.25 #> -0.33       |      0.49 |       0.65 #> -0.01       |      0.18 |       0.45 #> -0.18       |      0.19 |       0.38 #> -0.20       |      0.34 |       0.39 #> -0.01       |     -0.10 |       0.44 #> 0.10        |      0.25 |       0.33 #> 0.08        |     -0.06 |       0.55 #> -0.09       |      0.21 |       0.27 #> 0.10        |      0.10 |       0.53 #> -0.29       |      0.10 |       0.35 #> 0.31        |      0.04 |       0.47 #> -0.08       |     -0.01 |       0.40 #> 0.03        |      0.42 |       0.55 #> 0.05        |     -0.01 |       0.32 #> 8.53e-03    |      0.23 |       0.23 #> -0.11       |      0.20 |       0.20 #> 0.28        |      0.40 |       0.16 #> -0.42       |     -0.21 |       0.58 #> 0.25        |     -0.09 |       0.53 #> 0.38        |      0.02 |       0.40 #> -0.24       |     -0.02 |       0.49 #> -0.03       |     -0.07 |       0.44 #> 0.20        |      0.06 |       0.18 #> -0.13       |      0.13 |       0.57 #> 0.20        |      0.01 |       0.50 #> -0.12       |      0.19 |       0.39 #> 0.17        |     -0.08 |       0.39 #> -0.19       |      0.29 |       0.34 #> 0.12        |     -0.07 |       0.16 #> -0.12       |      0.29 |       0.66 #> 0.16        |     -0.20 |       0.59 #> -0.14       |      0.32 |       0.18 #> -0.10       |      0.22 |       0.21 #> 0.05        |     -0.07 |       0.60 #> -0.27       |      0.20 |       0.33 #> 0.07        |     -0.19 |       0.59 #> -0.03       |      0.33 |       0.27 #> -0.12       |     -0.18 |       0.53 #> 0.34        |      0.14 |       0.40 #> 0.07        |      0.05 |       0.62 #> -0.16       |     -0.13 |       0.51 #> 0.04        |      0.03 |       0.68 #> -0.04       |      0.02 |       0.34 #> 0.07        |      0.28 |       0.44 #> 0.18        |      0.09 |       0.37 #> 0.51        |      0.21 |       0.37 #> -0.63       |      0.18 |       0.04 #> 0.34        |     -0.09 |       0.67 #> -0.32       |      0.33 |       0.16 #> 0.02        |      0.11 |       0.44 #> -0.11       |  8.98e-03 |       0.53 #> 0.06        |      0.18 |       0.11 #> -0.10       |     -0.23 |       0.33 #> -0.14       |      0.19 |       0.44 #> -0.07       |      0.07 |       0.16 #> -0.04       |      0.13 |       0.22 #> -0.04       |      0.13 |       0.22 #> -0.15       |     -0.25 |       0.08 #> 0.03        |      0.07 |       0.37 #> 6.59e-03    |     -0.11 |       0.22 #> -0.38       |     -0.01 |       0.17 #> 0.23        |      0.32 |       0.41 #> -0.14       |  3.10e-03 |       0.32 #> 0.17        |      0.33 |       0.29 #> -0.20       |     -0.15 |       0.54 #> 0.24        |      0.17 |       0.17 #> 0.56        |      0.45 |       0.29 #> 0.59        |      0.50 |       0.30 #> 3.20e-03    |      0.09 |       0.13 #> -4.53e-03   |      0.16 |       0.61 #> -0.02       |      0.03 |       0.19 #> -0.02       |     -0.04 |       0.56 #> 0.08        |      0.20 |       0.35 #> -0.10       |     -0.04 |       0.40 #> 0.04        |      0.11 |       0.28 #> 0.24        |     -0.14 |       0.53 #> -0.42       |     -0.16 |       0.36 #> -0.11       |      0.17 |       0.09 #> 0.03        |      0.22 |       0.45 #> -4.17e-04   |      0.19 |       0.31 #> -0.01       |     -0.07 |       0.37 #> 0.03        |      0.14 |       0.55 #> -0.06       |      0.22 |       0.49 #> 0.16        |     -0.17 |       0.42 #> -0.35       |      0.19 |       0.40 #> 0.31        |      0.09 |       0.35 #> -0.12       |      0.17 |       0.52 #> -2.22e-03   |      0.09 |       0.36 #> -0.15       |      0.10 |       0.46 #> 0.04        |  9.37e-03 |       0.19 #> -0.17       |      0.24 |       0.50 #> -0.08       |      0.18 |       0.66 #> -0.11       |      0.11 |       0.61 #> -0.11       |      0.05 |       0.69 #> 7.49e-03    |      0.22 |       0.65 #> 0.10        |      0.22 |       0.32 #> -0.21       |     -0.06 |       0.45 #> 0.04        |      0.11 |       0.50 #> -0.10       |      0.27 |       0.37 #> -0.24       |      0.13 |       0.39 #> 0.16        |     -0.07 |       0.55 #> 0.33        | -3.71e-03 |       0.50 #> -0.18       |      0.39 |       0.40 #> -0.30       |      0.15 |       0.18 #> -0.30       |      0.15 |       0.18 #> -0.20       |      0.16 |       0.22 #> -0.09       |      0.14 |       0.32 #> 0.05        |     -0.05 |       0.35 #> -0.12       |     -0.04 |       0.82 #> -0.16       |     -0.04 |       0.71 #> -0.19       |      0.03 |       0.38 #> -0.25       |      0.08 |       0.48 #> 0.26        |      0.07 |       0.44 #> -0.24       |  9.79e-03 |       0.63 #> -0.32       |      0.02 |       0.61 #> 0.35        |      0.25 |       0.22 #> -0.45       |      0.06 |       0.49 #> -0.41       |      0.04 |       0.66 #> 0.18        |      0.31 |       0.56 #> 0.14        |      0.18 |       0.65 #> 0.13        |      0.11 |       0.53 #> 0.18        |      0.20 |       0.48 #> 0.02        |      0.23 |       0.44 #> 0.34        |      0.32 |       0.32 #> 0.33        |      0.42 |       0.29 #> -0.32       |      0.05 |       0.27 #> 0.07        |      0.30 |       0.61 #> 0.01        |      0.41 |       0.37 #> -0.14       |      0.17 |       0.33 #> -0.05       |      0.20 |       0.36 #> -0.03       |      0.09 |       0.44 #> -0.13       |      0.11 |       0.68 #> -0.16       |      0.12 |       0.41 #> 0.27        |      0.06 |       0.41 #> -0.03       |     -0.24 |       0.82 #> -0.06       |      0.70 |       0.05 #> 0.18        |      0.51 |       0.27 #> -0.22       |     -0.18 |       0.42 #> -0.09       |      0.08 |       0.55 #> 0.10        |     -0.18 |       0.57 #> -0.10       |      0.20 |       0.27 #> 0.15        |     -0.11 |       0.50 #> -0.11       |     -0.08 |       0.68 #> 0.15        |      0.28 |       0.23 #> 0.24        |      0.28 |       0.26 #> -0.23       |     -0.09 |       0.59 #> 0.03        |     -0.05 |       0.44 #> -1.85e-03   |      0.18 |       0.33 #> -0.10       |      0.06 |       0.34 #> -0.32       |     -0.24 |       0.40 #> 0.39        |      0.34 |       0.25 #> -0.28       |      0.03 |       0.33 #> 0.36        |  8.33e-03 |       0.73 #> -0.13       |     -0.16 |       0.78 #> 0.13        |      0.08 |       0.61 #> 0.03        |      0.31 |       0.34 #> 0.27        |      0.08 |       0.17 #> -0.13       |      0.07 |       0.44 #> -0.15       |     -0.01 |       0.42 #> 7.87e-04    |     -0.13 |       0.26 #> 0.14        |      0.11 |       0.26 #> -0.16       |      0.04 |       0.67 #> -0.21       |     -0.09 |       0.37 #> -0.03       |      0.01 |       0.38 #> -0.07       |      0.01 |       0.74 #> 0.06        |      0.01 |       0.82 #> -0.20       |      0.18 |       0.28 #> -0.10       |      0.16 |       0.29 #> -0.33       |     -0.16 |       0.39 #> -0.12       |      0.45 |       0.40 #> 0.40        |      0.02 |       0.32 #> 0.34        |      0.13 |       0.47 #> 0.16        |      0.05 |       0.36 #> 0.04        |      0.02 |       0.74 #> 0.16        |     -0.07 |       0.43 #> 0.20        |      0.45 |       0.50 #> -0.31       |      0.11 |       0.16 #> -0.36       |      0.11 |       0.15 #> -0.28       |      0.03 |       0.22 #> -0.16       |     -0.03 |       0.46 #> 0.04        |      0.11 |       0.57 #> -0.11       |      0.21 |       0.15 #> 0.19        |     -0.11 |       0.31 #> 0.14        |      0.14 |       0.48 #> 0.25        |     -0.10 |       0.53 #> 0.15        |  6.29e-03 |       0.37 #> -0.09       |      0.20 |       0.28 #> -0.19       |      0.17 |       0.41 #> 0.06        |     -0.12 |       0.36 #> -0.05       |      0.20 |       0.33 #> 0.16        |     -0.01 |       0.38 #> -0.05       |     -0.27 |       0.55 #> 0.12        |      0.20 |       0.56 #> -0.09       |     -0.09 |       0.37 #> 0.04        |      0.47 |       0.49 #> -0.07       |     -0.29 |       0.69 #> 0.19        |      0.33 |       0.04 #> -0.18       |     -0.06 |       0.78 #> 0.21        |     -0.02 |       0.43 #> 0.01        |      0.31 |       0.47 #> -0.11       |      0.27 |       0.58 #> 0.12        |     -0.14 |       0.27 #> 6.91e-03    |     -0.30 |       0.50 #> -0.08       |      0.34 |       0.50 #> 4.41e-03    |     -0.20 |       0.31 #> 0.07        |      0.27 |       0.06 #> -0.14       |      0.83 |       0.46 #> -0.14       |      0.20 |       0.28 #> 0.22        |     -0.21 |       0.34 #> 0.07        |      0.17 |       0.41 #> 0.21        |      0.21 |       0.60 #> -7.34e-03   |      0.08 |       0.52 #> -0.19       |      0.22 |       0.69 #> 0.38        |      0.07 |       0.31 #> 0.45        |      0.07 |       0.19 #> -2.14e-03   |     -0.08 |       0.33 #> 1.92e-03    |      0.29 |       0.45 #> -0.01       |      0.23 |       0.29 #> -0.11       |     -0.03 |       0.70 #> -0.02       |     -0.10 |       0.52 #> 0.02        |      0.29 |       0.24 #> -0.02       |     -0.09 |       0.60 #> -0.06       |     -0.11 |       0.76 #> 9.78e-03    |     -0.30 |       0.06 #> 0.11        |      0.02 |       0.11 #> -0.23       |     -0.38 |       0.45 #> 0.36        |     -0.02 |       0.83 #> -0.32       |      0.12 |       0.09 #> 0.34        | -8.67e-03 |       0.80 #> 0.19        |     -0.29 |       0.51 #> 0.05        |     -0.28 |       0.60 #> 0.34        |     -0.20 |       0.86 #> -0.27       |      0.23 |       0.15 #> -0.12       |     -0.11 |       0.45 #> -0.17       |     -0.20 |       0.54 #> 0.19        |      0.28 |       0.28 #> 0.12        |     -0.06 |       0.20 #> -0.07       |      0.18 |       0.48 #> 0.17        |      0.05 |       0.34 #> -0.22       |      0.07 |       0.41 #> 0.27        |     -0.10 |       0.39 #> 0.12        |      0.04 |       0.36 #> 0.16        | -5.92e-05 |       0.33 #> -0.24       |      0.11 |       0.24 #> -0.34       |      0.18 |       0.16 #> -0.17       |      0.12 |       0.44 #> -0.15       |      0.31 |       0.61 #> 0.03        |      0.18 |       0.38 #> -0.03       |      0.37 |       0.44 #> 0.23        |     -0.04 |       0.32 #> 0.15        |     -0.05 |       0.45 #> 0.12        |      0.18 |       0.40 #> -0.05       |      0.09 |       0.35 #> 0.16        |      0.16 |       0.43 #> -0.12       |      0.22 |       0.33 #> -0.12       |     -0.04 |       0.61 #> 0.01        |      0.09 |       0.31 #> 0.04        |     -0.14 |       0.23 #> -0.03       |      0.28 |       0.67 #> -0.15       |      0.21 |       0.55 #> -0.12       |      0.12 |       0.56 #> 0.20        |      0.14 |       0.36 #> -0.08       |      0.02 |       0.54 #> -0.13       |     -0.15 |       0.48 #> 0.10        |      0.21 |       0.26 #> 0.15        |     -0.13 |       0.41 #> -0.15       |      0.22 |       0.47 #> 0.07        |  5.14e-03 |       0.51 #> 0.07        |      0.24 |       0.11 #> -0.09       |      0.05 |       0.68 #> 0.08        |      0.01 |       0.60 #> 0.15        |      0.26 |       0.42 #> -0.03       |      0.04 |       0.71 #> 0.13        |      0.43 |       0.46 #> -0.04       |      0.06 |       0.50 #> -0.05       |      0.02 |       0.18 #> 0.08        |  5.34e-03 |       0.38 #> 0.18        |     -0.08 |       0.59 #> -0.02       |      0.27 |       0.21 #> 0.06        |      0.23 |       0.40 #> -0.20       |      0.32 |       0.40 #> -0.17       |      0.28 |       0.58 #> 0.03        |      0.03 |       0.38 #> 0.06        |      0.07 |       0.30 #> -0.16       |      0.15 |       0.39 #> 0.07        |      0.33 |       0.12 #> 0.25        |      0.34 |      -0.10 #> 0.23        |      0.53 |      -0.04 #> 0.19        |      0.47 |       0.14 #> 0.09        |      0.57 |       0.03 #> -0.08       |     -0.04 |       0.38 #> 0.04        |     -0.06 |       0.35 #> 0.23        |      0.07 |       0.23 #> -0.02       |      0.32 |       0.42 #> 0.01        |      0.26 |       0.46 #> -0.08       |      0.12 |       0.58 #> 0.23        |      0.08 |       0.22 #> -0.17       |      0.06 |       0.33 #> 0.26        |     -0.11 |       0.40 #> 0.06        |      0.13 |       0.46 #> -0.28       |     -0.18 |       0.43 #> 0.18        |      0.08 |       0.94 #> -0.10       |      0.26 |       0.44 #> -0.13       |      0.34 |       0.28 #> 0.14        |     -0.05 |       0.36 #> -0.15       |      0.31 |       0.56 #> -0.09       |      0.33 |       0.55 #> 0.11        |     -0.17 |       0.29 #> 0.24        |      0.15 |       0.40 #> -0.16       |  9.65e-03 |       0.39 #> 0.20        |      0.22 |       0.48 #> -0.15       |      0.12 |       0.48 #> -0.09       |     -0.07 |       0.32 #> 0.06        |      0.24 |       0.52 #> -0.13       |      0.10 |       0.15 #> -0.23       |      0.06 |       0.21 #> -0.30       |      0.19 |   3.98e-04 #> -0.08       |     -0.03 |       0.35 #> -0.49       |     -0.09 |       0.28 #> 0.52        |      0.28 |       0.28 #> 0.29        |      0.16 |       0.50 #> 0.01        |      0.26 |       0.20 #> 0.21        |      0.12 |       0.13 #> -0.05       |      0.09 |       0.53 #> -0.14       |      0.11 |       0.61 #> -0.13       |      0.04 |       0.50 #> 0.02        |      0.13 |       0.45 #> -0.22       | -3.04e-03 |       0.47 #> 0.11        |      0.28 |       0.29 #> -0.06       |     -0.04 |       0.39 #> 0.03        |      0.27 |       0.55 #> -0.02       |     -0.12 |       0.48 #> 0.09        |      0.27 |       0.49 #> -0.21       |      0.05 |       0.36 #> -0.11       |      0.12 |       0.29 #> -0.01       |     -0.12 |       0.24 #> 0.15        |     -0.20 |       0.49 #> -0.20       |      0.51 |       0.50 #> -2.19e-03   |     -0.32 |       0.48 #> 0.14        |     -0.09 |       0.48 #> 0.01        |      0.46 |       0.46 #> 0.09        |      0.41 |       0.67 #> -0.13       |      0.41 |       0.40 #> -0.14       |     -0.05 |       0.62 #> 0.18        |      0.19 |       0.32 #> 0.08        |      0.18 |       0.28 #> 0.16        |      0.33 |       0.24 #> -0.19       |     -0.09 |       0.58 #> -0.24       |     -0.15 |       0.65 #> 0.12        |      0.11 |       0.29 #> -0.02       |     -0.07 |       0.66 #> 0.04        |      0.25 |       0.31 #> 0.12        |     -0.03 |       0.18 #> -0.12       |      0.20 |       0.60 #> -0.29       |      0.33 |       0.48 #> 0.62        |     -0.21 |       0.20 #> 0.68        |     -0.24 |       0.19 #> 0.92        |     -0.06 |       0.12 #> 0.40        |      0.25 |       0.39 #> -0.42       | -6.55e-03 |       0.41 #> -0.28       |      0.20 |       0.52 #> 0.29        |     -0.10 |       0.44 #> -0.14       |  3.39e-03 |       0.26 #> 0.22        | -4.07e-03 |       0.60 #> 0.10        |     -0.03 |       0.66 #> -0.04       |      0.09 |       0.37 #> 0.20        |     -0.04 |       0.30 #> -0.11       |      0.27 |       0.26 #> -0.10       |      0.11 |       0.32 #> 0.03        |     -0.14 |       0.53 #> -0.07       |      0.46 |       0.34 #> -0.15       |      0.32 |       0.41 #> 0.23        |      0.09 |       0.29 #> -0.24       |      0.09 |       0.57 #> 0.29        |      0.06 |       0.16 #> -0.12       |      0.32 |       0.14 #> -0.13       |     -0.14 |       0.70 #> 5.58e-03    |      0.21 |       0.54 #> -0.16       |      0.04 |       0.39 #> -6.61e-03   |      0.06 |       0.58 #> -0.05       |      0.28 |       0.26 #> 0.14        |      0.41 |       0.15 #> -0.21       |     -0.40 |       0.77 #> 0.01        |      0.31 |       0.17 #> 0.02        |      0.14 |       0.45 #> 0.09        |      0.13 |       0.35 #> 0.39        |      0.03 |       0.40 #> -0.39       |      0.03 |       0.30 #> 0.32        |      0.09 |       0.28 #> 0.15        |      0.15 |       0.54 #> -0.01       |      0.11 |       0.35 #> 0.08        |      0.15 |       0.29 #> -0.09       |     -0.12 |       0.43 #> -0.10       |      0.13 |       0.56 #> 0.05        |      0.15 |       0.23 #> -0.10       |      0.39 |       0.32 #> 0.08        |     -0.22 |       0.52 #> 0.11        |     -0.19 |       0.71 #> -0.11       |      0.39 |       0.10 #> -0.05       |      0.20 |       0.15 #> 0.14        |      0.19 |       0.43 #> -0.01       |     -0.10 |       0.45 #> 8.59e-03    |      0.30 |       0.36 #> 0.11        |     -0.18 |       0.48 #> 0.14        |      0.13 |       0.45 #> -0.02       |      0.12 |       0.39 #> -0.02       |      0.12 |       0.39 #> 0.10        |      0.13 |       0.64 #> 0.04        |      0.09 |       0.44 #> -0.16       |      0.14 |       0.52 #> 0.16        |     -0.05 |       0.42 #> -0.23       |     -0.01 |       0.71 #> -8.09e-03   |      0.04 |       0.30 #> -6.74e-03   |      0.18 |       0.21 #> 0.11        |     -0.13 |       0.40 #> 0.09        |     -0.25 |       0.52 #> 0.26        |      0.35 |       0.62 #> 0.29        |      0.36 |       0.80 #> 0.16        |      0.24 |       0.41 #> -0.09       |      0.10 |       0.32 #> 0.10        |     -0.02 |       0.44 #> 0.08        |  3.64e-03 |       0.47 #> 0.31        |     -0.17 |       0.38 #> -0.25       |      0.36 |       0.44 #> 0.33        |     -0.19 |       0.28 #> 0.17        |     -0.09 |       0.45 #> -0.31       |      0.16 |       0.15 #> -0.19       |      0.04 |       0.37 #> 0.13        |      0.14 |       0.13 #> 0.32        |      0.02 |       0.48 #> -0.20       |      0.16 |       0.49 #> -0.50       |      0.33 |       0.32 #> -0.66       |      0.24 |       0.30 #> -0.24       |     -0.05 |       0.33 #> -0.09       |      0.31 |       0.27 #> -0.06       |      0.22 |       0.32 #> 0.07        |     -0.10 |       0.41 #> -4.28e-03   |      0.02 |       0.33 #> 3.59e-03    |      0.05 |       0.48 #> -0.11       |  3.74e-03 |       0.16 #> -0.05       |      0.19 |       0.48 #> -0.15       |      0.08 |       0.29 #> -0.08       |      0.15 |       0.65 #> 0.11        |      0.05 |       0.20 #> -0.23       |      0.02 |       0.44 #> -0.10       |      0.14 |       0.21 #> -0.35       |     -0.05 |       0.17 #> -0.33       |      0.31 |       0.53 #> -0.02       |     -0.15 |       0.23 #> -0.25       |      0.34 |       0.08 #> 0.25        |     -0.05 |       0.58 #> -0.07       |     -0.14 |       0.35 #> 0.12        |      0.28 |       0.40 #> -0.19       |      0.14 |       0.20 #> -0.09       |      0.28 |       0.18 #> -0.08       |      0.48 |       0.10 #> 0.25        |     -0.17 |       0.73 #> -0.21       |      0.41 |       0.15 #> -0.09       |      0.24 |      -0.02 #> 0.22        |      0.40 |       0.30 #> -0.20       |     -0.05 |       0.42 #> 0.19        |      0.23 |       0.42 #> 0.17        |     -0.21 |       0.60 #> -0.15       |      0.37 |       0.24 #> 0.09        |      0.33 |       0.21 #> 0.31        |     -0.07 |       0.54 #> -0.33       |      0.42 |       0.13 #> -0.22       |      0.27 |       0.11 #> 0.24        |     -0.07 |       0.63 #> 0.31        |     -0.24 |       0.61 #> 0.26        |     -0.31 |       0.67 #> 0.16        |     -0.35 |       0.66 #> 0.18        |      0.12 |       0.44 #> -0.32       |      0.14 |       0.38 #> 0.23        |     -0.04 |       0.55 #> 6.95e-03    |      0.10 |       0.62 #> 6.54e-03    |  2.63e-03 |       0.28 #> 0.04        |      0.15 |       0.46 #> 0.09        |      0.16 |       0.29 #> -0.06       |      0.16 |       0.61 #> 0.10        |      0.22 |       0.68 #> -0.03       |      0.21 |       0.36 #> 0.03        |     -0.12 |       0.52 #> 0.05        |      0.04 |       0.42 #> -0.05       |      0.10 |       0.36 #> 0.18        |      0.23 |       0.44 #> 0.56        |      0.21 |       0.23 #> -0.41       |      0.13 |       0.41 #> 0.20        |     -0.05 |       0.48 #> -0.28       |      0.30 |       0.32 #> 0.23        |     -0.09 |       0.47 #> 0.25        |     -0.05 |       0.39 #> -0.27       |      0.25 |       0.41 #> 0.30        |     -0.15 |       0.47 #> 0.43        |      0.06 |       0.33 #> -0.28       |      0.26 |       0.60 #> 0.10        |      0.14 |       0.39 #> -0.02       |      0.16 |       0.60 #> -0.09       |      0.52 |      -0.07 #> 0.06        |     -0.18 |       0.75 #> 0.03        |     -0.20 |       0.80 #> 0.19        |     -0.01 |       0.75 #> -2.41e-03   |      0.12 |       0.58 #> -0.05       |      0.03 |       0.17 #> -2.22e-03   |      0.14 |       0.51 #> -0.06       |      0.18 |       0.61 #> -0.02       | -5.43e-03 |       0.23 #> -0.13       |      0.04 |       0.70 #> -0.12       |  8.78e-03 |       0.65 #> -0.11       |     -0.04 |       0.24 #> 0.35        |     -0.01 |       0.38 #> 0.15        |     -0.06 |       0.52 #> -0.10       |     -0.04 |       0.28 #> 0.16        |      0.15 |       0.29 #> -0.26       |      0.09 |       0.43 #> 0.20        |      0.17 |       0.34 #> 0.25        |      0.20 |       0.27 #> 0.12        |      0.23 |       0.46 #> 0.09        |      0.22 |       0.40 #> -0.04       |      0.08 |       0.34 #> 0.03        |      0.25 |       0.39 #> 0.03        |      0.07 |       0.51 #> -0.05       |      0.10 |       0.44 #> 5.53e-03    |      0.04 |       0.28 #> -0.10       |      0.13 |       0.51 #> 0.08        |      0.02 |       0.27 #> 0.13        |      0.17 |       0.21 #> -0.05       |      0.38 |       0.31 #> -0.10       |      0.29 |       0.62 #> 0.04        |      0.15 |       0.51 #> -0.25       |     -0.10 |       0.57 #> 0.17        |      0.56 |       0.53 #> 0.21        |      0.48 |       0.38 #> -0.27       |      0.13 |       0.43 #> 0.31        |      0.07 |       0.35 #> -0.21       |      0.12 |       0.37 #> -0.10       |      0.07 |       0.43 #> -0.15       |      0.22 |       0.31 #> 0.03        |     -0.16 |       0.38 #> 0.32        |      0.07 |       0.53 #> -0.36       |      0.13 |       0.32 #> 0.41        |      0.02 |       0.47 #> -0.09       |      0.18 |       0.30 #> 0.06        |      0.05 |       0.51 #> 0.06        | -7.15e-03 |       0.59 #> -0.03       |      0.09 |       0.43 #> 0.12        |      0.39 |       0.50 #> -0.18       |     -0.29 |       0.23 #> -5.09e-03   |      0.46 |       0.32 #> 9.40e-04    |     -0.23 |       0.42 #> -0.03       |      0.30 |       0.25 #> -0.02       |      0.02 |       0.79 #> -0.01       |     -0.10 |       0.81 #> -0.04       |     -0.25 |       0.74 #> -0.01       |     -0.17 |       0.65 #> -0.01       |      0.27 |       0.20 #> 0.10        |      0.33 |       0.09 #> -0.13       |      0.21 |       0.31 #> -0.07       |      0.20 |       0.28 #> -7.46e-03   |      0.10 |       0.38 #> -0.02       |      0.04 |       0.25 #> -0.15       | -8.08e-03 |       0.67 #> 0.22        |      0.06 |       0.43 #> 0.21        |      0.11 |       0.66 #> -4.09e-03   |      0.01 |       0.52 #> -0.06       |      0.03 |       0.53 #> 0.16        |      0.09 |       0.31 #> -0.15       |      0.06 |       0.45 #> -0.23       |     -0.23 |       0.22 #> 0.36        |      0.09 |       0.64 #> -0.13       |      0.17 |       0.25 #> -2.11e-03   |      0.04 |       0.60 #> 0.12        |      0.30 |       0.52 #> 0.05        |      0.06 |       0.38 #> -0.06       |      0.26 |       0.43 #> -0.10       |      0.21 |       0.31 #> 0.19        |      0.58 |       0.33 #> -0.07       |     -0.02 |       0.29 #> -0.18       |      0.27 |       0.47 #> 0.01        |     -0.06 |       0.52 #> 0.13        |      0.08 |       0.65 #> -0.20       | -6.09e-03 |       0.34 #> 0.22        |      0.20 |       0.54 #> 0.06        |     -0.17 |       0.50 #> -0.12       |  7.98e-03 |       0.28 #> 0.10        |      0.18 |       0.34 #> -0.04       |      0.30 |       0.35 #> 0.01        |      0.03 |       0.44 #> -0.03       |      0.07 |       0.43 #> 0.01        |      0.23 |       0.46 #> 6.32e-05    |      0.38 |       0.42 #> 9.23e-03    |     -0.27 |       0.34 #> 0.14        |      0.26 |       0.74 #> -0.20       |     -0.32 |       0.13 #> -0.18       |     -0.04 |       0.16 #> -0.10       |      0.02 |       0.15 #> 0.04        |      0.38 |       0.31 #> 0.15        |      0.29 |       0.50 #> -0.07       |     -0.28 |       0.38 #> 0.01        |     -0.10 |       0.51 #> 0.09        |      0.07 |       0.54 #> -0.12       |      0.06 |       0.30 #> -0.24       |      0.17 |       0.17 #> 0.23        |      0.01 |       0.60 #> 0.27        |      0.04 |       0.56 #> -0.21       |      0.05 |       0.47 #> -0.27       |      0.02 |       0.49 #> 0.08        |      0.30 |       0.57 #> 0.13        |      0.21 |       0.32 #> -0.13       |      0.04 |       0.47 #> 0.07        |     -0.18 |       0.71 #> -0.29       |     -0.11 |       0.22 #> 0.04        |      0.40 |       0.45 #> 0.24        |     -0.09 |       0.32 #> -0.03       |      0.42 |       0.46 #> 0.02        |     -0.08 |       0.49 #> 0.06        |      0.42 |       0.30 #> -0.14       |      0.25 |       0.23 #> -0.02       |      0.22 |       0.38 #> 0.17        |     -0.12 |       0.79 #> -0.08       |      0.08 |       0.48 #> 0.05        |      0.21 |       0.03 #> 1.17e-04    |     -0.14 |       0.34 #> -6.35e-03   |      0.46 |       0.43 #> 0.03        |     -0.18 |       0.39 #> 0.39        |     -0.30 |       0.25 #> -0.41       |      0.30 |       0.80 #> -0.34       |      0.25 |       0.60 #> 0.25        |      0.03 |       0.43 #> 0.10        |      0.28 |       0.41 #> -0.30       |      0.11 |       0.31 #> -0.05       |      0.14 |       0.41 #> 0.10        |      0.11 |       0.21 #> 0.13        |      0.05 |       0.23 #> -0.03       |      0.07 |       0.52 #> 0.03        |      0.16 |       0.28 #> 0.03        |      0.05 |       0.58 #> -0.28       |      0.35 |       0.23 #> 0.42        |     -0.26 |       0.47 #> -0.02       |     -0.08 |       0.61 #> -0.02       |      0.11 |       0.27 #> -0.05       |      0.15 |       0.29 #> -0.13       |      0.20 |       0.30 #> -0.33       |      0.25 |       0.41 #> -0.09       |      0.23 |       0.52 #> -0.20       |      0.02 |       0.51 #> 0.20        |      0.21 |       0.28 #> 0.24        |      0.10 |       0.34 #> 0.09        |      0.30 |       0.42 #> -0.05       | -6.35e-03 |       0.38 #> 0.12        |      0.08 |       0.66 #> -0.14       |     -0.12 |       0.23 #> -0.03       |      0.38 |       0.52 #> 0.06        |      0.13 |       0.13 #> 0.05        |      0.14 |       0.12 #> -0.16       |      0.38 |       0.64 #> -0.20       |      0.15 |       0.49 #> -0.35       |     -0.35 |       0.54 #> -0.37       |     -0.27 |       0.52 #> 0.19        |      0.36 |       0.39 #> -0.01       |      0.23 |       0.34 #> -0.01       |     -0.02 |       0.48 #> 0.11        |     -0.08 |       0.27 #> 0.35        |     -0.14 |       0.27 #> -0.31       |      0.23 |       0.46 #> -0.33       |      0.25 |       0.54 #> 0.23        |     -0.07 |       0.28 #> -0.18       |      0.28 |       0.50 #> 0.29        |     -0.05 |       0.46 #> -0.33       |      0.27 |       0.33 #> 0.05        |      0.29 |       0.38 #> 0.15        |      0.05 |       0.25 #> 0.20        |      0.16 |       0.45 #> -0.04       |     -0.04 |       0.25 #> 0.04        |      0.08 |       0.28 #> -0.03       |      0.03 |       0.44 #> -0.13       |      0.28 |       0.49 #> 0.07        |      0.03 |       0.33 #> 0.01        |      0.16 |       0.49 #> -0.02       |      0.03 |       0.41 #> -0.17       |      0.14 |       0.47 #> 0.17        |      0.04 |       0.36 #> 0.06        |      0.59 |       0.16 #> -0.11       |     -0.11 |       0.66 #> 0.01        |     -0.05 |       0.56 #> 0.19        |      0.10 |       0.35 #> 0.22        |     -0.11 |       0.35 #> -0.02       |      0.25 |       0.43 #> -0.07       |      0.02 |       0.40 #> 0.07        |      0.05 |       0.27 #> -0.13       |      0.28 |       0.71 #> 0.02        |     -0.04 |       0.28 #> 0.19        |      0.35 |       0.53 #> 0.28        |      0.34 |       0.30 #> -0.40       |      0.01 |      -0.15 #> 0.07        |      0.22 |       0.86 #> 0.06        |      0.36 |       0.64 #> -0.17       |     -0.07 |       0.35 #> 0.10        |      0.28 |       0.48 #> 0.17        |      0.23 |       0.57 #> -0.16       |     -0.04 |       0.34 #> -0.15       |     -0.01 |       0.56 #> 0.23        |      0.05 |       0.44 #> -0.06       |     -0.05 |       0.51 #> 0.06        |      0.31 |       0.25 #> -0.04       |     -0.03 |       0.46 #> 0.04        |      0.25 |       0.37 #> -0.14       |      0.04 |       0.35 #> 0.21        |      0.14 |       0.45 #> -0.13       |      0.16 |       0.36 #> 0.33        |     -0.08 |       0.52 #> -0.43       |     -0.08 |       0.21 #> -0.19       |      0.02 |       0.36 #> 0.07        |      0.26 |       0.49 #> -0.08       |     -0.11 |       0.38 #> 0.14        |     -0.33 |       0.31 #> 0.14        |     -0.31 |       0.29 #> -0.18       |      0.60 |       0.59 #> -0.15       |      0.61 |       0.52 #> 0.19        |     -0.25 |       0.33 #> -0.17       |      0.59 |       0.38 #> -0.07       |      0.78 |       0.47 #> -0.02       |      0.59 |       0.35 #> 0.20        |      0.07 |       0.25 #> -0.04       | -6.57e-03 |       0.58 #> -0.40       |      0.28 |       0.55 #> -0.09       |      0.28 |       0.74 #> -0.33       |      0.06 |       0.77 #> -0.03       |      0.31 |       0.56 #> 0.04        |     -0.15 |       0.34 #> 3.20e-03    |      0.24 |       0.60 #> 1.20e-03    |     -0.29 |       0.46 #> 0.09        |      0.41 |       0.42 #> 0.20        |     -0.29 |       0.44 #> 0.09        |     -0.06 |      -0.14 #> 0.19        |     -0.17 |       0.83 #> -0.07       |      0.46 |       0.21 #> -0.03       |     -0.34 |       0.65 #> 0.09        |      0.35 |       0.25 #> -0.19       |      0.26 |       0.33 #> -0.07       |      0.04 |       0.49 #> 0.17        |      0.13 |       0.38 #> 0.16        |      0.02 |       0.97 #> -0.18       |      0.15 |      -0.05 #> 0.08        |     -0.06 |       0.73 #> 0.05        |      0.11 |       0.19 #> -0.31       |      0.04 |       0.15 #> 0.30        |      0.01 |       0.20 #> -0.04       |      0.17 |       0.56 #> 0.23        |  1.01e-03 |       0.43 #> -0.05       |      0.25 |       0.50 #> -0.35       |      0.05 |       0.58 #> 0.28        |      0.23 |       0.53 #> -7.22e-04   |     -0.03 |       0.08 #> -0.05       |      0.33 |       0.58 #> 0.09        |      0.02 |       0.57 #> 0.03        |      0.56 |       0.32 #> -0.06       |     -0.42 |       0.46 #> -0.04       |     -0.44 |       0.52 #> -0.02       |      0.18 |       0.55 #> 0.11        |     -0.12 |       0.33 #> 0.06        |      0.30 |       0.43 #> 0.06        |      0.35 |       0.29 #> 0.11        |      0.36 |       0.44 #> -0.03       |      0.44 |       0.36 #> -0.16       |     -0.09 |       0.35 #> 0.46        |      0.07 |       0.26 #> 0.37        |  2.50e-03 |       0.35 #> -0.20       |      0.12 |       0.55 #> 0.24        |      0.11 |       0.15 #> 0.31        |     -0.02 |       0.15 #> -0.27       |      0.42 |       0.42 #> -0.21       |      0.18 |       0.66 #> -0.23       |      0.17 |       0.39 #> -0.22       |      0.20 |       0.35 #> -0.17       |      0.18 |       0.19 #> 0.16        |      0.03 |       0.61 #> 0.22        |     -0.06 |       0.63 #> -0.10       |      0.17 |       0.19 #> -0.02       |      0.18 |       0.40 #> 0.15        |      0.08 |       0.44 #> 0.17        |      0.44 |       0.14 #> 0.34        |      0.65 |       0.25 #> -0.01       |     -0.02 |       0.18 #> 0.05        |     -0.05 |       0.20 #> 0.11        |     -0.05 |       0.38 #> 0.16        |     -0.01 |       0.46 #> 0.04        |     -0.14 |       0.42 #> 0.34        |      0.33 |       0.39 #> -0.22       |     -0.17 |       0.56 #> -0.18       |      0.01 |       0.57 #> 0.07        |     -0.09 |       0.38 #> -6.18e-04   |      0.17 |       0.36 #> -0.03       |      0.17 |       0.45 #> 0.11        |      0.04 |       0.39 #> -0.11       |      0.12 |       0.48 #> -0.14       |     -0.13 |       0.20 #> 0.15        |      0.28 |       0.60 #> 0.19        |      0.29 |       0.60 #> 0.07        |      0.29 |       0.48 #> -0.09       |     -0.24 |       0.57 #> 0.08        |      0.30 |       0.31 #> 0.10        |      0.27 |       0.38 #> -0.20       |      0.07 |       0.36 #> 0.33        |      0.15 |       0.51 #> -0.27       |      0.16 |       0.34 #> 0.31        |      0.13 |       0.42 #> -0.33       |      0.30 |       0.20 #> 0.23        | -4.60e-03 |       0.73 #> 0.21        |      0.03 |       0.55 #> 0.17        |      0.07 |       0.60 #> 0.25        |     -0.02 |       0.60 #> 0.30        |      0.14 |       0.55 #> -0.24       |      0.32 |       0.22 #> 0.29        |     -0.08 |       0.75 #> -0.10       |     -0.05 |       0.28 #> 0.04        |     -0.05 |       0.28 #> -0.08       |     -0.01 |       0.66 #> 0.16        |      0.26 |       0.18 #> -0.07       |      0.10 |       0.75 #> -0.15       |     -0.09 |       0.32 #> 0.14        |      0.20 |       0.49 #> -0.14       |      0.10 |       0.23 #> -0.33       |      0.22 |       0.31 #> 0.29        |      0.25 |       0.34 #> 0.21        |      0.27 |       0.30 #> -0.22       |     -0.09 |       0.58 #> -0.10       |     -0.10 |       0.60 #> -0.17       |      0.22 |       0.25 #> 0.11        |     -0.21 |       0.41 #> 0.24        |      0.58 |       0.37 #> 0.04        |      0.03 |       0.51 #> -0.03       |      0.17 |       0.33 #> 0.34        | -2.16e-03 |       0.52 #> 0.03        |     -0.02 |       0.61 #> 0.06        |     -0.25 |       0.48 #> 0.04        |      0.05 |       0.42 #> 0.05        |      0.20 |       0.51 #> -0.08       |      0.01 |       0.37 #> 0.19        |      0.16 |       0.65 #> -0.17       |      0.07 |       0.12 #> -0.16       |      0.08 |       0.11 #> 0.15        |      0.11 |       0.43 #> -0.14       |      0.03 |       0.46 #> 0.08        |      0.12 |       0.19 #> 0.11        |      0.17 |      -0.07 #> 0.07        |      0.18 |      -0.04 #> 0.06        |     -0.12 |       0.53 #> -0.15       |     -0.21 |       0.37 #> 0.18        |      0.52 |       0.39 #> -0.17       |     -0.03 |       0.59 #> -0.06       |     -0.26 |       0.34 #> 0.06        |      0.35 |       0.36 #> -0.16       |     -0.11 |       0.54 #> 0.08        |      0.32 |       0.27 #> -0.06       |      0.07 |       0.47 #> 0.04        |      0.18 |       0.43 #> -0.02       |     -0.28 |       0.53 #> 0.18        |      0.34 |       0.38 #> -0.25       |     -0.34 |       0.57 #> 0.52        |      0.05 |       0.57 #> -0.19       |     -0.03 |       0.58 #> 0.23        |      0.19 |       0.29 #> -0.09       |      0.03 |       0.42 #> 0.09        |      0.16 |       0.40 #> 0.17        |      0.26 |       0.53 #> 0.02        |      0.22 |       0.34 #> -0.02       |     -0.03 |       0.47 #> -7.21e-03   |     -0.07 |       0.44 #> 0.06        |     -0.13 |       0.42 #> -0.06       |      0.32 |       0.39 #> 0.13        |      0.25 |       0.52 #> -0.02       |      0.08 |       0.25 #> -0.06       |      0.02 |       0.61 #> -0.04       |      0.15 |       0.21 #> 0.03        |      0.05 |       0.58 #> 0.26        |     -0.18 |       0.14 #> 0.04        |     -0.06 |       0.55 #> -0.03       |     -0.06 |       0.47 #> -0.07       |      0.28 |       0.31 #> 0.05        |     -0.13 |       0.45 #> 0.07        |     -0.07 |       0.54 #> -0.02       | -7.31e-03 |       0.41 #> -0.03       |      0.11 |       0.23 #> 0.05        |      0.23 |       0.44 #> -0.09       |     -0.25 |       0.20 #> 0.38        |     -0.28 |       0.45 #> -0.47       |      0.34 |       0.35 #> -0.28       |      0.30 |       0.44 #> -0.12       | -2.22e-03 |       0.27 #> 0.10        |      0.24 |       0.41 #> -0.12       |      0.05 |       0.27 #> -0.02       |      0.07 |       0.36 #> 0.02        |      0.13 |       0.90 #> -0.22       |      0.08 |       0.28 #> -0.20       |      0.16 |       0.37 #> 0.05        |      0.16 |       0.42 #> -0.07       |      0.03 |       0.36 #> -0.27       |      0.01 |       0.44 #> 0.18        |      0.10 |       0.32 #> 0.02        |      0.13 |       0.39 #> 0.02        |      0.13 |       0.39 #> -0.04       |  3.06e-03 |       0.44 #> 0.20        |      0.44 |       0.29 #> 0.11        |      0.40 |       0.45 #> -0.05       |      0.02 |       0.37 #> 0.06        |  8.41e-04 |       0.42 #> -0.05       |      0.25 |       0.41 #> 8.44e-03    |     -0.02 |       0.47 #> -0.09       |      0.14 |       0.42 #> 0.09        | -8.67e-03 |       0.44 #> 2.38e-03    |      0.28 |       0.40 #> 0.12        |      0.35 |       0.43 #> -0.08       |      0.05 |       0.28 #> 0.09        |      0.12 |       0.58 #> 0.21        |      0.23 |       0.16 #> -0.27       |     -0.09 |       0.70 #> 0.13        |      0.31 |       0.13 #> 0.05        |      0.23 |       0.29 #> -0.03       |      0.21 |       0.50 #> 0.02        |     -0.12 |       0.33 #> -0.16       |      0.22 |       0.45 #> 0.23        |     -0.08 |       0.32 #> 0.05        |     -0.14 |       0.47 #> 0.04        |      0.33 |       0.40 #> 0.05        |      0.18 |       0.53 #> 0.08        |     -0.11 |       0.40 #> 0.08        |     -0.03 |       0.45 #> 0.32        |     -0.21 |       0.54 #> -0.18       |      0.12 |       0.67 #> 0.09        |      0.16 |       0.37 #> 0.07        |      0.26 |       0.10 #> -0.07       |     -0.10 |       0.75 #> -0.06       |     -0.17 |       0.50 #> 0.21        |      0.17 |       0.65 #> -0.10       |      0.15 |       0.25 #> 0.25        |      0.22 |       0.38 #> -0.31       |      0.19 |       0.61 #> -0.30       |      0.07 |       0.70 #> -0.18       |      0.13 |       0.51 #> -0.07       |      0.19 |       0.39 #> 0.04        |     -0.07 |       0.35 #> 0.18        |      0.23 |       0.62 #> -0.18       |     -0.02 |       0.22 #> 0.08        |      0.23 |       0.43 #> -5.07e-03   |      0.08 |       0.43 #> -0.03       |      0.38 |       0.19 #> -0.02       |     -0.05 |       0.15 #> -0.02       |      0.18 |       0.59 #> 0.07        |      0.05 |       0.25 #> -0.02       |     -0.15 |       0.48 #> 0.18        |      0.12 |       0.45 #> -0.03       |      0.23 |       0.34 #> 0.18        |      0.11 |       0.39 #> 0.24        |      0.15 |       0.31 #> 4.20e-03    |      0.52 |       0.27 #> -0.18       |     -0.06 |       0.24 #> -0.09       |      0.32 |       0.42 #> 0.16        |     -0.05 |       0.44 #> -0.12       |     -0.04 |       0.63 #> 0.11        |      0.16 |       0.27 #> -0.14       |      0.10 |       0.57 #> 0.21        |      0.17 |       0.43 #> -0.23       |      0.06 |       0.36 #> 0.18        |      0.13 |       0.54 #> -0.16       |      0.24 |       0.45 #> 0.17        |      0.24 |       0.26 #> -0.07       |     -0.07 |       0.51 #> 0.08        |      0.22 |       0.38 #> 0.28        |      0.25 |       0.31 #> -0.33       |     -0.03 |       0.61 #> 0.18        |     -0.10 |       0.47 #> 0.21        |     -0.11 |       0.47 #> -0.07       |      0.02 |       0.60 #> -5.58e-03   |     -0.06 |       0.35 #> -5.58e-03   |     -0.06 |       0.35 #> -0.08       |      0.16 |       0.56 #> 0.13        |      0.22 |       0.26 #> -0.37       |      0.17 |       0.20 #> -0.06       |     -0.05 |       0.33 #> -0.31       |      0.13 |       0.57 #> 8.86e-03    |     -0.02 |       0.37 #> -0.42       |     -0.05 |       0.06 #> -0.41       |     -0.35 |      -0.03 #> -0.26       |     -0.39 |      -0.10 #> 0.19        |      0.34 |       0.03 #> -0.19       |     -0.06 |       0.70 #> 0.28        |      0.42 |       0.28 #> 0.01        |     -0.16 |       0.30 #> 0.12        |      0.09 |       0.41 #> 0.27        |      0.18 |       0.34 #> 0.16        |      0.13 |       0.34 #> -0.09       |     -0.09 |       0.39 #> -0.27       |      0.04 |       0.50 #> 0.28        |      0.34 |       0.16 #> 0.03        |     -0.16 |       0.50 #> -0.04       |      0.27 |       0.39 #> -0.05       |      0.19 |       0.26 #> 0.08        |      0.09 |       0.48 #> 0.13        |      0.26 |       0.17 #> -0.04       |      0.23 |       0.40 #> 0.09        |      0.25 |       0.32 #> 0.11        |      0.03 |       0.17 #> 0.14        |      0.10 |       0.27 #> -0.11       |      0.17 |       0.47 #> 0.07        |      0.24 |       0.51 #> 0.01        |      0.02 |       0.41 #> -0.02       |  9.17e-04 |       0.25 #> -0.16       |      0.06 |       0.64 #> -0.13       |      0.08 |       0.72 #> -0.14       |     -0.02 |       0.54 #> -0.05       |      0.24 |       0.34 #> -0.17       |      0.24 |       0.15 #> -0.15       |      0.18 |       0.33 #> 0.14        |     -0.10 |       0.54 #> -0.10       |      0.23 |       0.29 #> -0.09       |      0.28 |       0.31 #> -0.25       |      0.18 |       0.56 #> 0.40        |      0.23 |       0.21 #> 0.27        |      0.28 |       0.48 #> 0.37        |      0.03 |       0.82 #> -0.28       |      0.04 |       0.29 #> 0.16        |      0.03 |       0.62 #> -0.07       |      0.09 |       0.41 #> 0.06        |     -0.04 |       0.52 #> -0.16       |      0.08 |       0.45 #> 0.25        |      0.15 |       0.50 #> -0.13       |      0.18 |       0.47 #> -0.26       |      0.20 |       0.60 #> 0.18        |      0.44 |       0.36 #> -0.38       |      0.05 |       0.73 #> -0.27       |      0.05 |       0.63 #> -0.26       |      0.10 |       0.65 #> -0.29       |     -0.19 |       0.50 #> 0.38        |      0.31 |       0.22 #> 0.36        |     -0.30 |       0.36 #> -0.24       |      0.59 |       0.34 #> -0.24       |      0.59 |       0.30 #> -0.07       |      0.51 |       0.45 #> 0.16        |      0.27 |       0.12 #> 0.04        |     -0.24 |       0.60 #> 0.13        |     -0.24 |       0.66 #> -0.14       |      0.45 |       0.11 #> 0.21        |      0.24 |       0.29 #> 0.17        |      0.67 |       0.10 #> -0.02       |     -0.02 |       0.33 #> -0.22       |     -0.07 |       0.34 #> 0.23        |      0.24 |       0.56 #> -0.33       |     -0.12 |       0.28 #> 0.24        |      0.15 |       0.65 #> 0.17        |      0.04 |       0.56 #> -0.07       |      0.16 |       0.27 #> -0.41       |      0.15 |       0.04 #> 0.05        |      0.12 |       0.23 #> -0.10       |     -0.08 |       0.33 #> -0.09       |      0.11 |       0.28 #> -0.19       |      0.13 |       0.22 #> 0.03        |      0.19 |       0.54 #> 0.41        |      0.13 |       0.67 #> -0.15       |      0.11 |       0.45 #> 0.26        |      0.17 |       0.40 #> -0.17       |     -0.15 |       0.60 #> 0.09        |      0.13 |       0.44 #> -0.09       |      0.02 |       0.40 #> 1.36e-03    |      0.23 |       0.46 #> -0.09       |      0.36 |       0.44 #> 0.17        |     -0.10 |       0.50 #> -0.36       |      0.03 |       0.40 #> 0.05        |     -0.02 |       0.60 #> -0.06       |     -0.04 |       0.41 #> -0.07       |      0.23 |       0.33 #> 0.09        |      0.14 |       0.43 #> -0.13       |      0.14 |       0.60 #> 0.15        |      0.06 |       0.17 #> 0.23        |      0.08 |       0.06 #> 0.18        |      0.11 |       0.11 #> -0.04       |     -0.01 |       0.44 #> -0.10       |     -0.19 |       0.44 #> 0.03        |     -0.31 |       0.45 #> -0.19       |      0.31 |       0.21 #> 0.20        |     -0.23 |       0.72 #> -0.22       |      0.40 |       0.07 #> 0.24        |     -0.15 |       0.59 #> -0.03       |     -0.04 |       0.57 #> 0.26        |     -0.28 |       0.82 #> -0.18       |      0.36 |       0.13 #> -0.07       |      0.32 |       0.13 #> 0.04        |     -0.07 |       0.67 #> -0.04       |      0.27 |       0.11 #> -0.03       |      0.17 |       0.16 #> 0.12        |      0.13 |       0.60 #> -0.19       |     -0.23 |       0.31 #> 4.76e-03    |     -0.06 |       0.23 #> 0.32        |      0.29 |       0.06 #> 0.41        |      0.15 |       0.07 #> 0.17        |     -0.01 |       0.47 #> -0.06       |      0.37 |       0.08 #> -0.17       |      0.10 |       0.33 #> 0.04        |      0.04 |       0.52 #> -0.05       |      0.04 |       0.35 #> 0.06        |      0.22 |       0.45 #> -1.55e-04   |      0.19 |       0.38 #> 0.08        |     -0.17 |       0.41 #> 0.11        |      0.42 |       0.44 #> -0.20       |      0.07 |       0.48 #> -0.19       |      0.03 |       0.60 #> -0.48       |     -0.12 |       0.55 #> -0.12       |      0.02 |       0.47 #> 6.75e-04    |      0.15 |       0.55 #> -0.05       |      0.54 |       0.58 #> -0.09       |      0.29 |       0.72 #> -0.20       |      0.17 |       0.57 #> 0.20        |     -0.06 |       0.25 #> 0.08        |     -0.03 |       0.06 #> 0.03        |      0.07 |       0.15 #> 0.10        |      0.31 |       0.39 #> -0.14       | -9.84e-03 |       0.22 #> -0.08       |      0.44 |       0.31 #> -0.28       |      0.31 |       0.27 #> 0.10        |      0.10 |       0.60 #> -0.05       |      0.20 |       0.52 #> 0.08        |     -0.02 |       0.29 #> -0.19       |      0.12 |       0.40 #> -0.19       |      0.24 |       0.41 #> -0.15       |     -0.19 |       0.47 #> -0.19       |     -0.16 |       0.56 #> 0.05        |     -0.07 |       0.80 #> -0.13       |      0.10 |       0.08 #> -0.15       |      0.08 |       0.28 #> -0.08       |     -0.02 |       0.25 #> -0.16       | -9.52e-03 |       0.46 #> 0.17        |      0.30 |       0.27 #> 0.28        |      0.14 |       0.33 #> -0.02       |      0.10 |       0.05 #> -0.12       |      0.12 |       0.67 #> -0.08       |     -0.10 |       0.54 #> -0.02       |     -0.03 |       0.66 #> 0.07        |      0.28 |       0.02 #> -0.07       |      0.25 |       0.36 #> 0.09        |     -0.16 |       0.53 #> -0.06       |     -0.18 |       0.39 #> -0.04       |     -0.19 |       0.10 #> 0.04        |      0.35 |       0.65 #> 7.43e-03    |     -0.16 |       0.18 #> -0.11       |     -0.05 |       0.41 #> 0.05        |      0.20 |       0.41 #> -0.06       |     -0.07 |       0.42 #> -0.03       |     -0.29 |       0.51 #> -0.13       |      0.19 |       0.52 #> 0.10        |  8.11e-03 |       0.31 #> -0.25       |      0.09 |       0.66 #> 0.02        |      0.19 |       0.15 #> 0.07        |      0.27 |       0.50 #> 0.06        |     -0.16 |       0.20 #> 0.07        |     -0.15 |       0.22 #> 5.72e-03    |  4.64e-03 |       0.96 #> 0.05        |     -0.11 |       0.97 #> 0.04        |  6.29e-03 |       0.21 #> 0.14        |      0.20 |       0.45 #> 0.04        |      0.42 |       0.30 #> 0.20        |      0.27 |       0.12 #> 0.18        | -3.79e-03 |       0.62 #> -0.10       |      0.22 |       0.21 #> 0.11        |      0.03 |       0.56 #> -0.10       |      0.14 |       0.32 #> -0.12       |      0.15 |       0.17 #> 0.12        |      0.05 |       0.63 #> -0.33       |      0.03 |       0.70 #> 0.36        |      0.12 |       0.45 #> 0.61        |      0.17 |       0.72 #> 0.36        |     -0.04 |       0.36 #> 0.26        |     -0.16 |       0.49 #> -0.28       |      0.38 |       0.42 #> -0.15       |      0.28 |       0.45 #> -0.16       |      0.25 |       0.31 #> -9.54e-03   |     -0.22 |       0.45 #> -0.27       |     -0.15 |       0.51 #> -0.53       |     -0.12 |       0.54 #> 0.55        |      0.38 |       0.28 #> 0.27        |      0.28 |       0.89 #> 0.15        | -8.43e-03 |       0.36 #> -0.16       |      0.12 |       0.52 #> -0.02       |      0.46 |       0.20 #> 9.51e-03    |      0.42 |       0.10 #> -0.02       |      0.27 |       0.15 #> -0.05       |      0.28 |       0.38 #> -0.24       |     -0.11 |       0.52 #> 0.12        |      0.15 |       0.28 #> -0.07       |     -0.17 |       0.46 #> 0.04        |      0.36 |       0.42 #> 0.12        |     -0.16 |       0.44 #> -0.02       |      0.37 |       0.31 #> -0.21       |     -0.03 |       0.29 #> 0.13        |      0.23 |       0.54 #> 0.02        |      0.03 |       0.38 #> -0.17       |  7.51e-03 |       0.43 #> 0.13        |      0.31 |       0.50 #> 0.06        |      0.23 |       0.47 #> -0.02       |      0.08 |       0.42 #> 0.13        |      0.27 |       0.01 #> 0.03        |     -0.10 |       0.33 #> 0.04        |     -0.10 |       0.35 #> -0.09       |      0.11 |       0.23 #> 0.13        |      0.03 |       0.48 #> 0.22        |      0.17 |       0.15 #> -0.25       |  6.79e-03 |       0.60 #> 0.06        |      0.29 |       0.34 #> -0.03       |  1.93e-04 |       0.39 #> 0.04        |      0.13 |       0.40 #> -0.15       |      0.03 |       0.44 #> 0.13        |      0.10 |       0.37 #> 0.26        |      0.12 |       0.33 #> -0.32       |     -0.02 |       0.55 #> -0.14       |      0.09 |      -0.06 #> -0.04       |      0.03 |       0.19 #> 7.31e-03    |      0.15 |       0.60 #> 6.33e-03    |      0.06 |       0.45 #> 0.04        |      0.03 |       0.53 #> -0.07       |      0.12 |       0.34 #> 0.06        |      0.16 |       0.42 #> -0.07       |      0.23 |       0.25 #> 0.16        |      0.18 |       0.35 #> 0.09        |      0.16 |       0.30 #> -0.03       |     -0.03 |       0.33 #> -0.18       |      0.15 |       0.52 #> 0.07        |     -0.04 |       0.43 #> -0.05       |      0.16 |       0.35 #> -0.21       |      0.14 |       0.18 #> 0.18        |      0.07 |       0.55 #> 0.13        |     -0.08 |       0.73 #> -0.09       |      0.02 |       0.20 #> -0.02       |      0.05 |       0.09 #> -0.08       |      0.15 |       0.79 #> -6.29e-03   |      0.05 |       0.61 #> -0.01       |      0.16 |       0.25 #> -0.11       |      0.08 |       0.36 #> -0.41       |      0.21 |       0.15 #> -0.39       |      0.14 |       0.18 #> 0.22        |     -0.29 |       0.47 #> -0.21       |      0.44 |       0.35 #> 0.16        |     -0.28 |       0.43 #> 0.05        |      0.39 |       0.54 #> 0.15        |      0.64 |       0.35 #> 0.11        |      0.59 |       0.37 #> 0.07        |      0.40 |       0.09 #> -0.13       |     -0.20 |       0.64 #> -0.06       |     -0.22 |       0.44 #> -0.20       |     -0.24 |       0.35 #> 0.29        |      0.35 |       0.50 #> -0.32       |     -0.03 |       0.23 #> 0.16        |  4.50e-03 |       0.37 #> -0.21       |      0.14 |       0.31 #> -0.14       |      0.15 |       0.28 #> -0.13       |      0.38 |       0.48 #> -0.20       |      0.37 |       0.33 #> 0.19        |     -0.11 |       0.45 #> -0.15       |      0.24 |       0.47 #> -0.14       |     -0.13 |       0.20 #> -0.06       |      0.03 |       0.33 #> -0.28       |  6.24e-03 |       0.51 #> 0.35        |      0.12 |       0.27 #> 6.60e-03    |      0.22 |       0.03 #> -0.05       |     -0.06 |       0.71 #> -7.17e-03   |     -0.11 |       0.64 #> 0.07        |      0.35 |       0.13 #> 0.15        |      0.28 |       0.22 #> 0.27        |      0.22 |       0.77 #> -0.36       |     -0.02 |       0.16 #> -0.34       |      0.06 |       0.24 #> 0.53        |      0.37 |       0.33 #> -0.40       |     -0.15 |       0.29 #> -0.42       |     -0.23 |       0.33 #> 0.30        |      0.51 |       0.63 #> -0.07       |      0.75 |       0.67 #> -0.18       |      0.60 |       0.59 #> -0.16       |      0.71 |       0.70 #> -0.06       |  6.13e-04 |       0.75 #> 0.12        |      0.02 |       0.15 #> -0.13       |      0.20 |       0.66 #> -0.05       |      0.37 |       0.55 #> 0.03        | -7.74e-03 |       0.18 #> -0.26       |     -0.02 |       0.48 #> -0.26       |     -0.18 |       0.32 #> 0.25        |      0.07 |       0.62 #> -0.18       |     -0.14 |       0.48 #> -0.31       |     -0.07 |       0.42 #> 0.26        |      0.31 |       0.23 #> 0.16        |      0.07 |       0.15 #> 0.16        |      0.10 |      -0.15 #> 0.24        |      0.23 |      -0.22 #> -0.28       |      0.40 |      -0.10 #> 0.17        |     -0.28 |       1.00 #> 0.15        |     -0.06 |       0.74 #> -0.06       |      0.31 |       0.38 #> 0.06        |     -0.07 |       0.43 #> -0.07       |      0.33 |       0.41 #> 0.05        |     -0.11 |       0.46 #> -0.19       |      0.11 |       0.61 #> -0.09       |      0.25 |       0.49 #> -0.34       |      0.37 |       0.15 #> -0.20       |      0.07 |       0.27 #> 0.17        |      0.23 |       0.49 #> 0.32        |      0.04 |       0.44 #> 0.16        |      0.12 |       0.46 #> -0.16       |      0.06 |       0.60 #> 0.03        |      0.12 |       0.39 #> -0.02       |      0.03 |       0.45 #> 0.04        |      0.25 |       0.07 #> -0.03       |      0.36 |       0.07 #> 0.23        |     -0.09 |       0.54 #> -0.05       |      0.32 |       0.26 #> -0.06       |     -0.12 |       0.60 #> 0.28        |      0.31 |       0.30 #> 0.28        |      0.04 |       0.05 #> 0.43        |      0.13 |       0.03 #> 0.15        |     -0.03 |       0.02 #> -0.14       |      0.23 |       0.67 #> 0.62        |     -0.11 |       0.36 #> 0.61        |     -0.07 |       0.51 #> 0.53        |     -0.07 |       0.47 #> 0.48        |     -0.05 |       0.46 #> -0.23       |      0.11 |       0.33 #> -0.11       | -8.43e-03 |       0.35 #> -0.16       |      0.34 |       0.41 #> -0.34       |      0.04 |       0.37 #> 0.24        |      0.07 |       0.43 #> -0.10       |      0.21 |       0.29 #> 0.13        |      0.08 |       0.53 #> -0.28       |      0.13 |       0.40 #> -0.08       |      0.08 |       0.43 #> -0.30       |      0.57 |       0.03 #> -0.15       |      0.40 |      -0.44 #> 0.17        |     -0.08 |       0.75 #> 0.17        |     -0.22 |       0.58 #> -0.03       |      0.48 |       0.46 #> 0.07        |     -0.29 |       0.07 #> -0.14       |      0.45 |       0.63 #> 0.26        |     -0.27 |       0.21 #> 0.29        |     -0.08 |       0.17 #> -0.25       |      0.13 |       0.68 #> 0.46        |      0.25 |       0.58 #> -0.32       |      0.05 |       0.27 #> 0.43        |      0.02 |       0.72 #> 0.54        |     -0.03 |       0.83 #> 0.67        |      0.13 |       0.98 #> 0.21        |     -0.23 |       0.56 #> -0.15       |      0.38 |       0.27 #> -0.23       |      0.07 |       0.26 #> 0.03        |     -0.06 |       0.48 #> 0.03        |      0.23 |       0.36 #> 0.05        |      0.10 |       0.30 #> 0.19        |     -0.02 |       0.49 #> 0.09        |      0.39 |       0.39 #> -0.06       |     -0.03 |       0.11 #> -0.13       |     -0.06 |       0.15 #> -0.05       |      0.40 |       0.30 #> -0.17       |      0.10 |       0.46 #> 0.09        |     -0.07 |       0.59 #> -0.11       |      0.28 |       0.16 #> -0.21       |      0.30 |       0.22 #> 0.11        |      0.02 |       0.48 #> 0.31        |      0.34 |       0.35 #> -0.32       |     -0.26 |       0.37 standardize_posteriors(model, method = \"posthoc\", verbose = FALSE) #> # Standardization method: posthoc #>  #> (Intercept) |  critical | privileges #> ------------------------------------ #> 0.00        |      0.21 |       0.51 #> 0.00        |     -0.02 |       0.31 #> 0.00        |      0.07 |       0.33 #> 0.00        |     -0.03 |       0.13 #> 0.00        |     -0.03 |       0.23 #> 0.00        |     -0.08 |       0.34 #> 0.00        |      0.29 |       0.50 #> 0.00        |      0.48 |       0.32 #> 0.00        |      0.03 |       0.27 #> 0.00        |      0.18 |       0.51 #> 0.00        |      0.32 |       0.62 #> 0.00        |      0.27 |       0.45 #> 0.00        |      0.11 |       0.36 #> 0.00        |      0.14 |       0.51 #> 0.00        |      0.11 |       0.57 #> 0.00        |      0.20 |       0.06 #> 0.00        |      0.02 |       0.85 #> 0.00        |      0.20 |      -0.06 #> 0.00        | -6.82e-03 |       0.31 #> 0.00        | -3.25e-03 |  -7.31e-03 #> 0.00        |      0.13 |       0.77 #> 0.00        |      0.17 |       0.12 #> 0.00        |      0.06 |       0.69 #> 0.00        |     -0.03 |       0.50 #> 0.00        |     -0.03 |       0.54 #> 0.00        |      0.17 |       0.47 #> 0.00        |     -0.17 |       0.33 #> 0.00        |      0.10 |       0.22 #> 0.00        |     -0.12 |       0.25 #> 0.00        |     -0.03 |       0.27 #> 0.00        |      0.24 |       0.57 #> 0.00        |      0.24 |       0.18 #> 0.00        |      0.05 |       0.53 #> 0.00        |      0.31 |       0.43 #> 0.00        |      0.05 |       0.39 #> 0.00        |      0.06 |       0.49 #> 0.00        |      0.17 |       0.58 #> 0.00        |      0.02 |       0.24 #> 0.00        |      0.14 |       0.59 #> 0.00        |     -0.03 |       0.23 #> 0.00        |      0.07 |       0.40 #> 0.00        | -5.86e-03 |       0.42 #> 0.00        |      0.26 |       0.49 #> 0.00        |      0.72 |       0.32 #> 0.00        |     -0.11 |       0.59 #> 0.00        |      0.08 |       0.58 #> 0.00        |      0.28 |       0.24 #> 0.00        |     -0.07 |       0.52 #> 0.00        |      0.14 |       0.21 #> 0.00        |  3.11e-03 |       0.10 #> 0.00        |      0.36 |       0.61 #> 0.00        |     -0.36 |       0.55 #> 0.00        |     -0.33 |       0.56 #> 0.00        |      0.27 |       0.32 #> 0.00        |      0.34 |       0.50 #> 0.00        |     -0.10 |       0.26 #> 0.00        |     -0.08 |       0.31 #> 0.00        |      0.15 |       0.35 #> 0.00        |     -0.14 |       0.31 #> 0.00        |      0.09 |       0.28 #> 0.00        |     -0.21 |       0.27 #> 0.00        |      0.26 |       0.77 #> 0.00        |     -0.04 |       0.07 #> 0.00        |      0.18 |       0.27 #> 0.00        |     -0.10 |       0.55 #> 0.00        |      0.30 |       0.39 #> 0.00        |      0.22 |       0.64 #> 0.00        |      0.21 |       0.14 #> 0.00        |      0.16 |       0.29 #> 0.00        |      0.13 |       0.33 #> 0.00        |      0.16 |       0.34 #> 0.00        |      0.27 |       0.35 #> 0.00        |      0.10 |       0.30 #> 0.00        |      0.28 |       0.36 #> 0.00        |      0.15 |       0.32 #> 0.00        |     -0.27 |       0.73 #> 0.00        |     -0.15 |       0.63 #> 0.00        |  8.94e-03 |       0.53 #> 0.00        |      0.28 |       0.20 #> 0.00        |      0.09 |       0.64 #> 0.00        |      0.08 |       0.36 #> 0.00        |      0.09 |       0.55 #> 0.00        |      0.23 |       0.49 #> 0.00        |      0.25 |       0.18 #> 0.00        |     -0.12 |       0.72 #> 0.00        |      0.45 |       0.30 #> 0.00        |     -0.23 |       0.44 #> 0.00        |      0.40 |       0.35 #> 0.00        |      0.21 |       0.53 #> 0.00        |      0.14 |       0.40 #> 0.00        |     -0.04 |       0.41 #> 0.00        |     -0.10 |       0.46 #> 0.00        |     -0.36 |       0.47 #> 0.00        |     -0.35 |       0.53 #> 0.00        |     -0.32 |       0.45 #> 0.00        |      0.04 |       0.40 #> 0.00        |      0.10 |       0.21 #> 0.00        |      0.33 |       0.63 #> 0.00        |      0.19 |       0.49 #> 0.00        |     -0.13 |       0.50 #> 0.00        |      0.32 |       0.33 #> 0.00        |      0.15 |       0.30 #> 0.00        |     -0.06 |       0.30 #> 0.00        |     -0.06 |       0.72 #> 0.00        |      0.34 |   4.23e-03 #> 0.00        |      0.16 |       0.04 #> 0.00        |      0.21 |       0.56 #> 0.00        |     -0.01 |       0.16 #> 0.00        |      0.26 |       0.60 #> 0.00        |     -0.13 |       0.59 #> 0.00        |      0.35 |       0.32 #> 0.00        |     -0.05 |       0.46 #> 0.00        |      0.11 |       0.25 #> 0.00        |      0.23 |       0.47 #> 0.00        |     -0.05 |       0.31 #> 0.00        |      0.19 |       0.51 #> 0.00        |     -0.10 |       0.44 #> 0.00        |  5.61e-03 |       0.23 #> 0.00        |      0.25 |       0.41 #> 0.00        |      0.50 |       0.15 #> 0.00        |      0.53 |       0.40 #> 0.00        |      0.18 |       0.33 #> 0.00        |      0.21 |       0.32 #> 0.00        |     -0.02 |       0.49 #> 0.00        |      0.11 |       0.46 #> 0.00        |      0.24 |       0.54 #> 0.00        |      0.22 |       0.16 #> 0.00        |      0.02 |       0.66 #> 0.00        |     -0.18 |       0.56 #> 0.00        |      0.12 |       0.44 #> 0.00        |      0.01 |       0.31 #> 0.00        |      0.36 |       0.35 #> 0.00        |      0.12 |       0.40 #> 0.00        |      0.28 |       0.38 #> 0.00        |     -0.10 |       0.51 #> 0.00        |     -0.03 |       0.46 #> 0.00        |      0.09 |       0.60 #> 0.00        |     -0.05 |       0.22 #> 0.00        |      0.23 |       0.46 #> 0.00        |     -0.01 |       0.31 #> 0.00        |      0.14 |       0.72 #> 0.00        |      0.06 |       0.45 #> 0.00        |      0.28 |       0.16 #> 0.00        |     -0.21 |       0.49 #> 0.00        |      0.02 |       0.25 #> 0.00        |     -0.13 |       0.61 #> 0.00        |      0.10 |       0.16 #> 0.00        |      0.05 |       0.12 #> 0.00        |      0.39 |       0.48 #> 0.00        |      0.41 |       0.29 #> 0.00        |      0.16 |       0.54 #> 0.00        |     -0.21 |       0.47 #> 0.00        |      0.15 |       0.81 #> 0.00        |      0.03 |  -7.31e-04 #> 0.00        |      0.27 |       0.65 #> 0.00        |      0.11 |       0.68 #> 0.00        |      0.36 |       0.73 #> 0.00        |     -0.17 |       0.43 #> 0.00        |      0.33 |       0.26 #> 0.00        |      0.19 |       0.41 #> 0.00        |      0.02 |       0.39 #> 0.00        |      0.19 |       0.38 #> 0.00        |      0.14 |       0.31 #> 0.00        |      0.09 |       0.49 #> 0.00        | -3.93e-03 |       0.16 #> 0.00        |      0.03 |       0.60 #> 0.00        |      0.05 |       0.49 #> 0.00        |      0.16 |       0.08 #> 0.00        |      0.16 |       0.48 #> 0.00        |      0.10 |       0.35 #> 0.00        |      0.16 |       0.22 #> 0.00        |  9.23e-03 |       0.61 #> 0.00        |      0.27 |       0.54 #> 0.00        |      0.07 |       0.42 #> 0.00        |     -0.03 |       0.45 #> 0.00        |      0.08 |       0.61 #> 0.00        |      0.14 |       0.38 #> 0.00        |      0.28 |       0.60 #> 0.00        |      0.36 |       0.56 #> 0.00        |      0.09 |       0.25 #> 0.00        | -2.72e-03 |       0.61 #> 0.00        |     -0.04 |       0.35 #> 0.00        |      0.20 |       0.41 #> 0.00        |      0.03 |       0.28 #> 0.00        |      0.21 |       0.49 #> 0.00        |      0.13 |       0.21 #> 0.00        |      0.11 |       0.47 #> 0.00        |      0.07 |       0.29 #> 0.00        |      0.28 |       0.29 #> 0.00        |      0.22 |       0.58 #> 0.00        |      0.10 |       0.51 #> 0.00        |      0.12 |       0.22 #> 0.00        |      0.26 |       0.35 #> 0.00        |     -0.01 |       0.48 #> 0.00        |     -0.12 |       0.36 #> 0.00        |      0.25 |       0.33 #> 0.00        |      0.19 |       0.35 #> 0.00        |     -0.06 |       0.53 #> 0.00        |      0.06 |       0.36 #> 0.00        |      0.34 |       0.34 #> 0.00        |      0.13 |      -0.04 #> 0.00        |     -0.29 |       0.39 #> 0.00        |      0.46 |       0.44 #> 0.00        |      0.21 |       0.30 #> 0.00        |      0.25 |       0.12 #> 0.00        |     -0.13 |       0.21 #> 0.00        |      0.22 |       0.51 #> 0.00        |      0.12 |       0.45 #> 0.00        |     -0.02 |       0.23 #> 0.00        |      0.02 |       0.24 #> 0.00        |     -0.24 |       0.49 #> 0.00        |     -0.04 |       0.39 #> 0.00        |      0.05 |       0.28 #> 0.00        |      0.11 |       0.53 #> 0.00        |     -0.13 |       0.32 #> 0.00        |     -0.14 |       0.63 #> 0.00        |     -0.25 |       0.66 #> 0.00        |     -0.09 |       0.68 #> 0.00        |      0.40 |       0.16 #> 0.00        |      0.35 |       0.32 #> 0.00        |     -0.22 |       0.49 #> 0.00        |      0.20 |       0.36 #> 0.00        |     -0.05 |       0.43 #> 0.00        |      0.24 |       0.73 #> 0.00        |      0.13 |       0.82 #> 0.00        |      0.17 |       0.04 #> 0.00        |      0.25 |       0.65 #> 0.00        |      0.14 |       0.50 #> 0.00        |      0.23 |       0.52 #> 0.00        |     -0.05 |       0.26 #> 0.00        |      0.27 |       0.65 #> 0.00        |     -0.16 |       0.55 #> 0.00        |      0.30 |       0.30 #> 0.00        |     -0.22 |       0.67 #> 0.00        |     -0.06 |       0.36 #> 0.00        |      0.15 |       0.33 #> 0.00        |      0.06 |       0.50 #> 0.00        |      0.15 |       0.30 #> 0.00        |      0.17 |       0.44 #> 0.00        |      0.15 |       0.36 #> 0.00        |  9.67e-03 |       0.48 #> 0.00        |      0.11 |       0.41 #> 0.00        |      0.12 |       0.38 #> 0.00        |      0.01 |       0.50 #> 0.00        |      0.16 |       0.35 #> 0.00        |      0.20 |       0.20 #> 0.00        |      0.21 |       0.58 #> 0.00        |     -0.03 |       0.51 #> 0.00        |      0.25 |       0.15 #> 0.00        |     -0.11 |       0.71 #> 0.00        |      0.21 |       0.15 #> 0.00        |      0.05 |       0.62 #> 0.00        |      0.07 |       0.10 #> 0.00        |     -0.18 |       0.82 #> 0.00        |     -0.04 |       0.51 #> 0.00        |      0.31 |       0.10 #> 0.00        |      0.07 |       0.42 #> 0.00        |      0.18 |       0.30 #> 0.00        |      0.25 |       0.36 #> 0.00        |     -0.06 |       0.47 #> 0.00        |      0.29 |       0.40 #> 0.00        |      0.19 |       0.40 #> 0.00        |      0.25 |       0.56 #> 0.00        |      0.24 |       0.49 #> 0.00        | -3.16e-03 |       0.23 #> 0.00        |      0.11 |       0.55 #> 0.00        |      0.11 |       0.44 #> 0.00        |      0.10 |       0.35 #> 0.00        |      0.15 |       0.47 #> 0.00        |      0.14 |       0.33 #> 0.00        |      0.05 |       0.49 #> 0.00        |      0.17 |       0.37 #> 0.00        |      0.30 |       0.19 #> 0.00        |      0.08 |       0.65 #> 0.00        |      0.14 |       0.47 #> 0.00        |      0.04 |       0.23 #> 0.00        |     -0.01 |       0.62 #> 0.00        |      0.05 |       0.12 #> 0.00        |      0.03 |       0.07 #> 0.00        |     -0.30 |       0.52 #> 0.00        |     -0.14 |       0.60 #> 0.00        |      0.36 |       0.20 #> 0.00        |      0.31 |       0.17 #> 0.00        |     -0.08 |       0.45 #> 0.00        |      0.24 |       0.38 #> 0.00        |      0.20 |       0.29 #> 0.00        |      0.31 |       0.80 #> 0.00        |     -0.04 |       0.71 #> 0.00        |      0.12 |       0.66 #> 0.00        |      0.02 |       0.23 #> 0.00        |      0.01 |       0.25 #> 0.00        |      0.14 |       0.28 #> 0.00        |      0.11 |       0.17 #> 0.00        |      0.22 |       0.36 #> 0.00        |      0.56 |       0.35 #> 0.00        |     -0.49 |       0.67 #> 0.00        |      0.09 |       0.65 #> 0.00        |      0.07 |       0.80 #> 0.00        |      0.23 |       0.24 #> 0.00        |      0.02 |       0.58 #> 0.00        |      0.13 |       0.67 #> 0.00        |      0.13 |       0.53 #> 0.00        |     -0.03 |       0.38 #> 0.00        |      0.12 |       0.40 #> 0.00        | -1.53e-03 |       0.23 #> 0.00        |  5.49e-03 |       0.47 #> 0.00        |     -0.09 |       0.52 #> 0.00        |      0.09 |       0.51 #> 0.00        |      0.03 |       0.18 #> 0.00        |      0.06 |       0.65 #> 0.00        |     -0.21 |       0.27 #> 0.00        |     -0.20 |       0.14 #> 0.00        |      0.45 |       0.67 #> 0.00        |      0.17 |       0.52 #> 0.00        |      0.06 |       0.76 #> 0.00        |      0.10 |       0.18 #> 0.00        |      0.44 |       0.44 #> 0.00        |     -0.31 |       0.41 #> 0.00        |     -0.32 |       0.49 #> 0.00        |     -0.12 |       0.29 #> 0.00        |      0.49 |       0.37 #> 0.00        |     -0.27 |       0.45 #> 0.00        |     -0.16 |       0.67 #> 0.00        |      0.19 |       0.25 #> 0.00        |     -0.02 |       0.59 #> 0.00        |      0.22 |       0.42 #> 0.00        |      0.17 |       0.49 #> 0.00        |      0.05 |       0.25 #> 0.00        |      0.29 |       0.42 #> 0.00        |     -0.13 |       0.55 #> 0.00        |     -0.33 |       0.27 #> 0.00        |     -0.27 |       0.21 #> 0.00        |      0.35 |       0.40 #> 0.00        |      0.38 |       0.21 #> 0.00        |      0.11 |       0.36 #> 0.00        |     -0.01 |       0.55 #> 0.00        | -8.06e-03 |       0.05 #> 0.00        |      0.16 |       0.28 #> 0.00        |      0.21 |       0.45 #> 0.00        |      0.05 |       0.17 #> 0.00        |      0.10 |       0.75 #> 0.00        |      0.04 |       0.79 #> 0.00        |      0.23 |       0.07 #> 0.00        |      0.18 |       0.54 #> 0.00        |     -0.06 |       0.29 #> 0.00        |      0.04 |       0.64 #> 0.00        |      0.17 |       0.52 #> 0.00        |      0.05 |       0.35 #> 0.00        |      0.07 |       0.51 #> 0.00        |      0.01 |       0.20 #> 0.00        |      0.03 |       0.13 #> 0.00        |     -0.11 |       0.12 #> 0.00        |      0.69 |       0.54 #> 0.00        |      0.25 |       0.77 #> 0.00        |     -0.06 |       0.20 #> 0.00        |     -0.08 |       0.29 #> 0.00        |     -0.14 |       0.44 #> 0.00        |     -0.05 |       0.16 #> 0.00        |     -0.09 |       0.36 #> 0.00        |     -0.18 |       0.49 #> 0.00        |      0.27 |       0.49 #> 0.00        |      0.13 |       0.70 #> 0.00        |      0.15 |       0.88 #> 0.00        |      0.12 |       0.90 #> 0.00        |      0.17 |       0.30 #> 0.00        |     -0.09 |       0.51 #> 0.00        |      0.11 |       0.46 #> 0.00        |      0.17 |       0.47 #> 0.00        |      0.04 |       0.38 #> 0.00        | -2.52e-03 |       0.35 #> 0.00        |      0.29 |       0.18 #> 0.00        |      0.66 |       0.19 #> 0.00        |      0.21 |       0.20 #> 0.00        |      0.22 |       0.28 #> 0.00        |     -0.20 |       0.39 #> 0.00        |      0.11 |       0.45 #> 0.00        |     -0.20 |       0.43 #> 0.00        |      0.16 |       0.29 #> 0.00        |     -0.15 |       0.44 #> 0.00        |      0.12 |       0.31 #> 0.00        |     -0.03 |       0.59 #> 0.00        |      0.32 |       0.29 #> 0.00        |     -0.09 |       0.52 #> 0.00        |      0.10 |       0.33 #> 0.00        |      0.13 |       0.38 #> 0.00        |      0.37 |       0.11 #> 0.00        |     -0.28 |       0.67 #> 0.00        |      0.48 |       0.21 #> 0.00        |      0.45 |       0.18 #> 0.00        |     -0.21 |       0.58 #> 0.00        |      0.26 |       0.17 #> 0.00        |     -0.10 |       0.76 #> 0.00        |      0.29 |       0.19 #> 0.00        |     -0.11 |       0.66 #> 0.00        |      0.25 |       0.12 #> 0.00        |     -0.16 |       0.66 #> 0.00        |     -0.21 |       0.52 #> 0.00        |      0.20 |       0.50 #> 0.00        |      0.09 |       0.32 #> 0.00        |     -0.08 |       0.47 #> 0.00        |      0.08 |       0.26 #> 0.00        |     -0.21 |       0.23 #> 0.00        |      0.29 |       0.51 #> 0.00        |      0.15 |       0.75 #> 0.00        |     -0.09 |       0.31 #> 0.00        |      0.08 |       0.71 #> 0.00        |      0.07 |       0.80 #> 0.00        |      0.39 |       0.08 #> 0.00        |      0.43 |       0.17 #> 0.00        |     -0.19 |       0.39 #> 0.00        |      0.23 |       0.33 #> 0.00        |      0.11 |       0.40 #> 0.00        |      0.16 |       0.42 #> 0.00        |      0.06 |       0.59 #> 0.00        |      0.24 |       0.72 #> 0.00        |     -0.02 |       0.31 #> 0.00        |      0.10 |       0.52 #> 0.00        |      0.18 |       0.39 #> 0.00        |      0.20 |       0.55 #> 0.00        |      0.35 |       0.64 #> 0.00        |     -0.04 |       0.35 #> 0.00        |      0.16 |       0.54 #> 0.00        |      0.06 |       0.68 #> 0.00        |     -0.05 |       0.26 #> 0.00        |      0.27 |       0.57 #> 0.00        |     -0.10 |       0.43 #> 0.00        |      0.34 |       0.34 #> 0.00        |      0.33 |       0.02 #> 0.00        |     -0.31 |       0.72 #> 0.00        |      0.49 |       0.16 #> 0.00        |     -0.10 |       0.87 #> 0.00        |      0.02 |       0.13 #> 0.00        |      0.32 |       0.36 #> 0.00        |      0.02 |       0.23 #> 0.00        |      0.05 |       0.20 #> 0.00        |     -0.09 |       0.51 #> 0.00        |      0.36 |       0.34 #> 0.00        |      0.18 |       0.40 #> 0.00        |      0.31 |       0.30 #> 0.00        |     -0.18 |       0.60 #> 0.00        |      0.26 |       0.31 #> 0.00        |      0.26 |       0.45 #> 0.00        |      0.12 |       0.32 #> 0.00        |     -0.06 |       0.33 #> 0.00        |     -0.05 |       0.49 #> 0.00        |     -0.16 |       0.28 #> 0.00        |      0.06 |       0.42 #> 0.00        |      0.47 |       0.39 #> 0.00        |      0.05 |       0.32 #> 0.00        |      0.15 |       0.47 #> 0.00        |      0.03 |       0.45 #> 0.00        |      0.27 |       0.17 #> 0.00        |      0.02 |       0.67 #> 0.00        |      0.24 |       0.20 #> 0.00        |     -0.08 |       0.83 #> 0.00        |     -0.21 |       0.52 #> 0.00        |     -0.23 |       0.69 #> 0.00        |     -0.07 |       0.65 #> 0.00        |      0.31 |       0.10 #> 0.00        |      0.06 |       0.28 #> 0.00        |      0.11 |       0.26 #> 0.00        |     -0.09 |       0.75 #> 0.00        |      0.41 |       0.09 #> 0.00        |      0.08 |       0.17 #> 0.00        |      0.24 |       0.48 #> 0.00        |      0.06 |      -0.15 #> 0.00        |      0.16 |       0.02 #> 0.00        |     -0.16 |      -0.02 #> 0.00        |     -0.09 |       0.21 #> 0.00        |      0.15 |       0.41 #> 0.00        |      0.01 |       0.48 #> 0.00        |      0.42 |       0.41 #> 0.00        |      0.78 |       0.42 #> 0.00        |     -0.13 |       0.75 #> 0.00        |      0.21 |       0.11 #> 0.00        |     -0.02 |       0.74 #> 0.00        |     -0.05 |       0.57 #> 0.00        |      0.12 |       0.47 #> 0.00        |      0.27 |       0.44 #> 0.00        |     -0.16 |       0.38 #> 0.00        |      0.27 |       0.48 #> 0.00        |      0.11 |       0.51 #> 0.00        |     -0.12 |       0.19 #> 0.00        |     -0.05 |       0.37 #> 0.00        |      0.16 |       0.40 #> 0.00        |      0.09 |       0.49 #> 0.00        |      0.05 |       0.36 #> 0.00        |      0.16 |       0.61 #> 0.00        |      0.14 |       0.69 #> 0.00        |     -0.05 |       0.38 #> 0.00        |      0.14 |       0.64 #> 0.00        |      0.07 |       0.33 #> 0.00        |      0.14 |       0.49 #> 0.00        |      0.28 |       0.34 #> 0.00        |     -0.11 |       0.22 #> 0.00        |      0.20 |       0.68 #> 0.00        |      0.12 |       0.52 #> 0.00        |      0.10 |       0.35 #> 0.00        |     -0.06 |       0.49 #> 0.00        |  6.66e-03 |       0.28 #> 0.00        |  1.14e-03 |       0.23 #> 0.00        |      0.14 |       0.33 #> 0.00        |      0.12 |       0.54 #> 0.00        |      0.29 |       0.24 #> 0.00        |     -0.05 |       0.53 #> 0.00        |     -0.26 |       0.50 #> 0.00        |     -0.19 |       0.54 #> 0.00        |      0.33 |       0.23 #> 0.00        |     -0.02 |       0.65 #> 0.00        |      0.09 |       0.69 #> 0.00        |      0.03 |       0.18 #> 0.00        |      0.10 |       0.35 #> 0.00        |      0.10 |       0.49 #> 0.00        |      0.14 |       0.13 #> 0.00        |     -0.03 |       0.70 #> 0.00        |      0.03 |       0.63 #> 0.00        |     -0.08 |       0.63 #> 0.00        |      0.17 |       0.24 #> 0.00        |      0.11 |       0.48 #> 0.00        |      0.49 |       0.45 #> 0.00        |      0.29 |       0.51 #> 0.00        |      0.24 |       0.44 #> 0.00        |      0.44 |       0.46 #> 0.00        |      0.48 |       0.54 #> 0.00        |      0.31 |       0.23 #> 0.00        |     -0.09 |       0.66 #> 0.00        |      0.12 |       0.44 #> 0.00        |     -0.05 |       0.24 #> 0.00        |      0.05 |       0.34 #> 0.00        |      0.10 |       0.21 #> 0.00        |      0.19 |       0.60 #> 0.00        |      0.18 |       0.59 #> 0.00        |      0.17 |       0.50 #> 0.00        |      0.08 |       0.68 #> 0.00        |      0.12 |      -0.04 #> 0.00        |     -0.27 |       0.24 #> 0.00        |      0.55 |       0.60 #> 0.00        |      0.04 |       0.39 #> 0.00        |      0.19 |       0.08 #> 0.00        |     -0.06 |       0.83 #> 0.00        |      0.28 |       0.43 #> 0.00        |     -0.10 |       0.27 #> 0.00        |  4.93e-03 |       0.29 #> 0.00        |     -0.08 |       0.06 #> 0.00        |     -0.08 |       0.42 #> 0.00        |      0.06 |       0.52 #> 0.00        |      0.13 |       0.30 #> 0.00        |      0.09 |       0.26 #> 0.00        |      0.16 |       0.50 #> 0.00        |      0.05 |       0.42 #> 0.00        |      0.26 |       0.40 #> 0.00        |      0.12 |       0.49 #> 0.00        |      0.20 |       0.57 #> 0.00        |      0.05 |       0.52 #> 0.00        |     -0.18 |       0.42 #> 0.00        |      0.35 |       0.42 #> 0.00        |     -0.21 |       0.44 #> 0.00        |      0.29 |       0.45 #> 0.00        |     -0.04 |       0.27 #> 0.00        |      0.27 |       0.56 #> 0.00        |      0.28 |       0.57 #> 0.00        |      0.04 |       0.29 #> 0.00        |     -0.08 |       0.46 #> 0.00        |     -0.08 |       0.44 #> 0.00        |      0.22 |       0.43 #> 0.00        |     -0.01 |       0.12 #> 0.00        |      0.39 |       0.15 #> 0.00        |      0.13 |       0.69 #> 0.00        |      0.08 |       0.24 #> 0.00        |      0.03 |       0.37 #> 0.00        |  7.34e-03 |       0.26 #> 0.00        |      0.06 |       0.28 #> 0.00        |  1.24e-03 |       0.29 #> 0.00        |      0.07 |       0.39 #> 0.00        |      0.16 |       0.48 #> 0.00        |      0.17 |       0.62 #> 0.00        |     -0.05 |       0.29 #> 0.00        |      0.21 |       0.52 #> 0.00        |      0.02 |       0.49 #> 0.00        |      0.37 |       0.43 #> 0.00        |      0.17 |       0.43 #> 0.00        |      0.17 |       0.36 #> 0.00        |      0.35 |       0.51 #> 0.00        |      0.12 |       0.47 #> 0.00        |     -0.02 |       0.55 #> 0.00        |      0.29 |       0.37 #> 0.00        |     -0.10 |       0.68 #> 0.00        |      0.06 |       0.25 #> 0.00        |      0.03 |       0.35 #> 0.00        |      0.36 |       0.49 #> 0.00        |     -0.22 |       0.33 #> 0.00        |      0.10 |       0.49 #> 0.00        |      0.21 |       0.43 #> 0.00        |      0.49 |       0.40 #> 0.00        |      0.30 |       0.36 #> 0.00        |     -0.06 |       0.54 #> 0.00        |      0.19 |       0.28 #> 0.00        |      0.02 |       0.45 #> 0.00        |      0.12 |       0.43 #> 0.00        |      0.11 |       0.40 #> 0.00        |      0.04 |       0.48 #> 0.00        |     -0.09 |       0.52 #> 0.00        |     -0.08 |       0.43 #> 0.00        |      0.06 |       0.66 #> 0.00        |     -0.05 |       0.41 #> 0.00        |      0.25 |       0.41 #> 0.00        |     -0.09 |       0.41 #> 0.00        |     -0.18 |       0.03 #> 0.00        |      0.41 |       0.74 #> 0.00        |      0.15 |       0.55 #> 0.00        |      0.11 |       0.72 #> 0.00        |      0.04 |       0.24 #> 0.00        |      0.18 |       0.71 #> 0.00        |      0.21 |       0.73 #> 0.00        |      0.15 |       0.25 #> 0.00        |  3.96e-03 |       0.55 #> 0.00        |      0.07 |       0.36 #> 0.00        |      0.13 |       0.36 #> 0.00        |      0.09 |       0.22 #> 0.00        |     -0.03 |       0.66 #> 0.00        |      0.13 |       0.43 #> 0.00        |      0.12 |       0.33 #> 0.00        |      0.13 |       0.37 #> 0.00        |      0.19 |       0.48 #> 0.00        |     -0.10 |       0.32 #> 0.00        |  2.29e-03 |       0.40 #> 0.00        |      0.08 |       0.26 #> 0.00        |      0.06 |       0.51 #> 0.00        |      0.10 |       0.30 #> 0.00        |      0.12 |       0.28 #> 0.00        |      0.12 |       0.36 #> 0.00        |      0.02 |       0.36 #> 0.00        | -3.52e-03 |       0.47 #> 0.00        |     -0.16 |       0.60 #> 0.00        |      0.06 |       0.52 #> 0.00        |      0.45 |       0.29 #> 0.00        |      0.52 |       0.44 #> 0.00        |      0.25 |       0.32 #> 0.00        |      0.03 |       0.38 #> 0.00        |  2.98e-03 |       0.57 #> 0.00        |     -0.06 |       0.61 #> 0.00        |     -0.08 |       0.25 #> 0.00        |     -0.10 |       0.27 #> 0.00        |      0.12 |       0.76 #> 0.00        |      0.28 |       0.18 #> 0.00        |      0.26 |       0.40 #> 0.00        |      0.18 |       0.17 #> 0.00        |      0.32 |       0.74 #> 0.00        |      0.15 |       0.28 #> 0.00        |     -0.07 |       0.58 #> 0.00        |      0.04 |       0.55 #> 0.00        |     -0.09 |       0.38 #> 0.00        |      0.18 |       0.49 #> 0.00        |      0.02 |       0.34 #> 0.00        |      0.16 |       0.38 #> 0.00        |     -0.01 |       0.48 #> 0.00        |      0.11 |       0.37 #> 0.00        |      0.11 |       0.27 #> 0.00        |     -0.12 |       0.31 #> 0.00        |      0.12 |       0.14 #> 0.00        |     -0.06 |       0.05 #> 0.00        |      0.03 |       0.45 #> 0.00        | -6.35e-03 |       0.24 #> 0.00        |      0.21 |       0.55 #> 0.00        |      0.05 |       0.43 #> 0.00        |     -0.34 |       0.24 #> 0.00        |     -0.10 |       0.23 #> 0.00        |      0.27 |       0.56 #> 0.00        |      0.21 |       0.49 #> 0.00        |  9.17e-03 |       0.36 #> 0.00        |      0.22 |       0.44 #> 0.00        |     -0.14 |       0.39 #> 0.00        |      0.26 |       0.51 #> 0.00        |      0.02 |       0.43 #> 0.00        |     -0.14 |       0.48 #> 0.00        |      0.21 |       0.33 #> 0.00        |     -0.03 |       0.41 #> 0.00        |     -0.04 |       0.45 #> 0.00        |      0.32 |       0.34 #> 0.00        |     -0.15 |       0.33 #> 0.00        |      0.03 |       0.39 #> 0.00        |      0.21 |       0.42 #> 0.00        |     -0.04 |       0.41 #> 0.00        |      0.43 |       0.30 #> 0.00        |      0.14 |       0.31 #> 0.00        |      0.24 |       0.36 #> 0.00        |      0.20 |       0.36 #> 0.00        |     -0.02 |       0.25 #> 0.00        |      0.02 |       0.39 #> 0.00        |      0.10 |       0.13 #> 0.00        |      0.32 |       0.17 #> 0.00        |     -0.03 |       0.74 #> 0.00        |     -0.51 |       0.82 #> 0.00        |      0.77 |       0.40 #> 0.00        |      0.55 |       0.43 #> 0.00        |      0.02 |       0.44 #> 0.00        |     -0.13 |       0.46 #> 0.00        |     -0.09 |       0.52 #> 0.00        |      0.25 |       0.28 #> 0.00        |     -0.11 |       0.59 #> 0.00        |     -0.11 |       0.47 #> 0.00        |     -0.25 |       0.52 #> 0.00        |      0.61 |       0.30 #> 0.00        |     -0.28 |       0.34 #> 0.00        |      0.33 |       0.55 #> 0.00        |      0.15 |       0.34 #> 0.00        | -8.86e-03 |       0.62 #> 0.00        |      0.11 |       0.58 #> 0.00        |     -0.09 |       0.28 #> 0.00        |      0.04 |       0.61 #> 0.00        |     -0.10 |       0.53 #> 0.00        |      0.04 |       0.28 #> 0.00        |      0.15 |       0.50 #> 0.00        |      0.24 |       0.36 #> 0.00        |     -0.05 |       0.40 #> 0.00        |      0.14 |       0.28 #> 0.00        |      0.09 |       0.41 #> 0.00        |      0.05 |       0.73 #> 0.00        |      0.11 |       0.38 #> 0.00        |      0.09 |       0.62 #> 0.00        |      0.21 |       0.17 #> 0.00        |      0.19 |       0.22 #> 0.00        |      0.21 |       0.31 #> 0.00        |      0.28 |       0.29 #> 0.00        |      0.32 |       0.36 #> 0.00        |      0.09 |       0.24 #> 0.00        |      0.39 |       0.36 #> 0.00        |     -0.30 |       0.48 #> 0.00        |      0.08 |       0.21 #> 0.00        | -4.96e-03 |       0.46 #> 0.00        |     -0.03 |       0.17 #> 0.00        |      0.32 |       0.43 #> 0.00        |      0.34 |       0.29 #> 0.00        |      0.46 |       0.40 #> 0.00        |     -0.18 |       0.43 #> 0.00        |      0.17 |       0.38 #> 0.00        |     -0.22 |       0.58 #> 0.00        |      0.18 |       0.36 #> 0.00        |  1.09e-03 |       0.07 #> 0.00        |     -0.04 |       0.45 #> 0.00        |     -0.14 |       0.71 #> 0.00        |      0.32 |       0.56 #> 0.00        |      0.01 |       0.31 #> 0.00        |      0.01 |       0.47 #> 0.00        |      0.09 |       0.48 #> 0.00        |      0.14 |       0.35 #> 0.00        |      0.12 |       0.64 #> 0.00        |      0.37 |       0.11 #> 0.00        |     -0.11 |       0.68 #> 0.00        |      0.04 |       0.52 #> 0.00        |     -0.12 |       0.53 #> 0.00        |     -0.01 |       0.51 #> 0.00        | -3.97e-03 |       0.21 #> 0.00        |      0.18 |       0.25 #> 0.00        |      0.21 |       0.22 #> 0.00        |      0.24 |       0.37 #> 0.00        |      0.25 |       0.23 #> 0.00        |     -0.09 |       0.59 #> 0.00        |      0.03 |       0.47 #> 0.00        |      0.30 |       0.22 #> 0.00        |     -0.05 |       0.64 #> 0.00        |      0.19 |       0.32 #> 0.00        |      0.25 |       0.41 #> 0.00        |     -0.11 |       0.45 #> 0.00        |      0.20 |       0.71 #> 0.00        |      0.03 |       0.14 #> 0.00        |      0.14 |       0.44 #> 0.00        |     -0.06 |       0.26 #> 0.00        |     -0.06 |       0.35 #> 0.00        |      0.06 |       0.38 #> 0.00        |      0.12 |       0.52 #> 0.00        |      0.15 |       0.36 #> 0.00        |      0.12 |       0.39 #> 0.00        |      0.04 |       0.48 #> 0.00        |      0.07 |       0.31 #> 0.00        |     -0.01 |       0.19 #> 0.00        |      0.13 |       0.63 #> 0.00        |      0.16 |       0.12 #> 0.00        |      0.19 |       0.51 #> 0.00        |      0.09 |       0.35 #> 0.00        |      0.09 |       0.35 #> 0.00        |      0.14 |       0.64 #> 0.00        |      0.23 |       0.31 #> 0.00        |     -0.15 |       0.67 #> 0.00        |     -0.08 |       0.61 #> 0.00        |      0.03 |       0.74 #> 0.00        |      0.09 |       0.68 #> 0.00        |     -0.45 |       0.62 #> 0.00        |     -0.46 |       0.60 #> 0.00        |      0.22 |       0.12 #> 0.00        |      0.05 |       0.66 #> 0.00        |      0.11 |       0.07 #> 0.00        |      0.27 |       0.33 #> 0.00        |      0.01 |       0.50 #> 0.00        |      0.23 |       0.34 #> 0.00        |     -0.02 |       0.42 #> 0.00        |      0.25 |       0.41 #> 0.00        |     -0.04 |       0.51 #> 0.00        |     -0.19 |       0.90 #> 0.00        |      0.16 |       0.10 #> 0.00        |      0.05 |       0.14 #> 0.00        |     -0.01 |       0.39 #> 0.00        |      0.39 |       0.33 #> 0.00        |     -0.21 |       0.46 #> 0.00        |     -0.04 |       0.46 #> 0.00        |      0.26 |       0.62 #> 0.00        |      0.27 |       0.67 #> 0.00        |      0.09 |       0.43 #> 0.00        |      0.14 |       0.44 #> 0.00        |     -0.16 |       0.46 #> 0.00        |      0.36 |       0.50 #> 0.00        |     -0.02 |       0.35 #> 0.00        |      0.04 |       0.47 #> 0.00        |      0.10 |       0.43 #> 0.00        |      0.21 |       0.54 #> 0.00        |      0.17 |       0.33 #> 0.00        |      0.05 |       0.45 #> 0.00        |      0.08 |       0.41 #> 0.00        |      0.14 |       0.27 #> 0.00        |      0.17 |       0.58 #> 0.00        |     -0.06 |       0.61 #> 0.00        |      0.36 |       0.46 #> 0.00        |      0.31 |       0.41 #> 0.00        | -4.89e-03 |       0.42 #> 0.00        |      0.11 |       0.67 #> 0.00        |      0.07 |       0.19 #> 0.00        |      0.12 |       0.74 #> 0.00        |      0.07 |       0.27 #> 0.00        |      0.09 |       0.66 #> 0.00        |      0.03 |       0.06 #> 0.00        |      0.24 |       0.49 #> 0.00        |      0.15 |       0.24 #> 0.00        |      0.11 |       0.59 #> 0.00        |     -0.12 |       0.54 #> 0.00        |      0.18 |       0.46 #> 0.00        |  5.47e-03 |       0.54 #> 0.00        |      0.24 |       0.37 #> 0.00        |      0.27 |       0.51 #> 0.00        |     -0.02 |       0.25 #> 0.00        |      0.25 |       0.56 #> 0.00        |      0.15 |       0.39 #> 0.00        |      0.03 |       0.56 #> 0.00        |     -0.35 |      -0.18 #> 0.00        |      0.08 |       0.47 #> 0.00        |      0.06 |       0.39 #> 0.00        |      0.06 |       0.44 #> 0.00        |      0.08 |       0.47 #> 0.00        |      0.16 |       0.38 #> 0.00        |     -0.01 |       0.57 #> 0.00        |      0.16 |       0.28 #> 0.00        |     -0.31 |       0.44 #> 0.00        |     -0.38 |       0.31 #> 0.00        |      0.11 |       0.26 #> 0.00        |      0.17 |       0.45 #> 0.00        |      0.27 |       0.25 #> 0.00        |  4.01e-03 |       0.43 #> 0.00        |      0.19 |       0.39 #> 0.00        |     -0.02 |       0.46 #> 0.00        |      0.12 |       0.22 #> 0.00        |      0.05 |       0.66 #> 0.00        |      0.12 |       0.74 #> 0.00        |      0.03 |       0.67 #> 0.00        |      0.42 |       0.29 #> 0.00        |  1.70e-03 |       0.39 #> 0.00        |     -0.13 |       0.37 #> 0.00        |      0.26 |       0.48 #> 0.00        |      0.13 |       0.22 #> 0.00        |      0.27 |       0.68 #> 0.00        |     -0.34 |       0.13 #> 0.00        |      0.04 |       0.55 #> 0.00        |      0.27 |       0.36 #> 0.00        |      0.04 |       0.60 #> 0.00        |     -0.21 |       0.34 #> 0.00        |     -0.24 |       0.51 #> 0.00        |      0.40 |       0.32 #> 0.00        |     -0.28 |       0.50 #> 0.00        |      0.31 |       0.23 #> 0.00        |     -0.02 |       0.50 #> 0.00        |      0.23 |       0.30 #> 0.00        |      0.25 |       0.30 #> 0.00        |     -0.14 |       0.52 #> 0.00        |     -0.15 |       0.59 #> 0.00        |      0.32 |       0.12 #> 0.00        |      0.19 |       0.07 #> 0.00        |     -0.04 |       0.74 #> 0.00        |     -0.09 |       0.48 #> 0.00        |      0.42 |       0.41 #> 0.00        |      0.23 |       0.28 #> 0.00        |     -0.04 |       0.52 #> 0.00        |      0.08 |       0.49 #> 0.00        |      0.08 |       0.49 #> 0.00        |      0.13 |       0.35 #> 0.00        |     -0.13 |       0.57 #> 0.00        |      0.28 |       0.30 #> 0.00        |      0.39 |       0.31 #> 0.00        |     -0.18 |       0.53 #> 0.00        |     -0.21 |       0.54 #> 0.00        |      0.39 |       0.42 #> 0.00        |      0.72 |       0.23 #> 0.00        |     -0.08 |       0.48 #> 0.00        |     -0.22 |       0.55 #> 0.00        |     -0.29 |       0.54 #> 0.00        |     -0.28 |       0.46 #> 0.00        |      0.35 |       0.50 #> 0.00        |     -0.12 |       0.35 #> 0.00        |     -0.03 |       0.31 #> 0.00        |      0.11 |       0.26 #> 0.00        |      0.19 |       0.32 #> 0.00        |      0.12 |       0.40 #> 0.00        |      0.34 |       0.23 #> 0.00        |      0.43 |       0.15 #> 0.00        |      0.31 |       0.05 #> 0.00        |      0.14 |       0.60 #> 0.00        |      0.15 |       0.63 #> 0.00        |      0.11 |       0.59 #> 0.00        |      0.32 |  -2.51e-03 #> 0.00        |     -0.08 |       0.87 #> 0.00        |      0.21 |       0.06 #> 0.00        |     -0.11 |       0.89 #> 0.00        |      0.02 |       0.70 #> 0.00        |      0.33 |       0.36 #> 0.00        |     -0.20 |       0.42 #> 0.00        |      0.33 |       0.60 #> 0.00        |     -0.08 |       0.25 #> 0.00        |      0.13 |       0.69 #> 0.00        |     -0.08 |       0.64 #> 0.00        |      0.06 |       0.44 #> 0.00        |      0.05 |       0.72 #> 0.00        |     -0.26 |       0.44 #> 0.00        | -3.19e-03 |       0.23 #> 0.00        |      0.33 |       0.20 #> 0.00        |      0.36 |       0.21 #> 0.00        |     -0.11 |       0.57 #> 0.00        |      0.06 |       0.38 #> 0.00        |      0.16 |       0.24 #> 0.00        |     -0.18 |       0.69 #> 0.00        |      0.16 |       0.21 #> 0.00        |     -0.11 |       0.46 #> 0.00        |      0.33 |       0.17 #> 0.00        | -5.90e-03 |       0.69 #> 0.00        |      0.02 |       0.69 #> 0.00        |     -0.09 |       0.69 #> 0.00        |     -0.14 |       0.72 #> 0.00        |      0.20 |       0.32 #> 0.00        |     -0.09 |       0.24 #> 0.00        |      0.06 |       0.22 #> 0.00        |      0.04 |       0.58 #> 0.00        |     -0.31 |       0.56 #> 0.00        |     -0.41 |       0.56 #> 0.00        |     -0.39 |       0.60 #> 0.00        |     -0.28 |       0.49 #> 0.00        | -1.99e-03 |       0.58 #> 0.00        |      0.21 |       0.44 #> 0.00        |      0.17 |       0.39 #> 0.00        |      0.02 |       0.46 #> 0.00        |      0.02 |       0.46 #> 0.00        |      0.50 |       0.41 #> 0.00        |      0.14 |       0.41 #> 0.00        |      0.29 |       0.30 #> 0.00        |      0.18 |       0.57 #> 0.00        |      0.18 |       0.57 #> 0.00        |      0.11 |       0.32 #> 0.00        |      0.21 |       0.43 #> 0.00        |      0.20 |       0.31 #> 0.00        |      0.22 |       0.39 #> 0.00        |      0.10 |       0.34 #> 0.00        |      0.11 |       0.25 #> 0.00        |      0.54 |       0.26 #> 0.00        |     -0.07 |       0.31 #> 0.00        |     -0.17 |       0.82 #> 0.00        |     -0.10 |       0.76 #> 0.00        |      0.18 |       0.37 #> 0.00        |      0.07 |       0.30 #> 0.00        |      0.11 |       0.63 #> 0.00        |      0.07 |       0.05 #> 0.00        |      0.03 |       0.56 #> 0.00        |     -0.02 |       0.49 #> 0.00        |      0.25 |       0.65 #> 0.00        |      0.07 |       0.80 #> 0.00        |      0.14 |       0.07 #> 0.00        |      0.12 |       0.74 #> 0.00        |     -0.12 |       0.53 #> 0.00        |      0.21 |       0.26 #> 0.00        |     -0.03 |       0.56 #> 0.00        |     -0.13 |       0.70 #> 0.00        |      0.35 |       0.12 #> 0.00        |      0.28 |       0.22 #> 0.00        |      0.02 |       0.66 #> 0.00        |     -0.24 |       0.33 #> 0.00        |      0.50 |       0.45 #> 0.00        |     -0.08 |       0.23 #> 0.00        |     -0.02 |       0.20 #> 0.00        |      0.26 |       0.59 #> 0.00        |      0.18 |       0.41 #> 0.00        |      0.12 |       0.50 #> 0.00        |      0.13 |       0.48 #> 0.00        |      0.11 |       0.25 #> 0.00        |      0.18 |       0.20 #> 0.00        |      0.24 |       0.22 #> 0.00        | -1.57e-04 |       0.46 #> 0.00        |     -0.14 |       0.71 #> 0.00        |      0.11 |       0.14 #> 0.00        |      0.23 |       0.75 #> 0.00        |      0.04 |       0.08 #> 0.00        |     -0.07 |       0.51 #> 0.00        |     -0.02 |       0.13 #> 0.00        |      0.21 |       0.69 #> 0.00        |     -0.05 |       0.19 #> 0.00        |      0.04 |       0.21 #> 0.00        |      0.05 |       0.76 #> 0.00        |      0.07 |       0.24 #> 0.00        |      0.06 |       0.71 #> 0.00        |      0.14 |       0.42 #> 0.00        |      0.34 |       0.50 #> 0.00        |      0.12 |       0.41 #> 0.00        |      0.19 |       0.38 #> 0.00        |      0.22 |       0.36 #> 0.00        |      0.25 |       0.66 #> 0.00        |      0.23 |       0.14 #> 0.00        |      0.20 |       0.53 #> 0.00        |      0.45 |       0.39 #> 0.00        |     -0.30 |       0.49 #> 0.00        |      0.18 |       0.37 #> 0.00        |      0.32 |       0.34 #> 0.00        |     -0.12 |       0.48 #> 0.00        |     -0.26 |       0.63 #> 0.00        |      0.38 |       0.22 #> 0.00        |      0.02 |       0.49 #> 0.00        |      0.50 |       0.39 #> 0.00        |     -0.30 |       0.39 #> 0.00        |     -0.11 |       0.24 #> 0.00        |      0.01 |       0.65 #> 0.00        |      0.19 |       0.22 #> 0.00        | -1.76e-04 |       0.56 #> 0.00        |      0.11 |       0.48 #> 0.00        |      0.16 |       0.27 #> 0.00        |      0.10 |       0.53 #> 0.00        |      0.06 |       0.38 #> 0.00        |      0.02 |       0.65 #> 0.00        |      0.15 |       0.25 #> 0.00        |      0.05 |       0.54 #> 0.00        |     -0.04 |       0.36 #> 0.00        | -8.11e-03 |       0.36 #> 0.00        |      0.04 |       0.30 #> 0.00        |      0.16 |       0.51 #> 0.00        |      0.66 |       0.26 #> 0.00        |      0.05 |       0.08 #> 0.00        |     -0.11 |       0.37 #> 0.00        |      0.07 |       0.44 #> 0.00        |     -0.02 |       0.63 #> 0.00        |      0.13 |       0.35 #> 0.00        |      0.16 |       0.46 #> 0.00        |      0.21 |       0.54 #> 0.00        |     -0.03 |       0.34 #> 0.00        |      0.27 |       0.46 #> 0.00        |     -0.14 |       0.42 #> 0.00        |      0.25 |       0.21 #> 0.00        |      0.27 |       0.05 #> 0.00        |      0.20 |       0.07 #> 0.00        |      0.40 |      -0.14 #> 0.00        |     -0.10 |       0.83 #> 0.00        |      0.06 |       0.38 #> 0.00        |      0.10 |       0.33 #> 0.00        |     -0.08 |       0.51 #> 0.00        |     -0.25 |       0.32 #> 0.00        |      0.28 |       0.69 #> 0.00        |      0.06 |       0.74 #> 0.00        |     -0.05 |       0.27 #> 0.00        |      0.23 |       0.58 #> 0.00        |     -0.32 |       0.48 #> 0.00        |      0.44 |       0.28 #> 0.00        |      0.50 |       0.31 #> 0.00        |      0.02 |       0.50 #> 0.00        | -2.04e-03 |       0.45 #> 0.00        |      0.14 |       0.41 #> 0.00        |      0.14 |       0.20 #> 0.00        |     -0.02 |       0.17 #> 0.00        |      0.04 |       0.27 #> 0.00        |      0.40 |       0.30 #> 0.00        |     -0.28 |       0.46 #> 0.00        |     -0.16 |       0.47 #> 0.00        |      0.08 |       0.40 #> 0.00        |      0.03 |       0.14 #> 0.00        |     -0.10 |       0.11 #> 0.00        |     -0.09 |       0.68 #> 0.00        |      0.15 |       0.39 #> 0.00        |      0.17 |       0.47 #> 0.00        |     -0.03 |       0.30 #> 0.00        |      0.23 |       0.31 #> 0.00        |      0.02 |       0.60 #> 0.00        |      0.12 |       0.29 #> 0.00        |      0.11 |       0.66 #> 0.00        |      0.11 |       0.66 #> 0.00        |      0.03 |       0.18 #> 0.00        |     -0.04 |       0.49 #> 0.00        |      0.37 |       0.30 #> 0.00        |     -0.07 |       0.48 #> 0.00        |      0.25 |       0.35 #> 0.00        |      0.18 |       0.60 #> 0.00        |     -0.15 |   4.73e-04 #> 0.00        |      0.44 |       0.38 #> 0.00        |      0.34 |       0.43 #> 0.00        |      0.11 |       0.35 #> 0.00        |     -0.05 |       0.20 #> 0.00        |      0.29 |       0.57 #> 0.00        |      0.43 |       0.41 #> 0.00        |      0.22 |       0.15 #> 0.00        |      0.21 |       0.48 #> 0.00        |      0.23 |       0.25 #> 0.00        |      0.10 |       0.23 #> 0.00        |      0.13 |       0.56 #> 0.00        |  2.56e-03 |       0.56 #> 0.00        |      0.12 |       0.24 #> 0.00        |     -0.02 |       0.69 #> 0.00        |      0.20 |       0.09 #> 0.00        |      0.08 |       0.32 #> 0.00        |      0.16 |       0.25 #> 0.00        |     -0.01 |       0.64 #> 0.00        |      0.20 |       0.18 #> 0.00        |     -0.08 |       0.65 #> 0.00        |     -0.15 |       0.80 #> 0.00        |      0.33 |       0.02 #> 0.00        |      0.30 |       0.12 #> 0.00        |     -0.05 |       0.48 #> 0.00        |      0.12 |       0.39 #> 0.00        |     -0.16 |       0.62 #> 0.00        |      0.30 |       0.61 #> 0.00        |     -0.05 |       0.33 #> 0.00        |      0.09 |       0.50 #> 0.00        |      0.01 |       0.35 #> 0.00        |      0.05 |       0.47 #> 0.00        |      0.29 |       0.44 #> 0.00        |      0.31 |       0.25 #> 0.00        |      0.21 |       0.27 #> 0.00        |     -0.35 |       0.49 #> 0.00        |     -0.17 |       0.60 #> 0.00        |      0.15 |       0.32 #> 0.00        |      0.22 |       0.49 #> 0.00        |      0.01 |       0.42 #> 0.00        |      0.12 |       0.56 #> 0.00        |      0.06 |       0.41 #> 0.00        |      0.07 |       0.48 #> 0.00        | -2.43e-03 |       0.56 #> 0.00        |      0.04 |       0.65 #> 0.00        |  9.99e-03 |       0.32 #> 0.00        |      0.16 |       0.62 #> 0.00        |     -0.18 |       0.41 #> 0.00        |     -0.11 |       0.30 #> 0.00        |      0.27 |       0.48 #> 0.00        |     -0.10 |       0.44 #> 0.00        |      0.15 |       0.48 #> 0.00        |      0.07 |       0.61 #> 0.00        |  2.72e-03 |       0.50 #> 0.00        |      0.12 |       0.45 #> 0.00        |      0.29 |       0.33 #> 0.00        |     -0.18 |       0.77 #> 0.00        |      0.35 |       0.74 #> 0.00        |      0.45 |       0.31 #> 0.00        |     -0.19 |       0.51 #> 0.00        |     -0.12 |       0.21 #> 0.00        |     -0.21 |       0.36 #> 0.00        |     -0.04 |       0.48 #> 0.00        |      0.24 |       0.49 #> 0.00        |      0.15 |       0.56 #> 0.00        |      0.15 |       0.54 #> 0.00        |      0.12 |       0.33 #> 0.00        |     -0.02 |       0.52 #> 0.00        |      0.13 |       0.39 #> 0.00        |      0.28 |       0.31 #> 0.00        |     -0.14 |       0.44 #> 0.00        |      0.29 |       0.21 #> 0.00        |      0.22 |       0.45 #> 0.00        |     -0.03 |       0.30 #> 0.00        |      0.27 |       0.34 #> 0.00        |     -0.19 |       0.44 #> 0.00        |     -0.11 |       0.55 #> 0.00        |     -0.03 |       0.50 #> 0.00        |      0.24 |       0.49 #> 0.00        |      0.18 |       0.42 #> 0.00        |      0.10 |       0.36 #> 0.00        |      0.06 |       0.53 #> 0.00        |      0.11 |       0.33 #> 0.00        |      0.13 |       0.34 #> 0.00        |      0.07 |       0.42 #> 0.00        |      0.03 |       0.32 #> 0.00        |      0.11 |       0.62 #> 0.00        |      0.09 |       0.47 #> 0.00        |      0.08 |       0.38 #> 0.00        |      0.19 |       0.55 #> 0.00        |      0.38 |       0.80 #> 0.00        |     -0.08 |       0.12 #> 0.00        |     -0.09 |       0.24 #> 0.00        |     -0.17 |       0.15 #> 0.00        |      0.14 |       0.87 #> 0.00        |     -0.19 |       0.25 #> 0.00        |      0.33 |       0.41 #> 0.00        |     -0.06 |       0.40 #> 0.00        |      0.38 |       0.41 #> 0.00        |     -0.09 |       0.42 #> 0.00        |      0.14 |       0.31 #> 0.00        |      0.05 |       0.49 #> 0.00        |      0.30 |       0.09 #> 0.00        |      0.19 |       0.04 #> 0.00        |      0.32 |       0.13 #> 0.00        |      0.42 |       0.30 #> 0.00        |      0.18 |      -0.17 #> 0.00        |      0.40 |       0.37 #> 0.00        |     -0.07 |       0.37 #> 0.00        |     -0.27 |       0.48 #> 0.00        |      0.03 |       0.27 #> 0.00        |      0.29 |       0.35 #> 0.00        |      0.27 |       0.42 #> 0.00        |     -0.09 |       0.45 #> 0.00        |      0.33 |       0.42 #> 0.00        |      0.06 |       0.47 #> 0.00        |      0.09 |       0.29 #> 0.00        |      0.14 |       0.45 #> 0.00        |      0.11 |       0.55 #> 0.00        |      0.01 |       0.30 #> 0.00        |      0.23 |       0.37 #> 0.00        |      0.29 |       0.41 #> 0.00        |     -0.04 |       0.71 #> 0.00        |      0.38 |       0.25 #> 0.00        |      0.42 |       0.34 #> 0.00        |     -0.13 |       0.52 #> 0.00        |      0.13 |       0.62 #> 0.00        | -6.23e-03 |       0.57 #> 0.00        |     -0.02 |       0.43 #> 0.00        |      0.03 |       0.39 #> 0.00        |      0.16 |       0.56 #> 0.00        |      0.11 |       0.19 #> 0.00        |      0.29 |       0.50 #> 0.00        |      0.01 |       0.30 #> 0.00        |      0.22 |       0.74 #> 0.00        |     -0.22 |       0.62 #> 0.00        |      0.06 |       0.36 #> 0.00        |     -0.01 |       0.20 #> 0.00        |  1.08e-03 |       0.71 #> 0.00        |      0.37 |       0.30 #> 0.00        |      0.30 |       0.20 #> 0.00        |      0.16 |       0.50 #> 0.00        |     -0.03 |       0.24 #> 0.00        |     -0.12 |       0.34 #> 0.00        |     -0.09 |       0.27 #> 0.00        |      0.24 |       0.54 #> 0.00        |     -0.03 |       0.33 #> 0.00        |      0.20 |       0.03 #> 0.00        |      0.36 |       0.18 #> 0.00        |      0.44 |       0.25 #> 0.00        |      0.38 |       0.23 #> 0.00        |      0.17 |       0.48 #> 0.00        |      0.07 |       0.32 #> 0.00        |      0.21 |       0.30 #> 0.00        |      0.09 |       0.61 #> 0.00        |      0.29 |       0.62 #> 0.00        |     -0.13 |       0.12 #> 0.00        |     -0.12 |       0.44 #> 0.00        |     -0.22 |       0.52 #> 0.00        |     -0.19 |       0.65 #> 0.00        |     -0.04 |       0.44 #> 0.00        |      0.36 |       0.32 #> 0.00        |     -0.08 |       0.31 #> 0.00        |      0.08 |       0.64 #> 0.00        |      0.14 |       0.09 #> 0.00        |     -0.07 |       0.54 #> 0.00        |      0.10 |       0.48 #> 0.00        |     -0.01 |       0.32 #> 0.00        |      0.21 |       0.46 #> 0.00        | -1.53e-03 |       0.35 #> 0.00        |      0.21 |       0.50 #> 0.00        |     -0.12 |       0.73 #> 0.00        |     -0.04 |       0.76 #> 0.00        | -5.91e-03 |       0.25 #> 0.00        |      0.01 |       0.46 #> 0.00        |      0.27 |       0.71 #> 0.00        |     -0.07 |       0.13 #> 0.00        |      0.15 |       0.69 #> 0.00        |     -0.03 |       0.03 #> 0.00        |     -0.18 |       0.60 #> 0.00        |      0.07 |       0.36 #> 0.00        |      0.16 |       0.55 #> 0.00        |      0.50 |       0.53 #> 0.00        |     -0.35 |       0.26 #> 0.00        |      0.29 |       0.55 #> 0.00        |     -0.15 |       0.26 #> 0.00        |     -0.24 |       0.34 #> 0.00        |     -0.01 |       0.32 #> 0.00        |     -0.21 |       0.57 #> 0.00        |     -0.27 |       0.64 #> 0.00        |      0.43 |       0.21 #> 0.00        |      0.51 |       0.13 #> 0.00        |      0.39 |       0.18 #> 0.00        |      0.14 |       0.53 #> 0.00        |      0.24 |       0.59 #> 0.00        |      0.22 |       0.42 #> 0.00        |      0.12 |       0.51 #> 0.00        |      0.11 |       0.52 #> 0.00        |      0.11 |       0.34 #> 0.00        |      0.17 |       0.48 #> 0.00        |      0.06 |       0.38 #> 0.00        |      0.24 |       0.37 #> 0.00        |  3.21e-03 |       0.43 #> 0.00        |     -0.03 |       0.46 #> 0.00        |     -0.04 |       0.64 #> 0.00        |     -0.08 |       0.65 #> 0.00        |      0.05 |       0.79 #> 0.00        |      0.21 |       0.56 #> 0.00        |     -0.07 |       0.11 #> 0.00        |      0.04 |       0.53 #> 0.00        |     -0.13 |       0.32 #> 0.00        |     -0.14 |       0.37 #> 0.00        |     -0.09 |       0.31 #> 0.00        |      0.49 |       0.27 #> 0.00        |     -0.15 |       0.54 #> 0.00        |      0.27 |       0.20 #> 0.00        |     -0.01 |       0.51 #> 0.00        |      0.05 |       0.47 #> 0.00        |     -0.15 |       0.50 #> 0.00        | -9.27e-04 |       0.38 #> 0.00        |      0.06 |       0.43 #> 0.00        |      0.27 |       0.30 #> 0.00        |      0.26 |       0.34 #> 0.00        | -2.21e-04 |       0.50 #> 0.00        |      0.06 |       0.62 #> 0.00        |      0.12 |       0.55 #> 0.00        |     -0.09 |       0.37 #> 0.00        |     -0.01 |       0.58 #> 0.00        |      0.13 |       0.46 #> 0.00        |      0.11 |       0.39 #> 0.00        |      0.09 |       0.41 #> 0.00        |     -0.02 |       0.50 #> 0.00        |      0.05 |       0.52 #> 0.00        |     -0.03 |       0.45 #> 0.00        |      0.22 |       0.20 #> 0.00        |     -0.13 |       0.76 #> 0.00        |     -0.02 |       0.91 #> 0.00        |      0.07 |       0.16 #> 0.00        |      0.24 |       0.12 #> 0.00        |      0.09 |       0.61 #> 0.00        |      0.11 |       0.66 #> 0.00        |      0.05 |       0.73 #> 0.00        |     -0.03 |       0.78 #> 0.00        |     -0.05 |       0.81 #> 0.00        |      0.10 |       0.36 #> 0.00        |      0.21 |       0.48 #> 0.00        |     -0.05 |       0.46 #> 0.00        | -7.22e-03 |       0.42 #> 0.00        |      0.11 |       0.31 #> 0.00        |     -0.02 |       0.60 #> 0.00        |      0.20 |       0.20 #> 0.00        |      0.06 |       0.50 #> 0.00        |      0.24 |       0.25 #> 0.00        |     -0.05 |       0.66 #> 0.00        |      0.07 |       0.28 #> 0.00        |      0.09 |       0.54 #> 0.00        |     -0.02 |       0.57 #> 0.00        |      0.33 |       0.16 #> 0.00        |      0.38 |       0.26 #> 0.00        |     -0.23 |       0.28 #> 0.00        |     -0.09 |       0.27 #> 0.00        |      0.11 |       0.43 #> 0.00        |      0.25 |       0.66 #> 0.00        |      0.15 |       0.42 #> 0.00        |      0.19 |       0.27 #> 0.00        |      0.02 |       0.41 #> 0.00        |      0.05 |       0.27 #> 0.00        |      0.22 |       0.64 #> 0.00        |  7.20e-03 |       0.21 #> 0.00        |      0.04 |       0.21 #> 0.00        |     -0.07 |       0.22 #> 0.00        |      0.55 |       0.33 #> 0.00        |     -0.32 |       0.58 #> 0.00        |      0.46 |       0.18 #> 0.00        |     -0.23 |       0.66 #> 0.00        |      0.08 |       0.32 #> 0.00        |      0.51 |       0.07 #> 0.00        |     -0.13 |       0.34 #> 0.00        |      0.37 |       0.38 #> 0.00        |  9.57e-03 |       0.77 #> 0.00        |      0.03 |       0.91 #> 0.00        |      0.06 |       0.60 #> 0.00        |     -0.05 |       0.35 #> 0.00        |     -0.25 |       0.06 #> 0.00        |     -0.06 |       0.24 #> 0.00        |      0.25 |       0.52 #> 0.00        |     -0.04 |       0.39 #> 0.00        |      0.07 |       0.38 #> 0.00        |  2.44e-03 |       0.41 #> 0.00        |      0.32 |       0.50 #> 0.00        |      0.22 |       0.48 #> 0.00        |      0.35 |       0.48 #> 0.00        |     -0.10 |       0.35 #> 0.00        |      0.02 |       0.27 #> 0.00        |     -0.15 |       0.39 #> 0.00        |     -0.02 |       0.43 #> 0.00        |      0.19 |       0.24 #> 0.00        |      0.08 |       0.30 #> 0.00        |      0.12 |       0.41 #> 0.00        |      0.44 |       0.12 #> 0.00        |      0.22 |       0.27 #> 0.00        |      0.37 |       0.83 #> 0.00        |      0.50 |       0.70 #> 0.00        |     -0.12 |       0.09 #> 0.00        |      0.32 |       0.59 #> 0.00        |      0.15 |       0.45 #> 0.00        |     -0.12 |       0.49 #> 0.00        |     -0.01 |       0.51 #> 0.00        |      0.17 |       0.40 #> 0.00        |      0.11 |       0.74 #> 0.00        |     -0.09 |       0.36 #> 0.00        |     -0.42 |       0.32 #> 0.00        |     -0.32 |       0.18 #> 0.00        |      0.16 |       0.29 #> 0.00        |     -0.13 |       0.34 #> 0.00        |      0.15 |       0.35 #> 0.00        |      0.10 |       0.57 #> 0.00        |      0.02 |       0.29 #> 0.00        |      0.15 |       0.57 #> 0.00        |      0.07 |       0.31 #> 0.00        |      0.18 |       0.44 #> 0.00        |      0.23 |       0.17 #> 0.00        |     -0.14 |       0.58 #> 0.00        |     -0.02 |       0.22 #> 0.00        |      0.16 |       0.21 #> 0.00        |      0.10 |       0.02 #> 0.00        |      0.06 |       0.05 #> 0.00        |      0.13 |       0.74 #> 0.00        |     -0.13 |       0.20 #> 0.00        |      0.50 |       0.24 #> 0.00        |     -0.24 |       0.52 #> 0.00        |      0.40 |       0.55 #> 0.00        |     -0.02 |       0.41 #> 0.00        |      0.13 |       0.24 #> 0.00        |      0.09 |       0.51 #> 0.00        |      0.02 |       0.20 #> 0.00        |      0.19 |       0.47 #> 0.00        |      0.01 |       0.13 #> 0.00        |     -0.24 |       0.29 #> 0.00        |     -0.07 |       0.33 #> 0.00        |      0.39 |       0.59 #> 0.00        |     -0.17 |       0.29 #> 0.00        |     -0.14 |       0.71 #> 0.00        |     -0.02 |       0.54 #> 0.00        |     -0.05 |       0.51 #> 0.00        | -9.23e-03 |       0.45 #> 0.00        |      0.26 |       0.30 #> 0.00        |     -0.05 |       0.45 #> 0.00        |      0.14 |       0.46 #> 0.00        |      0.30 |       0.45 #> 0.00        |      0.15 |       0.46 #> 0.00        |      0.04 |       0.52 #> 0.00        |      0.11 |       0.30 #> 0.00        |      0.37 |       0.40 #> 0.00        |     -0.21 |       0.20 #> 0.00        |     -0.18 |       0.25 #> 0.00        |      0.65 |       0.54 #> 0.00        |      0.15 |       0.42 #> 0.00        |      0.12 |       0.32 #> 0.00        |      0.22 |       0.23 #> 0.00        |      0.06 |       0.25 #> 0.00        |     -0.08 |       0.58 #> 0.00        |     -0.04 |       0.64 #> 0.00        |      0.18 |       0.43 #> 0.00        |      0.15 |       0.40 #> 0.00        |      0.21 |       0.26 #> 0.00        |      0.15 |       0.22 #> 0.00        |      0.14 |       0.25 #> 0.00        |      0.08 |       0.36 #> 0.00        |      0.11 |       0.30 #> 0.00        |      0.10 |       0.52 #> 0.00        |     -0.07 |       0.34 #> 0.00        |     -0.13 |       0.35 #> 0.00        |      0.26 |       0.47 #> 0.00        |      0.15 |       0.46 #> 0.00        |      0.08 |       0.29 #> 0.00        | -9.21e-03 |       0.30 #> 0.00        |      0.05 |       0.57 #> 0.00        |      0.12 |       0.46 #> 0.00        |     -0.09 |       0.35 #> 0.00        |      0.43 |       0.11 #> 0.00        |      0.39 |       0.12 #> 0.00        |      0.27 |       0.26 #> 0.00        |      0.40 |       0.30 #> 0.00        |      0.22 |       0.68 #> 0.00        |      0.27 |       0.30 #> 0.00        |     -0.02 |       0.68 #> 0.00        |     -0.22 |       0.76 #> 0.00        |      0.39 |       0.42 #> 0.00        |      0.19 |       0.51 #> 0.00        |     -0.08 |       0.69 #> 0.00        |      0.17 |       0.37 #> 0.00        |      0.05 |       0.45 #> 0.00        |      0.13 |       0.20 #> 0.00        |      0.08 |       0.28 #> 0.00        | -1.10e-03 |       0.50 #> 0.00        |      0.11 |       0.39 #> 0.00        |     -0.06 |       0.57 #> 0.00        |     -0.08 |       0.48 #> 0.00        |      0.04 |       0.32 #> 0.00        |      0.08 |       0.66 #> 0.00        |      0.07 |       0.47 #> 0.00        |      0.68 |       0.35 #> 0.00        |      0.60 |       0.40 #> 0.00        |      0.29 |       0.51 #> 0.00        |      0.15 |       0.43 #> 0.00        |      0.22 |       0.47 #> 0.00        |     -0.10 |       0.55 #> 0.00        |      0.03 |       0.35 #> 0.00        |      0.22 |       0.60 #> 0.00        |      0.22 |       0.48 #> 0.00        |      0.06 |       0.54 #> 0.00        |      0.16 |       0.37 #> 0.00        |      0.17 |       0.26 #> 0.00        |      0.05 |       0.31 #> 0.00        |      0.13 |       0.16 #> 0.00        |      0.37 |       0.19 #> 0.00        |      0.19 |       0.50 #> 0.00        |      0.23 |       0.65 #> 0.00        |     -0.24 |       0.26 #> 0.00        |      0.52 |       0.34 #> 0.00        |      0.08 |       0.38 #> 0.00        |      0.09 |       0.09 #> 0.00        |     -0.06 |       0.59 #> 0.00        |      0.06 |       0.40 #> 0.00        |      0.10 |       0.43 #> 0.00        |      0.35 |       0.51 #> 0.00        |      0.29 |       0.54 #> 0.00        |      0.29 |       0.51 #> 0.00        |     -0.04 |       0.41 #> 0.00        |      0.23 |       0.39 #> 0.00        |     -0.10 |       0.34 #> 0.00        |     -0.27 |       0.60 #> 0.00        |      0.21 |       0.16 #> 0.00        |      0.03 |       0.26 #> 0.00        |      0.05 |       0.30 #> 0.00        |      0.11 |       0.64 #> 0.00        |      0.13 |       0.66 #> 0.00        |     -0.08 |       0.51 #> 0.00        |      0.07 |       0.51 #> 0.00        |      0.12 |       0.62 #> 0.00        |     -0.06 |       0.50 #> 0.00        |      0.14 |       0.37 #> 0.00        |     -0.10 |       0.44 #> 0.00        |      0.25 |       0.43 #> 0.00        |      0.14 |       0.63 #> 0.00        |      0.25 |       0.62 #> 0.00        |      0.19 |       0.64 #> 0.00        |     -0.02 |       0.47 #> 0.00        |      0.01 |       0.71 #> 0.00        |      0.14 |       0.16 #> 0.00        |      0.03 |       0.68 #> 0.00        |     -0.04 |       0.65 #> 0.00        |      0.20 |       0.20 #> 0.00        |      0.26 |       0.12 #> 0.00        |     -0.09 |       0.72 #> 0.00        |      0.20 |       0.12 #> 0.00        |     -0.07 |       0.70 #> 0.00        |     -0.02 |       0.24 #> 0.00        |      0.51 |       0.36 #> 0.00        |      0.06 |       0.22 #> 0.00        |      0.02 |       0.89 #> 0.00        |      0.17 |       0.59 #> 0.00        |     -0.05 |       0.40 #> 0.00        |      0.26 |       0.51 #> 0.00        |      0.26 |       0.61 #> 0.00        |      0.29 |       0.45 #> 0.00        |      0.22 |       0.42 #> 0.00        |      0.13 |       0.42 #> 0.00        |      0.17 |       0.38 #> 0.00        |      0.13 |       0.22 #> 0.00        |      0.08 |       0.65 #> 0.00        |     -0.28 |       0.69 #> 0.00        |      0.44 |       0.13 #> 0.00        |     -0.25 |       0.64 #> 0.00        |      0.27 |       0.31 #> 0.00        |      0.28 |       0.61 #> 0.00        |      0.15 |       0.43 #> 0.00        |     -0.04 |       0.14 #> 0.00        |     -0.19 |       0.61 #> 0.00        |     -0.07 |       0.65 #> 0.00        |      0.25 |       0.17 #> 0.00        |     -0.23 |       0.51 #> 0.00        |      0.25 |       0.43 #> 0.00        |  6.86e-03 |       0.45 #> 0.00        |      0.32 |       0.36 #> 0.00        |     -0.09 |       0.50 #> 0.00        |     -0.02 |       0.54 #> 0.00        |      0.45 |       0.45 #> 0.00        |      0.25 |       0.27 #> 0.00        |      0.12 |       0.35 #> 0.00        |      0.21 |       0.39 #> 0.00        |      0.17 |       0.33 #> 0.00        |     -0.06 |       0.50 #> 0.00        |      0.18 |       0.38 #> 0.00        |      0.15 |       0.29 #> 0.00        |     -0.19 |       0.40 #> 0.00        |      0.40 |       0.36 #> 0.00        |      0.45 |       0.40 #> 0.00        |     -0.33 |       0.54 #> 0.00        |      0.11 |       0.51 #> 0.00        |      0.11 |       0.61 #> 0.00        |      0.16 |       0.10 #> 0.00        |      0.29 |      -0.18 #> 0.00        |      0.30 |      -0.22 #> 0.00        |      0.56 |       0.20 #> 0.00        |     -0.07 |       0.54 #> 0.00        |      0.28 |       0.29 #> 0.00        |     -0.01 |       0.53 #> 0.00        |      0.16 |       0.27 #> 0.00        |      0.03 |       0.44 #> 0.00        |      0.06 |       0.37 #> 0.00        |     -0.22 |       0.66 #> 0.00        |      0.09 |       0.53 #> 0.00        |  3.35e-03 |       0.07 #> 0.00        |      0.16 |       0.29 #> 0.00        |  3.05e-03 |       0.26 #> 0.00        |      0.04 |       0.40 #> 0.00        |      0.16 |       0.38 #> 0.00        |      0.08 |       0.42 #> 0.00        |     -0.02 |       0.48 #> 0.00        |     -0.05 |       0.23 #> 0.00        |      0.28 |       0.52 #> 0.00        |      0.18 |       0.43 #> 0.00        |      0.10 |       0.69 #> 0.00        |      0.09 |       0.65 #> 0.00        |      0.07 |       0.14 #> 0.00        |      0.06 |       0.14 #> 0.00        |      0.33 |       0.65 #> 0.00        |      0.31 |       0.52 #> 0.00        |     -0.09 |       0.43 #> 0.00        |      0.14 |       0.24 #> 0.00        |      0.02 |       0.60 #> 0.00        |     -0.15 |       0.46 #> 0.00        |      0.61 |       0.12 #> 0.00        |     -0.28 |       0.51 #> 0.00        |  6.97e-03 |       0.25 #> 0.00        |     -0.14 |       0.47 #> 0.00        |      0.28 |       0.24 #> 0.00        |     -0.02 |       0.55 #> 0.00        |      0.09 |       0.44 #> 0.00        |      0.14 |       0.30 #> 0.00        |      0.08 |       0.49 #> 0.00        |  8.51e-03 |       0.41 #> 0.00        |      0.07 |       0.50 #> 0.00        |     -0.22 |       0.53 #> 0.00        |      0.09 |       0.36 #> 0.00        |      0.07 |       0.52 #> 0.00        | -1.73e-04 |       0.35 #> 0.00        |      0.27 |       0.33 #> 0.00        |      0.24 |       0.37 #> 0.00        |     -0.09 |       0.32 #> 0.00        |     -0.17 |       0.29 #> 0.00        |      0.20 |       0.42 #> 0.00        |      0.36 |       0.63 #> 0.00        |      0.14 |       0.18 #> 0.00        |      0.19 |       0.23 #> 0.00        |      0.27 |       0.34 #> 0.00        |     -0.07 |       0.50 #> 0.00        |     -0.24 |       0.36 #> 0.00        |      0.46 |       0.48 #> 0.00        |      0.24 |       0.27 #> 0.00        |      0.25 |       0.40 #> 0.00        |      0.11 |       0.19 #> 0.00        |      0.04 |       0.58 #> 0.00        |      0.20 |       0.17 #> 0.00        |      0.10 |       0.48 #> 0.00        |      0.30 |       0.14 #> 0.00        |     -0.12 |       0.68 #> 0.00        |      0.25 |       0.25 #> 0.00        |      0.20 |       0.13 #> 0.00        |      0.19 |      -0.16 #> 0.00        |     -0.16 |       0.53 #> 0.00        |      0.48 |       0.26 #> 0.00        |      0.46 |       0.15 #> 0.00        |     -0.13 |       0.82 #> 0.00        |      0.38 |       0.01 #> 0.00        |     -0.15 |       0.75 #> 0.00        |      0.30 |       0.07 #> 0.00        |      0.19 |       0.12 #> 0.00        |      0.19 |       0.05 #> 0.00        |      0.20 |       0.23 #> 0.00        |     -0.12 |       0.68 #> 0.00        |      0.24 |       0.07 #> 0.00        |      0.23 |       0.57 #> 0.00        |      0.46 |       0.14 #> 0.00        |      0.45 |       0.08 #> 0.00        |      0.53 |       0.23 #> 0.00        |      0.23 |       0.46 #> 0.00        |      0.01 |       0.43 #> 0.00        |     -0.25 |       0.35 #> 0.00        |      0.15 |       0.32 #> 0.00        |      0.28 |       0.24 #> 0.00        |      0.19 |       0.38 #> 0.00        |      0.24 |      -0.04 #> 0.00        |      0.04 |       0.73 #> 0.00        |     -0.07 |       0.23 #> 0.00        |      0.06 |       0.60 #> 0.00        |      0.09 |       0.51 #> 0.00        |      0.15 |       0.55 #> 0.00        |      0.05 |       0.29 #> 0.00        |      0.03 |       0.52 #> 0.00        |     -0.07 |       0.23 #> 0.00        |      0.27 |       0.57 #> 0.00        |      0.11 |       0.77 #> 0.00        |      0.23 |       0.26 #> 0.00        |      0.02 |       0.45 #> 0.00        |      0.25 |       0.24 #> 0.00        |      0.16 |       0.43 #> 0.00        |     -0.16 |       0.45 #> 0.00        |      0.32 |       0.39 #> 0.00        |      0.36 |       0.13 #> 0.00        |     -0.14 |       0.65 #> 0.00        |      0.32 |       0.19 #> 0.00        | -6.08e-03 |       0.32 #> 0.00        |      0.11 |       0.60 #> 0.00        |      0.14 |       0.51 #> 0.00        |      0.11 |       0.28 #> 0.00        |      0.05 |       0.47 #> 0.00        |      0.19 |       0.42 #> 0.00        |      0.05 |       0.45 #> 0.00        |      0.12 |       0.51 #> 0.00        |      0.08 |       0.33 #> 0.00        |      0.11 |       0.45 #> 0.00        |      0.38 |       0.34 #> 0.00        |      0.21 |       0.45 #> 0.00        |     -0.02 |       0.43 #> 0.00        |      0.16 |       0.46 #> 0.00        |     -0.20 |       0.22 #> 0.00        |      0.26 |       0.66 #> 0.00        |     -0.19 |       0.26 #> 0.00        |      0.10 |       0.80 #> 0.00        |     -0.16 |       0.49 #> 0.00        |  6.89e-03 |       0.52 #> 0.00        |      0.19 |       0.60 #> 0.00        |     -0.02 |       0.36 #> 0.00        |  5.93e-03 |       0.44 #> 0.00        |      0.06 |       0.38 #> 0.00        |      0.16 |       0.36 #> 0.00        | -9.96e-03 |       0.51 #> 0.00        |      0.30 |       0.51 #> 0.00        |     -0.16 |       0.19 #> 0.00        |      0.32 |       0.72 #> 0.00        |     -0.07 |       0.05 #> 0.00        |      0.22 |       0.62 #> 0.00        |      0.15 |       0.07 #> 0.00        |     -0.03 |       0.16 #> 0.00        |      0.09 |       0.74 #> 0.00        |     -0.26 |       0.18 #> 0.00        |     -0.45 |       0.64 #> 0.00        |     -0.49 |       0.69 #> 0.00        |     -0.04 |       0.68 #> 0.00        |      0.25 |       0.11 #> 0.00        |      0.34 |       0.11 #> 0.00        |     -0.09 |       0.50 #> 0.00        |      0.13 |       0.22 #> 0.00        |      0.11 |       0.14 #> 0.00        |      0.18 |       0.32 #> 0.00        |      0.16 |       0.35 #> 0.00        |     -0.06 |       0.72 #> 0.00        |      0.40 |   5.94e-04 #> 0.00        |      0.14 |       0.35 #> 0.00        |  3.30e-03 |       0.38 #> 0.00        |      0.23 |       0.47 #> 0.00        |      0.11 |       0.31 #> 0.00        |      0.04 |       0.25 #> 0.00        |      0.22 |       0.47 #> 0.00        |      0.33 |       0.35 #> 0.00        |      0.16 |       0.45 #> 0.00        |      0.21 |       0.57 #> 0.00        |      0.05 |       0.23 #> 0.00        |      0.28 |       0.58 #> 0.00        |     -0.29 |       0.46 #> 0.00        | -9.78e-03 |       0.55 #> 0.00        |      0.27 |       0.25 #> 0.00        |      0.04 |       0.43 #> 0.00        |      0.10 |       0.60 #> 0.00        |      0.31 |       0.63 #> 0.00        |     -0.14 |       0.19 #> 0.00        |      0.44 |       0.47 #> 0.00        |      0.30 |       0.32 #> 0.00        |     -0.16 |       0.66 #> 0.00        |      0.02 |       0.17 #> 0.00        |      0.01 |       0.59 #> 0.00        |      0.16 |       0.64 #> 0.00        |      0.10 |       0.48 #> 0.00        |      0.11 |       0.35 #> 0.00        |      0.25 |       0.39 #> 0.00        |     -0.06 |       0.45 #> 0.00        |      0.02 |       0.44 #> 0.00        |      0.02 |       0.53 #> 0.00        |      0.22 |       0.23 #> 0.00        |      0.07 |       0.43 #> 0.00        |      0.09 |       0.54 #> 0.00        |      0.09 |       0.31 #> 0.00        |     -0.43 |       0.65 #> 0.00        |     -0.28 |       0.50 #> 0.00        |     -0.25 |       0.18 #> 0.00        |     -0.27 |       0.33 #> 0.00        |     -0.23 |       0.43 #> 0.00        |      0.22 |       0.90 #> 0.00        |      0.14 |       0.77 #> 0.00        |     -0.25 |       0.48 #> 0.00        |      0.41 |       0.30 #> 0.00        |      0.42 |       0.44 #> 0.00        |     -0.17 |       0.54 #> 0.00        |      0.38 |       0.53 #> 0.00        |      0.40 |       0.62 #> 0.00        |     -0.28 |       0.26 #> 0.00        |      0.44 |       0.53 #> 0.00        |     -0.16 |       0.34 #> 0.00        |      0.31 |       0.38 #> 0.00        |     -0.08 |       0.47 #> 0.00        |     -0.24 |       0.57 #> 0.00        |      0.55 |       0.41 #> 0.00        |      0.42 |       0.38 #> 0.00        |      0.26 |       0.43 #> 0.00        |     -0.09 |       0.44 #> 0.00        |     -0.17 |       0.68 #> 0.00        |     -0.14 |       0.64 #> 0.00        |      0.08 |       0.08 #> 0.00        |      0.14 |       0.16 #> 0.00        |      0.12 |       0.65 #> 0.00        |      0.12 |       0.55 #> 0.00        |      0.19 |       0.39 #> 0.00        |      0.19 |       0.44 #> 0.00        |     -0.01 |       0.40 #> 0.00        |     -0.15 |       0.53 #> 0.00        |      0.25 |       0.34 #> 0.00        |     -0.16 |       0.34 #> 0.00        |      0.09 |       0.19 #> 0.00        |     -0.19 |       0.50 #> 0.00        |      0.19 |       0.49 #> 0.00        |      0.11 |       0.37 #> 0.00        |      0.14 |       0.38 #> 0.00        |     -0.01 |       0.32 #> 0.00        |     -0.13 |       0.36 #> 0.00        |      0.24 |       0.42 #> 0.00        |      0.34 |       0.15 #> 0.00        |     -0.08 |       0.62 #> 0.00        |      0.34 |       0.11 #> 0.00        |     -0.05 |       0.62 #> 0.00        |      0.11 |       0.48 #> 0.00        |      0.23 |       0.34 #> 0.00        |     -0.18 |       0.46 #> 0.00        |      0.10 |       0.54 #> 0.00        |      0.24 |       0.07 #> 0.00        |      0.15 |       0.66 #> 0.00        |      0.09 |       0.77 #> 0.00        |      0.02 |       0.90 #> 0.00        |      0.03 |       0.19 #> 0.00        |      0.25 |       0.74 #> 0.00        |      0.05 |       0.19 #> 0.00        |      0.07 |       0.76 #> 0.00        |      0.09 |       0.21 #> 0.00        |     -0.12 |       0.67 #> 0.00        |      0.10 |       0.26 #> 0.00        |      0.12 |       0.42 #> 0.00        |      0.15 |       0.42 #> 0.00        |     -0.02 |       0.58 #> 0.00        |      0.20 |       0.24 #> 0.00        |  2.96e-03 |       0.58 #> 0.00        |     -0.06 |       0.57 #> 0.00        |      0.21 |       0.48 #> 0.00        |      0.11 |       0.50 #> 0.00        |     -0.16 |       0.29 #> 0.00        |      0.34 |       0.24 #> 0.00        |     -0.16 |       0.60 #> 0.00        |      0.34 |       0.21 #> 0.00        |  7.71e-03 |       0.39 #> 0.00        |      0.18 |       0.58 #> 0.00        |      0.20 |       0.31 #> 0.00        |      0.19 |       0.26 #> 0.00        |      0.52 |       0.37 #> 0.00        |      0.03 |       0.23 #> 0.00        |      0.17 |       0.37 #> 0.00        |      0.17 |       0.44 #> 0.00        |      0.06 |       0.40 #> 0.00        |     -0.20 |       0.47 #> 0.00        |      0.19 |       0.41 #> 0.00        |      0.07 |       0.45 #> 0.00        |      0.31 |       0.43 #> 0.00        |      0.15 |       0.42 #> 0.00        |      0.18 |   5.42e-03 #> 0.00        |      0.42 |       0.21 #> 0.00        |     -0.15 |       0.70 #> 0.00        |      0.28 |       0.48 #> 0.00        |     -0.04 |       0.30 #> 0.00        |     -0.08 |       0.36 #> 0.00        |      0.17 |       0.41 #> 0.00        |      0.05 |       0.51 #> 0.00        | -2.09e-04 |       0.50 #> 0.00        |      0.20 |       0.34 #> 0.00        |      0.05 |       0.47 #> 0.00        |      0.18 |       0.40 #> 0.00        |      0.33 |       0.49 #> 0.00        |     -0.24 |       0.37 #> 0.00        |      0.41 |       0.48 #> 0.00        |      0.33 |       0.10 #> 0.00        |      0.32 |       0.32 #> 0.00        |      0.28 |       0.26 #> 0.00        |     -0.01 |       0.68 #> 0.00        |      0.18 |       0.58 #> 0.00        |      0.09 |       0.44 #> 0.00        |     -0.06 |       0.52 #> 0.00        |      0.02 |       0.52 #> 0.00        |     -0.16 |       0.38 #> 0.00        |      0.07 |       0.42 #> 0.00        |      0.27 |       0.53 #> 0.00        |      0.38 |       0.55 #> 0.00        |     -0.21 |       0.25 #> 0.00        |     -0.03 |       0.26 #> 0.00        |      0.38 |       0.55 #> 0.00        |      0.06 |       0.66 #> 0.00        |      0.26 |       0.46 #> 0.00        |      0.31 |       0.60 #> 0.00        |     -0.05 |       0.32 #> 0.00        |      0.30 |       0.64 #> 0.00        |      0.20 |       0.72 #> 0.00        | -5.78e-03 |       0.15 #> 0.00        |     -0.13 |       0.13 #> 0.00        |      0.26 |       0.33 #> 0.00        |      0.25 |       0.43 #> 0.00        |      0.18 |       0.38 #> 0.00        |      0.12 |       0.49 #> 0.00        |     -0.10 |       0.43 #> 0.00        |      0.20 |       0.59 #> 0.00        |      0.21 |       0.53 #> 0.00        |      0.11 |       0.44 #> 0.00        |     -0.02 |       0.50 #> 0.00        |      0.29 |       0.38 #> 0.00        |      0.32 |       0.07 #> 0.00        |      0.06 |       0.66 #> 0.00        |      0.11 |       0.67 #> 0.00        | -5.60e-03 |       0.27 #> 0.00        |      0.27 |       0.40 #> 0.00        |      0.31 |       0.48 #> 0.00        |     -0.12 |       0.26 #> 0.00        |      0.50 |       0.22 #> 0.00        |      0.47 |       0.13 #> 0.00        |     -0.36 |       0.60 #> 0.00        |     -0.08 |       0.51 #> 0.00        |      0.22 |       0.34 #> 0.00        |     -0.07 |       0.06 #> 0.00        |      0.26 |       0.53 #> 0.00        |      0.13 |       0.28 #> 0.00        |      0.26 |       0.31 #> 0.00        |     -0.13 |       0.75 #> 0.00        |     -0.12 |       0.67 #> 0.00        |      0.08 |       0.45 #> 0.00        |      0.24 |       0.37 #> 0.00        |     -0.04 |       0.46 #> 0.00        |      0.25 |       0.39 #> 0.00        |      0.14 |       0.43 #> 0.00        | -7.62e-03 |       0.42 #> 0.00        |      0.13 |       0.32 #> 0.00        |     -0.19 |       0.62 #> 0.00        |      0.40 |       0.23 #> 0.00        |      0.58 |       0.45 #> 0.00        |     -0.16 |       0.31 #> 0.00        |      0.39 |       0.45 #> 0.00        |     -0.39 |       0.57 #> 0.00        |      0.18 |       0.23 #> 0.00        |      0.30 |       0.46 #> 0.00        |     -0.23 |       0.44 #> 0.00        |      0.06 |       0.56 #> 0.00        |     -0.03 |       0.33 #> 0.00        |      0.28 |       0.50 #> 0.00        |     -0.08 |       0.58 #> 0.00        |      0.24 |       0.03 #> 0.00        |      0.48 |       0.06 #> 0.00        |     -0.17 |       0.68 #> 0.00        |      0.15 |       0.51 #> 0.00        |      0.06 |       0.37 #> 0.00        |     -0.14 |       0.63 #> 0.00        |      0.46 |       0.39 #> 0.00        |      0.15 |       0.73 #> 0.00        |      0.26 |       0.80 #> 0.00        |      0.03 |       0.28 #> 0.00        |      0.01 |       0.08 #> 0.00        |     -0.42 |       0.54 #> 0.00        |  1.85e-03 |       0.46 #> 0.00        |      0.18 |       0.44 #> 0.00        |      0.04 |       0.37 #> 0.00        |  3.61e-03 |       0.35 #> 0.00        |      0.08 |       0.39 #> 0.00        |      0.15 |       0.31 #> 0.00        |      0.10 |       0.40 #> 0.00        |      0.08 |       0.44 #> 0.00        |      0.23 |       0.30 #> 0.00        |     -0.12 |       0.57 #> 0.00        |     -0.07 |       0.76 #> 0.00        |      0.23 |       0.14 #> 0.00        |      0.08 |       0.10 #> 0.00        |     -0.25 |       0.62 #> 0.00        |      0.08 |       0.46 #> 0.00        |      0.04 |       0.24 #> 0.00        |      0.22 |       0.59 #> 0.00        |     -0.19 |       0.29 #> 0.00        |     -0.02 |       0.39 #> 0.00        |     -0.09 |       0.27 #> 0.00        |  6.61e-03 |       0.58 #> 0.00        |      0.21 |       0.26 #> 0.00        |      0.32 |       0.15 #> 0.00        |     -0.05 |       0.73 #> 0.00        |      0.31 |       0.02 #> 0.00        |     -0.31 |       0.83 #> 0.00        |     -0.11 |       0.58 #> 0.00        |      0.08 |       0.13 #> 0.00        |     -0.47 |       0.38 #> 0.00        |      0.10 |       0.72 #> 0.00        |     -0.02 |       0.97 #> 0.00        |      0.34 |       0.26 #> 0.00        |      0.35 |       0.27 #> 0.00        |  5.16e-03 |       0.56 #> 0.00        |      0.09 |       0.44 #> 0.00        |      0.02 |       0.46 #> 0.00        |      0.08 |       0.48 #> 0.00        |      0.30 |       0.41 #> 0.00        |     -0.08 |       0.63 #> 0.00        |      0.29 |       0.33 #> 0.00        |     -0.02 |       0.64 #> 0.00        |      0.37 |       0.62 #> 0.00        |      0.43 |       0.43 #> 0.00        |      0.44 |       0.41 #> 0.00        |     -0.25 |       0.37 #> 0.00        |      0.36 |       0.48 #> 0.00        |     -0.04 |       0.28 #> 0.00        |      0.05 |       0.48 #> 0.00        |      0.09 |       0.66 #> 0.00        |      0.12 |       0.14 #> 0.00        |     -0.07 |       0.37 #> 0.00        |     -0.06 |       0.34 #> 0.00        |     -0.34 |       0.32 #> 0.00        |      0.47 |       0.52 #> 0.00        |      0.38 |       0.24 #> 0.00        |      0.28 |       0.08 #> 0.00        |      0.05 |       0.68 #> 0.00        |      0.02 |       0.44 #> 0.00        |      0.13 |       0.20 #> 0.00        |      0.19 |       0.69 #> 0.00        |      0.14 |       0.48 #> 0.00        |      0.22 |       0.34 #> 0.00        |      0.23 |       0.49 #> 0.00        |     -0.05 |       0.23 #> 0.00        |      0.35 |       0.51 #> 0.00        |      0.14 |       0.40 #> 0.00        |      0.17 |       0.25 #> 0.00        |      0.02 |       0.62 #> 0.00        |      0.02 |       0.26 #> 0.00        |      0.13 |       0.21 #> 0.00        |      0.04 |       0.41 #> 0.00        |      0.21 |       0.01 #> 0.00        |      0.04 |       0.56 #> 0.00        |      0.11 |       0.24 #> 0.00        |     -0.01 |       0.59 #> 0.00        |      0.17 |       0.21 #> 0.00        |      0.08 |       0.47 #> 0.00        |      0.02 |       0.58 #> 0.00        |      0.09 |       0.62 #> 0.00        |     -0.05 |      -0.02 #> 0.00        |      0.14 |       0.96 #> 0.00        |      0.18 |       0.13 #> 0.00        |      0.07 |       0.23 #> 0.00        |      0.16 |       0.41 #> 0.00        |      0.20 |       0.44 #> 0.00        |      0.12 |       0.49 #> 0.00        |     -0.23 |       0.76 #> 0.00        |      0.02 |       0.70 #> 0.00        |      0.14 |       0.50 #> 0.00        |      0.09 |       0.25 #> 0.00        |      0.12 |       0.33 #> 0.00        |      0.24 |       0.61 #> 0.00        |      0.21 |       0.27 #> 0.00        |      0.26 |       0.30 #> 0.00        |      0.14 |       0.18 #> 0.00        |     -0.12 |       0.49 #> 0.00        |      0.24 |       0.37 #> 0.00        |     -0.06 |       0.46 #> 0.00        |      0.24 |       0.40 #> 0.00        |     -0.04 |       0.42 #> 0.00        |      0.07 |       0.55 #> 0.00        |      0.05 |       0.29 #> 0.00        |      0.26 |       0.06 #> 0.00        |     -0.29 |       0.37 #> 0.00        |      0.25 |       0.64 #> 0.00        |     -0.22 |       0.25 #> 0.00        |      0.02 |       0.70 #> 0.00        |     -0.31 |       0.71 #> 0.00        |      0.44 |       0.27 #> 0.00        |      0.24 |       0.29 #> 0.00        |      0.12 |       0.33 #> 0.00        |      0.08 |       0.18 #> 0.00        |      0.03 |       0.40 #> 0.00        |      0.06 |       0.04 #> 0.00        |     -0.03 |       0.72 #> 0.00        |      0.10 |       0.55 #> 0.00        |      0.04 |       0.32 #> 0.00        |     -0.05 |       0.44 #> 0.00        |      0.22 |       0.64 #> 0.00        |      0.03 |       0.46 #> 0.00        |      0.06 |       0.23 #> 0.00        |      0.09 |       0.43 #> 0.00        |      0.12 |       0.31 #> 0.00        |      0.01 |       0.58 #> 0.00        |     -0.09 |       0.48 #> 0.00        |      0.18 |       0.42 #> 0.00        |      0.11 |       0.44 #> 0.00        |      0.12 |       0.35 #> 0.00        |      0.18 |       0.36 #> 0.00        |      0.16 |       0.28 #> 0.00        |      0.15 |       0.13 #> 0.00        |      0.01 |       0.03 #> 0.00        |      0.37 |       0.45 #> 0.00        |     -0.29 |       0.13 #> 0.00        |  2.47e-03 |       0.58 #> 0.00        |      0.28 |       0.71 #> 0.00        |      0.29 |       0.72 #> 0.00        |      0.65 |       0.38 #> 0.00        |      0.13 |       0.23 #> 0.00        |      0.38 |       0.61 #> 0.00        |      0.25 |       0.47 #> 0.00        |      0.06 |       0.44 #> 0.00        |     -0.07 |       0.21 #> 0.00        |      0.19 |       0.40 #> 0.00        |      0.15 |       0.62 #> 0.00        |      0.08 |       0.46 #> 0.00        |     -0.04 |       0.46 #> 0.00        |      0.13 |       0.34 #> 0.00        |     -0.05 |       0.39 #> 0.00        |      0.26 |       0.38 #> 0.00        |     -0.11 |       0.52 #> 0.00        |      0.27 |       0.33 #> 0.00        |     -0.04 |       0.47 #> 0.00        |      0.44 |       0.39 #> 0.00        |     -0.02 |       0.17 #> 0.00        |      0.20 |       0.90 #> 0.00        |      0.20 |       0.73 #> 0.00        |     -0.14 |       0.35 #> 0.00        |     -0.09 |       0.36 #> 0.00        |      0.30 |       0.65 #> 0.00        |      0.24 |       0.60 #> 0.00        |     -0.15 |       0.45 #> 0.00        |      0.26 |       0.33 #> 0.00        |      0.13 |       0.12 #> 0.00        |      0.14 |       0.74 #> 0.00        |      0.23 |       0.79 #> 0.00        |      0.28 |       0.55 #> 0.00        |      0.06 |       0.37 #> 0.00        |      0.45 |       0.22 #> 0.00        |      0.21 |       0.42 #> 0.00        |      0.29 |       0.39 #> 0.00        |      0.10 |       0.46 #> 0.00        |      0.03 |       0.53 #> 0.00        |      0.17 |       0.27 #> 0.00        |      0.05 |       0.53 #> 0.00        |      0.11 |       0.42 #> 0.00        |      0.06 |       0.38 #> 0.00        |      0.06 |       0.35 #> 0.00        | -4.62e-03 |       0.63 #> 0.00        |      0.04 |       0.44 #> 0.00        |      0.10 |       0.28 #> 0.00        |      0.11 |       0.18 #> 0.00        |      0.13 |       0.55 #> 0.00        | -3.13e-03 |       0.27 #> 0.00        |      0.07 |       0.36 #> 0.00        |      0.04 |       0.56 #> 0.00        |      0.06 |       0.31 #> 0.00        |      0.28 |       0.33 #> 0.00        |      0.13 |       0.28 #> 0.00        |     -0.02 |       0.50 #> 0.00        |      0.02 |       0.21 #> 0.00        |      0.02 |       0.32 #> 0.00        |      0.15 |       0.41 #> 0.00        |      0.05 |       0.37 #> 0.00        |      0.29 |       0.42 #> 0.00        |     -0.15 |       0.25 #> 0.00        |     -0.03 |       0.65 #> 0.00        |  9.58e-03 |       0.60 #> 0.00        |      0.12 |       0.51 #> 0.00        |      0.16 |       0.58 #> 0.00        |     -0.01 |       0.31 #> 0.00        |      0.26 |       0.27 #> 0.00        |      0.46 |       0.16 #> 0.00        |     -0.06 |  -8.79e-03 #> 0.00        |      0.24 |       0.16 #> 0.00        |     -0.09 |       0.54 #> 0.00        |      0.32 |       0.19 #> 0.00        |      0.03 |       0.84 #> 0.00        |      0.24 |       0.70 #> 0.00        |      0.03 |       0.19 #> 0.00        |      0.09 |       0.44 #> 0.00        |      0.08 |       0.37 #> 0.00        |      0.08 |       0.44 #> 0.00        |      0.31 |       0.13 #> 0.00        |      0.19 |       0.42 #> 0.00        |      0.26 |       0.34 #> 0.00        |     -0.13 |       0.71 #> 0.00        |      0.45 |       0.26 #> 0.00        |     -0.20 |       0.53 #> 0.00        |     -0.08 |       0.50 #> 0.00        |      0.08 |       0.47 #> 0.00        |      0.13 |       0.50 #> 0.00        |      0.18 |       0.44 #> 0.00        |      0.01 |       0.71 #> 0.00        |      0.12 |       0.18 #> 0.00        |      0.07 |       0.63 #> 0.00        |  5.09e-03 |       0.30 #> 0.00        |      0.18 |       0.21 #> 0.00        |      0.04 |       0.60 #> 0.00        |      0.04 |       0.14 #> 0.00        |      0.25 |       0.63 #> 0.00        |      0.18 |       0.38 #> 0.00        |      0.06 |       0.39 #> 0.00        |     -0.03 |       0.42 #> 0.00        |      0.16 |       0.36 #> 0.00        |      0.17 |       0.17 #> 0.00        |      0.06 |       0.68 #> 0.00        |      0.03 |       0.75 #> 0.00        |      0.34 |       0.27 #> 0.00        |     -0.31 |       0.51 #> 0.00        |      0.44 |       0.36 #> 0.00        |      0.19 |       0.43 #> 0.00        |      0.17 |       0.54 #> 0.00        | -1.02e-03 |       0.50 #> 0.00        |      0.09 |       0.46 #> 0.00        |      0.22 |       0.21 #> 0.00        |     -0.07 |       0.10 #> 0.00        |      0.09 |       0.62 #> 0.00        |      0.16 |       0.56 #> 0.00        |      0.33 |       0.13 #> 0.00        |      0.16 |       0.34 #> 0.00        |      0.21 |       0.37 #> 0.00        |      0.28 |       0.36 #> 0.00        |      0.15 |       0.36 #> 0.00        |      0.05 |       0.42 #> 0.00        | -8.06e-03 |       0.30 #> 0.00        |      0.21 |       0.55 #> 0.00        |      0.02 |       0.25 #> 0.00        |      0.19 |       0.24 #> 0.00        | -5.45e-03 |       0.47 #> 0.00        |     -0.03 |       0.43 #> 0.00        |      0.16 |       0.36 #> 0.00        |      0.27 |       0.34 #> 0.00        |     -0.02 |       0.44 #> 0.00        |      0.24 |       0.37 #> 0.00        | -8.30e-03 |       0.54 #> 0.00        |     -0.05 |       0.36 #> 0.00        |      0.25 |       0.43 #> 0.00        |     -0.18 |       0.15 #> 0.00        |     -0.01 |       0.28 #> 0.00        |     -0.07 |       0.37 #> 0.00        |      0.07 |       0.45 #> 0.00        |      0.01 |       0.49 #> 0.00        |      0.11 |       0.15 #> 0.00        |     -0.14 |       0.64 #> 0.00        |      0.21 |       0.16 #> 0.00        |     -0.03 |       0.63 #> 0.00        |      0.04 |       0.62 #> 0.00        |      0.03 |       0.40 #> 0.00        |      0.19 |       0.40 #> 0.00        |      0.03 |       0.33 #> 0.00        |      0.06 |       0.22 #> 0.00        |     -0.02 |       0.11 #> 0.00        |     -0.02 |       0.37 #> 0.00        |      0.14 |       0.38 #> 0.00        |      0.12 |       0.30 #> 0.00        |  3.00e-03 |       0.46 #> 0.00        |     -0.04 |       0.64 #> 0.00        |     -0.06 |       0.28 #> 0.00        |      0.25 |       0.38 #> 0.00        |     -0.04 |       0.32 #> 0.00        |      0.07 |       0.25 #> 0.00        |      0.43 |       0.56 #> 0.00        |     -0.03 |       0.34 #> 0.00        |      0.30 |       0.72 #> 0.00        |      0.40 |       0.61 #> 0.00        |     -0.12 |       0.37 #> 0.00        |      0.31 |       0.35 #> 0.00        |      0.28 |       0.45 #> 0.00        |      0.29 |       0.50 #> 0.00        |      0.05 |       0.55 #> 0.00        |      0.47 |       0.04 #> 0.00        |      0.29 |       0.33 #> 0.00        |      0.06 |       0.52 #> 0.00        |      0.21 |       0.47 #> 0.00        |      0.10 |       0.56 #> 0.00        |      0.12 |       0.47 #> 0.00        |      0.52 |       0.64 #> 0.00        |      0.47 |       0.60 #> 0.00        |      0.40 |       0.57 #> 0.00        |     -0.12 |      -0.26 #> 0.00        |     -0.02 |      -0.35 #> 0.00        |      0.34 |       0.86 #> 0.00        |      0.27 |       0.65 #> 0.00        |      0.07 |       0.32 #> 0.00        |      0.07 |       0.52 #> 0.00        |      0.34 |       0.32 #> 0.00        |      0.24 |       0.14 #> 0.00        |      0.17 |       0.43 #> 0.00        |      0.22 |       0.63 #> 0.00        |     -0.19 |       0.26 #> 0.00        |      0.04 |       0.54 #> 0.00        |      0.08 |       0.77 #> 0.00        |     -0.13 |       0.27 #> 0.00        |      0.37 |       0.50 #> 0.00        |     -0.09 |       0.11 #> 0.00        |      0.23 |       0.64 #> 0.00        |      0.06 |       0.07 #> 0.00        |      0.03 |       0.11 #> 0.00        |      0.31 |       0.57 #> 0.00        |      0.28 |       0.43 #> 0.00        |     -0.02 |       0.34 #> 0.00        |      0.35 |       0.47 #> 0.00        |     -0.11 |       0.40 #> 0.00        |      0.10 |       0.30 #> 0.00        |      0.37 |       0.36 #> 0.00        |      0.33 |       0.44 #> 0.00        |      0.40 |       0.53 #> 0.00        |     -0.05 |       0.18 #> 0.00        |      0.02 |       0.25 #> 0.00        |      0.33 |       0.42 #> 0.00        |      0.17 |       0.63 #> 0.00        |     -0.19 |       0.57 #> 0.00        |      0.27 |       0.13 #> 0.00        |      0.14 |       0.42 #> 0.00        |     -0.20 |       0.27 #> 0.00        |      0.01 |       0.31 #> 0.00        |     -0.09 |       0.40 #> 0.00        |      0.04 |       0.33 #> 0.00        |      0.62 |       0.18 #> 0.00        |      0.28 |       0.26 #> 0.00        |     -0.15 |       0.71 #> 0.00        |      0.32 |       0.10 #> 0.00        |     -0.22 |       0.75 #> 0.00        |     -0.06 |       0.25 #> 0.00        |     -0.26 |       0.29 #> 0.00        |      0.38 |       0.60 #> 0.00        |      0.24 |       0.50 #> 0.00        |      0.08 |       0.37 #> 0.00        |      0.10 |       0.26 #> 0.00        |      0.19 |       0.41 #> 0.00        | -3.47e-03 |       0.15 #> 0.00        |     -0.13 |       0.16 #> 0.00        |     -0.07 |       0.32 #> 0.00        |     -0.15 |       0.46 #> 0.00        |      0.06 |       0.22 #> 0.00        |      0.16 |       0.76 #> 0.00        |     -0.10 |       0.94 #> 0.00        |     -0.18 |       0.18 #> 0.00        |      0.17 |       0.79 #> 0.00        | -8.91e-03 |       0.71 #> 0.00        |     -0.06 |       0.57 #> 0.00        |      0.07 |       0.59 #> 0.00        |      0.08 |       0.26 #> 0.00        |      0.02 |       0.51 #> 0.00        |      0.11 |       0.44 #> 0.00        |      0.16 |       0.40 #> 0.00        |     -0.16 |       0.46 #> 0.00        |      0.37 |       0.28 #> 0.00        |     -0.21 |       0.63 #> 0.00        |      0.28 |       0.15 #> 0.00        |      0.09 |       0.37 #> 0.00        |      0.15 |       0.47 #> 0.00        |      0.08 |       0.37 #> 0.00        |      0.05 |       0.76 #> 0.00        |      0.29 |       0.20 #> 0.00        |      0.28 |       0.27 #> 0.00        |      0.13 |       0.25 #> 0.00        |      0.10 |       0.39 #> 0.00        |      0.10 |       0.26 #> 0.00        |     -0.13 |       0.55 #> 0.00        |     -0.04 |       0.44 #> 0.00        |      0.05 |       0.45 #> 0.00        |      0.20 |       0.45 #> 0.00        | -3.41e-03 |       0.46 #> 0.00        |      0.13 |       0.70 #> 0.00        |      0.06 |       0.20 #> 0.00        |      0.05 |       0.79 #> 0.00        |     -0.06 |       0.81 #> 0.00        |      0.22 |       0.10 #> 0.00        |      0.14 |       0.39 #> 0.00        |      0.20 |       0.52 #> 0.00        |      0.03 |       0.39 #> 0.00        |  1.33e-03 |       0.44 #> 0.00        |     -0.09 |       0.41 #> 0.00        |  9.66e-03 |       0.30 #> 0.00        |      0.18 |       0.53 #> 0.00        |      0.09 |       0.13 #> 0.00        |      0.10 |       0.69 #> 0.00        |      0.16 |       0.35 #> 0.00        |  4.91e-03 |       0.52 #> 0.00        |      0.12 |       0.49 #> 0.00        |      0.17 |       0.35 #> 0.00        |      0.17 |       0.57 #> 0.00        |      0.27 |       0.70 #> 0.00        |      0.47 |       0.81 #> 0.00        |      0.16 |       0.18 #> 0.00        |      0.07 |       0.57 #> 0.00        |      0.07 |       0.53 #> 0.00        |      0.07 |       0.34 #> 0.00        |      0.10 |       0.48 #> 0.00        |      0.13 |       0.32 #> 0.00        |      0.12 |       0.60 #> 0.00        |      0.10 |       0.13 #> 0.00        |     -0.18 |       0.37 #> 0.00        |     -0.12 |       0.49 #> 0.00        |     -0.10 |       0.50 #> 0.00        |      0.23 |       0.44 #> 0.00        |      0.10 |       0.23 #> 0.00        |      0.29 |       0.23 #> 0.00        |      0.07 |       0.44 #> 0.00        |      0.11 |       0.42 #> 0.00        |      0.09 |       0.59 #> 0.00        |     -0.13 |       0.54 #> 0.00        |     -0.03 |       0.86 #> 0.00        |      0.14 |       0.12 #> 0.00        |     -0.02 |       0.82 #> 0.00        |      0.33 |       0.29 #> 0.00        |      0.09 |       0.36 #> 0.00        |      0.14 |       0.43 #> 0.00        |      0.20 |       0.45 #> 0.00        | -6.48e-03 |       0.56 #> 0.00        |      0.49 |       0.30 #> 0.00        |     -0.17 |       0.31 #> 0.00        |     -0.09 |       0.24 #> 0.00        |      0.22 |       0.53 #> 0.00        |      0.06 |       0.64 #> 0.00        |      0.04 |       0.68 #> 0.00        |      0.01 |       0.29 #> 0.00        |      0.08 |       0.24 #> 0.00        |      0.39 |       0.43 #> 0.00        | -3.98e-03 |       0.47 #> 0.00        |      0.16 |       0.43 #> 0.00        |      0.08 |      -0.03 #> 0.00        |      0.53 |       0.38 #> 0.00        |     -0.17 |       0.26 #> 0.00        |      0.22 |       0.55 #> 0.00        |      0.13 |       0.49 #> 0.00        |      0.07 |       0.33 #> 0.00        |      0.26 |       0.32 #> 0.00        |      0.28 |       0.29 #> 0.00        |      0.36 |       0.18 #> 0.00        |      0.07 |       0.44 #> 0.00        |      0.07 |       0.31 #> 0.00        |     -0.10 |       0.45 #> 0.00        |      0.09 |       0.63 #> 0.00        |      0.16 |       0.61 #> 0.00        |      0.06 |       0.15 #> 0.00        |      0.24 |       0.68 #> 0.00        |      0.23 |       0.71 #> 0.00        |     -0.19 |       0.13 #> 0.00        |     -0.15 |       0.11 #> 0.00        |     -0.19 |       0.06 #> 0.00        |      0.05 |       0.40 #> 0.00        |      0.10 |       0.49 #> 0.00        |      0.34 |       0.56 #> 0.00        |      0.04 |       0.11 #> 0.00        |      0.10 |       0.70 #> 0.00        |     -0.02 |       0.18 #> 0.00        |      0.17 |       0.59 #> 0.00        |      0.10 |       0.51 #> 0.00        |      0.21 |       0.51 #> 0.00        |      0.03 |       0.42 #> 0.00        |      0.01 |       0.32 #> 0.00        |     -0.27 |       0.47 #> 0.00        |      0.23 |       0.29 #> 0.00        |      0.02 |       0.47 #> 0.00        |      0.29 |       0.46 #> 0.00        |      0.02 |       0.48 #> 0.00        |     -0.05 |       0.77 #> 0.00        |      0.14 |       0.22 #> 0.00        |     -0.09 |       0.64 #> 0.00        |      0.35 |       0.41 #> 0.00        |     -0.02 |       0.46 #> 0.00        |      0.28 |       0.41 #> 0.00        |      0.34 |       0.44 #> 0.00        |     -0.11 |       0.39 #> 0.00        |      0.51 |       0.33 #> 0.00        |     -0.27 |       0.64 #> 0.00        |      0.45 |       0.16 #> 0.00        |     -0.08 |       0.64 #> 0.00        |      0.29 |       0.22 #> 0.00        |     -0.13 |       0.57 #> 0.00        |      0.32 |       0.33 #> 0.00        |     -0.10 |       0.49 #> 0.00        |      0.08 |       0.31 #> 0.00        |      0.12 |       0.63 #> 0.00        |      0.14 |       0.60 #> 0.00        | -8.01e-03 |       0.54 #> 0.00        |      0.27 |       0.68 #> 0.00        |      0.10 |       0.45 #> 0.00        |      0.08 |       0.56 #> 0.00        |      0.13 |       0.30 #> 0.00        |  6.61e-03 |       0.31 #> 0.00        |      0.07 |       0.30 #> 0.00        |      0.13 |       0.06 #> 0.00        |      0.13 |       0.68 #> 0.00        |      0.22 |       0.33 #> 0.00        |      0.20 |       0.39 #> 0.00        |     -0.23 |       0.76 #> 0.00        |      0.34 |       0.03 #> 0.00        |      0.06 |       0.50 #> 0.00        |  4.35e-03 |       0.30 #> 0.00        |     -0.23 |       0.21 #> 0.00        |      0.02 |       0.70 #> 0.00        |      0.28 |       0.19 #> 0.00        |     -0.10 |       0.57 #> 0.00        |      0.37 |       0.27 #> 0.00        |     -0.33 |       0.76 #> 0.00        |      0.38 |       0.20 #> 0.00        |     -0.15 |       0.46 #> 0.00        |      0.31 |       0.30 #> 0.00        |     -0.15 |       0.73 #> 0.00        |     -0.29 |       0.47 #> 0.00        |     -0.22 |       0.88 #> 0.00        |      0.06 |       0.32 #> 0.00        |      0.21 |       0.59 #> 0.00        |      0.27 |       0.36 #> 0.00        |     -0.02 |       0.34 #> 0.00        |     -0.15 |       0.67 #> 0.00        |      0.08 |       0.34 #> 0.00        |     -0.22 |      -0.01 #> 0.00        |      0.36 |       0.20 #> 0.00        |     -0.01 |       0.66 #> 0.00        |      0.19 |       0.05 #> 0.00        |      0.26 |       0.33 #> 0.00        |      0.26 |       0.56 #> 0.00        |     -0.10 |       0.32 #> 0.00        |      0.09 |       0.25 #> 0.00        |      0.10 |       0.27 #> 0.00        |      0.22 |       0.35 #> 0.00        |     -0.04 |       0.14 #> 0.00        |      0.47 |       0.51 #> 0.00        |      0.05 |       0.41 #> 0.00        |      0.03 |       0.32 #> 0.00        |     -0.11 |       0.41 #> 0.00        |      0.34 |       0.41 #> 0.00        |     -0.55 |       0.73 #> 0.00        |      0.82 |       0.17 #> 0.00        |      0.52 |       0.18 #> 0.00        |     -0.10 |       0.18 #> 0.00        |     -0.04 |       0.23 #> 0.00        |     -0.13 |       0.29 #> 0.00        |      0.29 |       0.65 #> 0.00        |      0.38 |       0.58 #> 0.00        |      0.39 |       0.31 #> 0.00        |      0.13 |       0.96 #> 0.00        |      0.22 |       0.74 #> 0.00        |      0.05 |       0.07 #> 0.00        |     -0.13 |       0.60 #> 0.00        |     -0.18 |       0.44 #> 0.00        |      0.28 |       0.57 #> 0.00        |     -0.10 |       0.22 #> 0.00        |      0.01 |       0.48 #> 0.00        |     -0.06 |       0.48 #> 0.00        |      0.05 |       0.43 #> 0.00        |      0.06 |       0.43 #> 0.00        |      0.05 |       0.33 #> 0.00        |      0.24 |       0.44 #> 0.00        |     -0.11 |       0.26 #> 0.00        |     -0.05 |       0.71 #> 0.00        |      0.06 |       0.36 #> 0.00        |      0.18 |       0.52 #> 0.00        |      0.07 |       0.54 #> 0.00        |      0.12 |       0.31 #> 0.00        |      0.23 |       0.24 #> 0.00        |      0.23 |       0.45 #> 0.00        |      0.33 |       0.34 #> 0.00        |      0.31 |       0.37 #> 0.00        |     -0.04 |       0.31 #> 0.00        |      0.06 |       0.32 #> 0.00        |      0.05 |       0.21 #> 0.00        |      0.12 |       0.50 #> 0.00        |      0.05 |       0.32 #> 0.00        |     -0.33 |       0.37 #> 0.00        |     -0.28 |       0.37 #> 0.00        |     -0.42 |       0.25 #> 0.00        |     -0.13 |       0.53 #> 0.00        |      0.06 |       0.43 #> 0.00        |  7.78e-03 |       0.59 #> 0.00        |      0.09 |       0.47 #> 0.00        | -8.77e-03 |       0.71 #> 0.00        |      0.08 |       0.66 #> 0.00        |      0.25 |       0.25 #> 0.00        |      0.46 |       0.81 #> 0.00        |      0.40 |       0.44 #> 0.00        | -7.60e-04 |       0.30 #> 0.00        |      0.23 |       0.37 #> 0.00        |     -0.11 |       0.52 #> 0.00        |      0.27 |       0.31 #> 0.00        |      0.04 |       0.48 #> 0.00        |      0.08 |       0.68 #> 0.00        |  9.56e-03 |       0.15 #> 0.00        |      0.28 |       0.48 #> 0.00        |      0.04 |       0.55 #> 0.00        |      0.24 |       0.66 #> 0.00        |      0.09 |       0.49 #> 0.00        |      0.16 |       0.28 #> 0.00        |  6.11e-03 |       0.36 #> 0.00        |     -0.05 |       0.36 #> 0.00        |      0.23 |       0.40 #> 0.00        |     -0.18 |       0.30 #> 0.00        |      0.10 |       0.35 #> 0.00        |      0.16 |       0.25 #> 0.00        |     -0.02 |       0.50 #> 0.00        |      0.40 |       0.30 #> 0.00        |     -0.22 |       0.51 #> 0.00        |      0.08 |       0.56 #> 0.00        |     -0.06 |       0.45 #> 0.00        |      0.15 |       0.39 #> 0.00        |      0.03 |       0.42 #> 0.00        |      0.24 |       0.28 #> 0.00        |      0.39 |       0.17 #> 0.00        |      0.07 |       0.40 #> 0.00        |      0.46 |       0.68 #> 0.00        |     -0.08 |      -0.03 #> 0.00        |      0.41 |       0.71 #> 0.00        |  1.77e-03 |       0.23 #> 0.00        |      0.12 |       0.53 #> 0.00        |      0.14 |       0.26 #> 0.00        |      0.03 |       0.58 #> 0.00        |      0.06 |       0.63 #> 0.00        |      0.12 |       0.48 #> 0.00        |      0.12 |       0.33 #> 0.00        |     -0.02 |       0.35 #> 0.00        |      0.20 |       0.18 #> 0.00        |     -0.07 |       0.65 #> 0.00        |     -0.05 |       0.53 #> 0.00        |  4.63e-03 |       0.43 #> 0.00        |      0.36 |       0.20 #> 0.00        |      0.13 |       0.27 #> 0.00        |      0.12 |       0.47 #> 0.00        |      0.16 |       0.37 #> 0.00        |      0.05 |       0.27 #> 0.00        |      0.27 |       0.52 #> 0.00        |  4.14e-03 |       0.36 #> 0.00        |     -0.08 |       0.80 #> 0.00        |      0.26 |       0.03 #> 0.00        |      0.11 |       0.72 #> 0.00        |      0.31 |       0.39 #> 0.00        |      0.06 |       0.40 #> 0.00        |      0.10 |       0.43 #> 0.00        |      0.19 |       0.45 #> 0.00        |      0.11 |       0.28 #> 0.00        |     -0.05 |       0.50 #> 0.00        |      0.21 |       0.26 #> 0.00        |      0.18 |       0.50 #> 0.00        |      0.22 |       0.46 #> 0.00        |      0.24 |       0.44 #> 0.00        |      0.18 |       0.43 #> 0.00        |      0.30 |       0.18 #> 0.00        |     -0.25 |       0.29 #> 0.00        |      0.04 |       0.34 #> 0.00        |      0.35 |       0.46 #> 0.00        |      0.34 |       0.37 #> 0.00        |     -0.09 |       0.34 #> 0.00        |      0.20 |       0.40 #> 0.00        |      0.14 |       0.38 #> 0.00        |     -0.09 |       0.32 #> 0.00        |      0.26 |       0.51 #> 0.00        |      0.29 |       0.56 #> 0.00        |      0.13 |       0.20 #> 0.00        |      0.24 |       0.54 #> 0.00        |     -0.09 |       0.38 #> 0.00        |     -0.12 |       0.54 #> 0.00        |     -0.16 |       0.44 #> 0.00        |     -0.14 |       0.45 #> 0.00        |     -0.37 |       0.52 #> 0.00        |     -0.02 |       0.29 #> 0.00        |      0.04 |       0.65 #> 0.00        |     -0.18 |       0.36 #> 0.00        |      0.46 |       0.39 #> 0.00        |     -0.16 |       0.57 #> 0.00        |      0.31 |       0.30 #> 0.00        |      0.03 |       0.44 #> 0.00        |     -0.07 |       0.46 #> 0.00        |     -0.10 |       0.60 #> 0.00        |      0.14 |       0.53 #> 0.00        |      0.07 |       0.56 #> 0.00        |      0.17 |       0.36 #> 0.00        |      0.13 |       0.18 #> 0.00        |      0.12 |       0.79 #> 0.00        |      0.14 |       0.10 #> 0.00        |      0.37 |       0.13 #> 0.00        |      0.21 |       0.09 #> 0.00        |     -0.07 |       0.38 #> 0.00        |      0.32 |       0.35 #> 0.00        |     -0.04 |       0.45 #> 0.00        |      0.15 |       0.43 #> 0.00        |     -0.02 |       0.33 #> 0.00        |     -0.04 |       0.67 #> 0.00        |     -0.28 |       0.55 #> 0.00        |     -0.20 |       0.36 #> 0.00        |      0.13 |       0.39 #> 0.00        |      0.12 |       0.44 #> 0.00        |      0.11 |       0.39 #> 0.00        |      0.27 |       0.45 #> 0.00        |     -0.14 |       0.34 #> 0.00        |     -0.04 |       0.60 #> 0.00        |      0.09 |       0.41 #> 0.00        |      0.05 |       0.69 #> 0.00        |      0.04 |       0.21 #> 0.00        |      0.33 |       0.42 #> 0.00        |     -0.01 |       0.30 #> 0.00        |      0.24 |       0.58 #> 0.00        |      0.15 |       0.33 #> 0.00        |     -0.09 |       0.34 #> 0.00        |      0.13 |       0.38 #> 0.00        |      0.07 |       0.40 #> 0.00        |      0.12 |       0.24 #> 0.00        |     -0.03 |       0.46 #> 0.00        |      0.05 |       0.49 #> 0.00        |      0.16 |       0.49 #> 0.00        |      0.24 |       0.25 #> 0.00        |      0.11 |       0.39 #> 0.00        |     -0.07 |       0.50 #> 0.00        |      0.02 |       0.45 #> 0.00        |      0.11 |       0.33 #> 0.00        | -4.13e-04 |       0.59 #> 0.00        |      0.12 |       0.55 #> 0.00        |      0.56 |       0.75 #> 0.00        |     -0.34 |       0.03 #> 0.00        |     -0.23 |       0.24 #> 0.00        |     -0.23 |       0.23 #> 0.00        |     -0.12 |       0.39 #> 0.00        |      0.08 |       0.48 #> 0.00        |      0.35 |       0.29 #> 0.00        |     -0.14 |       0.46 #> 0.00        |      0.30 |       0.41 #> 0.00        |      0.11 |       0.36 #> 0.00        |     -0.16 |       0.26 #> 0.00        |     -0.18 |       0.22 #> 0.00        |      0.41 |       0.56 #> 0.00        |      0.33 |       0.63 #> 0.00        |      0.09 |       0.20 #> 0.00        |      0.12 |       0.61 #> 0.00        |      0.17 |       0.61 #> 0.00        | -3.88e-03 |       0.21 #> 0.00        |      0.16 |       0.45 #> 0.00        |      0.16 |       0.11 #> 0.00        |      0.14 |       0.14 #> 0.00        |      0.09 |       0.35 #> 0.00        |      0.04 |       0.51 #> 0.00        |      0.25 |       0.24 #> 0.00        |      0.07 |       0.59 #> 0.00        |      0.28 |       0.43 #> 0.00        |      0.34 |       0.57 #> 0.00        |     -0.17 |       0.37 #> 0.00        |     -0.16 |       0.55 #> 0.00        |     -0.18 |       0.07 #> 0.00        |      0.40 |       0.70 #> 0.00        |     -0.30 |       0.14 #> 0.00        |     -0.25 |       0.23 #> 0.00        |      0.07 |       0.25 #> 0.00        |      0.29 |       0.52 #> 0.00        |      0.15 |       0.60 #> 0.00        |      0.13 |       0.24 #> 0.00        |     -0.18 |       0.62 #> 0.00        |     -0.27 |       0.46 #> 0.00        |     -0.24 |       0.64 #> 0.00        |      0.48 |       0.20 #> 0.00        |     -0.16 |       0.48 #> 0.00        |      0.07 |       0.57 #> 0.00        |      0.15 |       0.21 #> 0.00        |      0.23 |       0.27 #> 0.00        |     -0.07 |       0.53 #> 0.00        |      0.35 |       0.13 #> 0.00        |     -0.12 |       0.68 #> 0.00        |     -0.13 |       0.72 #> 0.00        |      0.18 |       0.58 #> 0.00        |     -0.12 |       0.35 #> 0.00        |      0.27 |       0.47 #> 0.00        |      0.35 |       0.37 #> 0.00        |      0.12 |       0.33 #> 0.00        |      0.17 |       0.40 #> 0.00        |      0.34 |       0.35 #> 0.00        |     -0.07 |       0.50 #> 0.00        |     -0.23 |       0.33 #> 0.00        |      0.48 |       0.35 #> 0.00        |      0.36 |       0.35 #> 0.00        |     -0.10 |       0.44 #> 0.00        |      0.42 |       0.49 #> 0.00        |  7.69e-03 |       0.38 #> 0.00        |     -0.05 |       0.26 #> 0.00        |      0.18 |       0.60 #> 0.00        |      0.26 |       0.39 #> 0.00        |      0.55 |       0.47 #> 0.00        |     -0.13 |       0.56 #> 0.00        |      0.03 |       0.35 #> 0.00        |     -0.28 |       0.51 #> 0.00        |      0.12 |       0.67 #> 0.00        |     -0.03 |       0.10 #> 0.00        |     -0.03 |       0.30 #> 0.00        |      0.19 |       0.50 #> 0.00        |      0.04 |       0.30 #> 0.00        |      0.14 |       0.39 #> 0.00        |      0.09 |       0.45 #> 0.00        |      0.09 |       0.15 #> 0.00        |      0.11 |       0.29 #> 0.00        |      0.02 |       0.56 #> 0.00        |     -0.22 |       0.46 #> 0.00        |      0.03 |       0.43 #> 0.00        |     -0.04 |       0.39 #> 0.00        |      0.05 |       0.33 #> 0.00        |      0.09 |       0.14 #> 0.00        |      0.19 |       0.38 #> 0.00        |      0.19 |       0.51 #> 0.00        |      0.07 |       0.32 #> 0.00        |      0.17 |       0.31 #> 0.00        |     -0.13 |       0.39 #> 0.00        |      0.72 |       0.21 #> 0.00        |     -0.10 |       0.53 #> 0.00        |     -0.13 |       0.48 #> 0.00        |     -0.16 |       0.69 #> 0.00        |      0.13 |       0.41 #> 0.00        |      0.07 |       0.39 #> 0.00        |  6.36e-03 |       0.52 #> 0.00        |      0.16 |       0.33 #> 0.00        |      0.07 |       0.41 #> 0.00        |      0.08 |       0.38 #> 0.00        |      0.35 |       0.21 #> 0.00        |      0.46 |       0.55 #> 0.00        |     -0.09 |   6.53e-03 #> 0.00        |      0.07 |       0.73 #> 0.00        |      0.17 |       0.09 #> 0.00        |     -0.11 |       0.13 #> 0.00        |     -0.12 |       0.61 #> 0.00        |      0.30 |       0.31 #> 0.00        |     -0.20 |       0.42 #> 0.00        |      0.26 |       0.30 #> 0.00        |      0.45 |       0.11 #> 0.00        |      0.07 |      -0.12 #> 0.00        |      0.23 |       0.65 #> 0.00        |      0.28 |       0.34 #> 0.00        |      0.06 |       0.46 #> 0.00        |      0.13 |       0.45 #> 0.00        |      0.24 |       0.30 #> 0.00        |      0.16 |       0.44 #> 0.00        |     -0.10 |       0.42 #> 0.00        |      0.28 |       0.33 #> 0.00        |     -0.09 |       0.48 #> 0.00        |      0.23 |       0.43 #> 0.00        |      0.30 |       0.21 #> 0.00        |      0.20 |       0.30 #> 0.00        |     -0.04 |       0.56 #> 0.00        |      0.22 |       0.34 #> 0.00        |      0.04 |       0.43 #> 0.00        |      0.25 |       0.59 #> 0.00        |      0.14 |       0.62 #> 0.00        |      0.14 |       0.47 #> 0.00        |      0.22 |       0.28 #> 0.00        |      0.32 |       0.20 #> 0.00        |      0.16 |       0.38 #> 0.00        |  7.71e-03 |       0.54 #> 0.00        |  1.78e-03 |       0.71 #> 0.00        |  3.64e-03 |       0.25 #> 0.00        |      0.35 |       0.51 #> 0.00        |      0.01 |       0.33 #> 0.00        |      0.19 |       0.39 #> 0.00        |      0.03 |       0.68 #> 0.00        |      0.06 |       0.17 #> 0.00        |      0.38 |       0.35 #> 0.00        |      0.16 |       0.61 #> 0.00        |      0.02 |       0.43 #> 0.00        |      0.25 |       0.35 #> 0.00        |     -0.12 |       0.56 #> 0.00        |     -0.15 |       0.57 #> 0.00        | -5.82e-03 |       0.31 #> 0.00        |      0.22 |       0.58 #> 0.00        |      0.08 |       0.44 #> 0.00        |     -0.11 |       0.33 #> 0.00        |      0.49 |       0.26 #> 0.00        |     -0.17 |       0.77 #> 0.00        |      0.16 |       0.14 #> 0.00        |      0.10 |       0.60 #> 0.00        |     -0.10 |       0.36 #> 0.00        |      0.35 |       0.45 #> 0.00        |     -0.10 |       0.20 #> 0.00        |      0.08 |       0.82 #> 0.00        |     -0.09 |       0.26 #> 0.00        |      0.34 |       0.59 #> 0.00        |     -0.03 |       0.25 #> 0.00        |     -0.14 |       0.27 #> 0.00        |      0.14 |       0.37 #> 0.00        |      0.29 |       0.54 #> 0.00        |     -0.20 |       0.41 #> 0.00        |     -0.02 |       0.44 #> 0.00        |      0.04 |       0.47 #> 0.00        |     -0.05 |       0.25 #> 0.00        |      0.13 |       0.32 #> 0.00        |     -0.04 |       0.60 #> 0.00        |     -0.05 |       0.66 #> 0.00        |      0.30 |       0.23 #> 0.00        |     -0.14 |       0.48 #> 0.00        |      0.16 |       0.53 #> 0.00        |      0.06 |       0.25 #> 0.00        |      0.29 |       0.42 #> 0.00        |     -0.21 |       0.61 #> 0.00        |     -0.04 |       0.57 #> 0.00        |      0.04 |       0.50 #> 0.00        |      0.25 |       0.50 #> 0.00        |     -0.08 |       0.30 #> 0.00        |     -0.17 |       0.22 #> 0.00        |     -0.17 |       0.22 #> 0.00        |      0.27 |       0.56 #> 0.00        |      0.24 |       0.27 #> 0.00        |      0.15 |       0.48 #> 0.00        |     -0.21 |       0.38 #> 0.00        |      0.35 |       0.51 #> 0.00        |      0.38 |       0.44 #> 0.00        |     -0.01 |       0.42 #> 0.00        |      0.06 |       0.42 #> 0.00        |      0.09 |       0.40 #> 0.00        | -6.01e-03 |       0.39 #> 0.00        |      0.13 |       0.35 #> 0.00        |      0.10 |       0.55 #> 0.00        |      0.43 |       0.23 #> 0.00        |      0.55 |       0.54 #> 0.00        |      0.15 |       0.09 #> 0.00        |     -0.06 |       0.34 #> 0.00        |      0.41 |       0.34 #> 0.00        |      0.12 |       0.39 #> 0.00        |      0.04 |       0.40 #> 0.00        |      0.11 |       0.44 #> 0.00        |      0.24 |       0.27 #> 0.00        |      0.04 |       0.22 #> 0.00        |      0.16 |       0.59 #> 0.00        |      0.41 |       0.08 #> 0.00        |      0.27 |       0.03 #> 0.00        |     -0.03 |       0.48 #> 0.00        |     -0.11 |       0.70 #> 0.00        |      0.10 |       0.23 #> 0.00        |     -0.39 |       0.33 #> 0.00        |      0.44 |       0.51 #> 0.00        |      0.12 |      -0.16 #> 0.00        |     -0.04 |       0.16 #> 0.00        |     -0.14 |       0.50 #> 0.00        |      0.18 |       0.16 #> 0.00        |     -0.22 |       0.59 #> 0.00        |      0.36 |       0.66 #> 0.00        |      0.10 |       0.31 #> 0.00        |      0.06 |       0.35 #> 0.00        |      0.15 |       0.72 #> 0.00        |      0.33 |       0.30 #> 0.00        |     -0.10 |       0.29 #> 0.00        |      0.20 |       0.28 #> 0.00        |      0.09 |       0.54 #> 0.00        |      0.20 |       0.66 #> 0.00        |      0.21 |       0.20 #> 0.00        |     -0.11 |       0.70 #> 0.00        |     -0.12 |       0.80 #> 0.00        |      0.33 |       0.25 #> 0.00        |     -0.18 |       0.54 #> 0.00        |      0.17 |       0.60 #> 0.00        |      0.05 |       0.64 #> 0.00        |      0.05 |       0.14 #> 0.00        |      0.20 |       0.64 #> 0.00        |      0.14 |       0.12 #> 0.00        |      0.03 |       0.27 #> 0.00        |      0.13 |       0.59 #> 0.00        |     -0.05 |       0.29 #> 0.00        |     -0.16 |       0.70 #> 0.00        |      0.10 |       0.30 #> 0.00        |      0.08 |       0.36 #> 0.00        |     -0.27 |       0.70 #> 0.00        |      0.26 |       0.23 #> 0.00        |      0.35 |  -6.63e-03 #> 0.00        |      0.47 |       0.29 #> 0.00        |     -0.07 |       0.62 #> 0.00        |      0.11 |       0.36 #> 0.00        |      0.09 |       0.45 #> 0.00        |      0.08 |       0.48 #> 0.00        |      0.07 |       0.73 #> 0.00        |      0.16 |       0.45 #> 0.00        |      0.09 |       0.28 #> 0.00        |      0.28 |       0.38 #> 0.00        |      0.36 |       0.80 #> 0.00        |      0.11 |       0.27 #> 0.00        |      0.02 |       0.65 #> 0.00        |     -0.33 |       0.40 #> 0.00        |     -0.18 |       0.57 #> 0.00        |     -0.10 |       0.44 #> 0.00        |      0.10 |       0.38 #> 0.00        |     -0.01 |       0.46 #> 0.00        |      0.08 |       0.33 #> 0.00        |     -0.10 |       0.45 #> 0.00        |      0.55 |       0.58 #> 0.00        |      0.37 |       0.38 #> 0.00        |     -0.20 |       0.53 #> 0.00        |     -0.25 |       0.68 #> 0.00        |      0.07 |       0.45 #> 0.00        |      0.13 |       0.48 #> 0.00        |      0.13 |       0.35 #> 0.00        |      0.10 |       0.41 #> 0.00        |      0.26 |       0.40 #> 0.00        |      0.08 |       0.39 #> 0.00        |      0.19 |       0.32 #> 0.00        |      0.27 |       0.44 #> 0.00        |      0.09 |       0.52 #> 0.00        |      0.19 |       0.41 #> 0.00        |     -0.34 |       0.59 #> 0.00        |     -0.19 |       0.64 #> 0.00        |      0.20 |       0.29 #> 0.00        |     -0.07 |       0.24 #> 0.00        |      0.16 |       0.32 #> 0.00        |      0.04 |       0.28 #> 0.00        |      0.12 |       0.49 #> 0.00        |      0.22 |       0.71 #> 0.00        |      0.07 |  -1.60e-03 #> 0.00        |      0.07 |       0.08 #> 0.00        |      0.17 |       0.28 #> 0.00        |      0.08 |       0.49 #> 0.00        |      0.08 |       0.51 #> 0.00        |      0.09 |       0.38 #> 0.00        |      0.05 |       0.44 #> 0.00        |      0.20 |       0.38 #> 0.00        |     -0.04 |       0.44 #> 0.00        |      0.51 |       0.30 #> 0.00        |      0.56 |       0.52 #> 0.00        |      0.09 |      -0.02 #> 0.00        |      0.04 |      -0.03 #> 0.00        |      0.31 |       0.77 #> 0.00        |     -0.05 |       0.21 #> 0.00        |      0.38 |       0.48 #> 0.00        |     -0.25 |       0.36 #> 0.00        |      0.07 |       0.26 #> 0.00        |      0.04 |       0.58 #> 0.00        |      0.14 |       0.40 #> 0.00        |      0.17 |       0.56 #> 0.00        | -5.53e-03 |       0.60 #> 0.00        |      0.20 |       0.22 #> 0.00        |      0.21 |       0.11 #> 0.00        |     -0.17 |       0.41 #> 0.00        |     -0.30 |       0.81 #> 0.00        |     -0.30 |       0.82 #> 0.00        |     -0.15 |       0.06 #> 0.00        |      0.36 |       0.69 #> 0.00        |      0.11 |       0.28 #> 0.00        |     -0.15 |       0.43 #> 0.00        |     -0.06 |       0.72 #> 0.00        |      0.14 |       0.13 #> 0.00        |      0.11 |       0.38 #> 0.00        |      0.30 |       0.44 #> 0.00        |     -0.17 |       0.22 #> 0.00        |      0.04 |       0.63 #> 0.00        |     -0.17 |       0.38 #> 0.00        |     -0.20 |       0.22 #> 0.00        |      0.60 |       0.45 #> 0.00        |      0.34 |       0.46 #> 0.00        |      0.27 |       0.64 #> 0.00        |      0.02 |       0.53 #> 0.00        |     -0.14 |       0.45 #> 0.00        |     -0.10 |       0.49 #> 0.00        |     -0.05 |       0.46 #> 0.00        |      0.40 |       0.28 #> 0.00        |      0.40 |       0.31 #> 0.00        |     -0.16 |       0.49 #> 0.00        |      0.14 |       0.40 #> 0.00        |     -0.08 |       0.45 #> 0.00        |      0.13 |       0.40 #> 0.00        |      0.03 |       0.58 #> 0.00        |      0.22 |       0.47 #> 0.00        |      0.11 |       0.43 #> 0.00        |      0.04 |       0.29 #> 0.00        |     -0.02 |       0.64 #> 0.00        |      0.40 |       0.15 #> 0.00        |      0.42 |       0.04 #> 0.00        |     -0.08 |       0.80 #> 0.00        |     -0.15 |       0.78 #> 0.00        |      0.24 |       0.13 #> 0.00        |      0.12 |       0.54 #> 0.00        |      0.06 |       0.43 #> 0.00        |      0.09 |       0.36 #> 0.00        |      0.35 |       0.44 #> 0.00        |      0.25 |       0.52 #> 0.00        |      0.49 |       0.32 #> 0.00        |     -0.15 |       0.49 #> 0.00        |      0.39 |       0.37 #> 0.00        |     -0.08 |      -0.01 #> 0.00        |      0.42 |       0.61 #> 0.00        |     -0.09 |       0.20 #> 0.00        |     -0.06 |       0.63 #> 0.00        |     -0.16 |       0.47 #> 0.00        |      0.41 |       0.32 #> 0.00        |      0.23 |       0.26 #> 0.00        |      0.02 |       0.44 #> 0.00        |      0.25 |       0.39 #> 0.00        |      0.15 |       0.34 #> 0.00        |      0.26 |       0.25 #> 0.00        |      0.08 |       0.79 #> 0.00        |     -0.32 |       0.62 #> 0.00        |     -0.40 |       0.64 #> 0.00        |      0.07 |       0.65 #> 0.00        |      0.51 |       0.31 #> 0.00        |      0.19 |       0.20 #> 0.00        |      0.22 |       0.60 #> 0.00        |      0.06 |       0.48 #> 0.00        |      0.50 |       0.25 #> 0.00        |      0.17 |       0.49 #> 0.00        |      0.14 |       0.35 #> 0.00        |      0.09 |       0.56 #> 0.00        |      0.10 |       0.64 #> 0.00        |     -0.11 |       0.30 #> 0.00        |      0.18 |       0.34 #> 0.00        |      0.02 |       0.35 #> 0.00        |      0.05 |       0.27 #> 0.00        |      0.35 |       0.38 #> 0.00        |     -0.03 |       0.61 #> 0.00        |      0.23 |       0.20 #> 0.00        |      0.29 |       0.19 #> 0.00        |     -0.16 |       0.62 #> 0.00        |      0.33 |       0.21 #> 0.00        |      0.36 |       0.23 #> 0.00        |      0.02 |       0.50 #> 0.00        |  1.70e-03 |       0.41 #> 0.00        |      0.19 |       0.43 #> 0.00        |      0.28 |       0.31 #> 0.00        |      0.03 |       0.34 #> 0.00        |     -0.06 |       0.39 #> 0.00        |      0.27 |       0.40 #> 0.00        |      0.23 |       0.36 #> 0.00        |      0.19 |       0.21 #> 0.00        |      0.31 |       0.15 #> 0.00        |      0.27 |       0.24 #> 0.00        |     -0.15 |       0.56 #> 0.00        |      0.12 |       0.62 #> 0.00        |      0.11 |       0.14 #> 0.00        |      0.24 |       0.30 #> 0.00        |      0.14 |       0.34 #> 0.00        |      0.07 |       0.48 #> 0.00        |      0.03 |       0.33 #> 0.00        |     -0.14 |       0.21 #> 0.00        |      0.19 |       0.40 #> 0.00        |     -0.04 |       0.33 #> 0.00        |     -0.16 |       0.57 #> 0.00        |      0.26 |       0.15 #> 0.00        |     -0.13 |       0.61 #> 0.00        |      0.38 |       0.19 #> 0.00        |      0.21 |       0.09 #> 0.00        | -7.93e-03 |       0.68 #> 0.00        |      0.10 |       0.65 #> 0.00        |      0.03 |       0.17 #> 0.00        |      0.19 |       0.18 #> 0.00        |      0.38 |       0.40 #> 0.00        |     -0.29 |       0.48 #> 0.00        |     -0.07 |       0.31 #> 0.00        |      0.12 |       0.61 #> 0.00        |      0.14 |       0.22 #> 0.00        |      0.10 |       0.31 #> 0.00        |      0.05 |       0.56 #> 0.00        |      0.14 |       0.13 #> 0.00        |      0.13 |       0.34 #> 0.00        |      0.18 |       0.38 #> 0.00        |     -0.02 |       0.46 #> 0.00        |     -0.03 |       0.28 #> 0.00        |     -0.14 |       0.46 #> 0.00        |      0.21 |       0.31 #> 0.00        |     -0.02 |       0.41 #> 0.00        |     -0.04 |       0.56 #> 0.00        |     -0.16 |       0.62 #> 0.00        |     -0.05 |       0.36 #> 0.00        |      0.14 |       0.41 #> 0.00        | -2.83e-03 |       0.39 #> 0.00        |      0.22 |       0.46 #> 0.00        |      0.25 |       0.16 #> 0.00        |      0.19 |  -3.10e-03 #> 0.00        |      0.09 |       0.43 #> 0.00        |      0.18 |       0.61 #> 0.00        |     -0.22 |       0.16 #> 0.00        |     -0.20 |       0.43 #> 0.00        |     -0.19 |       0.26 #> 0.00        |      0.34 |       0.53 #> 0.00        |     -0.29 |       0.22 #> 0.00        |     -0.06 |      -0.03 #> 0.00        |      0.23 |      -0.09 #> 0.00        |     -0.10 |       0.78 #> 0.00        |      0.15 |      -0.02 #> 0.00        |      0.14 |       0.17 #> 0.00        |      0.54 |       0.55 #> 0.00        |      0.55 |       0.38 #> 0.00        |      0.20 |       0.42 #> 0.00        |      0.28 |       0.35 #> 0.00        |  3.51e-03 |       0.35 #> 0.00        |      0.14 |       0.41 #> 0.00        |      0.04 |       0.36 #> 0.00        |     -0.09 |       0.29 #> 0.00        |      0.18 |       0.40 #> 0.00        |      0.08 |       0.47 #> 0.00        |      0.04 |       0.45 #> 0.00        |      0.18 |       0.39 #> 0.00        |      0.03 |       0.27 #> 0.00        |      0.20 |       0.34 #> 0.00        |     -0.02 |       0.43 #> 0.00        |     -0.05 |       0.41 #> 0.00        |      0.08 |       0.62 #> 0.00        |      0.07 |       0.08 #> 0.00        |      0.26 |       0.26 #> 0.00        |      0.35 |       0.19 #> 0.00        |      0.31 |       0.45 #> 0.00        |      0.02 |       0.67 #> 0.00        |      0.09 |       0.15 #> 0.00        |      0.13 |       0.63 #> 0.00        |     -0.04 |       0.45 #> 0.00        |      0.16 |       0.28 #> 0.00        |     -0.13 |       0.37 #> 0.00        |      0.30 |       0.36 #> 0.00        |     -0.14 |       0.47 #> 0.00        |      0.11 |       0.25 #> 0.00        |      0.02 |       0.59 #> 0.00        |      0.04 |       0.32 #> 0.00        |      0.05 |       0.65 #> 0.00        |      0.14 |       0.18 #> 0.00        |     -0.07 |       0.70 #> 0.00        |      0.06 |       0.40 #> 0.00        |      0.11 |       0.21 #> 0.00        |      0.08 |       0.39 #> 0.00        |      0.10 |       0.40 #> 0.00        |      0.14 |       0.49 #> 0.00        |      0.16 |       0.47 #> 0.00        |      0.12 |       0.77 #> 0.00        |      0.35 |       0.41 #> 0.00        |      0.25 |       0.54 #> 0.00        |     -0.07 |       0.40 #> 0.00        |      0.25 |       0.58 #> 0.00        |      0.18 |       0.46 #> 0.00        |      0.02 |       0.13 #> 0.00        |      0.04 |       0.22 #> 0.00        |      0.37 |       0.50 #> 0.00        |      0.20 |       0.24 #> 0.00        |      0.41 |       0.05 #> 0.00        |      0.25 |       0.64 #> 0.00        |     -0.01 |       0.08 #> 0.00        |      0.12 |       0.38 #> 0.00        |      0.32 |       0.35 #> 0.00        |      0.20 |       0.43 #> 0.00        |      0.12 |       0.26 #> 0.00        |      0.34 |       0.41 #> 0.00        |      0.06 |       0.35 #> 0.00        |      0.10 |       0.35 #> 0.00        |     -0.11 |       0.57 #> 0.00        |      0.03 |       0.55 #> 0.00        |      0.32 |       0.08 #> 0.00        |      0.18 |       0.16 #> 0.00        |     -0.37 |       0.91 #> 0.00        |      0.10 |      -0.11 #> 0.00        |      0.13 |       0.07 #> 0.00        |      0.29 |  -8.37e-03 #> 0.00        |      0.39 |       0.51 #> 0.00        |     -0.06 |       0.28 #> 0.00        |      0.28 |       0.50 #> 0.00        |      0.19 |       0.33 #> 0.00        |      0.22 |       0.25 #> 0.00        |     -0.07 |       0.51 #> 0.00        |      0.01 |       0.29 #> 0.00        |     -0.02 |       0.36 #> 0.00        |      0.18 |       0.40 #> 0.00        |      0.22 |       0.36 #> 0.00        |      0.09 |       0.42 #> 0.00        |      0.31 |       0.45 #> 0.00        |      0.28 |       0.45 #> 0.00        |      0.21 |       0.61 #> 0.00        |      0.38 |       0.54 #> 0.00        |      0.07 |       0.12 #> 0.00        |     -0.03 |       0.47 #> 0.00        |      0.02 |       0.49 #> 0.00        |     -0.12 |       0.28 #> 0.00        |      0.29 |       0.36 #> 0.00        |      0.34 |       0.34 #> 0.00        |      0.22 |       0.45 #> 0.00        |     -0.07 |       0.30 #> 0.00        |  8.13e-03 |       0.54 #> 0.00        |      0.02 |       0.63 #> 0.00        |      0.34 |       0.04 #> 0.00        |      0.26 |       0.36 #> 0.00        |      0.12 |       0.37 #> 0.00        |      0.15 |       0.39 #> 0.00        |      0.17 |       0.35 #> 0.00        |      0.02 |       0.25 #> 0.00        |      0.28 |       0.45 #> 0.00        |      0.30 |       0.44 #> 0.00        |     -0.09 |       0.44 #> 0.00        |      0.30 |       0.46 #> 0.00        |     -0.09 |       0.35 #> 0.00        |      0.14 |       0.41 #> 0.00        |     -0.08 |       0.54 #> 0.00        |     -0.03 |       0.38 #> 0.00        |      0.13 |       0.57 #> 0.00        |      0.04 |       0.30 #> 0.00        |     -0.02 |       0.49 #> 0.00        |      0.15 |       0.43 #> 0.00        |     -0.02 |       0.30 #> 0.00        |      0.35 |       0.72 #> 0.00        |     -0.05 |       0.49 #> 0.00        |      0.57 |       0.29 #> 0.00        |      0.41 |       0.36 #> 0.00        |      0.02 |       0.29 #> 0.00        |  2.98e-03 |       0.50 #> 0.00        |      0.05 |       0.67 #> 0.00        |      0.25 |       0.29 #> 0.00        |      0.30 |       0.75 #> 0.00        |  3.51e-03 |       0.43 #> 0.00        |      0.08 |       0.60 #> 0.00        |     -0.02 |       0.49 #> 0.00        |      0.12 |       0.36 #> 0.00        |      0.12 |       0.57 #> 0.00        |      0.06 |       0.30 #> 0.00        |      0.49 |       0.64 #> 0.00        |      0.16 |       0.28 #> 0.00        |     -0.08 |       0.37 #> 0.00        |      0.32 |       0.42 #> 0.00        |     -0.08 |       0.38 #> 0.00        |      0.12 |       0.50 #> 0.00        |      0.03 |       0.57 #> 0.00        |      0.15 |       0.27 #> 0.00        |      0.03 |       0.52 #> 0.00        |      0.20 |       0.15 #> 0.00        |      0.06 |       0.61 #> 0.00        | -9.31e-03 |       0.53 #> 0.00        |      0.15 |       0.62 #> 0.00        |      0.27 |       0.48 #> 0.00        |      0.27 |       0.53 #> 0.00        |      0.04 |       0.12 #> 0.00        |      0.23 |       0.70 #> 0.00        |     -0.06 |       0.41 #> 0.00        |      0.14 |       0.51 #> 0.00        |      0.08 |       0.39 #> 0.00        |      0.14 |       0.44 #> 0.00        |      0.01 |       0.12 #> 0.00        |     -0.02 |       0.80 #> 0.00        |     -0.05 |       0.67 #> 0.00        |      0.10 |       0.71 #> 0.00        |      0.03 |       0.34 #> 0.00        |      0.29 |       0.51 #> 0.00        |      0.20 |       0.02 #> 0.00        |      0.49 |       0.22 #> 0.00        |      0.26 |       0.26 #> 0.00        |      0.13 |       0.15 #> 0.00        |      0.05 |       0.63 #> 0.00        |      0.18 |       0.63 #> 0.00        |      0.22 |       0.63 #> 0.00        |  6.69e-03 |       0.21 #> 0.00        |     -0.06 |       0.32 #> 0.00        |     -0.25 |       0.76 #> 0.00        |      0.16 |       0.40 #> 0.00        |      0.15 |       0.52 #> 0.00        |      0.09 |       0.56 #> 0.00        |      0.01 |       0.12 #> 0.00        |     -0.28 |       0.36 #> 0.00        |     -0.17 |       0.36 #> 0.00        |      0.39 |       0.28 #> 0.00        |      0.34 |       0.20 #> 0.00        |      0.24 |       0.66 #> 0.00        |      0.10 |       0.29 #> 0.00        |      0.09 |       0.39 #> 0.00        |      0.12 |       0.25 #> 0.00        |  4.00e-03 |       0.43 #> 0.00        |      0.16 |       0.34 #> 0.00        |      0.01 |       0.50 #> 0.00        |     -0.11 |       0.31 #> 0.00        |      0.23 |       0.54 #> 0.00        |      0.17 |       0.54 #> 0.00        |      0.18 |       0.63 #> 0.00        |      0.13 |       0.44 #> 0.00        |  1.14e-03 |       0.40 #> 0.00        |      0.09 |       0.44 #> 0.00        |      0.12 |       0.10 #> 0.00        |      0.37 |       0.23 #> 0.00        |      0.14 |       0.45 #> 0.00        |     -0.11 |       0.41 #> 0.00        |      0.12 |       0.41 #> 0.00        |      0.06 |       0.37 #> 0.00        |     -0.09 |       0.40 #> 0.00        |      0.32 |       0.56 #> 0.00        |      0.34 |       0.32 #> 0.00        |      0.25 |       0.37 #> 0.00        |      0.19 |       0.47 #> 0.00        |      0.14 |       0.67 #> 0.00        |     -0.12 |       0.31 #> 0.00        |      0.35 |       0.41 #> 0.00        |     -0.04 |       0.31 #> 0.00        |      0.42 |       0.24 #> 0.00        |      0.39 |       0.25 #> 0.00        |     -0.07 |       0.49 #> 0.00        |      0.09 |       0.43 #> 0.00        |      0.02 |       0.22 #> 0.00        |      0.22 |       0.61 #> 0.00        |     -0.07 |       0.25 #> 0.00        |      0.13 |       0.36 #> 0.00        |      0.21 |       0.36 #> 0.00        |      0.14 |       0.39 #> 0.00        |      0.47 |       0.46 #> 0.00        |     -0.24 |       0.19 #> 0.00        |     -0.17 |       0.24 #> 0.00        |      0.17 |       0.74 #> 0.00        |  3.16e-03 |       0.07 #> 0.00        |      0.33 |       0.12 #> 0.00        |      0.33 |       0.06 #> 0.00        |      0.14 |       0.28 #> 0.00        |     -0.08 |       0.46 #> 0.00        |      0.21 |       0.31 #> 0.00        |      0.26 |       0.47 #> 0.00        |     -0.07 |       0.49 #> 0.00        |      0.24 |       0.46 #> 0.00        |     -0.12 |       0.32 #> 0.00        |      0.06 |       0.35 #> 0.00        |      0.17 |       0.69 #> 0.00        |      0.26 |       0.14 #> 0.00        |      0.26 |       0.28 #> 0.00        |      0.30 |       0.44 #> 0.00        |      0.52 |       0.55 #> 0.00        |     -0.12 |      -0.13 #> 0.00        |     -0.08 |       0.50 #> 0.00        |     -0.10 |       0.52 #> 0.00        |     -0.06 |       0.47 #> 0.00        |      0.37 |       0.41 #> 0.00        |     -0.02 |       0.25 #> 0.00        |      0.10 |       0.41 #> 0.00        |     -0.15 |       0.32 #> 0.00        |     -0.07 |       0.51 #> 0.00        |      0.17 |       0.47 #> 0.00        |      0.03 |       0.38 #> 0.00        |     -0.14 |       0.36 #> 0.00        |      0.13 |       0.47 #> 0.00        |     -0.07 |       0.33 #> 0.00        |      0.17 |       0.38 #> 0.00        |      0.09 |       0.41 #> 0.00        |     -0.12 |       0.43 #> 0.00        |      0.07 |       0.24 #> 0.00        |     -0.06 |       0.43 #> 0.00        |     -0.07 |       0.45 #> 0.00        |     -0.09 |       0.48 #> 0.00        |     -0.17 |       0.44 #> 0.00        |      0.33 |       0.24 #> 0.00        |      0.21 |       0.47 #> 0.00        |      0.11 |       0.29 #> 0.00        |     -0.08 |       0.56 #> 0.00        |      0.03 |       0.14 #> 0.00        |      0.12 |       0.72 #> 0.00        |      0.19 |       0.69 #> 0.00        |      0.13 |       0.14 #> 0.00        |      0.10 |       0.79 #> 0.00        |     -0.17 |       0.33 #> 0.00        |      0.16 |       0.45 #> 0.00        |     -0.12 |       0.59 #> 0.00        |      0.10 |       0.42 #> 0.00        |     -0.06 |       0.43 #> 0.00        |     -0.15 |       0.25 #> 0.00        |     -0.11 |       0.37 #> 0.00        |      0.37 |       0.32 #> 0.00        | -8.49e-03 |       0.32 #> 0.00        |     -0.09 |       0.41 #> 0.00        |      0.10 |       0.57 #> 0.00        |      0.27 |       0.85 #> 0.00        |      0.14 |       0.54 #> 0.00        |      0.08 |       0.29 #> 0.00        |     -0.08 |       0.58 #> 0.00        |      0.16 |       0.75 #> 0.00        |     -0.20 |       0.77 #> 0.00        |      0.20 |       0.56 #> 0.00        |     -0.03 |       0.23 #> 0.00        |      0.08 |       0.38 #> 0.00        |      0.10 |       0.43 #> 0.00        |     -0.05 |       0.39 #> 0.00        |      0.22 |       0.54 #> 0.00        |      0.05 |       0.26 #> 0.00        |      0.07 |       0.29 #> 0.00        | -7.81e-03 |       0.60 #> 0.00        |      0.33 |       0.47 #> 0.00        |      0.01 |       0.51 #> 0.00        |      0.05 |       0.49 #> 0.00        |      0.20 |       0.15 #> 0.00        |      0.18 |       0.50 #> 0.00        |      0.01 |       0.31 #> 0.00        |      0.04 |       0.37 #> 0.00        |      0.35 |       0.37 #> 0.00        |      0.09 |       0.25 #> 0.00        |      0.02 |       0.77 #> 0.00        |     -0.05 |       0.20 #> 0.00        |      0.32 |       0.72 #> 0.00        |     -0.16 |       0.30 #> 0.00        |     -0.11 |       0.72 #> 0.00        |     -0.02 |       0.61 #> 0.00        |     -0.06 |       0.18 #> 0.00        |      0.30 |       0.44 #> 0.00        |     -0.18 |       0.44 #> 0.00        |      0.07 |       0.76 #> 0.00        |      0.25 |       0.46 #> 0.00        |     -0.02 |       0.45 #> 0.00        |      0.25 |       0.40 #> 0.00        |      0.13 |       0.34 #> 0.00        |      0.17 |       0.55 #> 0.00        |     -0.18 |       0.27 #> 0.00        |      0.42 |       0.54 #> 0.00        |      0.19 |       0.57 #> 0.00        | -7.78e-03 |       0.21 #> 0.00        |      0.21 |       0.63 #> 0.00        |      0.37 |       0.22 #> 0.00        |     -0.13 |       0.58 #> 0.00        |      0.28 |       0.17 #> 0.00        |      0.32 |       0.28 #> 0.00        |     -0.18 |       0.64 #> 0.00        |      0.26 |       0.40 #> 0.00        |      0.40 |       0.61 #> 0.00        |      0.34 |       0.57 #> 0.00        |      0.24 |       0.49 #> 0.00        |      0.09 |       0.27 #> 0.00        |     -0.04 |       0.17 #> 0.00        | -1.46e-03 |       0.40 #> 0.00        |      0.21 |       0.38 #> 0.00        |     -0.03 |       0.39 #> 0.00        |      0.01 |       0.76 #> 0.00        | -6.93e-03 |       0.58 #> 0.00        |      0.10 |       0.37 #> 0.00        |      0.07 |       0.43 #> 0.00        |      0.04 |       0.44 #> 0.00        |      0.09 |       0.58 #> 0.00        |      0.12 |       0.27 #> 0.00        |      0.33 |       0.23 #> 0.00        |      0.21 |       0.36 #> 0.00        |      0.28 |       0.15 #> 0.00        |      0.12 |       0.68 #> 0.00        |      0.26 |       0.40 #> 0.00        |      0.21 |       0.19 #> 0.00        |      0.22 |       0.24 #> 0.00        | -4.58e-03 |       0.50 #> 0.00        |     -0.10 |       0.28 #> 0.00        |      0.33 |       0.67 #> 0.00        |      0.01 |       0.22 #> 0.00        |     -0.29 |       0.56 #> 0.00        |      0.16 |       0.29 #> 0.00        |      0.15 |       0.38 #> 0.00        |      0.09 |       0.65 #> 0.00        |     -0.32 |       0.38 #> 0.00        |     -0.20 |       0.43 #> 0.00        |      0.14 |       0.77 #> 0.00        |     -0.17 |       0.23 #> 0.00        |     -0.29 |       0.24 #> 0.00        |      0.36 |       0.60 #> 0.00        |     -0.27 |       0.31 #> 0.00        |      0.29 |       0.65 #> 0.00        |     -0.26 |       0.19 #> 0.00        |     -0.18 |       0.22 #> 0.00        |      0.43 |       0.57 #> 0.00        |      0.07 |       0.36 #> 0.00        |     -0.02 |       0.53 #> 0.00        |      0.18 |       0.30 #> 0.00        |     -0.07 |       0.48 #> 0.00        |      0.22 |       0.39 #> 0.00        |     -0.21 |       0.41 #> 0.00        |      0.12 |       0.42 #> 0.00        |      0.17 |       0.40 #> 0.00        |      0.20 |       0.27 #> 0.00        |      0.14 |       0.09 #> 0.00        |      0.17 |       0.55 #> 0.00        |      0.08 |       0.49 #> 0.00        |     -0.02 |       0.59 #> 0.00        |      0.02 |       0.64 #> 0.00        |     -0.42 |       0.37 #> 0.00        |     -0.47 |       0.34 #> 0.00        |      0.16 |       0.15 #> 0.00        |     -0.15 |       0.09 #> 0.00        |      0.15 |       0.57 #> 0.00        |      0.15 |       0.22 #> 0.00        | -2.94e-03 |       0.19 #> 0.00        |      0.32 |       0.57 #> 0.00        |     -0.09 |       0.22 #> 0.00        |      0.05 |       0.56 #> 0.00        |      0.06 |       0.02 #> 0.00        |      0.03 |       0.11 #> 0.00        |      0.31 |       0.49 #> 0.00        |      0.28 |       0.47 #> 0.00        |      0.26 |       0.45 #> 0.00        |      0.36 |       0.33 #> 0.00        |      0.33 |       0.40 #> 0.00        |      0.21 |       0.48 #> 0.00        |     -0.14 |       0.10 #> 0.00        |      0.24 |       0.58 #> 0.00        |      0.21 |       0.22 #> 0.00        |      0.13 |       0.31 #> 0.00        |      0.17 |       0.37 #> 0.00        |      0.19 |       0.50 #> 0.00        |      0.15 |       0.49 #> 0.00        |      0.20 |       0.50 #> 0.00        |      0.52 |       0.03 #> 0.00        |      0.17 |       0.38 #> 0.00        |      0.25 |       0.34 #> 0.00        |      0.06 |       0.52 #> 0.00        |      0.20 |       0.27 #> 0.00        |      0.41 |       0.67 #> 0.00        |     -0.30 |       0.01 #> 0.00        |     -0.18 |       0.07 #> 0.00        |      0.07 |       0.62 #> 0.00        |      0.09 |       0.41 #> 0.00        |      0.09 |       0.48 #> 0.00        |      0.07 |       0.44 #> 0.00        |      0.31 |       0.45 #> 0.00        |      0.03 |       0.26 #> 0.00        |      0.16 |       0.25 #> 0.00        |      0.12 |       0.48 #> 0.00        |      0.10 |       0.28 #> 0.00        |      0.37 |       0.41 #> 0.00        |      0.18 |       0.66 #> 0.00        |     -0.11 |       0.27 #> 0.00        |      0.26 |       0.44 #> 0.00        |      0.07 |       0.56 #> 0.00        |      0.17 |       0.26 #> 0.00        |      0.02 |       0.54 #> 0.00        |      0.02 |       0.28 #> 0.00        |      0.12 |       0.61 #> 0.00        |      0.16 |       0.28 #> 0.00        |      0.11 |       0.21 #> 0.00        |      0.12 |       0.14 #> 0.00        |      0.20 |       0.29 #> 0.00        |      0.09 |       0.53 #> 0.00        |      0.28 |       0.22 #> 0.00        |      0.03 |       0.54 #> 0.00        |      0.21 |       0.23 #> 0.00        |      0.03 |       0.34 #> 0.00        |      0.03 |       0.33 #> 0.00        |     -0.37 |       0.83 #> 0.00        |      0.27 |       0.10 #> 0.00        |      0.03 |       0.63 #> 0.00        |      0.14 |       0.15 #> 0.00        |      0.27 |       0.36 #> 0.00        |     -0.04 |       0.59 #> 0.00        |      0.12 |       0.27 #> 0.00        |      0.23 |       0.48 #> 0.00        |      0.05 |       0.30 #> 0.00        |      0.27 |       0.63 #> 0.00        |     -0.04 |       0.33 #> 0.00        |      0.22 |       0.43 #> 0.00        |      0.36 |       0.55 #> 0.00        |     -0.28 |       0.31 #> 0.00        |     -0.28 |       0.36 #> 0.00        |     -0.36 |       0.29 #> 0.00        |      0.03 |       0.40 #> 0.00        |      0.15 |       0.45 #> 0.00        |      0.07 |       0.03 #> 0.00        |     -0.20 |       0.80 #> 0.00        |      0.53 |       0.41 #> 0.00        |     -0.05 |       0.15 #> 0.00        |      0.18 |       0.60 #> 0.00        |      0.23 |       0.64 #> 0.00        |      0.52 |       0.98 #> 0.00        |      0.42 |       0.83 #> 0.00        |      0.49 |       0.27 #> 0.00        |      0.44 |       0.63 #> 0.00        |     -0.10 |       0.23 #> 0.00        |      0.03 |       0.51 #> 0.00        |      0.04 |       0.21 #> 0.00        |      0.30 |       0.53 #> 0.00        |     -0.13 |       0.80 #> 0.00        |      0.03 |       0.25 #> 0.00        |      0.06 |       0.09 #> 0.00        |      0.55 |       0.60 #> 0.00        |     -0.39 |       0.23 #> 0.00        |     -0.22 |       0.64 #> 0.00        |      0.45 |       0.15 #> 0.00        |      0.43 |       0.56 #> 0.00        |      0.45 |       0.38 #> 0.00        |      0.26 |       0.19 #> 0.00        |     -0.05 |       0.61 #> 0.00        |      0.33 |       0.31 #> 0.00        |     -0.06 |       0.43 #> 0.00        |      0.30 |       0.33 #> 0.00        |  6.35e-03 |       0.58 #> 0.00        |      0.11 |       0.35 #> 0.00        |      0.13 |       0.49 #> 0.00        |      0.16 |       0.21 #> 0.00        |      0.11 |       0.24 #> 0.00        |      0.34 |       0.50 #> 0.00        |      0.11 |       0.26 #> 0.00        |      0.13 |       0.65 #> 0.00        |     -0.05 |       0.38 #> 0.00        |     -0.21 |       0.76 #> 0.00        |      0.09 |  -5.23e-04 #> 0.00        | -9.35e-03 |       0.66 #> 0.00        |      0.15 |       0.20 #> 0.00        |      0.19 |       0.38 #> 0.00        |      0.22 |       0.51 #> 0.00        |     -0.01 |       0.35 #> 0.00        |      0.17 |       0.28 #> 0.00        |      0.21 |       0.26 #> 0.00        |     -0.03 |       0.36 #> 0.00        |      0.16 |       0.54 #> 0.00        |      0.05 |       0.32 #> 0.00        |      0.06 |       0.33 #> 0.00        |      0.05 |       0.54 #> 0.00        |      0.04 |       0.60 #> 0.00        |      0.23 |       0.33 #> 0.00        |      0.26 |       0.59 #> 0.00        |     -0.02 |       0.74 #> 0.00        |      0.11 |       0.19 #> 0.00        |      0.06 |       0.59 #> 0.00        | -6.56e-03 |       0.49 #> 0.00        |      0.08 |       0.65 #> 0.00        |     -0.03 |       0.61 #> 0.00        |      0.28 |       0.39 #> 0.00        |     -0.15 |       0.40 #> 0.00        |      0.40 |       0.47 #> 0.00        |      0.23 |       0.51 #> 0.00        |      0.20 |       0.47 #> 0.00        |      0.16 |       0.25 #> 0.00        |      0.28 |       0.28 #> 0.00        |      0.22 |       0.23 #> 0.00        |      0.03 |       0.67 #> 0.00        |     -0.09 |       0.59 #> 0.00        |     -0.09 |       0.70 #> 0.00        |      0.30 |       0.16 #> 0.00        |      0.33 |       0.56 #> 0.00        |      0.28 |       0.40 #> 0.00        |      0.26 |       0.20 #> 0.00        |      0.26 |       0.20 #> 0.00        |      0.33 |       0.38 #> 0.00        |      0.07 |       0.55 #> 0.00        |      0.19 |       0.27 #> 0.00        |     -0.05 |       0.57 #> 0.00        |      0.08 |       0.48 #> 0.00        |     -0.06 |       0.59 #> 0.00        |     -0.11 |       0.35 #> 0.00        |      0.17 |       0.51 #> 0.00        |      0.04 |       0.37 #> 0.00        |      0.31 |       0.34 #> 0.00        |      0.29 |       0.24 #> 0.00        |     -0.22 |       0.39 #> 0.00        |      0.16 |       0.53 #> 0.00        |      0.21 |       0.51 #> 0.00        |      0.26 |       0.44 #> 0.00        |      0.11 |       0.24 #> 0.00        |      0.14 |       0.60 #> 0.00        |      0.20 |       0.23 #> 0.00        |     -0.03 |       0.60 #> 0.00        |     -0.02 |       0.53 #> 0.00        |      0.07 |       0.34 #> 0.00        |     -0.12 |       0.31 #> 0.00        |     -0.17 |       0.23 #> 0.00        |     -0.09 |       0.31 #> 0.00        |      0.29 |       0.50 #> 0.00        |     -0.10 |       0.38 #> 0.00        |      0.08 |       0.46 #> 0.00        |      0.19 |       0.51 #> 0.00        |     -0.26 |       0.92 #> 0.00        |      0.42 |       0.18 #> 0.00        |      0.31 |       0.32 #> 0.00        |      0.30 |       0.19 #> 0.00        |      0.18 |       0.29 #> 0.00        |     -0.13 |       0.65 #> 0.00        |      0.06 |       0.62 #> 0.00        |      0.14 |       0.18 #> 0.00        |      0.06 |       0.35 #> 0.00        |      0.03 |       0.28 #> 0.00        |      0.30 |       0.54 #> 0.00        |      0.26 |       0.47 #> 0.00        |      0.34 |       0.35 #> 0.00        |      0.22 |       0.23 #> 0.00        |      0.29 |       0.08 #> 0.00        |      0.19 |       0.05 #> 0.00        |     -0.15 |       0.53 #> 0.00        |     -0.03 |       0.27 #> 0.00        |      0.22 |       0.63 #> 0.00        |      0.15 |       0.42 #> 0.00        |      0.07 |       0.42 #> 0.00        |      0.08 |       0.42 #> 0.00        | -3.94e-05 |       0.35 #> 0.00        |      0.38 |       0.41 #> 0.00        |      0.13 |       0.41 #> 0.00        |      0.41 |       0.48 #> 0.00        |     -0.10 |       0.39 #> 0.00        |     -0.05 |       0.38 #> 0.00        |      0.14 |       0.41 #> 0.00        |     -0.14 |       0.35 #> 0.00        |      0.29 |       0.07 #> 0.00        |      0.42 |       0.12 #> 0.00        |      0.29 |       0.27 #> 0.00        |  7.92e-03 |       0.67 #> 0.00        |      0.11 |       0.24 #> 0.00        |      0.09 |       0.56 #> 0.00        |      0.05 |       0.37 #> 0.00        |     -0.09 |       0.61 #> 0.00        |      0.27 |       0.35 #> 0.00        |      0.45 |       0.35 #> 0.00        |      0.09 |       0.43 #> 0.00        |      0.08 |       0.47 #> 0.00        |      0.30 |       0.12 #> 0.00        |     -0.23 |       0.59 #> 0.00        |      0.18 |       0.62 #> 0.00        |      0.55 |       0.61 #> 0.00        |      0.24 |       0.28 #> 0.00        |     -0.06 |       0.55 #> 0.00        |      0.08 |       0.41 #> 0.00        |     -0.06 |       0.34 #> 0.00        |      0.15 |       0.47 #> 0.00        |      0.28 |       0.47 #> 0.00        |     -0.18 |       0.27 #> 0.00        |      0.06 |       0.55 #> 0.00        |     -0.02 |       0.62 #> 0.00        |      0.07 |       0.42 #> 0.00        |      0.52 |       0.21 #> 0.00        |      0.46 |       0.21 #> 0.00        |      0.28 |       0.60 #> 0.00        |      0.03 |       0.18 #> 0.00        |      0.16 |       0.47 #> 0.00        |      0.27 |       0.22 #> 0.00        |     -0.11 |       0.58 #> 0.00        |      0.27 |       0.27 #> 0.00        |      0.18 |       0.38 #> 0.00        |      0.19 |       0.38 #> 0.00        |      0.16 |       0.68 #> 0.00        |     -0.13 |       0.12 #> 0.00        |     -0.07 |       0.21 #> 0.00        |      0.12 |       0.66 #> 0.00        |      0.03 |       0.08 #> 0.00        |      0.11 |       0.42 #> 0.00        |      0.11 |       0.44 #> 0.00        |     -0.10 |       0.46 #> 0.00        |     -0.04 |       0.69 #> 0.00        |      0.29 |       0.24 #> 0.00        |      0.34 |       0.19 #> 0.00        |     -0.08 |       0.67 #> 0.00        |     -0.23 |       0.61 #> 0.00        |     -0.19 |       0.51 #> 0.00        |     -0.04 |       0.69 #> 0.00        |     -0.06 |       0.52 #> 0.00        |      0.08 |       0.54 #> 0.00        |     -0.31 |       0.56 #> 0.00        |      0.28 |       0.25 #> 0.00        |      0.08 |       0.28 #> 0.00        |      0.22 |       0.28 #> 0.00        |      0.13 |       0.34 #> 0.00        |      0.17 |   9.50e-04 #> 0.00        |      0.26 |       0.71 #> 0.00        |      0.03 |       0.50 #> 0.00        |      0.25 |       0.57 #> 0.00        |      0.35 |       0.56 #> 0.00        |      0.02 |       0.83 #> 0.00        |      0.01 |       0.81 #> 0.00        |  6.17e-03 |       0.71 #> 0.00        |      0.13 |       0.09 #> 0.00        |      0.29 |       0.53 #> 0.00        |      0.22 |       0.10 #> 0.00        |     -0.12 |       0.75 #> 0.00        | -6.81e-03 |       0.35 #> 0.00        |      0.48 |       0.49 #> 0.00        |     -0.17 |       0.42 #> 0.00        |      0.02 |       0.47 #> 0.00        |      0.32 |       0.26 #> 0.00        |     -0.04 |       0.46 #> 0.00        |      0.02 |       0.48 #> 0.00        |      0.17 |       0.30 #> 0.00        |      0.11 |       0.35 #> 0.00        |      0.20 |       0.41 #> 0.00        |      0.06 |       0.47 #> 0.00        |      0.03 |       0.42 #> 0.00        |     -0.17 |       0.37 #> 0.00        |  6.32e-03 |       0.70 #> 0.00        |     -0.10 |       0.48 #> 0.00        |     -0.16 |       0.13 #> 0.00        |     -0.16 |       0.55 #> 0.00        |      0.21 |       0.25 #> 0.00        |      0.28 |       0.47 #> 0.00        |      0.34 |       0.40 #> 0.00        |      0.21 |       0.14 #> 0.00        |      0.29 |       0.45 #> 0.00        |     -0.08 |       0.46 #> 0.00        |      0.11 |       0.50 #> 0.00        |      0.04 |       0.23 #> 0.00        |      0.21 |       0.62 #> 0.00        |      0.29 |       0.53 #> 0.00        |     -0.10 |       0.20 #> 0.00        |      0.18 |       0.31 #> 0.00        |      0.24 |       0.55 #> 0.00        |     -0.05 |       0.33 #> 0.00        |      0.06 |       0.50 #> 0.00        |      0.03 |       0.55 #> 0.00        |      0.15 |       0.61 #> 0.00        |      0.11 |       0.27 #> 0.00        |      0.16 |       0.57 #> 0.00        |      0.11 |       0.23 #> 0.00        |      0.12 |       0.31 #> 0.00        |     -0.01 |       0.54 #> 0.00        |      0.27 |       0.27 #> 0.00        |     -0.06 |       0.55 #> 0.00        |     -0.07 |       0.42 #> 0.00        |      0.24 |       0.32 #> 0.00        |      0.09 |       0.61 #> 0.00        |      0.28 |       0.13 #> 0.00        |      0.05 |       0.31 #> 0.00        |      0.14 |       0.21 #> 0.00        |     -0.05 |       0.37 #> 0.00        |      0.26 |       0.55 #> 0.00        |      0.38 |       0.60 #> 0.00        |     -0.17 |       0.50 #> 0.00        |      0.04 |       0.52 #> 0.00        |      0.26 |       0.49 #> 0.00        |     -0.24 |       0.37 #> 0.00        |      0.60 |       0.28 #> 0.00        |     -0.32 |       0.55 #> 0.00        |     -0.25 |       0.40 #> 0.00        |     -0.18 |       0.40 #> 0.00        |      0.44 |       0.44 #> 0.00        |      0.12 |       0.38 #> 0.00        |      0.10 |       0.47 #> 0.00        |      0.03 |       0.66 #> 0.00        |      0.04 |       0.62 #> 0.00        |      0.14 |       0.23 #> 0.00        |     -0.08 |       0.69 #> 0.00        |     -0.14 |       0.67 #> 0.00        |     -0.13 |       0.70 #> 0.00        |      0.06 |       0.15 #> 0.00        |     -0.17 |       0.85 #> 0.00        |      0.07 |       0.68 #> 0.00        |      0.25 |       0.20 #> 0.00        |      0.21 |       0.23 #> 0.00        |     -0.04 |       0.42 #> 0.00        |      0.03 |       0.52 #> 0.00        |      0.12 |       0.37 #> 0.00        |     -0.06 |       0.43 #> 0.00        |      0.04 |       0.54 #> 0.00        |      0.07 |       0.33 #> 0.00        |      0.11 |       0.36 #> 0.00        |      0.10 |       0.52 #> 0.00        |      0.03 |       0.36 #> 0.00        |      0.09 |       0.59 #> 0.00        |     -0.39 |       0.59 #> 0.00        |      0.36 |       0.45 #> 0.00        |      0.17 |       0.32 #> 0.00        |      0.35 |       0.74 #> 0.00        |     -0.05 |       0.03 #> 0.00        |      0.15 |       0.26 #> 0.00        |      0.05 |       0.33 #> 0.00        |      0.37 |       0.43 #> 0.00        |     -0.24 |       0.57 #> 0.00        |      0.18 |       0.36 #> 0.00        |     -0.15 |       0.55 #> 0.00        |      0.37 |       0.22 #> 0.00        |      0.40 |       0.31 #> 0.00        |      0.36 |       0.30 #> 0.00        |     -0.08 |       0.50 #> 0.00        |      0.11 |       0.23 #> 0.00        |      0.06 |       0.45 #> 0.00        |      0.18 |       0.40 #> 0.00        |     -0.03 |       0.36 #> 0.00        |     -0.16 |       0.39 #> 0.00        |      0.20 |       0.27 #> 0.00        |     -0.13 |       0.31 #> 0.00        |      0.28 |       0.54 #> 0.00        |     -0.07 |       0.31 #> 0.00        |      0.27 |       0.52 #> 0.00        |      0.41 |       0.46 #> 0.00        |      0.13 |       0.19 #> 0.00        |      0.09 |       0.38 #> 0.00        |      0.19 |       0.58 #> 0.00        |      0.35 |      -0.08 #> 0.00        |      0.28 |       0.64 #> 0.00        | -9.05e-03 |       0.33 #> 0.00        |      0.07 |       0.40 #> 0.00        |      0.17 |       0.32 #> 0.00        |      0.13 |       0.52 #> 0.00        |     -0.14 |       0.50 #> 0.00        |      0.12 |       0.32 #> 0.00        |      0.12 |       0.32 #> 0.00        |      0.14 |       0.73 #> 0.00        |      0.15 |       0.48 #> 0.00        |      0.30 |       0.27 #> 0.00        |      0.11 |       0.44 #> 0.00        |      0.13 |       0.52 #> 0.00        |      0.21 |       0.22 #> 0.00        |      0.47 |       0.36 #> 0.00        |      0.61 |       0.53 #> 0.00        |      0.10 |       0.55 #> 0.00        |      0.38 |       0.17 #> 0.00        |     -0.19 |       0.57 #> 0.00        |      0.33 |       0.37 #> 0.00        |      0.30 |       0.28 #> 0.00        |      0.18 |       0.27 #> 0.00        |     -0.10 |       0.39 #> 0.00        |      0.22 |       0.38 #> 0.00        |      0.44 |       0.43 #> 0.00        |      0.17 |       0.52 #> 0.00        |      0.29 |       0.69 #> 0.00        |     -0.02 |       0.25 #> 0.00        |      0.20 |       0.51 #> 0.00        |      0.10 |       0.55 #> 0.00        |      0.05 |       0.35 #> 0.00        |     -0.10 |       0.81 #> 0.00        |     -0.07 |       0.41 #> 0.00        |      0.20 |       0.33 #> 0.00        |     -0.03 |       0.47 #> 0.00        |      0.14 |       0.31 #> 0.00        |      0.45 |       0.41 #> 0.00        |  3.28e-04 |       0.10 #> 0.00        |      0.16 |       0.58 #> 0.00        |      0.06 |       0.20 #> 0.00        |     -0.05 |       0.70 #> 0.00        |      0.26 |       0.35 #> 0.00        |      0.23 |       0.34 #> 0.00        |      0.06 |       0.42 #> 0.00        |     -0.12 |       0.69 #> 0.00        |      0.04 |       0.42 #> 0.00        |      0.25 |       0.38 standardize_posteriors(model, method = \"smart\", verbose = FALSE) #> # Standardization method: smart #>  #> (Intercept) |  critical | privileges #> ------------------------------------ #> 0.00        |      0.21 |       0.51 #> 0.00        |     -0.02 |       0.31 #> 0.00        |      0.07 |       0.33 #> 0.00        |     -0.03 |       0.13 #> 0.00        |     -0.03 |       0.23 #> 0.00        |     -0.08 |       0.34 #> 0.00        |      0.29 |       0.50 #> 0.00        |      0.48 |       0.32 #> 0.00        |      0.03 |       0.27 #> 0.00        |      0.18 |       0.51 #> 0.00        |      0.32 |       0.62 #> 0.00        |      0.27 |       0.45 #> 0.00        |      0.11 |       0.36 #> 0.00        |      0.14 |       0.51 #> 0.00        |      0.11 |       0.57 #> 0.00        |      0.20 |       0.06 #> 0.00        |      0.02 |       0.85 #> 0.00        |      0.20 |      -0.06 #> 0.00        | -6.82e-03 |       0.31 #> 0.00        | -3.25e-03 |  -7.31e-03 #> 0.00        |      0.13 |       0.77 #> 0.00        |      0.17 |       0.12 #> 0.00        |      0.06 |       0.69 #> 0.00        |     -0.03 |       0.50 #> 0.00        |     -0.03 |       0.54 #> 0.00        |      0.17 |       0.47 #> 0.00        |     -0.17 |       0.33 #> 0.00        |      0.10 |       0.22 #> 0.00        |     -0.12 |       0.25 #> 0.00        |     -0.03 |       0.27 #> 0.00        |      0.24 |       0.57 #> 0.00        |      0.24 |       0.18 #> 0.00        |      0.05 |       0.53 #> 0.00        |      0.31 |       0.43 #> 0.00        |      0.05 |       0.39 #> 0.00        |      0.06 |       0.49 #> 0.00        |      0.17 |       0.58 #> 0.00        |      0.02 |       0.24 #> 0.00        |      0.14 |       0.59 #> 0.00        |     -0.03 |       0.23 #> 0.00        |      0.07 |       0.40 #> 0.00        | -5.86e-03 |       0.42 #> 0.00        |      0.26 |       0.49 #> 0.00        |      0.72 |       0.32 #> 0.00        |     -0.11 |       0.59 #> 0.00        |      0.08 |       0.58 #> 0.00        |      0.28 |       0.24 #> 0.00        |     -0.07 |       0.52 #> 0.00        |      0.14 |       0.21 #> 0.00        |  3.11e-03 |       0.10 #> 0.00        |      0.36 |       0.61 #> 0.00        |     -0.36 |       0.55 #> 0.00        |     -0.33 |       0.56 #> 0.00        |      0.27 |       0.32 #> 0.00        |      0.34 |       0.50 #> 0.00        |     -0.10 |       0.26 #> 0.00        |     -0.08 |       0.31 #> 0.00        |      0.15 |       0.35 #> 0.00        |     -0.14 |       0.31 #> 0.00        |      0.09 |       0.28 #> 0.00        |     -0.21 |       0.27 #> 0.00        |      0.26 |       0.77 #> 0.00        |     -0.04 |       0.07 #> 0.00        |      0.18 |       0.27 #> 0.00        |     -0.10 |       0.55 #> 0.00        |      0.30 |       0.39 #> 0.00        |      0.22 |       0.64 #> 0.00        |      0.21 |       0.14 #> 0.00        |      0.16 |       0.29 #> 0.00        |      0.13 |       0.33 #> 0.00        |      0.16 |       0.34 #> 0.00        |      0.27 |       0.35 #> 0.00        |      0.10 |       0.30 #> 0.00        |      0.28 |       0.36 #> 0.00        |      0.15 |       0.32 #> 0.00        |     -0.27 |       0.73 #> 0.00        |     -0.15 |       0.63 #> 0.00        |  8.94e-03 |       0.53 #> 0.00        |      0.28 |       0.20 #> 0.00        |      0.09 |       0.64 #> 0.00        |      0.08 |       0.36 #> 0.00        |      0.09 |       0.55 #> 0.00        |      0.23 |       0.49 #> 0.00        |      0.25 |       0.18 #> 0.00        |     -0.12 |       0.72 #> 0.00        |      0.45 |       0.30 #> 0.00        |     -0.23 |       0.44 #> 0.00        |      0.40 |       0.35 #> 0.00        |      0.21 |       0.53 #> 0.00        |      0.14 |       0.40 #> 0.00        |     -0.04 |       0.41 #> 0.00        |     -0.10 |       0.46 #> 0.00        |     -0.36 |       0.47 #> 0.00        |     -0.35 |       0.53 #> 0.00        |     -0.32 |       0.45 #> 0.00        |      0.04 |       0.40 #> 0.00        |      0.10 |       0.21 #> 0.00        |      0.33 |       0.63 #> 0.00        |      0.19 |       0.49 #> 0.00        |     -0.13 |       0.50 #> 0.00        |      0.32 |       0.33 #> 0.00        |      0.15 |       0.30 #> 0.00        |     -0.06 |       0.30 #> 0.00        |     -0.06 |       0.72 #> 0.00        |      0.34 |   4.23e-03 #> 0.00        |      0.16 |       0.04 #> 0.00        |      0.21 |       0.56 #> 0.00        |     -0.01 |       0.16 #> 0.00        |      0.26 |       0.60 #> 0.00        |     -0.13 |       0.59 #> 0.00        |      0.35 |       0.32 #> 0.00        |     -0.05 |       0.46 #> 0.00        |      0.11 |       0.25 #> 0.00        |      0.23 |       0.47 #> 0.00        |     -0.05 |       0.31 #> 0.00        |      0.19 |       0.51 #> 0.00        |     -0.10 |       0.44 #> 0.00        |  5.61e-03 |       0.23 #> 0.00        |      0.25 |       0.41 #> 0.00        |      0.50 |       0.15 #> 0.00        |      0.53 |       0.40 #> 0.00        |      0.18 |       0.33 #> 0.00        |      0.21 |       0.32 #> 0.00        |     -0.02 |       0.49 #> 0.00        |      0.11 |       0.46 #> 0.00        |      0.24 |       0.54 #> 0.00        |      0.22 |       0.16 #> 0.00        |      0.02 |       0.66 #> 0.00        |     -0.18 |       0.56 #> 0.00        |      0.12 |       0.44 #> 0.00        |      0.01 |       0.31 #> 0.00        |      0.36 |       0.35 #> 0.00        |      0.12 |       0.40 #> 0.00        |      0.28 |       0.38 #> 0.00        |     -0.10 |       0.51 #> 0.00        |     -0.03 |       0.46 #> 0.00        |      0.09 |       0.60 #> 0.00        |     -0.05 |       0.22 #> 0.00        |      0.23 |       0.46 #> 0.00        |     -0.01 |       0.31 #> 0.00        |      0.14 |       0.72 #> 0.00        |      0.06 |       0.45 #> 0.00        |      0.28 |       0.16 #> 0.00        |     -0.21 |       0.49 #> 0.00        |      0.02 |       0.25 #> 0.00        |     -0.13 |       0.61 #> 0.00        |      0.10 |       0.16 #> 0.00        |      0.05 |       0.12 #> 0.00        |      0.39 |       0.48 #> 0.00        |      0.41 |       0.29 #> 0.00        |      0.16 |       0.54 #> 0.00        |     -0.21 |       0.47 #> 0.00        |      0.15 |       0.81 #> 0.00        |      0.03 |  -7.31e-04 #> 0.00        |      0.27 |       0.65 #> 0.00        |      0.11 |       0.68 #> 0.00        |      0.36 |       0.73 #> 0.00        |     -0.17 |       0.43 #> 0.00        |      0.33 |       0.26 #> 0.00        |      0.19 |       0.41 #> 0.00        |      0.02 |       0.39 #> 0.00        |      0.19 |       0.38 #> 0.00        |      0.14 |       0.31 #> 0.00        |      0.09 |       0.49 #> 0.00        | -3.93e-03 |       0.16 #> 0.00        |      0.03 |       0.60 #> 0.00        |      0.05 |       0.49 #> 0.00        |      0.16 |       0.08 #> 0.00        |      0.16 |       0.48 #> 0.00        |      0.10 |       0.35 #> 0.00        |      0.16 |       0.22 #> 0.00        |  9.23e-03 |       0.61 #> 0.00        |      0.27 |       0.54 #> 0.00        |      0.07 |       0.42 #> 0.00        |     -0.03 |       0.45 #> 0.00        |      0.08 |       0.61 #> 0.00        |      0.14 |       0.38 #> 0.00        |      0.28 |       0.60 #> 0.00        |      0.36 |       0.56 #> 0.00        |      0.09 |       0.25 #> 0.00        | -2.72e-03 |       0.61 #> 0.00        |     -0.04 |       0.35 #> 0.00        |      0.20 |       0.41 #> 0.00        |      0.03 |       0.28 #> 0.00        |      0.21 |       0.49 #> 0.00        |      0.13 |       0.21 #> 0.00        |      0.11 |       0.47 #> 0.00        |      0.07 |       0.29 #> 0.00        |      0.28 |       0.29 #> 0.00        |      0.22 |       0.58 #> 0.00        |      0.10 |       0.51 #> 0.00        |      0.12 |       0.22 #> 0.00        |      0.26 |       0.35 #> 0.00        |     -0.01 |       0.48 #> 0.00        |     -0.12 |       0.36 #> 0.00        |      0.25 |       0.33 #> 0.00        |      0.19 |       0.35 #> 0.00        |     -0.06 |       0.53 #> 0.00        |      0.06 |       0.36 #> 0.00        |      0.34 |       0.34 #> 0.00        |      0.13 |      -0.04 #> 0.00        |     -0.29 |       0.39 #> 0.00        |      0.46 |       0.44 #> 0.00        |      0.21 |       0.30 #> 0.00        |      0.25 |       0.12 #> 0.00        |     -0.13 |       0.21 #> 0.00        |      0.22 |       0.51 #> 0.00        |      0.12 |       0.45 #> 0.00        |     -0.02 |       0.23 #> 0.00        |      0.02 |       0.24 #> 0.00        |     -0.24 |       0.49 #> 0.00        |     -0.04 |       0.39 #> 0.00        |      0.05 |       0.28 #> 0.00        |      0.11 |       0.53 #> 0.00        |     -0.13 |       0.32 #> 0.00        |     -0.14 |       0.63 #> 0.00        |     -0.25 |       0.66 #> 0.00        |     -0.09 |       0.68 #> 0.00        |      0.40 |       0.16 #> 0.00        |      0.35 |       0.32 #> 0.00        |     -0.22 |       0.49 #> 0.00        |      0.20 |       0.36 #> 0.00        |     -0.05 |       0.43 #> 0.00        |      0.24 |       0.73 #> 0.00        |      0.13 |       0.82 #> 0.00        |      0.17 |       0.04 #> 0.00        |      0.25 |       0.65 #> 0.00        |      0.14 |       0.50 #> 0.00        |      0.23 |       0.52 #> 0.00        |     -0.05 |       0.26 #> 0.00        |      0.27 |       0.65 #> 0.00        |     -0.16 |       0.55 #> 0.00        |      0.30 |       0.30 #> 0.00        |     -0.22 |       0.67 #> 0.00        |     -0.06 |       0.36 #> 0.00        |      0.15 |       0.33 #> 0.00        |      0.06 |       0.50 #> 0.00        |      0.15 |       0.30 #> 0.00        |      0.17 |       0.44 #> 0.00        |      0.15 |       0.36 #> 0.00        |  9.67e-03 |       0.48 #> 0.00        |      0.11 |       0.41 #> 0.00        |      0.12 |       0.38 #> 0.00        |      0.01 |       0.50 #> 0.00        |      0.16 |       0.35 #> 0.00        |      0.20 |       0.20 #> 0.00        |      0.21 |       0.58 #> 0.00        |     -0.03 |       0.51 #> 0.00        |      0.25 |       0.15 #> 0.00        |     -0.11 |       0.71 #> 0.00        |      0.21 |       0.15 #> 0.00        |      0.05 |       0.62 #> 0.00        |      0.07 |       0.10 #> 0.00        |     -0.18 |       0.82 #> 0.00        |     -0.04 |       0.51 #> 0.00        |      0.31 |       0.10 #> 0.00        |      0.07 |       0.42 #> 0.00        |      0.18 |       0.30 #> 0.00        |      0.25 |       0.36 #> 0.00        |     -0.06 |       0.47 #> 0.00        |      0.29 |       0.40 #> 0.00        |      0.19 |       0.40 #> 0.00        |      0.25 |       0.56 #> 0.00        |      0.24 |       0.49 #> 0.00        | -3.16e-03 |       0.23 #> 0.00        |      0.11 |       0.55 #> 0.00        |      0.11 |       0.44 #> 0.00        |      0.10 |       0.35 #> 0.00        |      0.15 |       0.47 #> 0.00        |      0.14 |       0.33 #> 0.00        |      0.05 |       0.49 #> 0.00        |      0.17 |       0.37 #> 0.00        |      0.30 |       0.19 #> 0.00        |      0.08 |       0.65 #> 0.00        |      0.14 |       0.47 #> 0.00        |      0.04 |       0.23 #> 0.00        |     -0.01 |       0.62 #> 0.00        |      0.05 |       0.12 #> 0.00        |      0.03 |       0.07 #> 0.00        |     -0.30 |       0.52 #> 0.00        |     -0.14 |       0.60 #> 0.00        |      0.36 |       0.20 #> 0.00        |      0.31 |       0.17 #> 0.00        |     -0.08 |       0.45 #> 0.00        |      0.24 |       0.38 #> 0.00        |      0.20 |       0.29 #> 0.00        |      0.31 |       0.80 #> 0.00        |     -0.04 |       0.71 #> 0.00        |      0.12 |       0.66 #> 0.00        |      0.02 |       0.23 #> 0.00        |      0.01 |       0.25 #> 0.00        |      0.14 |       0.28 #> 0.00        |      0.11 |       0.17 #> 0.00        |      0.22 |       0.36 #> 0.00        |      0.56 |       0.35 #> 0.00        |     -0.49 |       0.67 #> 0.00        |      0.09 |       0.65 #> 0.00        |      0.07 |       0.80 #> 0.00        |      0.23 |       0.24 #> 0.00        |      0.02 |       0.58 #> 0.00        |      0.13 |       0.67 #> 0.00        |      0.13 |       0.53 #> 0.00        |     -0.03 |       0.38 #> 0.00        |      0.12 |       0.40 #> 0.00        | -1.53e-03 |       0.23 #> 0.00        |  5.49e-03 |       0.47 #> 0.00        |     -0.09 |       0.52 #> 0.00        |      0.09 |       0.51 #> 0.00        |      0.03 |       0.18 #> 0.00        |      0.06 |       0.65 #> 0.00        |     -0.21 |       0.27 #> 0.00        |     -0.20 |       0.14 #> 0.00        |      0.45 |       0.67 #> 0.00        |      0.17 |       0.52 #> 0.00        |      0.06 |       0.76 #> 0.00        |      0.10 |       0.18 #> 0.00        |      0.44 |       0.44 #> 0.00        |     -0.31 |       0.41 #> 0.00        |     -0.32 |       0.49 #> 0.00        |     -0.12 |       0.29 #> 0.00        |      0.49 |       0.37 #> 0.00        |     -0.27 |       0.45 #> 0.00        |     -0.16 |       0.67 #> 0.00        |      0.19 |       0.25 #> 0.00        |     -0.02 |       0.59 #> 0.00        |      0.22 |       0.42 #> 0.00        |      0.17 |       0.49 #> 0.00        |      0.05 |       0.25 #> 0.00        |      0.29 |       0.42 #> 0.00        |     -0.13 |       0.55 #> 0.00        |     -0.33 |       0.27 #> 0.00        |     -0.27 |       0.21 #> 0.00        |      0.35 |       0.40 #> 0.00        |      0.38 |       0.21 #> 0.00        |      0.11 |       0.36 #> 0.00        |     -0.01 |       0.55 #> 0.00        | -8.06e-03 |       0.05 #> 0.00        |      0.16 |       0.28 #> 0.00        |      0.21 |       0.45 #> 0.00        |      0.05 |       0.17 #> 0.00        |      0.10 |       0.75 #> 0.00        |      0.04 |       0.79 #> 0.00        |      0.23 |       0.07 #> 0.00        |      0.18 |       0.54 #> 0.00        |     -0.06 |       0.29 #> 0.00        |      0.04 |       0.64 #> 0.00        |      0.17 |       0.52 #> 0.00        |      0.05 |       0.35 #> 0.00        |      0.07 |       0.51 #> 0.00        |      0.01 |       0.20 #> 0.00        |      0.03 |       0.13 #> 0.00        |     -0.11 |       0.12 #> 0.00        |      0.69 |       0.54 #> 0.00        |      0.25 |       0.77 #> 0.00        |     -0.06 |       0.20 #> 0.00        |     -0.08 |       0.29 #> 0.00        |     -0.14 |       0.44 #> 0.00        |     -0.05 |       0.16 #> 0.00        |     -0.09 |       0.36 #> 0.00        |     -0.18 |       0.49 #> 0.00        |      0.27 |       0.49 #> 0.00        |      0.13 |       0.70 #> 0.00        |      0.15 |       0.88 #> 0.00        |      0.12 |       0.90 #> 0.00        |      0.17 |       0.30 #> 0.00        |     -0.09 |       0.51 #> 0.00        |      0.11 |       0.46 #> 0.00        |      0.17 |       0.47 #> 0.00        |      0.04 |       0.38 #> 0.00        | -2.52e-03 |       0.35 #> 0.00        |      0.29 |       0.18 #> 0.00        |      0.66 |       0.19 #> 0.00        |      0.21 |       0.20 #> 0.00        |      0.22 |       0.28 #> 0.00        |     -0.20 |       0.39 #> 0.00        |      0.11 |       0.45 #> 0.00        |     -0.20 |       0.43 #> 0.00        |      0.16 |       0.29 #> 0.00        |     -0.15 |       0.44 #> 0.00        |      0.12 |       0.31 #> 0.00        |     -0.03 |       0.59 #> 0.00        |      0.32 |       0.29 #> 0.00        |     -0.09 |       0.52 #> 0.00        |      0.10 |       0.33 #> 0.00        |      0.13 |       0.38 #> 0.00        |      0.37 |       0.11 #> 0.00        |     -0.28 |       0.67 #> 0.00        |      0.48 |       0.21 #> 0.00        |      0.45 |       0.18 #> 0.00        |     -0.21 |       0.58 #> 0.00        |      0.26 |       0.17 #> 0.00        |     -0.10 |       0.76 #> 0.00        |      0.29 |       0.19 #> 0.00        |     -0.11 |       0.66 #> 0.00        |      0.25 |       0.12 #> 0.00        |     -0.16 |       0.66 #> 0.00        |     -0.21 |       0.52 #> 0.00        |      0.20 |       0.50 #> 0.00        |      0.09 |       0.32 #> 0.00        |     -0.08 |       0.47 #> 0.00        |      0.08 |       0.26 #> 0.00        |     -0.21 |       0.23 #> 0.00        |      0.29 |       0.51 #> 0.00        |      0.15 |       0.75 #> 0.00        |     -0.09 |       0.31 #> 0.00        |      0.08 |       0.71 #> 0.00        |      0.07 |       0.80 #> 0.00        |      0.39 |       0.08 #> 0.00        |      0.43 |       0.17 #> 0.00        |     -0.19 |       0.39 #> 0.00        |      0.23 |       0.33 #> 0.00        |      0.11 |       0.40 #> 0.00        |      0.16 |       0.42 #> 0.00        |      0.06 |       0.59 #> 0.00        |      0.24 |       0.72 #> 0.00        |     -0.02 |       0.31 #> 0.00        |      0.10 |       0.52 #> 0.00        |      0.18 |       0.39 #> 0.00        |      0.20 |       0.55 #> 0.00        |      0.35 |       0.64 #> 0.00        |     -0.04 |       0.35 #> 0.00        |      0.16 |       0.54 #> 0.00        |      0.06 |       0.68 #> 0.00        |     -0.05 |       0.26 #> 0.00        |      0.27 |       0.57 #> 0.00        |     -0.10 |       0.43 #> 0.00        |      0.34 |       0.34 #> 0.00        |      0.33 |       0.02 #> 0.00        |     -0.31 |       0.72 #> 0.00        |      0.49 |       0.16 #> 0.00        |     -0.10 |       0.87 #> 0.00        |      0.02 |       0.13 #> 0.00        |      0.32 |       0.36 #> 0.00        |      0.02 |       0.23 #> 0.00        |      0.05 |       0.20 #> 0.00        |     -0.09 |       0.51 #> 0.00        |      0.36 |       0.34 #> 0.00        |      0.18 |       0.40 #> 0.00        |      0.31 |       0.30 #> 0.00        |     -0.18 |       0.60 #> 0.00        |      0.26 |       0.31 #> 0.00        |      0.26 |       0.45 #> 0.00        |      0.12 |       0.32 #> 0.00        |     -0.06 |       0.33 #> 0.00        |     -0.05 |       0.49 #> 0.00        |     -0.16 |       0.28 #> 0.00        |      0.06 |       0.42 #> 0.00        |      0.47 |       0.39 #> 0.00        |      0.05 |       0.32 #> 0.00        |      0.15 |       0.47 #> 0.00        |      0.03 |       0.45 #> 0.00        |      0.27 |       0.17 #> 0.00        |      0.02 |       0.67 #> 0.00        |      0.24 |       0.20 #> 0.00        |     -0.08 |       0.83 #> 0.00        |     -0.21 |       0.52 #> 0.00        |     -0.23 |       0.69 #> 0.00        |     -0.07 |       0.65 #> 0.00        |      0.31 |       0.10 #> 0.00        |      0.06 |       0.28 #> 0.00        |      0.11 |       0.26 #> 0.00        |     -0.09 |       0.75 #> 0.00        |      0.41 |       0.09 #> 0.00        |      0.08 |       0.17 #> 0.00        |      0.24 |       0.48 #> 0.00        |      0.06 |      -0.15 #> 0.00        |      0.16 |       0.02 #> 0.00        |     -0.16 |      -0.02 #> 0.00        |     -0.09 |       0.21 #> 0.00        |      0.15 |       0.41 #> 0.00        |      0.01 |       0.48 #> 0.00        |      0.42 |       0.41 #> 0.00        |      0.78 |       0.42 #> 0.00        |     -0.13 |       0.75 #> 0.00        |      0.21 |       0.11 #> 0.00        |     -0.02 |       0.74 #> 0.00        |     -0.05 |       0.57 #> 0.00        |      0.12 |       0.47 #> 0.00        |      0.27 |       0.44 #> 0.00        |     -0.16 |       0.38 #> 0.00        |      0.27 |       0.48 #> 0.00        |      0.11 |       0.51 #> 0.00        |     -0.12 |       0.19 #> 0.00        |     -0.05 |       0.37 #> 0.00        |      0.16 |       0.40 #> 0.00        |      0.09 |       0.49 #> 0.00        |      0.05 |       0.36 #> 0.00        |      0.16 |       0.61 #> 0.00        |      0.14 |       0.69 #> 0.00        |     -0.05 |       0.38 #> 0.00        |      0.14 |       0.64 #> 0.00        |      0.07 |       0.33 #> 0.00        |      0.14 |       0.49 #> 0.00        |      0.28 |       0.34 #> 0.00        |     -0.11 |       0.22 #> 0.00        |      0.20 |       0.68 #> 0.00        |      0.12 |       0.52 #> 0.00        |      0.10 |       0.35 #> 0.00        |     -0.06 |       0.49 #> 0.00        |  6.66e-03 |       0.28 #> 0.00        |  1.14e-03 |       0.23 #> 0.00        |      0.14 |       0.33 #> 0.00        |      0.12 |       0.54 #> 0.00        |      0.29 |       0.24 #> 0.00        |     -0.05 |       0.53 #> 0.00        |     -0.26 |       0.50 #> 0.00        |     -0.19 |       0.54 #> 0.00        |      0.33 |       0.23 #> 0.00        |     -0.02 |       0.65 #> 0.00        |      0.09 |       0.69 #> 0.00        |      0.03 |       0.18 #> 0.00        |      0.10 |       0.35 #> 0.00        |      0.10 |       0.49 #> 0.00        |      0.14 |       0.13 #> 0.00        |     -0.03 |       0.70 #> 0.00        |      0.03 |       0.63 #> 0.00        |     -0.08 |       0.63 #> 0.00        |      0.17 |       0.24 #> 0.00        |      0.11 |       0.48 #> 0.00        |      0.49 |       0.45 #> 0.00        |      0.29 |       0.51 #> 0.00        |      0.24 |       0.44 #> 0.00        |      0.44 |       0.46 #> 0.00        |      0.48 |       0.54 #> 0.00        |      0.31 |       0.23 #> 0.00        |     -0.09 |       0.66 #> 0.00        |      0.12 |       0.44 #> 0.00        |     -0.05 |       0.24 #> 0.00        |      0.05 |       0.34 #> 0.00        |      0.10 |       0.21 #> 0.00        |      0.19 |       0.60 #> 0.00        |      0.18 |       0.59 #> 0.00        |      0.17 |       0.50 #> 0.00        |      0.08 |       0.68 #> 0.00        |      0.12 |      -0.04 #> 0.00        |     -0.27 |       0.24 #> 0.00        |      0.55 |       0.60 #> 0.00        |      0.04 |       0.39 #> 0.00        |      0.19 |       0.08 #> 0.00        |     -0.06 |       0.83 #> 0.00        |      0.28 |       0.43 #> 0.00        |     -0.10 |       0.27 #> 0.00        |  4.93e-03 |       0.29 #> 0.00        |     -0.08 |       0.06 #> 0.00        |     -0.08 |       0.42 #> 0.00        |      0.06 |       0.52 #> 0.00        |      0.13 |       0.30 #> 0.00        |      0.09 |       0.26 #> 0.00        |      0.16 |       0.50 #> 0.00        |      0.05 |       0.42 #> 0.00        |      0.26 |       0.40 #> 0.00        |      0.12 |       0.49 #> 0.00        |      0.20 |       0.57 #> 0.00        |      0.05 |       0.52 #> 0.00        |     -0.18 |       0.42 #> 0.00        |      0.35 |       0.42 #> 0.00        |     -0.21 |       0.44 #> 0.00        |      0.29 |       0.45 #> 0.00        |     -0.04 |       0.27 #> 0.00        |      0.27 |       0.56 #> 0.00        |      0.28 |       0.57 #> 0.00        |      0.04 |       0.29 #> 0.00        |     -0.08 |       0.46 #> 0.00        |     -0.08 |       0.44 #> 0.00        |      0.22 |       0.43 #> 0.00        |     -0.01 |       0.12 #> 0.00        |      0.39 |       0.15 #> 0.00        |      0.13 |       0.69 #> 0.00        |      0.08 |       0.24 #> 0.00        |      0.03 |       0.37 #> 0.00        |  7.34e-03 |       0.26 #> 0.00        |      0.06 |       0.28 #> 0.00        |  1.24e-03 |       0.29 #> 0.00        |      0.07 |       0.39 #> 0.00        |      0.16 |       0.48 #> 0.00        |      0.17 |       0.62 #> 0.00        |     -0.05 |       0.29 #> 0.00        |      0.21 |       0.52 #> 0.00        |      0.02 |       0.49 #> 0.00        |      0.37 |       0.43 #> 0.00        |      0.17 |       0.43 #> 0.00        |      0.17 |       0.36 #> 0.00        |      0.35 |       0.51 #> 0.00        |      0.12 |       0.47 #> 0.00        |     -0.02 |       0.55 #> 0.00        |      0.29 |       0.37 #> 0.00        |     -0.10 |       0.68 #> 0.00        |      0.06 |       0.25 #> 0.00        |      0.03 |       0.35 #> 0.00        |      0.36 |       0.49 #> 0.00        |     -0.22 |       0.33 #> 0.00        |      0.10 |       0.49 #> 0.00        |      0.21 |       0.43 #> 0.00        |      0.49 |       0.40 #> 0.00        |      0.30 |       0.36 #> 0.00        |     -0.06 |       0.54 #> 0.00        |      0.19 |       0.28 #> 0.00        |      0.02 |       0.45 #> 0.00        |      0.12 |       0.43 #> 0.00        |      0.11 |       0.40 #> 0.00        |      0.04 |       0.48 #> 0.00        |     -0.09 |       0.52 #> 0.00        |     -0.08 |       0.43 #> 0.00        |      0.06 |       0.66 #> 0.00        |     -0.05 |       0.41 #> 0.00        |      0.25 |       0.41 #> 0.00        |     -0.09 |       0.41 #> 0.00        |     -0.18 |       0.03 #> 0.00        |      0.41 |       0.74 #> 0.00        |      0.15 |       0.55 #> 0.00        |      0.11 |       0.72 #> 0.00        |      0.04 |       0.24 #> 0.00        |      0.18 |       0.71 #> 0.00        |      0.21 |       0.73 #> 0.00        |      0.15 |       0.25 #> 0.00        |  3.96e-03 |       0.55 #> 0.00        |      0.07 |       0.36 #> 0.00        |      0.13 |       0.36 #> 0.00        |      0.09 |       0.22 #> 0.00        |     -0.03 |       0.66 #> 0.00        |      0.13 |       0.43 #> 0.00        |      0.12 |       0.33 #> 0.00        |      0.13 |       0.37 #> 0.00        |      0.19 |       0.48 #> 0.00        |     -0.10 |       0.32 #> 0.00        |  2.29e-03 |       0.40 #> 0.00        |      0.08 |       0.26 #> 0.00        |      0.06 |       0.51 #> 0.00        |      0.10 |       0.30 #> 0.00        |      0.12 |       0.28 #> 0.00        |      0.12 |       0.36 #> 0.00        |      0.02 |       0.36 #> 0.00        | -3.52e-03 |       0.47 #> 0.00        |     -0.16 |       0.60 #> 0.00        |      0.06 |       0.52 #> 0.00        |      0.45 |       0.29 #> 0.00        |      0.52 |       0.44 #> 0.00        |      0.25 |       0.32 #> 0.00        |      0.03 |       0.38 #> 0.00        |  2.98e-03 |       0.57 #> 0.00        |     -0.06 |       0.61 #> 0.00        |     -0.08 |       0.25 #> 0.00        |     -0.10 |       0.27 #> 0.00        |      0.12 |       0.76 #> 0.00        |      0.28 |       0.18 #> 0.00        |      0.26 |       0.40 #> 0.00        |      0.18 |       0.17 #> 0.00        |      0.32 |       0.74 #> 0.00        |      0.15 |       0.28 #> 0.00        |     -0.07 |       0.58 #> 0.00        |      0.04 |       0.55 #> 0.00        |     -0.09 |       0.38 #> 0.00        |      0.18 |       0.49 #> 0.00        |      0.02 |       0.34 #> 0.00        |      0.16 |       0.38 #> 0.00        |     -0.01 |       0.48 #> 0.00        |      0.11 |       0.37 #> 0.00        |      0.11 |       0.27 #> 0.00        |     -0.12 |       0.31 #> 0.00        |      0.12 |       0.14 #> 0.00        |     -0.06 |       0.05 #> 0.00        |      0.03 |       0.45 #> 0.00        | -6.35e-03 |       0.24 #> 0.00        |      0.21 |       0.55 #> 0.00        |      0.05 |       0.43 #> 0.00        |     -0.34 |       0.24 #> 0.00        |     -0.10 |       0.23 #> 0.00        |      0.27 |       0.56 #> 0.00        |      0.21 |       0.49 #> 0.00        |  9.17e-03 |       0.36 #> 0.00        |      0.22 |       0.44 #> 0.00        |     -0.14 |       0.39 #> 0.00        |      0.26 |       0.51 #> 0.00        |      0.02 |       0.43 #> 0.00        |     -0.14 |       0.48 #> 0.00        |      0.21 |       0.33 #> 0.00        |     -0.03 |       0.41 #> 0.00        |     -0.04 |       0.45 #> 0.00        |      0.32 |       0.34 #> 0.00        |     -0.15 |       0.33 #> 0.00        |      0.03 |       0.39 #> 0.00        |      0.21 |       0.42 #> 0.00        |     -0.04 |       0.41 #> 0.00        |      0.43 |       0.30 #> 0.00        |      0.14 |       0.31 #> 0.00        |      0.24 |       0.36 #> 0.00        |      0.20 |       0.36 #> 0.00        |     -0.02 |       0.25 #> 0.00        |      0.02 |       0.39 #> 0.00        |      0.10 |       0.13 #> 0.00        |      0.32 |       0.17 #> 0.00        |     -0.03 |       0.74 #> 0.00        |     -0.51 |       0.82 #> 0.00        |      0.77 |       0.40 #> 0.00        |      0.55 |       0.43 #> 0.00        |      0.02 |       0.44 #> 0.00        |     -0.13 |       0.46 #> 0.00        |     -0.09 |       0.52 #> 0.00        |      0.25 |       0.28 #> 0.00        |     -0.11 |       0.59 #> 0.00        |     -0.11 |       0.47 #> 0.00        |     -0.25 |       0.52 #> 0.00        |      0.61 |       0.30 #> 0.00        |     -0.28 |       0.34 #> 0.00        |      0.33 |       0.55 #> 0.00        |      0.15 |       0.34 #> 0.00        | -8.86e-03 |       0.62 #> 0.00        |      0.11 |       0.58 #> 0.00        |     -0.09 |       0.28 #> 0.00        |      0.04 |       0.61 #> 0.00        |     -0.10 |       0.53 #> 0.00        |      0.04 |       0.28 #> 0.00        |      0.15 |       0.50 #> 0.00        |      0.24 |       0.36 #> 0.00        |     -0.05 |       0.40 #> 0.00        |      0.14 |       0.28 #> 0.00        |      0.09 |       0.41 #> 0.00        |      0.05 |       0.73 #> 0.00        |      0.11 |       0.38 #> 0.00        |      0.09 |       0.62 #> 0.00        |      0.21 |       0.17 #> 0.00        |      0.19 |       0.22 #> 0.00        |      0.21 |       0.31 #> 0.00        |      0.28 |       0.29 #> 0.00        |      0.32 |       0.36 #> 0.00        |      0.09 |       0.24 #> 0.00        |      0.39 |       0.36 #> 0.00        |     -0.30 |       0.48 #> 0.00        |      0.08 |       0.21 #> 0.00        | -4.96e-03 |       0.46 #> 0.00        |     -0.03 |       0.17 #> 0.00        |      0.32 |       0.43 #> 0.00        |      0.34 |       0.29 #> 0.00        |      0.46 |       0.40 #> 0.00        |     -0.18 |       0.43 #> 0.00        |      0.17 |       0.38 #> 0.00        |     -0.22 |       0.58 #> 0.00        |      0.18 |       0.36 #> 0.00        |  1.09e-03 |       0.07 #> 0.00        |     -0.04 |       0.45 #> 0.00        |     -0.14 |       0.71 #> 0.00        |      0.32 |       0.56 #> 0.00        |      0.01 |       0.31 #> 0.00        |      0.01 |       0.47 #> 0.00        |      0.09 |       0.48 #> 0.00        |      0.14 |       0.35 #> 0.00        |      0.12 |       0.64 #> 0.00        |      0.37 |       0.11 #> 0.00        |     -0.11 |       0.68 #> 0.00        |      0.04 |       0.52 #> 0.00        |     -0.12 |       0.53 #> 0.00        |     -0.01 |       0.51 #> 0.00        | -3.97e-03 |       0.21 #> 0.00        |      0.18 |       0.25 #> 0.00        |      0.21 |       0.22 #> 0.00        |      0.24 |       0.37 #> 0.00        |      0.25 |       0.23 #> 0.00        |     -0.09 |       0.59 #> 0.00        |      0.03 |       0.47 #> 0.00        |      0.30 |       0.22 #> 0.00        |     -0.05 |       0.64 #> 0.00        |      0.19 |       0.32 #> 0.00        |      0.25 |       0.41 #> 0.00        |     -0.11 |       0.45 #> 0.00        |      0.20 |       0.71 #> 0.00        |      0.03 |       0.14 #> 0.00        |      0.14 |       0.44 #> 0.00        |     -0.06 |       0.26 #> 0.00        |     -0.06 |       0.35 #> 0.00        |      0.06 |       0.38 #> 0.00        |      0.12 |       0.52 #> 0.00        |      0.15 |       0.36 #> 0.00        |      0.12 |       0.39 #> 0.00        |      0.04 |       0.48 #> 0.00        |      0.07 |       0.31 #> 0.00        |     -0.01 |       0.19 #> 0.00        |      0.13 |       0.63 #> 0.00        |      0.16 |       0.12 #> 0.00        |      0.19 |       0.51 #> 0.00        |      0.09 |       0.35 #> 0.00        |      0.09 |       0.35 #> 0.00        |      0.14 |       0.64 #> 0.00        |      0.23 |       0.31 #> 0.00        |     -0.15 |       0.67 #> 0.00        |     -0.08 |       0.61 #> 0.00        |      0.03 |       0.74 #> 0.00        |      0.09 |       0.68 #> 0.00        |     -0.45 |       0.62 #> 0.00        |     -0.46 |       0.60 #> 0.00        |      0.22 |       0.12 #> 0.00        |      0.05 |       0.66 #> 0.00        |      0.11 |       0.07 #> 0.00        |      0.27 |       0.33 #> 0.00        |      0.01 |       0.50 #> 0.00        |      0.23 |       0.34 #> 0.00        |     -0.02 |       0.42 #> 0.00        |      0.25 |       0.41 #> 0.00        |     -0.04 |       0.51 #> 0.00        |     -0.19 |       0.90 #> 0.00        |      0.16 |       0.10 #> 0.00        |      0.05 |       0.14 #> 0.00        |     -0.01 |       0.39 #> 0.00        |      0.39 |       0.33 #> 0.00        |     -0.21 |       0.46 #> 0.00        |     -0.04 |       0.46 #> 0.00        |      0.26 |       0.62 #> 0.00        |      0.27 |       0.67 #> 0.00        |      0.09 |       0.43 #> 0.00        |      0.14 |       0.44 #> 0.00        |     -0.16 |       0.46 #> 0.00        |      0.36 |       0.50 #> 0.00        |     -0.02 |       0.35 #> 0.00        |      0.04 |       0.47 #> 0.00        |      0.10 |       0.43 #> 0.00        |      0.21 |       0.54 #> 0.00        |      0.17 |       0.33 #> 0.00        |      0.05 |       0.45 #> 0.00        |      0.08 |       0.41 #> 0.00        |      0.14 |       0.27 #> 0.00        |      0.17 |       0.58 #> 0.00        |     -0.06 |       0.61 #> 0.00        |      0.36 |       0.46 #> 0.00        |      0.31 |       0.41 #> 0.00        | -4.89e-03 |       0.42 #> 0.00        |      0.11 |       0.67 #> 0.00        |      0.07 |       0.19 #> 0.00        |      0.12 |       0.74 #> 0.00        |      0.07 |       0.27 #> 0.00        |      0.09 |       0.66 #> 0.00        |      0.03 |       0.06 #> 0.00        |      0.24 |       0.49 #> 0.00        |      0.15 |       0.24 #> 0.00        |      0.11 |       0.59 #> 0.00        |     -0.12 |       0.54 #> 0.00        |      0.18 |       0.46 #> 0.00        |  5.47e-03 |       0.54 #> 0.00        |      0.24 |       0.37 #> 0.00        |      0.27 |       0.51 #> 0.00        |     -0.02 |       0.25 #> 0.00        |      0.25 |       0.56 #> 0.00        |      0.15 |       0.39 #> 0.00        |      0.03 |       0.56 #> 0.00        |     -0.35 |      -0.18 #> 0.00        |      0.08 |       0.47 #> 0.00        |      0.06 |       0.39 #> 0.00        |      0.06 |       0.44 #> 0.00        |      0.08 |       0.47 #> 0.00        |      0.16 |       0.38 #> 0.00        |     -0.01 |       0.57 #> 0.00        |      0.16 |       0.28 #> 0.00        |     -0.31 |       0.44 #> 0.00        |     -0.38 |       0.31 #> 0.00        |      0.11 |       0.26 #> 0.00        |      0.17 |       0.45 #> 0.00        |      0.27 |       0.25 #> 0.00        |  4.01e-03 |       0.43 #> 0.00        |      0.19 |       0.39 #> 0.00        |     -0.02 |       0.46 #> 0.00        |      0.12 |       0.22 #> 0.00        |      0.05 |       0.66 #> 0.00        |      0.12 |       0.74 #> 0.00        |      0.03 |       0.67 #> 0.00        |      0.42 |       0.29 #> 0.00        |  1.70e-03 |       0.39 #> 0.00        |     -0.13 |       0.37 #> 0.00        |      0.26 |       0.48 #> 0.00        |      0.13 |       0.22 #> 0.00        |      0.27 |       0.68 #> 0.00        |     -0.34 |       0.13 #> 0.00        |      0.04 |       0.55 #> 0.00        |      0.27 |       0.36 #> 0.00        |      0.04 |       0.60 #> 0.00        |     -0.21 |       0.34 #> 0.00        |     -0.24 |       0.51 #> 0.00        |      0.40 |       0.32 #> 0.00        |     -0.28 |       0.50 #> 0.00        |      0.31 |       0.23 #> 0.00        |     -0.02 |       0.50 #> 0.00        |      0.23 |       0.30 #> 0.00        |      0.25 |       0.30 #> 0.00        |     -0.14 |       0.52 #> 0.00        |     -0.15 |       0.59 #> 0.00        |      0.32 |       0.12 #> 0.00        |      0.19 |       0.07 #> 0.00        |     -0.04 |       0.74 #> 0.00        |     -0.09 |       0.48 #> 0.00        |      0.42 |       0.41 #> 0.00        |      0.23 |       0.28 #> 0.00        |     -0.04 |       0.52 #> 0.00        |      0.08 |       0.49 #> 0.00        |      0.08 |       0.49 #> 0.00        |      0.13 |       0.35 #> 0.00        |     -0.13 |       0.57 #> 0.00        |      0.28 |       0.30 #> 0.00        |      0.39 |       0.31 #> 0.00        |     -0.18 |       0.53 #> 0.00        |     -0.21 |       0.54 #> 0.00        |      0.39 |       0.42 #> 0.00        |      0.72 |       0.23 #> 0.00        |     -0.08 |       0.48 #> 0.00        |     -0.22 |       0.55 #> 0.00        |     -0.29 |       0.54 #> 0.00        |     -0.28 |       0.46 #> 0.00        |      0.35 |       0.50 #> 0.00        |     -0.12 |       0.35 #> 0.00        |     -0.03 |       0.31 #> 0.00        |      0.11 |       0.26 #> 0.00        |      0.19 |       0.32 #> 0.00        |      0.12 |       0.40 #> 0.00        |      0.34 |       0.23 #> 0.00        |      0.43 |       0.15 #> 0.00        |      0.31 |       0.05 #> 0.00        |      0.14 |       0.60 #> 0.00        |      0.15 |       0.63 #> 0.00        |      0.11 |       0.59 #> 0.00        |      0.32 |  -2.51e-03 #> 0.00        |     -0.08 |       0.87 #> 0.00        |      0.21 |       0.06 #> 0.00        |     -0.11 |       0.89 #> 0.00        |      0.02 |       0.70 #> 0.00        |      0.33 |       0.36 #> 0.00        |     -0.20 |       0.42 #> 0.00        |      0.33 |       0.60 #> 0.00        |     -0.08 |       0.25 #> 0.00        |      0.13 |       0.69 #> 0.00        |     -0.08 |       0.64 #> 0.00        |      0.06 |       0.44 #> 0.00        |      0.05 |       0.72 #> 0.00        |     -0.26 |       0.44 #> 0.00        | -3.19e-03 |       0.23 #> 0.00        |      0.33 |       0.20 #> 0.00        |      0.36 |       0.21 #> 0.00        |     -0.11 |       0.57 #> 0.00        |      0.06 |       0.38 #> 0.00        |      0.16 |       0.24 #> 0.00        |     -0.18 |       0.69 #> 0.00        |      0.16 |       0.21 #> 0.00        |     -0.11 |       0.46 #> 0.00        |      0.33 |       0.17 #> 0.00        | -5.90e-03 |       0.69 #> 0.00        |      0.02 |       0.69 #> 0.00        |     -0.09 |       0.69 #> 0.00        |     -0.14 |       0.72 #> 0.00        |      0.20 |       0.32 #> 0.00        |     -0.09 |       0.24 #> 0.00        |      0.06 |       0.22 #> 0.00        |      0.04 |       0.58 #> 0.00        |     -0.31 |       0.56 #> 0.00        |     -0.41 |       0.56 #> 0.00        |     -0.39 |       0.60 #> 0.00        |     -0.28 |       0.49 #> 0.00        | -1.99e-03 |       0.58 #> 0.00        |      0.21 |       0.44 #> 0.00        |      0.17 |       0.39 #> 0.00        |      0.02 |       0.46 #> 0.00        |      0.02 |       0.46 #> 0.00        |      0.50 |       0.41 #> 0.00        |      0.14 |       0.41 #> 0.00        |      0.29 |       0.30 #> 0.00        |      0.18 |       0.57 #> 0.00        |      0.18 |       0.57 #> 0.00        |      0.11 |       0.32 #> 0.00        |      0.21 |       0.43 #> 0.00        |      0.20 |       0.31 #> 0.00        |      0.22 |       0.39 #> 0.00        |      0.10 |       0.34 #> 0.00        |      0.11 |       0.25 #> 0.00        |      0.54 |       0.26 #> 0.00        |     -0.07 |       0.31 #> 0.00        |     -0.17 |       0.82 #> 0.00        |     -0.10 |       0.76 #> 0.00        |      0.18 |       0.37 #> 0.00        |      0.07 |       0.30 #> 0.00        |      0.11 |       0.63 #> 0.00        |      0.07 |       0.05 #> 0.00        |      0.03 |       0.56 #> 0.00        |     -0.02 |       0.49 #> 0.00        |      0.25 |       0.65 #> 0.00        |      0.07 |       0.80 #> 0.00        |      0.14 |       0.07 #> 0.00        |      0.12 |       0.74 #> 0.00        |     -0.12 |       0.53 #> 0.00        |      0.21 |       0.26 #> 0.00        |     -0.03 |       0.56 #> 0.00        |     -0.13 |       0.70 #> 0.00        |      0.35 |       0.12 #> 0.00        |      0.28 |       0.22 #> 0.00        |      0.02 |       0.66 #> 0.00        |     -0.24 |       0.33 #> 0.00        |      0.50 |       0.45 #> 0.00        |     -0.08 |       0.23 #> 0.00        |     -0.02 |       0.20 #> 0.00        |      0.26 |       0.59 #> 0.00        |      0.18 |       0.41 #> 0.00        |      0.12 |       0.50 #> 0.00        |      0.13 |       0.48 #> 0.00        |      0.11 |       0.25 #> 0.00        |      0.18 |       0.20 #> 0.00        |      0.24 |       0.22 #> 0.00        | -1.57e-04 |       0.46 #> 0.00        |     -0.14 |       0.71 #> 0.00        |      0.11 |       0.14 #> 0.00        |      0.23 |       0.75 #> 0.00        |      0.04 |       0.08 #> 0.00        |     -0.07 |       0.51 #> 0.00        |     -0.02 |       0.13 #> 0.00        |      0.21 |       0.69 #> 0.00        |     -0.05 |       0.19 #> 0.00        |      0.04 |       0.21 #> 0.00        |      0.05 |       0.76 #> 0.00        |      0.07 |       0.24 #> 0.00        |      0.06 |       0.71 #> 0.00        |      0.14 |       0.42 #> 0.00        |      0.34 |       0.50 #> 0.00        |      0.12 |       0.41 #> 0.00        |      0.19 |       0.38 #> 0.00        |      0.22 |       0.36 #> 0.00        |      0.25 |       0.66 #> 0.00        |      0.23 |       0.14 #> 0.00        |      0.20 |       0.53 #> 0.00        |      0.45 |       0.39 #> 0.00        |     -0.30 |       0.49 #> 0.00        |      0.18 |       0.37 #> 0.00        |      0.32 |       0.34 #> 0.00        |     -0.12 |       0.48 #> 0.00        |     -0.26 |       0.63 #> 0.00        |      0.38 |       0.22 #> 0.00        |      0.02 |       0.49 #> 0.00        |      0.50 |       0.39 #> 0.00        |     -0.30 |       0.39 #> 0.00        |     -0.11 |       0.24 #> 0.00        |      0.01 |       0.65 #> 0.00        |      0.19 |       0.22 #> 0.00        | -1.76e-04 |       0.56 #> 0.00        |      0.11 |       0.48 #> 0.00        |      0.16 |       0.27 #> 0.00        |      0.10 |       0.53 #> 0.00        |      0.06 |       0.38 #> 0.00        |      0.02 |       0.65 #> 0.00        |      0.15 |       0.25 #> 0.00        |      0.05 |       0.54 #> 0.00        |     -0.04 |       0.36 #> 0.00        | -8.11e-03 |       0.36 #> 0.00        |      0.04 |       0.30 #> 0.00        |      0.16 |       0.51 #> 0.00        |      0.66 |       0.26 #> 0.00        |      0.05 |       0.08 #> 0.00        |     -0.11 |       0.37 #> 0.00        |      0.07 |       0.44 #> 0.00        |     -0.02 |       0.63 #> 0.00        |      0.13 |       0.35 #> 0.00        |      0.16 |       0.46 #> 0.00        |      0.21 |       0.54 #> 0.00        |     -0.03 |       0.34 #> 0.00        |      0.27 |       0.46 #> 0.00        |     -0.14 |       0.42 #> 0.00        |      0.25 |       0.21 #> 0.00        |      0.27 |       0.05 #> 0.00        |      0.20 |       0.07 #> 0.00        |      0.40 |      -0.14 #> 0.00        |     -0.10 |       0.83 #> 0.00        |      0.06 |       0.38 #> 0.00        |      0.10 |       0.33 #> 0.00        |     -0.08 |       0.51 #> 0.00        |     -0.25 |       0.32 #> 0.00        |      0.28 |       0.69 #> 0.00        |      0.06 |       0.74 #> 0.00        |     -0.05 |       0.27 #> 0.00        |      0.23 |       0.58 #> 0.00        |     -0.32 |       0.48 #> 0.00        |      0.44 |       0.28 #> 0.00        |      0.50 |       0.31 #> 0.00        |      0.02 |       0.50 #> 0.00        | -2.04e-03 |       0.45 #> 0.00        |      0.14 |       0.41 #> 0.00        |      0.14 |       0.20 #> 0.00        |     -0.02 |       0.17 #> 0.00        |      0.04 |       0.27 #> 0.00        |      0.40 |       0.30 #> 0.00        |     -0.28 |       0.46 #> 0.00        |     -0.16 |       0.47 #> 0.00        |      0.08 |       0.40 #> 0.00        |      0.03 |       0.14 #> 0.00        |     -0.10 |       0.11 #> 0.00        |     -0.09 |       0.68 #> 0.00        |      0.15 |       0.39 #> 0.00        |      0.17 |       0.47 #> 0.00        |     -0.03 |       0.30 #> 0.00        |      0.23 |       0.31 #> 0.00        |      0.02 |       0.60 #> 0.00        |      0.12 |       0.29 #> 0.00        |      0.11 |       0.66 #> 0.00        |      0.11 |       0.66 #> 0.00        |      0.03 |       0.18 #> 0.00        |     -0.04 |       0.49 #> 0.00        |      0.37 |       0.30 #> 0.00        |     -0.07 |       0.48 #> 0.00        |      0.25 |       0.35 #> 0.00        |      0.18 |       0.60 #> 0.00        |     -0.15 |   4.73e-04 #> 0.00        |      0.44 |       0.38 #> 0.00        |      0.34 |       0.43 #> 0.00        |      0.11 |       0.35 #> 0.00        |     -0.05 |       0.20 #> 0.00        |      0.29 |       0.57 #> 0.00        |      0.43 |       0.41 #> 0.00        |      0.22 |       0.15 #> 0.00        |      0.21 |       0.48 #> 0.00        |      0.23 |       0.25 #> 0.00        |      0.10 |       0.23 #> 0.00        |      0.13 |       0.56 #> 0.00        |  2.56e-03 |       0.56 #> 0.00        |      0.12 |       0.24 #> 0.00        |     -0.02 |       0.69 #> 0.00        |      0.20 |       0.09 #> 0.00        |      0.08 |       0.32 #> 0.00        |      0.16 |       0.25 #> 0.00        |     -0.01 |       0.64 #> 0.00        |      0.20 |       0.18 #> 0.00        |     -0.08 |       0.65 #> 0.00        |     -0.15 |       0.80 #> 0.00        |      0.33 |       0.02 #> 0.00        |      0.30 |       0.12 #> 0.00        |     -0.05 |       0.48 #> 0.00        |      0.12 |       0.39 #> 0.00        |     -0.16 |       0.62 #> 0.00        |      0.30 |       0.61 #> 0.00        |     -0.05 |       0.33 #> 0.00        |      0.09 |       0.50 #> 0.00        |      0.01 |       0.35 #> 0.00        |      0.05 |       0.47 #> 0.00        |      0.29 |       0.44 #> 0.00        |      0.31 |       0.25 #> 0.00        |      0.21 |       0.27 #> 0.00        |     -0.35 |       0.49 #> 0.00        |     -0.17 |       0.60 #> 0.00        |      0.15 |       0.32 #> 0.00        |      0.22 |       0.49 #> 0.00        |      0.01 |       0.42 #> 0.00        |      0.12 |       0.56 #> 0.00        |      0.06 |       0.41 #> 0.00        |      0.07 |       0.48 #> 0.00        | -2.43e-03 |       0.56 #> 0.00        |      0.04 |       0.65 #> 0.00        |  9.99e-03 |       0.32 #> 0.00        |      0.16 |       0.62 #> 0.00        |     -0.18 |       0.41 #> 0.00        |     -0.11 |       0.30 #> 0.00        |      0.27 |       0.48 #> 0.00        |     -0.10 |       0.44 #> 0.00        |      0.15 |       0.48 #> 0.00        |      0.07 |       0.61 #> 0.00        |  2.72e-03 |       0.50 #> 0.00        |      0.12 |       0.45 #> 0.00        |      0.29 |       0.33 #> 0.00        |     -0.18 |       0.77 #> 0.00        |      0.35 |       0.74 #> 0.00        |      0.45 |       0.31 #> 0.00        |     -0.19 |       0.51 #> 0.00        |     -0.12 |       0.21 #> 0.00        |     -0.21 |       0.36 #> 0.00        |     -0.04 |       0.48 #> 0.00        |      0.24 |       0.49 #> 0.00        |      0.15 |       0.56 #> 0.00        |      0.15 |       0.54 #> 0.00        |      0.12 |       0.33 #> 0.00        |     -0.02 |       0.52 #> 0.00        |      0.13 |       0.39 #> 0.00        |      0.28 |       0.31 #> 0.00        |     -0.14 |       0.44 #> 0.00        |      0.29 |       0.21 #> 0.00        |      0.22 |       0.45 #> 0.00        |     -0.03 |       0.30 #> 0.00        |      0.27 |       0.34 #> 0.00        |     -0.19 |       0.44 #> 0.00        |     -0.11 |       0.55 #> 0.00        |     -0.03 |       0.50 #> 0.00        |      0.24 |       0.49 #> 0.00        |      0.18 |       0.42 #> 0.00        |      0.10 |       0.36 #> 0.00        |      0.06 |       0.53 #> 0.00        |      0.11 |       0.33 #> 0.00        |      0.13 |       0.34 #> 0.00        |      0.07 |       0.42 #> 0.00        |      0.03 |       0.32 #> 0.00        |      0.11 |       0.62 #> 0.00        |      0.09 |       0.47 #> 0.00        |      0.08 |       0.38 #> 0.00        |      0.19 |       0.55 #> 0.00        |      0.38 |       0.80 #> 0.00        |     -0.08 |       0.12 #> 0.00        |     -0.09 |       0.24 #> 0.00        |     -0.17 |       0.15 #> 0.00        |      0.14 |       0.87 #> 0.00        |     -0.19 |       0.25 #> 0.00        |      0.33 |       0.41 #> 0.00        |     -0.06 |       0.40 #> 0.00        |      0.38 |       0.41 #> 0.00        |     -0.09 |       0.42 #> 0.00        |      0.14 |       0.31 #> 0.00        |      0.05 |       0.49 #> 0.00        |      0.30 |       0.09 #> 0.00        |      0.19 |       0.04 #> 0.00        |      0.32 |       0.13 #> 0.00        |      0.42 |       0.30 #> 0.00        |      0.18 |      -0.17 #> 0.00        |      0.40 |       0.37 #> 0.00        |     -0.07 |       0.37 #> 0.00        |     -0.27 |       0.48 #> 0.00        |      0.03 |       0.27 #> 0.00        |      0.29 |       0.35 #> 0.00        |      0.27 |       0.42 #> 0.00        |     -0.09 |       0.45 #> 0.00        |      0.33 |       0.42 #> 0.00        |      0.06 |       0.47 #> 0.00        |      0.09 |       0.29 #> 0.00        |      0.14 |       0.45 #> 0.00        |      0.11 |       0.55 #> 0.00        |      0.01 |       0.30 #> 0.00        |      0.23 |       0.37 #> 0.00        |      0.29 |       0.41 #> 0.00        |     -0.04 |       0.71 #> 0.00        |      0.38 |       0.25 #> 0.00        |      0.42 |       0.34 #> 0.00        |     -0.13 |       0.52 #> 0.00        |      0.13 |       0.62 #> 0.00        | -6.23e-03 |       0.57 #> 0.00        |     -0.02 |       0.43 #> 0.00        |      0.03 |       0.39 #> 0.00        |      0.16 |       0.56 #> 0.00        |      0.11 |       0.19 #> 0.00        |      0.29 |       0.50 #> 0.00        |      0.01 |       0.30 #> 0.00        |      0.22 |       0.74 #> 0.00        |     -0.22 |       0.62 #> 0.00        |      0.06 |       0.36 #> 0.00        |     -0.01 |       0.20 #> 0.00        |  1.08e-03 |       0.71 #> 0.00        |      0.37 |       0.30 #> 0.00        |      0.30 |       0.20 #> 0.00        |      0.16 |       0.50 #> 0.00        |     -0.03 |       0.24 #> 0.00        |     -0.12 |       0.34 #> 0.00        |     -0.09 |       0.27 #> 0.00        |      0.24 |       0.54 #> 0.00        |     -0.03 |       0.33 #> 0.00        |      0.20 |       0.03 #> 0.00        |      0.36 |       0.18 #> 0.00        |      0.44 |       0.25 #> 0.00        |      0.38 |       0.23 #> 0.00        |      0.17 |       0.48 #> 0.00        |      0.07 |       0.32 #> 0.00        |      0.21 |       0.30 #> 0.00        |      0.09 |       0.61 #> 0.00        |      0.29 |       0.62 #> 0.00        |     -0.13 |       0.12 #> 0.00        |     -0.12 |       0.44 #> 0.00        |     -0.22 |       0.52 #> 0.00        |     -0.19 |       0.65 #> 0.00        |     -0.04 |       0.44 #> 0.00        |      0.36 |       0.32 #> 0.00        |     -0.08 |       0.31 #> 0.00        |      0.08 |       0.64 #> 0.00        |      0.14 |       0.09 #> 0.00        |     -0.07 |       0.54 #> 0.00        |      0.10 |       0.48 #> 0.00        |     -0.01 |       0.32 #> 0.00        |      0.21 |       0.46 #> 0.00        | -1.53e-03 |       0.35 #> 0.00        |      0.21 |       0.50 #> 0.00        |     -0.12 |       0.73 #> 0.00        |     -0.04 |       0.76 #> 0.00        | -5.91e-03 |       0.25 #> 0.00        |      0.01 |       0.46 #> 0.00        |      0.27 |       0.71 #> 0.00        |     -0.07 |       0.13 #> 0.00        |      0.15 |       0.69 #> 0.00        |     -0.03 |       0.03 #> 0.00        |     -0.18 |       0.60 #> 0.00        |      0.07 |       0.36 #> 0.00        |      0.16 |       0.55 #> 0.00        |      0.50 |       0.53 #> 0.00        |     -0.35 |       0.26 #> 0.00        |      0.29 |       0.55 #> 0.00        |     -0.15 |       0.26 #> 0.00        |     -0.24 |       0.34 #> 0.00        |     -0.01 |       0.32 #> 0.00        |     -0.21 |       0.57 #> 0.00        |     -0.27 |       0.64 #> 0.00        |      0.43 |       0.21 #> 0.00        |      0.51 |       0.13 #> 0.00        |      0.39 |       0.18 #> 0.00        |      0.14 |       0.53 #> 0.00        |      0.24 |       0.59 #> 0.00        |      0.22 |       0.42 #> 0.00        |      0.12 |       0.51 #> 0.00        |      0.11 |       0.52 #> 0.00        |      0.11 |       0.34 #> 0.00        |      0.17 |       0.48 #> 0.00        |      0.06 |       0.38 #> 0.00        |      0.24 |       0.37 #> 0.00        |  3.21e-03 |       0.43 #> 0.00        |     -0.03 |       0.46 #> 0.00        |     -0.04 |       0.64 #> 0.00        |     -0.08 |       0.65 #> 0.00        |      0.05 |       0.79 #> 0.00        |      0.21 |       0.56 #> 0.00        |     -0.07 |       0.11 #> 0.00        |      0.04 |       0.53 #> 0.00        |     -0.13 |       0.32 #> 0.00        |     -0.14 |       0.37 #> 0.00        |     -0.09 |       0.31 #> 0.00        |      0.49 |       0.27 #> 0.00        |     -0.15 |       0.54 #> 0.00        |      0.27 |       0.20 #> 0.00        |     -0.01 |       0.51 #> 0.00        |      0.05 |       0.47 #> 0.00        |     -0.15 |       0.50 #> 0.00        | -9.27e-04 |       0.38 #> 0.00        |      0.06 |       0.43 #> 0.00        |      0.27 |       0.30 #> 0.00        |      0.26 |       0.34 #> 0.00        | -2.21e-04 |       0.50 #> 0.00        |      0.06 |       0.62 #> 0.00        |      0.12 |       0.55 #> 0.00        |     -0.09 |       0.37 #> 0.00        |     -0.01 |       0.58 #> 0.00        |      0.13 |       0.46 #> 0.00        |      0.11 |       0.39 #> 0.00        |      0.09 |       0.41 #> 0.00        |     -0.02 |       0.50 #> 0.00        |      0.05 |       0.52 #> 0.00        |     -0.03 |       0.45 #> 0.00        |      0.22 |       0.20 #> 0.00        |     -0.13 |       0.76 #> 0.00        |     -0.02 |       0.91 #> 0.00        |      0.07 |       0.16 #> 0.00        |      0.24 |       0.12 #> 0.00        |      0.09 |       0.61 #> 0.00        |      0.11 |       0.66 #> 0.00        |      0.05 |       0.73 #> 0.00        |     -0.03 |       0.78 #> 0.00        |     -0.05 |       0.81 #> 0.00        |      0.10 |       0.36 #> 0.00        |      0.21 |       0.48 #> 0.00        |     -0.05 |       0.46 #> 0.00        | -7.22e-03 |       0.42 #> 0.00        |      0.11 |       0.31 #> 0.00        |     -0.02 |       0.60 #> 0.00        |      0.20 |       0.20 #> 0.00        |      0.06 |       0.50 #> 0.00        |      0.24 |       0.25 #> 0.00        |     -0.05 |       0.66 #> 0.00        |      0.07 |       0.28 #> 0.00        |      0.09 |       0.54 #> 0.00        |     -0.02 |       0.57 #> 0.00        |      0.33 |       0.16 #> 0.00        |      0.38 |       0.26 #> 0.00        |     -0.23 |       0.28 #> 0.00        |     -0.09 |       0.27 #> 0.00        |      0.11 |       0.43 #> 0.00        |      0.25 |       0.66 #> 0.00        |      0.15 |       0.42 #> 0.00        |      0.19 |       0.27 #> 0.00        |      0.02 |       0.41 #> 0.00        |      0.05 |       0.27 #> 0.00        |      0.22 |       0.64 #> 0.00        |  7.20e-03 |       0.21 #> 0.00        |      0.04 |       0.21 #> 0.00        |     -0.07 |       0.22 #> 0.00        |      0.55 |       0.33 #> 0.00        |     -0.32 |       0.58 #> 0.00        |      0.46 |       0.18 #> 0.00        |     -0.23 |       0.66 #> 0.00        |      0.08 |       0.32 #> 0.00        |      0.51 |       0.07 #> 0.00        |     -0.13 |       0.34 #> 0.00        |      0.37 |       0.38 #> 0.00        |  9.57e-03 |       0.77 #> 0.00        |      0.03 |       0.91 #> 0.00        |      0.06 |       0.60 #> 0.00        |     -0.05 |       0.35 #> 0.00        |     -0.25 |       0.06 #> 0.00        |     -0.06 |       0.24 #> 0.00        |      0.25 |       0.52 #> 0.00        |     -0.04 |       0.39 #> 0.00        |      0.07 |       0.38 #> 0.00        |  2.44e-03 |       0.41 #> 0.00        |      0.32 |       0.50 #> 0.00        |      0.22 |       0.48 #> 0.00        |      0.35 |       0.48 #> 0.00        |     -0.10 |       0.35 #> 0.00        |      0.02 |       0.27 #> 0.00        |     -0.15 |       0.39 #> 0.00        |     -0.02 |       0.43 #> 0.00        |      0.19 |       0.24 #> 0.00        |      0.08 |       0.30 #> 0.00        |      0.12 |       0.41 #> 0.00        |      0.44 |       0.12 #> 0.00        |      0.22 |       0.27 #> 0.00        |      0.37 |       0.83 #> 0.00        |      0.50 |       0.70 #> 0.00        |     -0.12 |       0.09 #> 0.00        |      0.32 |       0.59 #> 0.00        |      0.15 |       0.45 #> 0.00        |     -0.12 |       0.49 #> 0.00        |     -0.01 |       0.51 #> 0.00        |      0.17 |       0.40 #> 0.00        |      0.11 |       0.74 #> 0.00        |     -0.09 |       0.36 #> 0.00        |     -0.42 |       0.32 #> 0.00        |     -0.32 |       0.18 #> 0.00        |      0.16 |       0.29 #> 0.00        |     -0.13 |       0.34 #> 0.00        |      0.15 |       0.35 #> 0.00        |      0.10 |       0.57 #> 0.00        |      0.02 |       0.29 #> 0.00        |      0.15 |       0.57 #> 0.00        |      0.07 |       0.31 #> 0.00        |      0.18 |       0.44 #> 0.00        |      0.23 |       0.17 #> 0.00        |     -0.14 |       0.58 #> 0.00        |     -0.02 |       0.22 #> 0.00        |      0.16 |       0.21 #> 0.00        |      0.10 |       0.02 #> 0.00        |      0.06 |       0.05 #> 0.00        |      0.13 |       0.74 #> 0.00        |     -0.13 |       0.20 #> 0.00        |      0.50 |       0.24 #> 0.00        |     -0.24 |       0.52 #> 0.00        |      0.40 |       0.55 #> 0.00        |     -0.02 |       0.41 #> 0.00        |      0.13 |       0.24 #> 0.00        |      0.09 |       0.51 #> 0.00        |      0.02 |       0.20 #> 0.00        |      0.19 |       0.47 #> 0.00        |      0.01 |       0.13 #> 0.00        |     -0.24 |       0.29 #> 0.00        |     -0.07 |       0.33 #> 0.00        |      0.39 |       0.59 #> 0.00        |     -0.17 |       0.29 #> 0.00        |     -0.14 |       0.71 #> 0.00        |     -0.02 |       0.54 #> 0.00        |     -0.05 |       0.51 #> 0.00        | -9.23e-03 |       0.45 #> 0.00        |      0.26 |       0.30 #> 0.00        |     -0.05 |       0.45 #> 0.00        |      0.14 |       0.46 #> 0.00        |      0.30 |       0.45 #> 0.00        |      0.15 |       0.46 #> 0.00        |      0.04 |       0.52 #> 0.00        |      0.11 |       0.30 #> 0.00        |      0.37 |       0.40 #> 0.00        |     -0.21 |       0.20 #> 0.00        |     -0.18 |       0.25 #> 0.00        |      0.65 |       0.54 #> 0.00        |      0.15 |       0.42 #> 0.00        |      0.12 |       0.32 #> 0.00        |      0.22 |       0.23 #> 0.00        |      0.06 |       0.25 #> 0.00        |     -0.08 |       0.58 #> 0.00        |     -0.04 |       0.64 #> 0.00        |      0.18 |       0.43 #> 0.00        |      0.15 |       0.40 #> 0.00        |      0.21 |       0.26 #> 0.00        |      0.15 |       0.22 #> 0.00        |      0.14 |       0.25 #> 0.00        |      0.08 |       0.36 #> 0.00        |      0.11 |       0.30 #> 0.00        |      0.10 |       0.52 #> 0.00        |     -0.07 |       0.34 #> 0.00        |     -0.13 |       0.35 #> 0.00        |      0.26 |       0.47 #> 0.00        |      0.15 |       0.46 #> 0.00        |      0.08 |       0.29 #> 0.00        | -9.21e-03 |       0.30 #> 0.00        |      0.05 |       0.57 #> 0.00        |      0.12 |       0.46 #> 0.00        |     -0.09 |       0.35 #> 0.00        |      0.43 |       0.11 #> 0.00        |      0.39 |       0.12 #> 0.00        |      0.27 |       0.26 #> 0.00        |      0.40 |       0.30 #> 0.00        |      0.22 |       0.68 #> 0.00        |      0.27 |       0.30 #> 0.00        |     -0.02 |       0.68 #> 0.00        |     -0.22 |       0.76 #> 0.00        |      0.39 |       0.42 #> 0.00        |      0.19 |       0.51 #> 0.00        |     -0.08 |       0.69 #> 0.00        |      0.17 |       0.37 #> 0.00        |      0.05 |       0.45 #> 0.00        |      0.13 |       0.20 #> 0.00        |      0.08 |       0.28 #> 0.00        | -1.10e-03 |       0.50 #> 0.00        |      0.11 |       0.39 #> 0.00        |     -0.06 |       0.57 #> 0.00        |     -0.08 |       0.48 #> 0.00        |      0.04 |       0.32 #> 0.00        |      0.08 |       0.66 #> 0.00        |      0.07 |       0.47 #> 0.00        |      0.68 |       0.35 #> 0.00        |      0.60 |       0.40 #> 0.00        |      0.29 |       0.51 #> 0.00        |      0.15 |       0.43 #> 0.00        |      0.22 |       0.47 #> 0.00        |     -0.10 |       0.55 #> 0.00        |      0.03 |       0.35 #> 0.00        |      0.22 |       0.60 #> 0.00        |      0.22 |       0.48 #> 0.00        |      0.06 |       0.54 #> 0.00        |      0.16 |       0.37 #> 0.00        |      0.17 |       0.26 #> 0.00        |      0.05 |       0.31 #> 0.00        |      0.13 |       0.16 #> 0.00        |      0.37 |       0.19 #> 0.00        |      0.19 |       0.50 #> 0.00        |      0.23 |       0.65 #> 0.00        |     -0.24 |       0.26 #> 0.00        |      0.52 |       0.34 #> 0.00        |      0.08 |       0.38 #> 0.00        |      0.09 |       0.09 #> 0.00        |     -0.06 |       0.59 #> 0.00        |      0.06 |       0.40 #> 0.00        |      0.10 |       0.43 #> 0.00        |      0.35 |       0.51 #> 0.00        |      0.29 |       0.54 #> 0.00        |      0.29 |       0.51 #> 0.00        |     -0.04 |       0.41 #> 0.00        |      0.23 |       0.39 #> 0.00        |     -0.10 |       0.34 #> 0.00        |     -0.27 |       0.60 #> 0.00        |      0.21 |       0.16 #> 0.00        |      0.03 |       0.26 #> 0.00        |      0.05 |       0.30 #> 0.00        |      0.11 |       0.64 #> 0.00        |      0.13 |       0.66 #> 0.00        |     -0.08 |       0.51 #> 0.00        |      0.07 |       0.51 #> 0.00        |      0.12 |       0.62 #> 0.00        |     -0.06 |       0.50 #> 0.00        |      0.14 |       0.37 #> 0.00        |     -0.10 |       0.44 #> 0.00        |      0.25 |       0.43 #> 0.00        |      0.14 |       0.63 #> 0.00        |      0.25 |       0.62 #> 0.00        |      0.19 |       0.64 #> 0.00        |     -0.02 |       0.47 #> 0.00        |      0.01 |       0.71 #> 0.00        |      0.14 |       0.16 #> 0.00        |      0.03 |       0.68 #> 0.00        |     -0.04 |       0.65 #> 0.00        |      0.20 |       0.20 #> 0.00        |      0.26 |       0.12 #> 0.00        |     -0.09 |       0.72 #> 0.00        |      0.20 |       0.12 #> 0.00        |     -0.07 |       0.70 #> 0.00        |     -0.02 |       0.24 #> 0.00        |      0.51 |       0.36 #> 0.00        |      0.06 |       0.22 #> 0.00        |      0.02 |       0.89 #> 0.00        |      0.17 |       0.59 #> 0.00        |     -0.05 |       0.40 #> 0.00        |      0.26 |       0.51 #> 0.00        |      0.26 |       0.61 #> 0.00        |      0.29 |       0.45 #> 0.00        |      0.22 |       0.42 #> 0.00        |      0.13 |       0.42 #> 0.00        |      0.17 |       0.38 #> 0.00        |      0.13 |       0.22 #> 0.00        |      0.08 |       0.65 #> 0.00        |     -0.28 |       0.69 #> 0.00        |      0.44 |       0.13 #> 0.00        |     -0.25 |       0.64 #> 0.00        |      0.27 |       0.31 #> 0.00        |      0.28 |       0.61 #> 0.00        |      0.15 |       0.43 #> 0.00        |     -0.04 |       0.14 #> 0.00        |     -0.19 |       0.61 #> 0.00        |     -0.07 |       0.65 #> 0.00        |      0.25 |       0.17 #> 0.00        |     -0.23 |       0.51 #> 0.00        |      0.25 |       0.43 #> 0.00        |  6.86e-03 |       0.45 #> 0.00        |      0.32 |       0.36 #> 0.00        |     -0.09 |       0.50 #> 0.00        |     -0.02 |       0.54 #> 0.00        |      0.45 |       0.45 #> 0.00        |      0.25 |       0.27 #> 0.00        |      0.12 |       0.35 #> 0.00        |      0.21 |       0.39 #> 0.00        |      0.17 |       0.33 #> 0.00        |     -0.06 |       0.50 #> 0.00        |      0.18 |       0.38 #> 0.00        |      0.15 |       0.29 #> 0.00        |     -0.19 |       0.40 #> 0.00        |      0.40 |       0.36 #> 0.00        |      0.45 |       0.40 #> 0.00        |     -0.33 |       0.54 #> 0.00        |      0.11 |       0.51 #> 0.00        |      0.11 |       0.61 #> 0.00        |      0.16 |       0.10 #> 0.00        |      0.29 |      -0.18 #> 0.00        |      0.30 |      -0.22 #> 0.00        |      0.56 |       0.20 #> 0.00        |     -0.07 |       0.54 #> 0.00        |      0.28 |       0.29 #> 0.00        |     -0.01 |       0.53 #> 0.00        |      0.16 |       0.27 #> 0.00        |      0.03 |       0.44 #> 0.00        |      0.06 |       0.37 #> 0.00        |     -0.22 |       0.66 #> 0.00        |      0.09 |       0.53 #> 0.00        |  3.35e-03 |       0.07 #> 0.00        |      0.16 |       0.29 #> 0.00        |  3.05e-03 |       0.26 #> 0.00        |      0.04 |       0.40 #> 0.00        |      0.16 |       0.38 #> 0.00        |      0.08 |       0.42 #> 0.00        |     -0.02 |       0.48 #> 0.00        |     -0.05 |       0.23 #> 0.00        |      0.28 |       0.52 #> 0.00        |      0.18 |       0.43 #> 0.00        |      0.10 |       0.69 #> 0.00        |      0.09 |       0.65 #> 0.00        |      0.07 |       0.14 #> 0.00        |      0.06 |       0.14 #> 0.00        |      0.33 |       0.65 #> 0.00        |      0.31 |       0.52 #> 0.00        |     -0.09 |       0.43 #> 0.00        |      0.14 |       0.24 #> 0.00        |      0.02 |       0.60 #> 0.00        |     -0.15 |       0.46 #> 0.00        |      0.61 |       0.12 #> 0.00        |     -0.28 |       0.51 #> 0.00        |  6.97e-03 |       0.25 #> 0.00        |     -0.14 |       0.47 #> 0.00        |      0.28 |       0.24 #> 0.00        |     -0.02 |       0.55 #> 0.00        |      0.09 |       0.44 #> 0.00        |      0.14 |       0.30 #> 0.00        |      0.08 |       0.49 #> 0.00        |  8.51e-03 |       0.41 #> 0.00        |      0.07 |       0.50 #> 0.00        |     -0.22 |       0.53 #> 0.00        |      0.09 |       0.36 #> 0.00        |      0.07 |       0.52 #> 0.00        | -1.73e-04 |       0.35 #> 0.00        |      0.27 |       0.33 #> 0.00        |      0.24 |       0.37 #> 0.00        |     -0.09 |       0.32 #> 0.00        |     -0.17 |       0.29 #> 0.00        |      0.20 |       0.42 #> 0.00        |      0.36 |       0.63 #> 0.00        |      0.14 |       0.18 #> 0.00        |      0.19 |       0.23 #> 0.00        |      0.27 |       0.34 #> 0.00        |     -0.07 |       0.50 #> 0.00        |     -0.24 |       0.36 #> 0.00        |      0.46 |       0.48 #> 0.00        |      0.24 |       0.27 #> 0.00        |      0.25 |       0.40 #> 0.00        |      0.11 |       0.19 #> 0.00        |      0.04 |       0.58 #> 0.00        |      0.20 |       0.17 #> 0.00        |      0.10 |       0.48 #> 0.00        |      0.30 |       0.14 #> 0.00        |     -0.12 |       0.68 #> 0.00        |      0.25 |       0.25 #> 0.00        |      0.20 |       0.13 #> 0.00        |      0.19 |      -0.16 #> 0.00        |     -0.16 |       0.53 #> 0.00        |      0.48 |       0.26 #> 0.00        |      0.46 |       0.15 #> 0.00        |     -0.13 |       0.82 #> 0.00        |      0.38 |       0.01 #> 0.00        |     -0.15 |       0.75 #> 0.00        |      0.30 |       0.07 #> 0.00        |      0.19 |       0.12 #> 0.00        |      0.19 |       0.05 #> 0.00        |      0.20 |       0.23 #> 0.00        |     -0.12 |       0.68 #> 0.00        |      0.24 |       0.07 #> 0.00        |      0.23 |       0.57 #> 0.00        |      0.46 |       0.14 #> 0.00        |      0.45 |       0.08 #> 0.00        |      0.53 |       0.23 #> 0.00        |      0.23 |       0.46 #> 0.00        |      0.01 |       0.43 #> 0.00        |     -0.25 |       0.35 #> 0.00        |      0.15 |       0.32 #> 0.00        |      0.28 |       0.24 #> 0.00        |      0.19 |       0.38 #> 0.00        |      0.24 |      -0.04 #> 0.00        |      0.04 |       0.73 #> 0.00        |     -0.07 |       0.23 #> 0.00        |      0.06 |       0.60 #> 0.00        |      0.09 |       0.51 #> 0.00        |      0.15 |       0.55 #> 0.00        |      0.05 |       0.29 #> 0.00        |      0.03 |       0.52 #> 0.00        |     -0.07 |       0.23 #> 0.00        |      0.27 |       0.57 #> 0.00        |      0.11 |       0.77 #> 0.00        |      0.23 |       0.26 #> 0.00        |      0.02 |       0.45 #> 0.00        |      0.25 |       0.24 #> 0.00        |      0.16 |       0.43 #> 0.00        |     -0.16 |       0.45 #> 0.00        |      0.32 |       0.39 #> 0.00        |      0.36 |       0.13 #> 0.00        |     -0.14 |       0.65 #> 0.00        |      0.32 |       0.19 #> 0.00        | -6.08e-03 |       0.32 #> 0.00        |      0.11 |       0.60 #> 0.00        |      0.14 |       0.51 #> 0.00        |      0.11 |       0.28 #> 0.00        |      0.05 |       0.47 #> 0.00        |      0.19 |       0.42 #> 0.00        |      0.05 |       0.45 #> 0.00        |      0.12 |       0.51 #> 0.00        |      0.08 |       0.33 #> 0.00        |      0.11 |       0.45 #> 0.00        |      0.38 |       0.34 #> 0.00        |      0.21 |       0.45 #> 0.00        |     -0.02 |       0.43 #> 0.00        |      0.16 |       0.46 #> 0.00        |     -0.20 |       0.22 #> 0.00        |      0.26 |       0.66 #> 0.00        |     -0.19 |       0.26 #> 0.00        |      0.10 |       0.80 #> 0.00        |     -0.16 |       0.49 #> 0.00        |  6.89e-03 |       0.52 #> 0.00        |      0.19 |       0.60 #> 0.00        |     -0.02 |       0.36 #> 0.00        |  5.93e-03 |       0.44 #> 0.00        |      0.06 |       0.38 #> 0.00        |      0.16 |       0.36 #> 0.00        | -9.96e-03 |       0.51 #> 0.00        |      0.30 |       0.51 #> 0.00        |     -0.16 |       0.19 #> 0.00        |      0.32 |       0.72 #> 0.00        |     -0.07 |       0.05 #> 0.00        |      0.22 |       0.62 #> 0.00        |      0.15 |       0.07 #> 0.00        |     -0.03 |       0.16 #> 0.00        |      0.09 |       0.74 #> 0.00        |     -0.26 |       0.18 #> 0.00        |     -0.45 |       0.64 #> 0.00        |     -0.49 |       0.69 #> 0.00        |     -0.04 |       0.68 #> 0.00        |      0.25 |       0.11 #> 0.00        |      0.34 |       0.11 #> 0.00        |     -0.09 |       0.50 #> 0.00        |      0.13 |       0.22 #> 0.00        |      0.11 |       0.14 #> 0.00        |      0.18 |       0.32 #> 0.00        |      0.16 |       0.35 #> 0.00        |     -0.06 |       0.72 #> 0.00        |      0.40 |   5.94e-04 #> 0.00        |      0.14 |       0.35 #> 0.00        |  3.30e-03 |       0.38 #> 0.00        |      0.23 |       0.47 #> 0.00        |      0.11 |       0.31 #> 0.00        |      0.04 |       0.25 #> 0.00        |      0.22 |       0.47 #> 0.00        |      0.33 |       0.35 #> 0.00        |      0.16 |       0.45 #> 0.00        |      0.21 |       0.57 #> 0.00        |      0.05 |       0.23 #> 0.00        |      0.28 |       0.58 #> 0.00        |     -0.29 |       0.46 #> 0.00        | -9.78e-03 |       0.55 #> 0.00        |      0.27 |       0.25 #> 0.00        |      0.04 |       0.43 #> 0.00        |      0.10 |       0.60 #> 0.00        |      0.31 |       0.63 #> 0.00        |     -0.14 |       0.19 #> 0.00        |      0.44 |       0.47 #> 0.00        |      0.30 |       0.32 #> 0.00        |     -0.16 |       0.66 #> 0.00        |      0.02 |       0.17 #> 0.00        |      0.01 |       0.59 #> 0.00        |      0.16 |       0.64 #> 0.00        |      0.10 |       0.48 #> 0.00        |      0.11 |       0.35 #> 0.00        |      0.25 |       0.39 #> 0.00        |     -0.06 |       0.45 #> 0.00        |      0.02 |       0.44 #> 0.00        |      0.02 |       0.53 #> 0.00        |      0.22 |       0.23 #> 0.00        |      0.07 |       0.43 #> 0.00        |      0.09 |       0.54 #> 0.00        |      0.09 |       0.31 #> 0.00        |     -0.43 |       0.65 #> 0.00        |     -0.28 |       0.50 #> 0.00        |     -0.25 |       0.18 #> 0.00        |     -0.27 |       0.33 #> 0.00        |     -0.23 |       0.43 #> 0.00        |      0.22 |       0.90 #> 0.00        |      0.14 |       0.77 #> 0.00        |     -0.25 |       0.48 #> 0.00        |      0.41 |       0.30 #> 0.00        |      0.42 |       0.44 #> 0.00        |     -0.17 |       0.54 #> 0.00        |      0.38 |       0.53 #> 0.00        |      0.40 |       0.62 #> 0.00        |     -0.28 |       0.26 #> 0.00        |      0.44 |       0.53 #> 0.00        |     -0.16 |       0.34 #> 0.00        |      0.31 |       0.38 #> 0.00        |     -0.08 |       0.47 #> 0.00        |     -0.24 |       0.57 #> 0.00        |      0.55 |       0.41 #> 0.00        |      0.42 |       0.38 #> 0.00        |      0.26 |       0.43 #> 0.00        |     -0.09 |       0.44 #> 0.00        |     -0.17 |       0.68 #> 0.00        |     -0.14 |       0.64 #> 0.00        |      0.08 |       0.08 #> 0.00        |      0.14 |       0.16 #> 0.00        |      0.12 |       0.65 #> 0.00        |      0.12 |       0.55 #> 0.00        |      0.19 |       0.39 #> 0.00        |      0.19 |       0.44 #> 0.00        |     -0.01 |       0.40 #> 0.00        |     -0.15 |       0.53 #> 0.00        |      0.25 |       0.34 #> 0.00        |     -0.16 |       0.34 #> 0.00        |      0.09 |       0.19 #> 0.00        |     -0.19 |       0.50 #> 0.00        |      0.19 |       0.49 #> 0.00        |      0.11 |       0.37 #> 0.00        |      0.14 |       0.38 #> 0.00        |     -0.01 |       0.32 #> 0.00        |     -0.13 |       0.36 #> 0.00        |      0.24 |       0.42 #> 0.00        |      0.34 |       0.15 #> 0.00        |     -0.08 |       0.62 #> 0.00        |      0.34 |       0.11 #> 0.00        |     -0.05 |       0.62 #> 0.00        |      0.11 |       0.48 #> 0.00        |      0.23 |       0.34 #> 0.00        |     -0.18 |       0.46 #> 0.00        |      0.10 |       0.54 #> 0.00        |      0.24 |       0.07 #> 0.00        |      0.15 |       0.66 #> 0.00        |      0.09 |       0.77 #> 0.00        |      0.02 |       0.90 #> 0.00        |      0.03 |       0.19 #> 0.00        |      0.25 |       0.74 #> 0.00        |      0.05 |       0.19 #> 0.00        |      0.07 |       0.76 #> 0.00        |      0.09 |       0.21 #> 0.00        |     -0.12 |       0.67 #> 0.00        |      0.10 |       0.26 #> 0.00        |      0.12 |       0.42 #> 0.00        |      0.15 |       0.42 #> 0.00        |     -0.02 |       0.58 #> 0.00        |      0.20 |       0.24 #> 0.00        |  2.96e-03 |       0.58 #> 0.00        |     -0.06 |       0.57 #> 0.00        |      0.21 |       0.48 #> 0.00        |      0.11 |       0.50 #> 0.00        |     -0.16 |       0.29 #> 0.00        |      0.34 |       0.24 #> 0.00        |     -0.16 |       0.60 #> 0.00        |      0.34 |       0.21 #> 0.00        |  7.71e-03 |       0.39 #> 0.00        |      0.18 |       0.58 #> 0.00        |      0.20 |       0.31 #> 0.00        |      0.19 |       0.26 #> 0.00        |      0.52 |       0.37 #> 0.00        |      0.03 |       0.23 #> 0.00        |      0.17 |       0.37 #> 0.00        |      0.17 |       0.44 #> 0.00        |      0.06 |       0.40 #> 0.00        |     -0.20 |       0.47 #> 0.00        |      0.19 |       0.41 #> 0.00        |      0.07 |       0.45 #> 0.00        |      0.31 |       0.43 #> 0.00        |      0.15 |       0.42 #> 0.00        |      0.18 |   5.42e-03 #> 0.00        |      0.42 |       0.21 #> 0.00        |     -0.15 |       0.70 #> 0.00        |      0.28 |       0.48 #> 0.00        |     -0.04 |       0.30 #> 0.00        |     -0.08 |       0.36 #> 0.00        |      0.17 |       0.41 #> 0.00        |      0.05 |       0.51 #> 0.00        | -2.09e-04 |       0.50 #> 0.00        |      0.20 |       0.34 #> 0.00        |      0.05 |       0.47 #> 0.00        |      0.18 |       0.40 #> 0.00        |      0.33 |       0.49 #> 0.00        |     -0.24 |       0.37 #> 0.00        |      0.41 |       0.48 #> 0.00        |      0.33 |       0.10 #> 0.00        |      0.32 |       0.32 #> 0.00        |      0.28 |       0.26 #> 0.00        |     -0.01 |       0.68 #> 0.00        |      0.18 |       0.58 #> 0.00        |      0.09 |       0.44 #> 0.00        |     -0.06 |       0.52 #> 0.00        |      0.02 |       0.52 #> 0.00        |     -0.16 |       0.38 #> 0.00        |      0.07 |       0.42 #> 0.00        |      0.27 |       0.53 #> 0.00        |      0.38 |       0.55 #> 0.00        |     -0.21 |       0.25 #> 0.00        |     -0.03 |       0.26 #> 0.00        |      0.38 |       0.55 #> 0.00        |      0.06 |       0.66 #> 0.00        |      0.26 |       0.46 #> 0.00        |      0.31 |       0.60 #> 0.00        |     -0.05 |       0.32 #> 0.00        |      0.30 |       0.64 #> 0.00        |      0.20 |       0.72 #> 0.00        | -5.78e-03 |       0.15 #> 0.00        |     -0.13 |       0.13 #> 0.00        |      0.26 |       0.33 #> 0.00        |      0.25 |       0.43 #> 0.00        |      0.18 |       0.38 #> 0.00        |      0.12 |       0.49 #> 0.00        |     -0.10 |       0.43 #> 0.00        |      0.20 |       0.59 #> 0.00        |      0.21 |       0.53 #> 0.00        |      0.11 |       0.44 #> 0.00        |     -0.02 |       0.50 #> 0.00        |      0.29 |       0.38 #> 0.00        |      0.32 |       0.07 #> 0.00        |      0.06 |       0.66 #> 0.00        |      0.11 |       0.67 #> 0.00        | -5.60e-03 |       0.27 #> 0.00        |      0.27 |       0.40 #> 0.00        |      0.31 |       0.48 #> 0.00        |     -0.12 |       0.26 #> 0.00        |      0.50 |       0.22 #> 0.00        |      0.47 |       0.13 #> 0.00        |     -0.36 |       0.60 #> 0.00        |     -0.08 |       0.51 #> 0.00        |      0.22 |       0.34 #> 0.00        |     -0.07 |       0.06 #> 0.00        |      0.26 |       0.53 #> 0.00        |      0.13 |       0.28 #> 0.00        |      0.26 |       0.31 #> 0.00        |     -0.13 |       0.75 #> 0.00        |     -0.12 |       0.67 #> 0.00        |      0.08 |       0.45 #> 0.00        |      0.24 |       0.37 #> 0.00        |     -0.04 |       0.46 #> 0.00        |      0.25 |       0.39 #> 0.00        |      0.14 |       0.43 #> 0.00        | -7.62e-03 |       0.42 #> 0.00        |      0.13 |       0.32 #> 0.00        |     -0.19 |       0.62 #> 0.00        |      0.40 |       0.23 #> 0.00        |      0.58 |       0.45 #> 0.00        |     -0.16 |       0.31 #> 0.00        |      0.39 |       0.45 #> 0.00        |     -0.39 |       0.57 #> 0.00        |      0.18 |       0.23 #> 0.00        |      0.30 |       0.46 #> 0.00        |     -0.23 |       0.44 #> 0.00        |      0.06 |       0.56 #> 0.00        |     -0.03 |       0.33 #> 0.00        |      0.28 |       0.50 #> 0.00        |     -0.08 |       0.58 #> 0.00        |      0.24 |       0.03 #> 0.00        |      0.48 |       0.06 #> 0.00        |     -0.17 |       0.68 #> 0.00        |      0.15 |       0.51 #> 0.00        |      0.06 |       0.37 #> 0.00        |     -0.14 |       0.63 #> 0.00        |      0.46 |       0.39 #> 0.00        |      0.15 |       0.73 #> 0.00        |      0.26 |       0.80 #> 0.00        |      0.03 |       0.28 #> 0.00        |      0.01 |       0.08 #> 0.00        |     -0.42 |       0.54 #> 0.00        |  1.85e-03 |       0.46 #> 0.00        |      0.18 |       0.44 #> 0.00        |      0.04 |       0.37 #> 0.00        |  3.61e-03 |       0.35 #> 0.00        |      0.08 |       0.39 #> 0.00        |      0.15 |       0.31 #> 0.00        |      0.10 |       0.40 #> 0.00        |      0.08 |       0.44 #> 0.00        |      0.23 |       0.30 #> 0.00        |     -0.12 |       0.57 #> 0.00        |     -0.07 |       0.76 #> 0.00        |      0.23 |       0.14 #> 0.00        |      0.08 |       0.10 #> 0.00        |     -0.25 |       0.62 #> 0.00        |      0.08 |       0.46 #> 0.00        |      0.04 |       0.24 #> 0.00        |      0.22 |       0.59 #> 0.00        |     -0.19 |       0.29 #> 0.00        |     -0.02 |       0.39 #> 0.00        |     -0.09 |       0.27 #> 0.00        |  6.61e-03 |       0.58 #> 0.00        |      0.21 |       0.26 #> 0.00        |      0.32 |       0.15 #> 0.00        |     -0.05 |       0.73 #> 0.00        |      0.31 |       0.02 #> 0.00        |     -0.31 |       0.83 #> 0.00        |     -0.11 |       0.58 #> 0.00        |      0.08 |       0.13 #> 0.00        |     -0.47 |       0.38 #> 0.00        |      0.10 |       0.72 #> 0.00        |     -0.02 |       0.97 #> 0.00        |      0.34 |       0.26 #> 0.00        |      0.35 |       0.27 #> 0.00        |  5.16e-03 |       0.56 #> 0.00        |      0.09 |       0.44 #> 0.00        |      0.02 |       0.46 #> 0.00        |      0.08 |       0.48 #> 0.00        |      0.30 |       0.41 #> 0.00        |     -0.08 |       0.63 #> 0.00        |      0.29 |       0.33 #> 0.00        |     -0.02 |       0.64 #> 0.00        |      0.37 |       0.62 #> 0.00        |      0.43 |       0.43 #> 0.00        |      0.44 |       0.41 #> 0.00        |     -0.25 |       0.37 #> 0.00        |      0.36 |       0.48 #> 0.00        |     -0.04 |       0.28 #> 0.00        |      0.05 |       0.48 #> 0.00        |      0.09 |       0.66 #> 0.00        |      0.12 |       0.14 #> 0.00        |     -0.07 |       0.37 #> 0.00        |     -0.06 |       0.34 #> 0.00        |     -0.34 |       0.32 #> 0.00        |      0.47 |       0.52 #> 0.00        |      0.38 |       0.24 #> 0.00        |      0.28 |       0.08 #> 0.00        |      0.05 |       0.68 #> 0.00        |      0.02 |       0.44 #> 0.00        |      0.13 |       0.20 #> 0.00        |      0.19 |       0.69 #> 0.00        |      0.14 |       0.48 #> 0.00        |      0.22 |       0.34 #> 0.00        |      0.23 |       0.49 #> 0.00        |     -0.05 |       0.23 #> 0.00        |      0.35 |       0.51 #> 0.00        |      0.14 |       0.40 #> 0.00        |      0.17 |       0.25 #> 0.00        |      0.02 |       0.62 #> 0.00        |      0.02 |       0.26 #> 0.00        |      0.13 |       0.21 #> 0.00        |      0.04 |       0.41 #> 0.00        |      0.21 |       0.01 #> 0.00        |      0.04 |       0.56 #> 0.00        |      0.11 |       0.24 #> 0.00        |     -0.01 |       0.59 #> 0.00        |      0.17 |       0.21 #> 0.00        |      0.08 |       0.47 #> 0.00        |      0.02 |       0.58 #> 0.00        |      0.09 |       0.62 #> 0.00        |     -0.05 |      -0.02 #> 0.00        |      0.14 |       0.96 #> 0.00        |      0.18 |       0.13 #> 0.00        |      0.07 |       0.23 #> 0.00        |      0.16 |       0.41 #> 0.00        |      0.20 |       0.44 #> 0.00        |      0.12 |       0.49 #> 0.00        |     -0.23 |       0.76 #> 0.00        |      0.02 |       0.70 #> 0.00        |      0.14 |       0.50 #> 0.00        |      0.09 |       0.25 #> 0.00        |      0.12 |       0.33 #> 0.00        |      0.24 |       0.61 #> 0.00        |      0.21 |       0.27 #> 0.00        |      0.26 |       0.30 #> 0.00        |      0.14 |       0.18 #> 0.00        |     -0.12 |       0.49 #> 0.00        |      0.24 |       0.37 #> 0.00        |     -0.06 |       0.46 #> 0.00        |      0.24 |       0.40 #> 0.00        |     -0.04 |       0.42 #> 0.00        |      0.07 |       0.55 #> 0.00        |      0.05 |       0.29 #> 0.00        |      0.26 |       0.06 #> 0.00        |     -0.29 |       0.37 #> 0.00        |      0.25 |       0.64 #> 0.00        |     -0.22 |       0.25 #> 0.00        |      0.02 |       0.70 #> 0.00        |     -0.31 |       0.71 #> 0.00        |      0.44 |       0.27 #> 0.00        |      0.24 |       0.29 #> 0.00        |      0.12 |       0.33 #> 0.00        |      0.08 |       0.18 #> 0.00        |      0.03 |       0.40 #> 0.00        |      0.06 |       0.04 #> 0.00        |     -0.03 |       0.72 #> 0.00        |      0.10 |       0.55 #> 0.00        |      0.04 |       0.32 #> 0.00        |     -0.05 |       0.44 #> 0.00        |      0.22 |       0.64 #> 0.00        |      0.03 |       0.46 #> 0.00        |      0.06 |       0.23 #> 0.00        |      0.09 |       0.43 #> 0.00        |      0.12 |       0.31 #> 0.00        |      0.01 |       0.58 #> 0.00        |     -0.09 |       0.48 #> 0.00        |      0.18 |       0.42 #> 0.00        |      0.11 |       0.44 #> 0.00        |      0.12 |       0.35 #> 0.00        |      0.18 |       0.36 #> 0.00        |      0.16 |       0.28 #> 0.00        |      0.15 |       0.13 #> 0.00        |      0.01 |       0.03 #> 0.00        |      0.37 |       0.45 #> 0.00        |     -0.29 |       0.13 #> 0.00        |  2.47e-03 |       0.58 #> 0.00        |      0.28 |       0.71 #> 0.00        |      0.29 |       0.72 #> 0.00        |      0.65 |       0.38 #> 0.00        |      0.13 |       0.23 #> 0.00        |      0.38 |       0.61 #> 0.00        |      0.25 |       0.47 #> 0.00        |      0.06 |       0.44 #> 0.00        |     -0.07 |       0.21 #> 0.00        |      0.19 |       0.40 #> 0.00        |      0.15 |       0.62 #> 0.00        |      0.08 |       0.46 #> 0.00        |     -0.04 |       0.46 #> 0.00        |      0.13 |       0.34 #> 0.00        |     -0.05 |       0.39 #> 0.00        |      0.26 |       0.38 #> 0.00        |     -0.11 |       0.52 #> 0.00        |      0.27 |       0.33 #> 0.00        |     -0.04 |       0.47 #> 0.00        |      0.44 |       0.39 #> 0.00        |     -0.02 |       0.17 #> 0.00        |      0.20 |       0.90 #> 0.00        |      0.20 |       0.73 #> 0.00        |     -0.14 |       0.35 #> 0.00        |     -0.09 |       0.36 #> 0.00        |      0.30 |       0.65 #> 0.00        |      0.24 |       0.60 #> 0.00        |     -0.15 |       0.45 #> 0.00        |      0.26 |       0.33 #> 0.00        |      0.13 |       0.12 #> 0.00        |      0.14 |       0.74 #> 0.00        |      0.23 |       0.79 #> 0.00        |      0.28 |       0.55 #> 0.00        |      0.06 |       0.37 #> 0.00        |      0.45 |       0.22 #> 0.00        |      0.21 |       0.42 #> 0.00        |      0.29 |       0.39 #> 0.00        |      0.10 |       0.46 #> 0.00        |      0.03 |       0.53 #> 0.00        |      0.17 |       0.27 #> 0.00        |      0.05 |       0.53 #> 0.00        |      0.11 |       0.42 #> 0.00        |      0.06 |       0.38 #> 0.00        |      0.06 |       0.35 #> 0.00        | -4.62e-03 |       0.63 #> 0.00        |      0.04 |       0.44 #> 0.00        |      0.10 |       0.28 #> 0.00        |      0.11 |       0.18 #> 0.00        |      0.13 |       0.55 #> 0.00        | -3.13e-03 |       0.27 #> 0.00        |      0.07 |       0.36 #> 0.00        |      0.04 |       0.56 #> 0.00        |      0.06 |       0.31 #> 0.00        |      0.28 |       0.33 #> 0.00        |      0.13 |       0.28 #> 0.00        |     -0.02 |       0.50 #> 0.00        |      0.02 |       0.21 #> 0.00        |      0.02 |       0.32 #> 0.00        |      0.15 |       0.41 #> 0.00        |      0.05 |       0.37 #> 0.00        |      0.29 |       0.42 #> 0.00        |     -0.15 |       0.25 #> 0.00        |     -0.03 |       0.65 #> 0.00        |  9.58e-03 |       0.60 #> 0.00        |      0.12 |       0.51 #> 0.00        |      0.16 |       0.58 #> 0.00        |     -0.01 |       0.31 #> 0.00        |      0.26 |       0.27 #> 0.00        |      0.46 |       0.16 #> 0.00        |     -0.06 |  -8.79e-03 #> 0.00        |      0.24 |       0.16 #> 0.00        |     -0.09 |       0.54 #> 0.00        |      0.32 |       0.19 #> 0.00        |      0.03 |       0.84 #> 0.00        |      0.24 |       0.70 #> 0.00        |      0.03 |       0.19 #> 0.00        |      0.09 |       0.44 #> 0.00        |      0.08 |       0.37 #> 0.00        |      0.08 |       0.44 #> 0.00        |      0.31 |       0.13 #> 0.00        |      0.19 |       0.42 #> 0.00        |      0.26 |       0.34 #> 0.00        |     -0.13 |       0.71 #> 0.00        |      0.45 |       0.26 #> 0.00        |     -0.20 |       0.53 #> 0.00        |     -0.08 |       0.50 #> 0.00        |      0.08 |       0.47 #> 0.00        |      0.13 |       0.50 #> 0.00        |      0.18 |       0.44 #> 0.00        |      0.01 |       0.71 #> 0.00        |      0.12 |       0.18 #> 0.00        |      0.07 |       0.63 #> 0.00        |  5.09e-03 |       0.30 #> 0.00        |      0.18 |       0.21 #> 0.00        |      0.04 |       0.60 #> 0.00        |      0.04 |       0.14 #> 0.00        |      0.25 |       0.63 #> 0.00        |      0.18 |       0.38 #> 0.00        |      0.06 |       0.39 #> 0.00        |     -0.03 |       0.42 #> 0.00        |      0.16 |       0.36 #> 0.00        |      0.17 |       0.17 #> 0.00        |      0.06 |       0.68 #> 0.00        |      0.03 |       0.75 #> 0.00        |      0.34 |       0.27 #> 0.00        |     -0.31 |       0.51 #> 0.00        |      0.44 |       0.36 #> 0.00        |      0.19 |       0.43 #> 0.00        |      0.17 |       0.54 #> 0.00        | -1.02e-03 |       0.50 #> 0.00        |      0.09 |       0.46 #> 0.00        |      0.22 |       0.21 #> 0.00        |     -0.07 |       0.10 #> 0.00        |      0.09 |       0.62 #> 0.00        |      0.16 |       0.56 #> 0.00        |      0.33 |       0.13 #> 0.00        |      0.16 |       0.34 #> 0.00        |      0.21 |       0.37 #> 0.00        |      0.28 |       0.36 #> 0.00        |      0.15 |       0.36 #> 0.00        |      0.05 |       0.42 #> 0.00        | -8.06e-03 |       0.30 #> 0.00        |      0.21 |       0.55 #> 0.00        |      0.02 |       0.25 #> 0.00        |      0.19 |       0.24 #> 0.00        | -5.45e-03 |       0.47 #> 0.00        |     -0.03 |       0.43 #> 0.00        |      0.16 |       0.36 #> 0.00        |      0.27 |       0.34 #> 0.00        |     -0.02 |       0.44 #> 0.00        |      0.24 |       0.37 #> 0.00        | -8.30e-03 |       0.54 #> 0.00        |     -0.05 |       0.36 #> 0.00        |      0.25 |       0.43 #> 0.00        |     -0.18 |       0.15 #> 0.00        |     -0.01 |       0.28 #> 0.00        |     -0.07 |       0.37 #> 0.00        |      0.07 |       0.45 #> 0.00        |      0.01 |       0.49 #> 0.00        |      0.11 |       0.15 #> 0.00        |     -0.14 |       0.64 #> 0.00        |      0.21 |       0.16 #> 0.00        |     -0.03 |       0.63 #> 0.00        |      0.04 |       0.62 #> 0.00        |      0.03 |       0.40 #> 0.00        |      0.19 |       0.40 #> 0.00        |      0.03 |       0.33 #> 0.00        |      0.06 |       0.22 #> 0.00        |     -0.02 |       0.11 #> 0.00        |     -0.02 |       0.37 #> 0.00        |      0.14 |       0.38 #> 0.00        |      0.12 |       0.30 #> 0.00        |  3.00e-03 |       0.46 #> 0.00        |     -0.04 |       0.64 #> 0.00        |     -0.06 |       0.28 #> 0.00        |      0.25 |       0.38 #> 0.00        |     -0.04 |       0.32 #> 0.00        |      0.07 |       0.25 #> 0.00        |      0.43 |       0.56 #> 0.00        |     -0.03 |       0.34 #> 0.00        |      0.30 |       0.72 #> 0.00        |      0.40 |       0.61 #> 0.00        |     -0.12 |       0.37 #> 0.00        |      0.31 |       0.35 #> 0.00        |      0.28 |       0.45 #> 0.00        |      0.29 |       0.50 #> 0.00        |      0.05 |       0.55 #> 0.00        |      0.47 |       0.04 #> 0.00        |      0.29 |       0.33 #> 0.00        |      0.06 |       0.52 #> 0.00        |      0.21 |       0.47 #> 0.00        |      0.10 |       0.56 #> 0.00        |      0.12 |       0.47 #> 0.00        |      0.52 |       0.64 #> 0.00        |      0.47 |       0.60 #> 0.00        |      0.40 |       0.57 #> 0.00        |     -0.12 |      -0.26 #> 0.00        |     -0.02 |      -0.35 #> 0.00        |      0.34 |       0.86 #> 0.00        |      0.27 |       0.65 #> 0.00        |      0.07 |       0.32 #> 0.00        |      0.07 |       0.52 #> 0.00        |      0.34 |       0.32 #> 0.00        |      0.24 |       0.14 #> 0.00        |      0.17 |       0.43 #> 0.00        |      0.22 |       0.63 #> 0.00        |     -0.19 |       0.26 #> 0.00        |      0.04 |       0.54 #> 0.00        |      0.08 |       0.77 #> 0.00        |     -0.13 |       0.27 #> 0.00        |      0.37 |       0.50 #> 0.00        |     -0.09 |       0.11 #> 0.00        |      0.23 |       0.64 #> 0.00        |      0.06 |       0.07 #> 0.00        |      0.03 |       0.11 #> 0.00        |      0.31 |       0.57 #> 0.00        |      0.28 |       0.43 #> 0.00        |     -0.02 |       0.34 #> 0.00        |      0.35 |       0.47 #> 0.00        |     -0.11 |       0.40 #> 0.00        |      0.10 |       0.30 #> 0.00        |      0.37 |       0.36 #> 0.00        |      0.33 |       0.44 #> 0.00        |      0.40 |       0.53 #> 0.00        |     -0.05 |       0.18 #> 0.00        |      0.02 |       0.25 #> 0.00        |      0.33 |       0.42 #> 0.00        |      0.17 |       0.63 #> 0.00        |     -0.19 |       0.57 #> 0.00        |      0.27 |       0.13 #> 0.00        |      0.14 |       0.42 #> 0.00        |     -0.20 |       0.27 #> 0.00        |      0.01 |       0.31 #> 0.00        |     -0.09 |       0.40 #> 0.00        |      0.04 |       0.33 #> 0.00        |      0.62 |       0.18 #> 0.00        |      0.28 |       0.26 #> 0.00        |     -0.15 |       0.71 #> 0.00        |      0.32 |       0.10 #> 0.00        |     -0.22 |       0.75 #> 0.00        |     -0.06 |       0.25 #> 0.00        |     -0.26 |       0.29 #> 0.00        |      0.38 |       0.60 #> 0.00        |      0.24 |       0.50 #> 0.00        |      0.08 |       0.37 #> 0.00        |      0.10 |       0.26 #> 0.00        |      0.19 |       0.41 #> 0.00        | -3.47e-03 |       0.15 #> 0.00        |     -0.13 |       0.16 #> 0.00        |     -0.07 |       0.32 #> 0.00        |     -0.15 |       0.46 #> 0.00        |      0.06 |       0.22 #> 0.00        |      0.16 |       0.76 #> 0.00        |     -0.10 |       0.94 #> 0.00        |     -0.18 |       0.18 #> 0.00        |      0.17 |       0.79 #> 0.00        | -8.91e-03 |       0.71 #> 0.00        |     -0.06 |       0.57 #> 0.00        |      0.07 |       0.59 #> 0.00        |      0.08 |       0.26 #> 0.00        |      0.02 |       0.51 #> 0.00        |      0.11 |       0.44 #> 0.00        |      0.16 |       0.40 #> 0.00        |     -0.16 |       0.46 #> 0.00        |      0.37 |       0.28 #> 0.00        |     -0.21 |       0.63 #> 0.00        |      0.28 |       0.15 #> 0.00        |      0.09 |       0.37 #> 0.00        |      0.15 |       0.47 #> 0.00        |      0.08 |       0.37 #> 0.00        |      0.05 |       0.76 #> 0.00        |      0.29 |       0.20 #> 0.00        |      0.28 |       0.27 #> 0.00        |      0.13 |       0.25 #> 0.00        |      0.10 |       0.39 #> 0.00        |      0.10 |       0.26 #> 0.00        |     -0.13 |       0.55 #> 0.00        |     -0.04 |       0.44 #> 0.00        |      0.05 |       0.45 #> 0.00        |      0.20 |       0.45 #> 0.00        | -3.41e-03 |       0.46 #> 0.00        |      0.13 |       0.70 #> 0.00        |      0.06 |       0.20 #> 0.00        |      0.05 |       0.79 #> 0.00        |     -0.06 |       0.81 #> 0.00        |      0.22 |       0.10 #> 0.00        |      0.14 |       0.39 #> 0.00        |      0.20 |       0.52 #> 0.00        |      0.03 |       0.39 #> 0.00        |  1.33e-03 |       0.44 #> 0.00        |     -0.09 |       0.41 #> 0.00        |  9.66e-03 |       0.30 #> 0.00        |      0.18 |       0.53 #> 0.00        |      0.09 |       0.13 #> 0.00        |      0.10 |       0.69 #> 0.00        |      0.16 |       0.35 #> 0.00        |  4.91e-03 |       0.52 #> 0.00        |      0.12 |       0.49 #> 0.00        |      0.17 |       0.35 #> 0.00        |      0.17 |       0.57 #> 0.00        |      0.27 |       0.70 #> 0.00        |      0.47 |       0.81 #> 0.00        |      0.16 |       0.18 #> 0.00        |      0.07 |       0.57 #> 0.00        |      0.07 |       0.53 #> 0.00        |      0.07 |       0.34 #> 0.00        |      0.10 |       0.48 #> 0.00        |      0.13 |       0.32 #> 0.00        |      0.12 |       0.60 #> 0.00        |      0.10 |       0.13 #> 0.00        |     -0.18 |       0.37 #> 0.00        |     -0.12 |       0.49 #> 0.00        |     -0.10 |       0.50 #> 0.00        |      0.23 |       0.44 #> 0.00        |      0.10 |       0.23 #> 0.00        |      0.29 |       0.23 #> 0.00        |      0.07 |       0.44 #> 0.00        |      0.11 |       0.42 #> 0.00        |      0.09 |       0.59 #> 0.00        |     -0.13 |       0.54 #> 0.00        |     -0.03 |       0.86 #> 0.00        |      0.14 |       0.12 #> 0.00        |     -0.02 |       0.82 #> 0.00        |      0.33 |       0.29 #> 0.00        |      0.09 |       0.36 #> 0.00        |      0.14 |       0.43 #> 0.00        |      0.20 |       0.45 #> 0.00        | -6.48e-03 |       0.56 #> 0.00        |      0.49 |       0.30 #> 0.00        |     -0.17 |       0.31 #> 0.00        |     -0.09 |       0.24 #> 0.00        |      0.22 |       0.53 #> 0.00        |      0.06 |       0.64 #> 0.00        |      0.04 |       0.68 #> 0.00        |      0.01 |       0.29 #> 0.00        |      0.08 |       0.24 #> 0.00        |      0.39 |       0.43 #> 0.00        | -3.98e-03 |       0.47 #> 0.00        |      0.16 |       0.43 #> 0.00        |      0.08 |      -0.03 #> 0.00        |      0.53 |       0.38 #> 0.00        |     -0.17 |       0.26 #> 0.00        |      0.22 |       0.55 #> 0.00        |      0.13 |       0.49 #> 0.00        |      0.07 |       0.33 #> 0.00        |      0.26 |       0.32 #> 0.00        |      0.28 |       0.29 #> 0.00        |      0.36 |       0.18 #> 0.00        |      0.07 |       0.44 #> 0.00        |      0.07 |       0.31 #> 0.00        |     -0.10 |       0.45 #> 0.00        |      0.09 |       0.63 #> 0.00        |      0.16 |       0.61 #> 0.00        |      0.06 |       0.15 #> 0.00        |      0.24 |       0.68 #> 0.00        |      0.23 |       0.71 #> 0.00        |     -0.19 |       0.13 #> 0.00        |     -0.15 |       0.11 #> 0.00        |     -0.19 |       0.06 #> 0.00        |      0.05 |       0.40 #> 0.00        |      0.10 |       0.49 #> 0.00        |      0.34 |       0.56 #> 0.00        |      0.04 |       0.11 #> 0.00        |      0.10 |       0.70 #> 0.00        |     -0.02 |       0.18 #> 0.00        |      0.17 |       0.59 #> 0.00        |      0.10 |       0.51 #> 0.00        |      0.21 |       0.51 #> 0.00        |      0.03 |       0.42 #> 0.00        |      0.01 |       0.32 #> 0.00        |     -0.27 |       0.47 #> 0.00        |      0.23 |       0.29 #> 0.00        |      0.02 |       0.47 #> 0.00        |      0.29 |       0.46 #> 0.00        |      0.02 |       0.48 #> 0.00        |     -0.05 |       0.77 #> 0.00        |      0.14 |       0.22 #> 0.00        |     -0.09 |       0.64 #> 0.00        |      0.35 |       0.41 #> 0.00        |     -0.02 |       0.46 #> 0.00        |      0.28 |       0.41 #> 0.00        |      0.34 |       0.44 #> 0.00        |     -0.11 |       0.39 #> 0.00        |      0.51 |       0.33 #> 0.00        |     -0.27 |       0.64 #> 0.00        |      0.45 |       0.16 #> 0.00        |     -0.08 |       0.64 #> 0.00        |      0.29 |       0.22 #> 0.00        |     -0.13 |       0.57 #> 0.00        |      0.32 |       0.33 #> 0.00        |     -0.10 |       0.49 #> 0.00        |      0.08 |       0.31 #> 0.00        |      0.12 |       0.63 #> 0.00        |      0.14 |       0.60 #> 0.00        | -8.01e-03 |       0.54 #> 0.00        |      0.27 |       0.68 #> 0.00        |      0.10 |       0.45 #> 0.00        |      0.08 |       0.56 #> 0.00        |      0.13 |       0.30 #> 0.00        |  6.61e-03 |       0.31 #> 0.00        |      0.07 |       0.30 #> 0.00        |      0.13 |       0.06 #> 0.00        |      0.13 |       0.68 #> 0.00        |      0.22 |       0.33 #> 0.00        |      0.20 |       0.39 #> 0.00        |     -0.23 |       0.76 #> 0.00        |      0.34 |       0.03 #> 0.00        |      0.06 |       0.50 #> 0.00        |  4.35e-03 |       0.30 #> 0.00        |     -0.23 |       0.21 #> 0.00        |      0.02 |       0.70 #> 0.00        |      0.28 |       0.19 #> 0.00        |     -0.10 |       0.57 #> 0.00        |      0.37 |       0.27 #> 0.00        |     -0.33 |       0.76 #> 0.00        |      0.38 |       0.20 #> 0.00        |     -0.15 |       0.46 #> 0.00        |      0.31 |       0.30 #> 0.00        |     -0.15 |       0.73 #> 0.00        |     -0.29 |       0.47 #> 0.00        |     -0.22 |       0.88 #> 0.00        |      0.06 |       0.32 #> 0.00        |      0.21 |       0.59 #> 0.00        |      0.27 |       0.36 #> 0.00        |     -0.02 |       0.34 #> 0.00        |     -0.15 |       0.67 #> 0.00        |      0.08 |       0.34 #> 0.00        |     -0.22 |      -0.01 #> 0.00        |      0.36 |       0.20 #> 0.00        |     -0.01 |       0.66 #> 0.00        |      0.19 |       0.05 #> 0.00        |      0.26 |       0.33 #> 0.00        |      0.26 |       0.56 #> 0.00        |     -0.10 |       0.32 #> 0.00        |      0.09 |       0.25 #> 0.00        |      0.10 |       0.27 #> 0.00        |      0.22 |       0.35 #> 0.00        |     -0.04 |       0.14 #> 0.00        |      0.47 |       0.51 #> 0.00        |      0.05 |       0.41 #> 0.00        |      0.03 |       0.32 #> 0.00        |     -0.11 |       0.41 #> 0.00        |      0.34 |       0.41 #> 0.00        |     -0.55 |       0.73 #> 0.00        |      0.82 |       0.17 #> 0.00        |      0.52 |       0.18 #> 0.00        |     -0.10 |       0.18 #> 0.00        |     -0.04 |       0.23 #> 0.00        |     -0.13 |       0.29 #> 0.00        |      0.29 |       0.65 #> 0.00        |      0.38 |       0.58 #> 0.00        |      0.39 |       0.31 #> 0.00        |      0.13 |       0.96 #> 0.00        |      0.22 |       0.74 #> 0.00        |      0.05 |       0.07 #> 0.00        |     -0.13 |       0.60 #> 0.00        |     -0.18 |       0.44 #> 0.00        |      0.28 |       0.57 #> 0.00        |     -0.10 |       0.22 #> 0.00        |      0.01 |       0.48 #> 0.00        |     -0.06 |       0.48 #> 0.00        |      0.05 |       0.43 #> 0.00        |      0.06 |       0.43 #> 0.00        |      0.05 |       0.33 #> 0.00        |      0.24 |       0.44 #> 0.00        |     -0.11 |       0.26 #> 0.00        |     -0.05 |       0.71 #> 0.00        |      0.06 |       0.36 #> 0.00        |      0.18 |       0.52 #> 0.00        |      0.07 |       0.54 #> 0.00        |      0.12 |       0.31 #> 0.00        |      0.23 |       0.24 #> 0.00        |      0.23 |       0.45 #> 0.00        |      0.33 |       0.34 #> 0.00        |      0.31 |       0.37 #> 0.00        |     -0.04 |       0.31 #> 0.00        |      0.06 |       0.32 #> 0.00        |      0.05 |       0.21 #> 0.00        |      0.12 |       0.50 #> 0.00        |      0.05 |       0.32 #> 0.00        |     -0.33 |       0.37 #> 0.00        |     -0.28 |       0.37 #> 0.00        |     -0.42 |       0.25 #> 0.00        |     -0.13 |       0.53 #> 0.00        |      0.06 |       0.43 #> 0.00        |  7.78e-03 |       0.59 #> 0.00        |      0.09 |       0.47 #> 0.00        | -8.77e-03 |       0.71 #> 0.00        |      0.08 |       0.66 #> 0.00        |      0.25 |       0.25 #> 0.00        |      0.46 |       0.81 #> 0.00        |      0.40 |       0.44 #> 0.00        | -7.60e-04 |       0.30 #> 0.00        |      0.23 |       0.37 #> 0.00        |     -0.11 |       0.52 #> 0.00        |      0.27 |       0.31 #> 0.00        |      0.04 |       0.48 #> 0.00        |      0.08 |       0.68 #> 0.00        |  9.56e-03 |       0.15 #> 0.00        |      0.28 |       0.48 #> 0.00        |      0.04 |       0.55 #> 0.00        |      0.24 |       0.66 #> 0.00        |      0.09 |       0.49 #> 0.00        |      0.16 |       0.28 #> 0.00        |  6.11e-03 |       0.36 #> 0.00        |     -0.05 |       0.36 #> 0.00        |      0.23 |       0.40 #> 0.00        |     -0.18 |       0.30 #> 0.00        |      0.10 |       0.35 #> 0.00        |      0.16 |       0.25 #> 0.00        |     -0.02 |       0.50 #> 0.00        |      0.40 |       0.30 #> 0.00        |     -0.22 |       0.51 #> 0.00        |      0.08 |       0.56 #> 0.00        |     -0.06 |       0.45 #> 0.00        |      0.15 |       0.39 #> 0.00        |      0.03 |       0.42 #> 0.00        |      0.24 |       0.28 #> 0.00        |      0.39 |       0.17 #> 0.00        |      0.07 |       0.40 #> 0.00        |      0.46 |       0.68 #> 0.00        |     -0.08 |      -0.03 #> 0.00        |      0.41 |       0.71 #> 0.00        |  1.77e-03 |       0.23 #> 0.00        |      0.12 |       0.53 #> 0.00        |      0.14 |       0.26 #> 0.00        |      0.03 |       0.58 #> 0.00        |      0.06 |       0.63 #> 0.00        |      0.12 |       0.48 #> 0.00        |      0.12 |       0.33 #> 0.00        |     -0.02 |       0.35 #> 0.00        |      0.20 |       0.18 #> 0.00        |     -0.07 |       0.65 #> 0.00        |     -0.05 |       0.53 #> 0.00        |  4.63e-03 |       0.43 #> 0.00        |      0.36 |       0.20 #> 0.00        |      0.13 |       0.27 #> 0.00        |      0.12 |       0.47 #> 0.00        |      0.16 |       0.37 #> 0.00        |      0.05 |       0.27 #> 0.00        |      0.27 |       0.52 #> 0.00        |  4.14e-03 |       0.36 #> 0.00        |     -0.08 |       0.80 #> 0.00        |      0.26 |       0.03 #> 0.00        |      0.11 |       0.72 #> 0.00        |      0.31 |       0.39 #> 0.00        |      0.06 |       0.40 #> 0.00        |      0.10 |       0.43 #> 0.00        |      0.19 |       0.45 #> 0.00        |      0.11 |       0.28 #> 0.00        |     -0.05 |       0.50 #> 0.00        |      0.21 |       0.26 #> 0.00        |      0.18 |       0.50 #> 0.00        |      0.22 |       0.46 #> 0.00        |      0.24 |       0.44 #> 0.00        |      0.18 |       0.43 #> 0.00        |      0.30 |       0.18 #> 0.00        |     -0.25 |       0.29 #> 0.00        |      0.04 |       0.34 #> 0.00        |      0.35 |       0.46 #> 0.00        |      0.34 |       0.37 #> 0.00        |     -0.09 |       0.34 #> 0.00        |      0.20 |       0.40 #> 0.00        |      0.14 |       0.38 #> 0.00        |     -0.09 |       0.32 #> 0.00        |      0.26 |       0.51 #> 0.00        |      0.29 |       0.56 #> 0.00        |      0.13 |       0.20 #> 0.00        |      0.24 |       0.54 #> 0.00        |     -0.09 |       0.38 #> 0.00        |     -0.12 |       0.54 #> 0.00        |     -0.16 |       0.44 #> 0.00        |     -0.14 |       0.45 #> 0.00        |     -0.37 |       0.52 #> 0.00        |     -0.02 |       0.29 #> 0.00        |      0.04 |       0.65 #> 0.00        |     -0.18 |       0.36 #> 0.00        |      0.46 |       0.39 #> 0.00        |     -0.16 |       0.57 #> 0.00        |      0.31 |       0.30 #> 0.00        |      0.03 |       0.44 #> 0.00        |     -0.07 |       0.46 #> 0.00        |     -0.10 |       0.60 #> 0.00        |      0.14 |       0.53 #> 0.00        |      0.07 |       0.56 #> 0.00        |      0.17 |       0.36 #> 0.00        |      0.13 |       0.18 #> 0.00        |      0.12 |       0.79 #> 0.00        |      0.14 |       0.10 #> 0.00        |      0.37 |       0.13 #> 0.00        |      0.21 |       0.09 #> 0.00        |     -0.07 |       0.38 #> 0.00        |      0.32 |       0.35 #> 0.00        |     -0.04 |       0.45 #> 0.00        |      0.15 |       0.43 #> 0.00        |     -0.02 |       0.33 #> 0.00        |     -0.04 |       0.67 #> 0.00        |     -0.28 |       0.55 #> 0.00        |     -0.20 |       0.36 #> 0.00        |      0.13 |       0.39 #> 0.00        |      0.12 |       0.44 #> 0.00        |      0.11 |       0.39 #> 0.00        |      0.27 |       0.45 #> 0.00        |     -0.14 |       0.34 #> 0.00        |     -0.04 |       0.60 #> 0.00        |      0.09 |       0.41 #> 0.00        |      0.05 |       0.69 #> 0.00        |      0.04 |       0.21 #> 0.00        |      0.33 |       0.42 #> 0.00        |     -0.01 |       0.30 #> 0.00        |      0.24 |       0.58 #> 0.00        |      0.15 |       0.33 #> 0.00        |     -0.09 |       0.34 #> 0.00        |      0.13 |       0.38 #> 0.00        |      0.07 |       0.40 #> 0.00        |      0.12 |       0.24 #> 0.00        |     -0.03 |       0.46 #> 0.00        |      0.05 |       0.49 #> 0.00        |      0.16 |       0.49 #> 0.00        |      0.24 |       0.25 #> 0.00        |      0.11 |       0.39 #> 0.00        |     -0.07 |       0.50 #> 0.00        |      0.02 |       0.45 #> 0.00        |      0.11 |       0.33 #> 0.00        | -4.13e-04 |       0.59 #> 0.00        |      0.12 |       0.55 #> 0.00        |      0.56 |       0.75 #> 0.00        |     -0.34 |       0.03 #> 0.00        |     -0.23 |       0.24 #> 0.00        |     -0.23 |       0.23 #> 0.00        |     -0.12 |       0.39 #> 0.00        |      0.08 |       0.48 #> 0.00        |      0.35 |       0.29 #> 0.00        |     -0.14 |       0.46 #> 0.00        |      0.30 |       0.41 #> 0.00        |      0.11 |       0.36 #> 0.00        |     -0.16 |       0.26 #> 0.00        |     -0.18 |       0.22 #> 0.00        |      0.41 |       0.56 #> 0.00        |      0.33 |       0.63 #> 0.00        |      0.09 |       0.20 #> 0.00        |      0.12 |       0.61 #> 0.00        |      0.17 |       0.61 #> 0.00        | -3.88e-03 |       0.21 #> 0.00        |      0.16 |       0.45 #> 0.00        |      0.16 |       0.11 #> 0.00        |      0.14 |       0.14 #> 0.00        |      0.09 |       0.35 #> 0.00        |      0.04 |       0.51 #> 0.00        |      0.25 |       0.24 #> 0.00        |      0.07 |       0.59 #> 0.00        |      0.28 |       0.43 #> 0.00        |      0.34 |       0.57 #> 0.00        |     -0.17 |       0.37 #> 0.00        |     -0.16 |       0.55 #> 0.00        |     -0.18 |       0.07 #> 0.00        |      0.40 |       0.70 #> 0.00        |     -0.30 |       0.14 #> 0.00        |     -0.25 |       0.23 #> 0.00        |      0.07 |       0.25 #> 0.00        |      0.29 |       0.52 #> 0.00        |      0.15 |       0.60 #> 0.00        |      0.13 |       0.24 #> 0.00        |     -0.18 |       0.62 #> 0.00        |     -0.27 |       0.46 #> 0.00        |     -0.24 |       0.64 #> 0.00        |      0.48 |       0.20 #> 0.00        |     -0.16 |       0.48 #> 0.00        |      0.07 |       0.57 #> 0.00        |      0.15 |       0.21 #> 0.00        |      0.23 |       0.27 #> 0.00        |     -0.07 |       0.53 #> 0.00        |      0.35 |       0.13 #> 0.00        |     -0.12 |       0.68 #> 0.00        |     -0.13 |       0.72 #> 0.00        |      0.18 |       0.58 #> 0.00        |     -0.12 |       0.35 #> 0.00        |      0.27 |       0.47 #> 0.00        |      0.35 |       0.37 #> 0.00        |      0.12 |       0.33 #> 0.00        |      0.17 |       0.40 #> 0.00        |      0.34 |       0.35 #> 0.00        |     -0.07 |       0.50 #> 0.00        |     -0.23 |       0.33 #> 0.00        |      0.48 |       0.35 #> 0.00        |      0.36 |       0.35 #> 0.00        |     -0.10 |       0.44 #> 0.00        |      0.42 |       0.49 #> 0.00        |  7.69e-03 |       0.38 #> 0.00        |     -0.05 |       0.26 #> 0.00        |      0.18 |       0.60 #> 0.00        |      0.26 |       0.39 #> 0.00        |      0.55 |       0.47 #> 0.00        |     -0.13 |       0.56 #> 0.00        |      0.03 |       0.35 #> 0.00        |     -0.28 |       0.51 #> 0.00        |      0.12 |       0.67 #> 0.00        |     -0.03 |       0.10 #> 0.00        |     -0.03 |       0.30 #> 0.00        |      0.19 |       0.50 #> 0.00        |      0.04 |       0.30 #> 0.00        |      0.14 |       0.39 #> 0.00        |      0.09 |       0.45 #> 0.00        |      0.09 |       0.15 #> 0.00        |      0.11 |       0.29 #> 0.00        |      0.02 |       0.56 #> 0.00        |     -0.22 |       0.46 #> 0.00        |      0.03 |       0.43 #> 0.00        |     -0.04 |       0.39 #> 0.00        |      0.05 |       0.33 #> 0.00        |      0.09 |       0.14 #> 0.00        |      0.19 |       0.38 #> 0.00        |      0.19 |       0.51 #> 0.00        |      0.07 |       0.32 #> 0.00        |      0.17 |       0.31 #> 0.00        |     -0.13 |       0.39 #> 0.00        |      0.72 |       0.21 #> 0.00        |     -0.10 |       0.53 #> 0.00        |     -0.13 |       0.48 #> 0.00        |     -0.16 |       0.69 #> 0.00        |      0.13 |       0.41 #> 0.00        |      0.07 |       0.39 #> 0.00        |  6.36e-03 |       0.52 #> 0.00        |      0.16 |       0.33 #> 0.00        |      0.07 |       0.41 #> 0.00        |      0.08 |       0.38 #> 0.00        |      0.35 |       0.21 #> 0.00        |      0.46 |       0.55 #> 0.00        |     -0.09 |   6.53e-03 #> 0.00        |      0.07 |       0.73 #> 0.00        |      0.17 |       0.09 #> 0.00        |     -0.11 |       0.13 #> 0.00        |     -0.12 |       0.61 #> 0.00        |      0.30 |       0.31 #> 0.00        |     -0.20 |       0.42 #> 0.00        |      0.26 |       0.30 #> 0.00        |      0.45 |       0.11 #> 0.00        |      0.07 |      -0.12 #> 0.00        |      0.23 |       0.65 #> 0.00        |      0.28 |       0.34 #> 0.00        |      0.06 |       0.46 #> 0.00        |      0.13 |       0.45 #> 0.00        |      0.24 |       0.30 #> 0.00        |      0.16 |       0.44 #> 0.00        |     -0.10 |       0.42 #> 0.00        |      0.28 |       0.33 #> 0.00        |     -0.09 |       0.48 #> 0.00        |      0.23 |       0.43 #> 0.00        |      0.30 |       0.21 #> 0.00        |      0.20 |       0.30 #> 0.00        |     -0.04 |       0.56 #> 0.00        |      0.22 |       0.34 #> 0.00        |      0.04 |       0.43 #> 0.00        |      0.25 |       0.59 #> 0.00        |      0.14 |       0.62 #> 0.00        |      0.14 |       0.47 #> 0.00        |      0.22 |       0.28 #> 0.00        |      0.32 |       0.20 #> 0.00        |      0.16 |       0.38 #> 0.00        |  7.71e-03 |       0.54 #> 0.00        |  1.78e-03 |       0.71 #> 0.00        |  3.64e-03 |       0.25 #> 0.00        |      0.35 |       0.51 #> 0.00        |      0.01 |       0.33 #> 0.00        |      0.19 |       0.39 #> 0.00        |      0.03 |       0.68 #> 0.00        |      0.06 |       0.17 #> 0.00        |      0.38 |       0.35 #> 0.00        |      0.16 |       0.61 #> 0.00        |      0.02 |       0.43 #> 0.00        |      0.25 |       0.35 #> 0.00        |     -0.12 |       0.56 #> 0.00        |     -0.15 |       0.57 #> 0.00        | -5.82e-03 |       0.31 #> 0.00        |      0.22 |       0.58 #> 0.00        |      0.08 |       0.44 #> 0.00        |     -0.11 |       0.33 #> 0.00        |      0.49 |       0.26 #> 0.00        |     -0.17 |       0.77 #> 0.00        |      0.16 |       0.14 #> 0.00        |      0.10 |       0.60 #> 0.00        |     -0.10 |       0.36 #> 0.00        |      0.35 |       0.45 #> 0.00        |     -0.10 |       0.20 #> 0.00        |      0.08 |       0.82 #> 0.00        |     -0.09 |       0.26 #> 0.00        |      0.34 |       0.59 #> 0.00        |     -0.03 |       0.25 #> 0.00        |     -0.14 |       0.27 #> 0.00        |      0.14 |       0.37 #> 0.00        |      0.29 |       0.54 #> 0.00        |     -0.20 |       0.41 #> 0.00        |     -0.02 |       0.44 #> 0.00        |      0.04 |       0.47 #> 0.00        |     -0.05 |       0.25 #> 0.00        |      0.13 |       0.32 #> 0.00        |     -0.04 |       0.60 #> 0.00        |     -0.05 |       0.66 #> 0.00        |      0.30 |       0.23 #> 0.00        |     -0.14 |       0.48 #> 0.00        |      0.16 |       0.53 #> 0.00        |      0.06 |       0.25 #> 0.00        |      0.29 |       0.42 #> 0.00        |     -0.21 |       0.61 #> 0.00        |     -0.04 |       0.57 #> 0.00        |      0.04 |       0.50 #> 0.00        |      0.25 |       0.50 #> 0.00        |     -0.08 |       0.30 #> 0.00        |     -0.17 |       0.22 #> 0.00        |     -0.17 |       0.22 #> 0.00        |      0.27 |       0.56 #> 0.00        |      0.24 |       0.27 #> 0.00        |      0.15 |       0.48 #> 0.00        |     -0.21 |       0.38 #> 0.00        |      0.35 |       0.51 #> 0.00        |      0.38 |       0.44 #> 0.00        |     -0.01 |       0.42 #> 0.00        |      0.06 |       0.42 #> 0.00        |      0.09 |       0.40 #> 0.00        | -6.01e-03 |       0.39 #> 0.00        |      0.13 |       0.35 #> 0.00        |      0.10 |       0.55 #> 0.00        |      0.43 |       0.23 #> 0.00        |      0.55 |       0.54 #> 0.00        |      0.15 |       0.09 #> 0.00        |     -0.06 |       0.34 #> 0.00        |      0.41 |       0.34 #> 0.00        |      0.12 |       0.39 #> 0.00        |      0.04 |       0.40 #> 0.00        |      0.11 |       0.44 #> 0.00        |      0.24 |       0.27 #> 0.00        |      0.04 |       0.22 #> 0.00        |      0.16 |       0.59 #> 0.00        |      0.41 |       0.08 #> 0.00        |      0.27 |       0.03 #> 0.00        |     -0.03 |       0.48 #> 0.00        |     -0.11 |       0.70 #> 0.00        |      0.10 |       0.23 #> 0.00        |     -0.39 |       0.33 #> 0.00        |      0.44 |       0.51 #> 0.00        |      0.12 |      -0.16 #> 0.00        |     -0.04 |       0.16 #> 0.00        |     -0.14 |       0.50 #> 0.00        |      0.18 |       0.16 #> 0.00        |     -0.22 |       0.59 #> 0.00        |      0.36 |       0.66 #> 0.00        |      0.10 |       0.31 #> 0.00        |      0.06 |       0.35 #> 0.00        |      0.15 |       0.72 #> 0.00        |      0.33 |       0.30 #> 0.00        |     -0.10 |       0.29 #> 0.00        |      0.20 |       0.28 #> 0.00        |      0.09 |       0.54 #> 0.00        |      0.20 |       0.66 #> 0.00        |      0.21 |       0.20 #> 0.00        |     -0.11 |       0.70 #> 0.00        |     -0.12 |       0.80 #> 0.00        |      0.33 |       0.25 #> 0.00        |     -0.18 |       0.54 #> 0.00        |      0.17 |       0.60 #> 0.00        |      0.05 |       0.64 #> 0.00        |      0.05 |       0.14 #> 0.00        |      0.20 |       0.64 #> 0.00        |      0.14 |       0.12 #> 0.00        |      0.03 |       0.27 #> 0.00        |      0.13 |       0.59 #> 0.00        |     -0.05 |       0.29 #> 0.00        |     -0.16 |       0.70 #> 0.00        |      0.10 |       0.30 #> 0.00        |      0.08 |       0.36 #> 0.00        |     -0.27 |       0.70 #> 0.00        |      0.26 |       0.23 #> 0.00        |      0.35 |  -6.63e-03 #> 0.00        |      0.47 |       0.29 #> 0.00        |     -0.07 |       0.62 #> 0.00        |      0.11 |       0.36 #> 0.00        |      0.09 |       0.45 #> 0.00        |      0.08 |       0.48 #> 0.00        |      0.07 |       0.73 #> 0.00        |      0.16 |       0.45 #> 0.00        |      0.09 |       0.28 #> 0.00        |      0.28 |       0.38 #> 0.00        |      0.36 |       0.80 #> 0.00        |      0.11 |       0.27 #> 0.00        |      0.02 |       0.65 #> 0.00        |     -0.33 |       0.40 #> 0.00        |     -0.18 |       0.57 #> 0.00        |     -0.10 |       0.44 #> 0.00        |      0.10 |       0.38 #> 0.00        |     -0.01 |       0.46 #> 0.00        |      0.08 |       0.33 #> 0.00        |     -0.10 |       0.45 #> 0.00        |      0.55 |       0.58 #> 0.00        |      0.37 |       0.38 #> 0.00        |     -0.20 |       0.53 #> 0.00        |     -0.25 |       0.68 #> 0.00        |      0.07 |       0.45 #> 0.00        |      0.13 |       0.48 #> 0.00        |      0.13 |       0.35 #> 0.00        |      0.10 |       0.41 #> 0.00        |      0.26 |       0.40 #> 0.00        |      0.08 |       0.39 #> 0.00        |      0.19 |       0.32 #> 0.00        |      0.27 |       0.44 #> 0.00        |      0.09 |       0.52 #> 0.00        |      0.19 |       0.41 #> 0.00        |     -0.34 |       0.59 #> 0.00        |     -0.19 |       0.64 #> 0.00        |      0.20 |       0.29 #> 0.00        |     -0.07 |       0.24 #> 0.00        |      0.16 |       0.32 #> 0.00        |      0.04 |       0.28 #> 0.00        |      0.12 |       0.49 #> 0.00        |      0.22 |       0.71 #> 0.00        |      0.07 |  -1.60e-03 #> 0.00        |      0.07 |       0.08 #> 0.00        |      0.17 |       0.28 #> 0.00        |      0.08 |       0.49 #> 0.00        |      0.08 |       0.51 #> 0.00        |      0.09 |       0.38 #> 0.00        |      0.05 |       0.44 #> 0.00        |      0.20 |       0.38 #> 0.00        |     -0.04 |       0.44 #> 0.00        |      0.51 |       0.30 #> 0.00        |      0.56 |       0.52 #> 0.00        |      0.09 |      -0.02 #> 0.00        |      0.04 |      -0.03 #> 0.00        |      0.31 |       0.77 #> 0.00        |     -0.05 |       0.21 #> 0.00        |      0.38 |       0.48 #> 0.00        |     -0.25 |       0.36 #> 0.00        |      0.07 |       0.26 #> 0.00        |      0.04 |       0.58 #> 0.00        |      0.14 |       0.40 #> 0.00        |      0.17 |       0.56 #> 0.00        | -5.53e-03 |       0.60 #> 0.00        |      0.20 |       0.22 #> 0.00        |      0.21 |       0.11 #> 0.00        |     -0.17 |       0.41 #> 0.00        |     -0.30 |       0.81 #> 0.00        |     -0.30 |       0.82 #> 0.00        |     -0.15 |       0.06 #> 0.00        |      0.36 |       0.69 #> 0.00        |      0.11 |       0.28 #> 0.00        |     -0.15 |       0.43 #> 0.00        |     -0.06 |       0.72 #> 0.00        |      0.14 |       0.13 #> 0.00        |      0.11 |       0.38 #> 0.00        |      0.30 |       0.44 #> 0.00        |     -0.17 |       0.22 #> 0.00        |      0.04 |       0.63 #> 0.00        |     -0.17 |       0.38 #> 0.00        |     -0.20 |       0.22 #> 0.00        |      0.60 |       0.45 #> 0.00        |      0.34 |       0.46 #> 0.00        |      0.27 |       0.64 #> 0.00        |      0.02 |       0.53 #> 0.00        |     -0.14 |       0.45 #> 0.00        |     -0.10 |       0.49 #> 0.00        |     -0.05 |       0.46 #> 0.00        |      0.40 |       0.28 #> 0.00        |      0.40 |       0.31 #> 0.00        |     -0.16 |       0.49 #> 0.00        |      0.14 |       0.40 #> 0.00        |     -0.08 |       0.45 #> 0.00        |      0.13 |       0.40 #> 0.00        |      0.03 |       0.58 #> 0.00        |      0.22 |       0.47 #> 0.00        |      0.11 |       0.43 #> 0.00        |      0.04 |       0.29 #> 0.00        |     -0.02 |       0.64 #> 0.00        |      0.40 |       0.15 #> 0.00        |      0.42 |       0.04 #> 0.00        |     -0.08 |       0.80 #> 0.00        |     -0.15 |       0.78 #> 0.00        |      0.24 |       0.13 #> 0.00        |      0.12 |       0.54 #> 0.00        |      0.06 |       0.43 #> 0.00        |      0.09 |       0.36 #> 0.00        |      0.35 |       0.44 #> 0.00        |      0.25 |       0.52 #> 0.00        |      0.49 |       0.32 #> 0.00        |     -0.15 |       0.49 #> 0.00        |      0.39 |       0.37 #> 0.00        |     -0.08 |      -0.01 #> 0.00        |      0.42 |       0.61 #> 0.00        |     -0.09 |       0.20 #> 0.00        |     -0.06 |       0.63 #> 0.00        |     -0.16 |       0.47 #> 0.00        |      0.41 |       0.32 #> 0.00        |      0.23 |       0.26 #> 0.00        |      0.02 |       0.44 #> 0.00        |      0.25 |       0.39 #> 0.00        |      0.15 |       0.34 #> 0.00        |      0.26 |       0.25 #> 0.00        |      0.08 |       0.79 #> 0.00        |     -0.32 |       0.62 #> 0.00        |     -0.40 |       0.64 #> 0.00        |      0.07 |       0.65 #> 0.00        |      0.51 |       0.31 #> 0.00        |      0.19 |       0.20 #> 0.00        |      0.22 |       0.60 #> 0.00        |      0.06 |       0.48 #> 0.00        |      0.50 |       0.25 #> 0.00        |      0.17 |       0.49 #> 0.00        |      0.14 |       0.35 #> 0.00        |      0.09 |       0.56 #> 0.00        |      0.10 |       0.64 #> 0.00        |     -0.11 |       0.30 #> 0.00        |      0.18 |       0.34 #> 0.00        |      0.02 |       0.35 #> 0.00        |      0.05 |       0.27 #> 0.00        |      0.35 |       0.38 #> 0.00        |     -0.03 |       0.61 #> 0.00        |      0.23 |       0.20 #> 0.00        |      0.29 |       0.19 #> 0.00        |     -0.16 |       0.62 #> 0.00        |      0.33 |       0.21 #> 0.00        |      0.36 |       0.23 #> 0.00        |      0.02 |       0.50 #> 0.00        |  1.70e-03 |       0.41 #> 0.00        |      0.19 |       0.43 #> 0.00        |      0.28 |       0.31 #> 0.00        |      0.03 |       0.34 #> 0.00        |     -0.06 |       0.39 #> 0.00        |      0.27 |       0.40 #> 0.00        |      0.23 |       0.36 #> 0.00        |      0.19 |       0.21 #> 0.00        |      0.31 |       0.15 #> 0.00        |      0.27 |       0.24 #> 0.00        |     -0.15 |       0.56 #> 0.00        |      0.12 |       0.62 #> 0.00        |      0.11 |       0.14 #> 0.00        |      0.24 |       0.30 #> 0.00        |      0.14 |       0.34 #> 0.00        |      0.07 |       0.48 #> 0.00        |      0.03 |       0.33 #> 0.00        |     -0.14 |       0.21 #> 0.00        |      0.19 |       0.40 #> 0.00        |     -0.04 |       0.33 #> 0.00        |     -0.16 |       0.57 #> 0.00        |      0.26 |       0.15 #> 0.00        |     -0.13 |       0.61 #> 0.00        |      0.38 |       0.19 #> 0.00        |      0.21 |       0.09 #> 0.00        | -7.93e-03 |       0.68 #> 0.00        |      0.10 |       0.65 #> 0.00        |      0.03 |       0.17 #> 0.00        |      0.19 |       0.18 #> 0.00        |      0.38 |       0.40 #> 0.00        |     -0.29 |       0.48 #> 0.00        |     -0.07 |       0.31 #> 0.00        |      0.12 |       0.61 #> 0.00        |      0.14 |       0.22 #> 0.00        |      0.10 |       0.31 #> 0.00        |      0.05 |       0.56 #> 0.00        |      0.14 |       0.13 #> 0.00        |      0.13 |       0.34 #> 0.00        |      0.18 |       0.38 #> 0.00        |     -0.02 |       0.46 #> 0.00        |     -0.03 |       0.28 #> 0.00        |     -0.14 |       0.46 #> 0.00        |      0.21 |       0.31 #> 0.00        |     -0.02 |       0.41 #> 0.00        |     -0.04 |       0.56 #> 0.00        |     -0.16 |       0.62 #> 0.00        |     -0.05 |       0.36 #> 0.00        |      0.14 |       0.41 #> 0.00        | -2.83e-03 |       0.39 #> 0.00        |      0.22 |       0.46 #> 0.00        |      0.25 |       0.16 #> 0.00        |      0.19 |  -3.10e-03 #> 0.00        |      0.09 |       0.43 #> 0.00        |      0.18 |       0.61 #> 0.00        |     -0.22 |       0.16 #> 0.00        |     -0.20 |       0.43 #> 0.00        |     -0.19 |       0.26 #> 0.00        |      0.34 |       0.53 #> 0.00        |     -0.29 |       0.22 #> 0.00        |     -0.06 |      -0.03 #> 0.00        |      0.23 |      -0.09 #> 0.00        |     -0.10 |       0.78 #> 0.00        |      0.15 |      -0.02 #> 0.00        |      0.14 |       0.17 #> 0.00        |      0.54 |       0.55 #> 0.00        |      0.55 |       0.38 #> 0.00        |      0.20 |       0.42 #> 0.00        |      0.28 |       0.35 #> 0.00        |  3.51e-03 |       0.35 #> 0.00        |      0.14 |       0.41 #> 0.00        |      0.04 |       0.36 #> 0.00        |     -0.09 |       0.29 #> 0.00        |      0.18 |       0.40 #> 0.00        |      0.08 |       0.47 #> 0.00        |      0.04 |       0.45 #> 0.00        |      0.18 |       0.39 #> 0.00        |      0.03 |       0.27 #> 0.00        |      0.20 |       0.34 #> 0.00        |     -0.02 |       0.43 #> 0.00        |     -0.05 |       0.41 #> 0.00        |      0.08 |       0.62 #> 0.00        |      0.07 |       0.08 #> 0.00        |      0.26 |       0.26 #> 0.00        |      0.35 |       0.19 #> 0.00        |      0.31 |       0.45 #> 0.00        |      0.02 |       0.67 #> 0.00        |      0.09 |       0.15 #> 0.00        |      0.13 |       0.63 #> 0.00        |     -0.04 |       0.45 #> 0.00        |      0.16 |       0.28 #> 0.00        |     -0.13 |       0.37 #> 0.00        |      0.30 |       0.36 #> 0.00        |     -0.14 |       0.47 #> 0.00        |      0.11 |       0.25 #> 0.00        |      0.02 |       0.59 #> 0.00        |      0.04 |       0.32 #> 0.00        |      0.05 |       0.65 #> 0.00        |      0.14 |       0.18 #> 0.00        |     -0.07 |       0.70 #> 0.00        |      0.06 |       0.40 #> 0.00        |      0.11 |       0.21 #> 0.00        |      0.08 |       0.39 #> 0.00        |      0.10 |       0.40 #> 0.00        |      0.14 |       0.49 #> 0.00        |      0.16 |       0.47 #> 0.00        |      0.12 |       0.77 #> 0.00        |      0.35 |       0.41 #> 0.00        |      0.25 |       0.54 #> 0.00        |     -0.07 |       0.40 #> 0.00        |      0.25 |       0.58 #> 0.00        |      0.18 |       0.46 #> 0.00        |      0.02 |       0.13 #> 0.00        |      0.04 |       0.22 #> 0.00        |      0.37 |       0.50 #> 0.00        |      0.20 |       0.24 #> 0.00        |      0.41 |       0.05 #> 0.00        |      0.25 |       0.64 #> 0.00        |     -0.01 |       0.08 #> 0.00        |      0.12 |       0.38 #> 0.00        |      0.32 |       0.35 #> 0.00        |      0.20 |       0.43 #> 0.00        |      0.12 |       0.26 #> 0.00        |      0.34 |       0.41 #> 0.00        |      0.06 |       0.35 #> 0.00        |      0.10 |       0.35 #> 0.00        |     -0.11 |       0.57 #> 0.00        |      0.03 |       0.55 #> 0.00        |      0.32 |       0.08 #> 0.00        |      0.18 |       0.16 #> 0.00        |     -0.37 |       0.91 #> 0.00        |      0.10 |      -0.11 #> 0.00        |      0.13 |       0.07 #> 0.00        |      0.29 |  -8.37e-03 #> 0.00        |      0.39 |       0.51 #> 0.00        |     -0.06 |       0.28 #> 0.00        |      0.28 |       0.50 #> 0.00        |      0.19 |       0.33 #> 0.00        |      0.22 |       0.25 #> 0.00        |     -0.07 |       0.51 #> 0.00        |      0.01 |       0.29 #> 0.00        |     -0.02 |       0.36 #> 0.00        |      0.18 |       0.40 #> 0.00        |      0.22 |       0.36 #> 0.00        |      0.09 |       0.42 #> 0.00        |      0.31 |       0.45 #> 0.00        |      0.28 |       0.45 #> 0.00        |      0.21 |       0.61 #> 0.00        |      0.38 |       0.54 #> 0.00        |      0.07 |       0.12 #> 0.00        |     -0.03 |       0.47 #> 0.00        |      0.02 |       0.49 #> 0.00        |     -0.12 |       0.28 #> 0.00        |      0.29 |       0.36 #> 0.00        |      0.34 |       0.34 #> 0.00        |      0.22 |       0.45 #> 0.00        |     -0.07 |       0.30 #> 0.00        |  8.13e-03 |       0.54 #> 0.00        |      0.02 |       0.63 #> 0.00        |      0.34 |       0.04 #> 0.00        |      0.26 |       0.36 #> 0.00        |      0.12 |       0.37 #> 0.00        |      0.15 |       0.39 #> 0.00        |      0.17 |       0.35 #> 0.00        |      0.02 |       0.25 #> 0.00        |      0.28 |       0.45 #> 0.00        |      0.30 |       0.44 #> 0.00        |     -0.09 |       0.44 #> 0.00        |      0.30 |       0.46 #> 0.00        |     -0.09 |       0.35 #> 0.00        |      0.14 |       0.41 #> 0.00        |     -0.08 |       0.54 #> 0.00        |     -0.03 |       0.38 #> 0.00        |      0.13 |       0.57 #> 0.00        |      0.04 |       0.30 #> 0.00        |     -0.02 |       0.49 #> 0.00        |      0.15 |       0.43 #> 0.00        |     -0.02 |       0.30 #> 0.00        |      0.35 |       0.72 #> 0.00        |     -0.05 |       0.49 #> 0.00        |      0.57 |       0.29 #> 0.00        |      0.41 |       0.36 #> 0.00        |      0.02 |       0.29 #> 0.00        |  2.98e-03 |       0.50 #> 0.00        |      0.05 |       0.67 #> 0.00        |      0.25 |       0.29 #> 0.00        |      0.30 |       0.75 #> 0.00        |  3.51e-03 |       0.43 #> 0.00        |      0.08 |       0.60 #> 0.00        |     -0.02 |       0.49 #> 0.00        |      0.12 |       0.36 #> 0.00        |      0.12 |       0.57 #> 0.00        |      0.06 |       0.30 #> 0.00        |      0.49 |       0.64 #> 0.00        |      0.16 |       0.28 #> 0.00        |     -0.08 |       0.37 #> 0.00        |      0.32 |       0.42 #> 0.00        |     -0.08 |       0.38 #> 0.00        |      0.12 |       0.50 #> 0.00        |      0.03 |       0.57 #> 0.00        |      0.15 |       0.27 #> 0.00        |      0.03 |       0.52 #> 0.00        |      0.20 |       0.15 #> 0.00        |      0.06 |       0.61 #> 0.00        | -9.31e-03 |       0.53 #> 0.00        |      0.15 |       0.62 #> 0.00        |      0.27 |       0.48 #> 0.00        |      0.27 |       0.53 #> 0.00        |      0.04 |       0.12 #> 0.00        |      0.23 |       0.70 #> 0.00        |     -0.06 |       0.41 #> 0.00        |      0.14 |       0.51 #> 0.00        |      0.08 |       0.39 #> 0.00        |      0.14 |       0.44 #> 0.00        |      0.01 |       0.12 #> 0.00        |     -0.02 |       0.80 #> 0.00        |     -0.05 |       0.67 #> 0.00        |      0.10 |       0.71 #> 0.00        |      0.03 |       0.34 #> 0.00        |      0.29 |       0.51 #> 0.00        |      0.20 |       0.02 #> 0.00        |      0.49 |       0.22 #> 0.00        |      0.26 |       0.26 #> 0.00        |      0.13 |       0.15 #> 0.00        |      0.05 |       0.63 #> 0.00        |      0.18 |       0.63 #> 0.00        |      0.22 |       0.63 #> 0.00        |  6.69e-03 |       0.21 #> 0.00        |     -0.06 |       0.32 #> 0.00        |     -0.25 |       0.76 #> 0.00        |      0.16 |       0.40 #> 0.00        |      0.15 |       0.52 #> 0.00        |      0.09 |       0.56 #> 0.00        |      0.01 |       0.12 #> 0.00        |     -0.28 |       0.36 #> 0.00        |     -0.17 |       0.36 #> 0.00        |      0.39 |       0.28 #> 0.00        |      0.34 |       0.20 #> 0.00        |      0.24 |       0.66 #> 0.00        |      0.10 |       0.29 #> 0.00        |      0.09 |       0.39 #> 0.00        |      0.12 |       0.25 #> 0.00        |  4.00e-03 |       0.43 #> 0.00        |      0.16 |       0.34 #> 0.00        |      0.01 |       0.50 #> 0.00        |     -0.11 |       0.31 #> 0.00        |      0.23 |       0.54 #> 0.00        |      0.17 |       0.54 #> 0.00        |      0.18 |       0.63 #> 0.00        |      0.13 |       0.44 #> 0.00        |  1.14e-03 |       0.40 #> 0.00        |      0.09 |       0.44 #> 0.00        |      0.12 |       0.10 #> 0.00        |      0.37 |       0.23 #> 0.00        |      0.14 |       0.45 #> 0.00        |     -0.11 |       0.41 #> 0.00        |      0.12 |       0.41 #> 0.00        |      0.06 |       0.37 #> 0.00        |     -0.09 |       0.40 #> 0.00        |      0.32 |       0.56 #> 0.00        |      0.34 |       0.32 #> 0.00        |      0.25 |       0.37 #> 0.00        |      0.19 |       0.47 #> 0.00        |      0.14 |       0.67 #> 0.00        |     -0.12 |       0.31 #> 0.00        |      0.35 |       0.41 #> 0.00        |     -0.04 |       0.31 #> 0.00        |      0.42 |       0.24 #> 0.00        |      0.39 |       0.25 #> 0.00        |     -0.07 |       0.49 #> 0.00        |      0.09 |       0.43 #> 0.00        |      0.02 |       0.22 #> 0.00        |      0.22 |       0.61 #> 0.00        |     -0.07 |       0.25 #> 0.00        |      0.13 |       0.36 #> 0.00        |      0.21 |       0.36 #> 0.00        |      0.14 |       0.39 #> 0.00        |      0.47 |       0.46 #> 0.00        |     -0.24 |       0.19 #> 0.00        |     -0.17 |       0.24 #> 0.00        |      0.17 |       0.74 #> 0.00        |  3.16e-03 |       0.07 #> 0.00        |      0.33 |       0.12 #> 0.00        |      0.33 |       0.06 #> 0.00        |      0.14 |       0.28 #> 0.00        |     -0.08 |       0.46 #> 0.00        |      0.21 |       0.31 #> 0.00        |      0.26 |       0.47 #> 0.00        |     -0.07 |       0.49 #> 0.00        |      0.24 |       0.46 #> 0.00        |     -0.12 |       0.32 #> 0.00        |      0.06 |       0.35 #> 0.00        |      0.17 |       0.69 #> 0.00        |      0.26 |       0.14 #> 0.00        |      0.26 |       0.28 #> 0.00        |      0.30 |       0.44 #> 0.00        |      0.52 |       0.55 #> 0.00        |     -0.12 |      -0.13 #> 0.00        |     -0.08 |       0.50 #> 0.00        |     -0.10 |       0.52 #> 0.00        |     -0.06 |       0.47 #> 0.00        |      0.37 |       0.41 #> 0.00        |     -0.02 |       0.25 #> 0.00        |      0.10 |       0.41 #> 0.00        |     -0.15 |       0.32 #> 0.00        |     -0.07 |       0.51 #> 0.00        |      0.17 |       0.47 #> 0.00        |      0.03 |       0.38 #> 0.00        |     -0.14 |       0.36 #> 0.00        |      0.13 |       0.47 #> 0.00        |     -0.07 |       0.33 #> 0.00        |      0.17 |       0.38 #> 0.00        |      0.09 |       0.41 #> 0.00        |     -0.12 |       0.43 #> 0.00        |      0.07 |       0.24 #> 0.00        |     -0.06 |       0.43 #> 0.00        |     -0.07 |       0.45 #> 0.00        |     -0.09 |       0.48 #> 0.00        |     -0.17 |       0.44 #> 0.00        |      0.33 |       0.24 #> 0.00        |      0.21 |       0.47 #> 0.00        |      0.11 |       0.29 #> 0.00        |     -0.08 |       0.56 #> 0.00        |      0.03 |       0.14 #> 0.00        |      0.12 |       0.72 #> 0.00        |      0.19 |       0.69 #> 0.00        |      0.13 |       0.14 #> 0.00        |      0.10 |       0.79 #> 0.00        |     -0.17 |       0.33 #> 0.00        |      0.16 |       0.45 #> 0.00        |     -0.12 |       0.59 #> 0.00        |      0.10 |       0.42 #> 0.00        |     -0.06 |       0.43 #> 0.00        |     -0.15 |       0.25 #> 0.00        |     -0.11 |       0.37 #> 0.00        |      0.37 |       0.32 #> 0.00        | -8.49e-03 |       0.32 #> 0.00        |     -0.09 |       0.41 #> 0.00        |      0.10 |       0.57 #> 0.00        |      0.27 |       0.85 #> 0.00        |      0.14 |       0.54 #> 0.00        |      0.08 |       0.29 #> 0.00        |     -0.08 |       0.58 #> 0.00        |      0.16 |       0.75 #> 0.00        |     -0.20 |       0.77 #> 0.00        |      0.20 |       0.56 #> 0.00        |     -0.03 |       0.23 #> 0.00        |      0.08 |       0.38 #> 0.00        |      0.10 |       0.43 #> 0.00        |     -0.05 |       0.39 #> 0.00        |      0.22 |       0.54 #> 0.00        |      0.05 |       0.26 #> 0.00        |      0.07 |       0.29 #> 0.00        | -7.81e-03 |       0.60 #> 0.00        |      0.33 |       0.47 #> 0.00        |      0.01 |       0.51 #> 0.00        |      0.05 |       0.49 #> 0.00        |      0.20 |       0.15 #> 0.00        |      0.18 |       0.50 #> 0.00        |      0.01 |       0.31 #> 0.00        |      0.04 |       0.37 #> 0.00        |      0.35 |       0.37 #> 0.00        |      0.09 |       0.25 #> 0.00        |      0.02 |       0.77 #> 0.00        |     -0.05 |       0.20 #> 0.00        |      0.32 |       0.72 #> 0.00        |     -0.16 |       0.30 #> 0.00        |     -0.11 |       0.72 #> 0.00        |     -0.02 |       0.61 #> 0.00        |     -0.06 |       0.18 #> 0.00        |      0.30 |       0.44 #> 0.00        |     -0.18 |       0.44 #> 0.00        |      0.07 |       0.76 #> 0.00        |      0.25 |       0.46 #> 0.00        |     -0.02 |       0.45 #> 0.00        |      0.25 |       0.40 #> 0.00        |      0.13 |       0.34 #> 0.00        |      0.17 |       0.55 #> 0.00        |     -0.18 |       0.27 #> 0.00        |      0.42 |       0.54 #> 0.00        |      0.19 |       0.57 #> 0.00        | -7.78e-03 |       0.21 #> 0.00        |      0.21 |       0.63 #> 0.00        |      0.37 |       0.22 #> 0.00        |     -0.13 |       0.58 #> 0.00        |      0.28 |       0.17 #> 0.00        |      0.32 |       0.28 #> 0.00        |     -0.18 |       0.64 #> 0.00        |      0.26 |       0.40 #> 0.00        |      0.40 |       0.61 #> 0.00        |      0.34 |       0.57 #> 0.00        |      0.24 |       0.49 #> 0.00        |      0.09 |       0.27 #> 0.00        |     -0.04 |       0.17 #> 0.00        | -1.46e-03 |       0.40 #> 0.00        |      0.21 |       0.38 #> 0.00        |     -0.03 |       0.39 #> 0.00        |      0.01 |       0.76 #> 0.00        | -6.93e-03 |       0.58 #> 0.00        |      0.10 |       0.37 #> 0.00        |      0.07 |       0.43 #> 0.00        |      0.04 |       0.44 #> 0.00        |      0.09 |       0.58 #> 0.00        |      0.12 |       0.27 #> 0.00        |      0.33 |       0.23 #> 0.00        |      0.21 |       0.36 #> 0.00        |      0.28 |       0.15 #> 0.00        |      0.12 |       0.68 #> 0.00        |      0.26 |       0.40 #> 0.00        |      0.21 |       0.19 #> 0.00        |      0.22 |       0.24 #> 0.00        | -4.58e-03 |       0.50 #> 0.00        |     -0.10 |       0.28 #> 0.00        |      0.33 |       0.67 #> 0.00        |      0.01 |       0.22 #> 0.00        |     -0.29 |       0.56 #> 0.00        |      0.16 |       0.29 #> 0.00        |      0.15 |       0.38 #> 0.00        |      0.09 |       0.65 #> 0.00        |     -0.32 |       0.38 #> 0.00        |     -0.20 |       0.43 #> 0.00        |      0.14 |       0.77 #> 0.00        |     -0.17 |       0.23 #> 0.00        |     -0.29 |       0.24 #> 0.00        |      0.36 |       0.60 #> 0.00        |     -0.27 |       0.31 #> 0.00        |      0.29 |       0.65 #> 0.00        |     -0.26 |       0.19 #> 0.00        |     -0.18 |       0.22 #> 0.00        |      0.43 |       0.57 #> 0.00        |      0.07 |       0.36 #> 0.00        |     -0.02 |       0.53 #> 0.00        |      0.18 |       0.30 #> 0.00        |     -0.07 |       0.48 #> 0.00        |      0.22 |       0.39 #> 0.00        |     -0.21 |       0.41 #> 0.00        |      0.12 |       0.42 #> 0.00        |      0.17 |       0.40 #> 0.00        |      0.20 |       0.27 #> 0.00        |      0.14 |       0.09 #> 0.00        |      0.17 |       0.55 #> 0.00        |      0.08 |       0.49 #> 0.00        |     -0.02 |       0.59 #> 0.00        |      0.02 |       0.64 #> 0.00        |     -0.42 |       0.37 #> 0.00        |     -0.47 |       0.34 #> 0.00        |      0.16 |       0.15 #> 0.00        |     -0.15 |       0.09 #> 0.00        |      0.15 |       0.57 #> 0.00        |      0.15 |       0.22 #> 0.00        | -2.94e-03 |       0.19 #> 0.00        |      0.32 |       0.57 #> 0.00        |     -0.09 |       0.22 #> 0.00        |      0.05 |       0.56 #> 0.00        |      0.06 |       0.02 #> 0.00        |      0.03 |       0.11 #> 0.00        |      0.31 |       0.49 #> 0.00        |      0.28 |       0.47 #> 0.00        |      0.26 |       0.45 #> 0.00        |      0.36 |       0.33 #> 0.00        |      0.33 |       0.40 #> 0.00        |      0.21 |       0.48 #> 0.00        |     -0.14 |       0.10 #> 0.00        |      0.24 |       0.58 #> 0.00        |      0.21 |       0.22 #> 0.00        |      0.13 |       0.31 #> 0.00        |      0.17 |       0.37 #> 0.00        |      0.19 |       0.50 #> 0.00        |      0.15 |       0.49 #> 0.00        |      0.20 |       0.50 #> 0.00        |      0.52 |       0.03 #> 0.00        |      0.17 |       0.38 #> 0.00        |      0.25 |       0.34 #> 0.00        |      0.06 |       0.52 #> 0.00        |      0.20 |       0.27 #> 0.00        |      0.41 |       0.67 #> 0.00        |     -0.30 |       0.01 #> 0.00        |     -0.18 |       0.07 #> 0.00        |      0.07 |       0.62 #> 0.00        |      0.09 |       0.41 #> 0.00        |      0.09 |       0.48 #> 0.00        |      0.07 |       0.44 #> 0.00        |      0.31 |       0.45 #> 0.00        |      0.03 |       0.26 #> 0.00        |      0.16 |       0.25 #> 0.00        |      0.12 |       0.48 #> 0.00        |      0.10 |       0.28 #> 0.00        |      0.37 |       0.41 #> 0.00        |      0.18 |       0.66 #> 0.00        |     -0.11 |       0.27 #> 0.00        |      0.26 |       0.44 #> 0.00        |      0.07 |       0.56 #> 0.00        |      0.17 |       0.26 #> 0.00        |      0.02 |       0.54 #> 0.00        |      0.02 |       0.28 #> 0.00        |      0.12 |       0.61 #> 0.00        |      0.16 |       0.28 #> 0.00        |      0.11 |       0.21 #> 0.00        |      0.12 |       0.14 #> 0.00        |      0.20 |       0.29 #> 0.00        |      0.09 |       0.53 #> 0.00        |      0.28 |       0.22 #> 0.00        |      0.03 |       0.54 #> 0.00        |      0.21 |       0.23 #> 0.00        |      0.03 |       0.34 #> 0.00        |      0.03 |       0.33 #> 0.00        |     -0.37 |       0.83 #> 0.00        |      0.27 |       0.10 #> 0.00        |      0.03 |       0.63 #> 0.00        |      0.14 |       0.15 #> 0.00        |      0.27 |       0.36 #> 0.00        |     -0.04 |       0.59 #> 0.00        |      0.12 |       0.27 #> 0.00        |      0.23 |       0.48 #> 0.00        |      0.05 |       0.30 #> 0.00        |      0.27 |       0.63 #> 0.00        |     -0.04 |       0.33 #> 0.00        |      0.22 |       0.43 #> 0.00        |      0.36 |       0.55 #> 0.00        |     -0.28 |       0.31 #> 0.00        |     -0.28 |       0.36 #> 0.00        |     -0.36 |       0.29 #> 0.00        |      0.03 |       0.40 #> 0.00        |      0.15 |       0.45 #> 0.00        |      0.07 |       0.03 #> 0.00        |     -0.20 |       0.80 #> 0.00        |      0.53 |       0.41 #> 0.00        |     -0.05 |       0.15 #> 0.00        |      0.18 |       0.60 #> 0.00        |      0.23 |       0.64 #> 0.00        |      0.52 |       0.98 #> 0.00        |      0.42 |       0.83 #> 0.00        |      0.49 |       0.27 #> 0.00        |      0.44 |       0.63 #> 0.00        |     -0.10 |       0.23 #> 0.00        |      0.03 |       0.51 #> 0.00        |      0.04 |       0.21 #> 0.00        |      0.30 |       0.53 #> 0.00        |     -0.13 |       0.80 #> 0.00        |      0.03 |       0.25 #> 0.00        |      0.06 |       0.09 #> 0.00        |      0.55 |       0.60 #> 0.00        |     -0.39 |       0.23 #> 0.00        |     -0.22 |       0.64 #> 0.00        |      0.45 |       0.15 #> 0.00        |      0.43 |       0.56 #> 0.00        |      0.45 |       0.38 #> 0.00        |      0.26 |       0.19 #> 0.00        |     -0.05 |       0.61 #> 0.00        |      0.33 |       0.31 #> 0.00        |     -0.06 |       0.43 #> 0.00        |      0.30 |       0.33 #> 0.00        |  6.35e-03 |       0.58 #> 0.00        |      0.11 |       0.35 #> 0.00        |      0.13 |       0.49 #> 0.00        |      0.16 |       0.21 #> 0.00        |      0.11 |       0.24 #> 0.00        |      0.34 |       0.50 #> 0.00        |      0.11 |       0.26 #> 0.00        |      0.13 |       0.65 #> 0.00        |     -0.05 |       0.38 #> 0.00        |     -0.21 |       0.76 #> 0.00        |      0.09 |  -5.23e-04 #> 0.00        | -9.35e-03 |       0.66 #> 0.00        |      0.15 |       0.20 #> 0.00        |      0.19 |       0.38 #> 0.00        |      0.22 |       0.51 #> 0.00        |     -0.01 |       0.35 #> 0.00        |      0.17 |       0.28 #> 0.00        |      0.21 |       0.26 #> 0.00        |     -0.03 |       0.36 #> 0.00        |      0.16 |       0.54 #> 0.00        |      0.05 |       0.32 #> 0.00        |      0.06 |       0.33 #> 0.00        |      0.05 |       0.54 #> 0.00        |      0.04 |       0.60 #> 0.00        |      0.23 |       0.33 #> 0.00        |      0.26 |       0.59 #> 0.00        |     -0.02 |       0.74 #> 0.00        |      0.11 |       0.19 #> 0.00        |      0.06 |       0.59 #> 0.00        | -6.56e-03 |       0.49 #> 0.00        |      0.08 |       0.65 #> 0.00        |     -0.03 |       0.61 #> 0.00        |      0.28 |       0.39 #> 0.00        |     -0.15 |       0.40 #> 0.00        |      0.40 |       0.47 #> 0.00        |      0.23 |       0.51 #> 0.00        |      0.20 |       0.47 #> 0.00        |      0.16 |       0.25 #> 0.00        |      0.28 |       0.28 #> 0.00        |      0.22 |       0.23 #> 0.00        |      0.03 |       0.67 #> 0.00        |     -0.09 |       0.59 #> 0.00        |     -0.09 |       0.70 #> 0.00        |      0.30 |       0.16 #> 0.00        |      0.33 |       0.56 #> 0.00        |      0.28 |       0.40 #> 0.00        |      0.26 |       0.20 #> 0.00        |      0.26 |       0.20 #> 0.00        |      0.33 |       0.38 #> 0.00        |      0.07 |       0.55 #> 0.00        |      0.19 |       0.27 #> 0.00        |     -0.05 |       0.57 #> 0.00        |      0.08 |       0.48 #> 0.00        |     -0.06 |       0.59 #> 0.00        |     -0.11 |       0.35 #> 0.00        |      0.17 |       0.51 #> 0.00        |      0.04 |       0.37 #> 0.00        |      0.31 |       0.34 #> 0.00        |      0.29 |       0.24 #> 0.00        |     -0.22 |       0.39 #> 0.00        |      0.16 |       0.53 #> 0.00        |      0.21 |       0.51 #> 0.00        |      0.26 |       0.44 #> 0.00        |      0.11 |       0.24 #> 0.00        |      0.14 |       0.60 #> 0.00        |      0.20 |       0.23 #> 0.00        |     -0.03 |       0.60 #> 0.00        |     -0.02 |       0.53 #> 0.00        |      0.07 |       0.34 #> 0.00        |     -0.12 |       0.31 #> 0.00        |     -0.17 |       0.23 #> 0.00        |     -0.09 |       0.31 #> 0.00        |      0.29 |       0.50 #> 0.00        |     -0.10 |       0.38 #> 0.00        |      0.08 |       0.46 #> 0.00        |      0.19 |       0.51 #> 0.00        |     -0.26 |       0.92 #> 0.00        |      0.42 |       0.18 #> 0.00        |      0.31 |       0.32 #> 0.00        |      0.30 |       0.19 #> 0.00        |      0.18 |       0.29 #> 0.00        |     -0.13 |       0.65 #> 0.00        |      0.06 |       0.62 #> 0.00        |      0.14 |       0.18 #> 0.00        |      0.06 |       0.35 #> 0.00        |      0.03 |       0.28 #> 0.00        |      0.30 |       0.54 #> 0.00        |      0.26 |       0.47 #> 0.00        |      0.34 |       0.35 #> 0.00        |      0.22 |       0.23 #> 0.00        |      0.29 |       0.08 #> 0.00        |      0.19 |       0.05 #> 0.00        |     -0.15 |       0.53 #> 0.00        |     -0.03 |       0.27 #> 0.00        |      0.22 |       0.63 #> 0.00        |      0.15 |       0.42 #> 0.00        |      0.07 |       0.42 #> 0.00        |      0.08 |       0.42 #> 0.00        | -3.94e-05 |       0.35 #> 0.00        |      0.38 |       0.41 #> 0.00        |      0.13 |       0.41 #> 0.00        |      0.41 |       0.48 #> 0.00        |     -0.10 |       0.39 #> 0.00        |     -0.05 |       0.38 #> 0.00        |      0.14 |       0.41 #> 0.00        |     -0.14 |       0.35 #> 0.00        |      0.29 |       0.07 #> 0.00        |      0.42 |       0.12 #> 0.00        |      0.29 |       0.27 #> 0.00        |  7.92e-03 |       0.67 #> 0.00        |      0.11 |       0.24 #> 0.00        |      0.09 |       0.56 #> 0.00        |      0.05 |       0.37 #> 0.00        |     -0.09 |       0.61 #> 0.00        |      0.27 |       0.35 #> 0.00        |      0.45 |       0.35 #> 0.00        |      0.09 |       0.43 #> 0.00        |      0.08 |       0.47 #> 0.00        |      0.30 |       0.12 #> 0.00        |     -0.23 |       0.59 #> 0.00        |      0.18 |       0.62 #> 0.00        |      0.55 |       0.61 #> 0.00        |      0.24 |       0.28 #> 0.00        |     -0.06 |       0.55 #> 0.00        |      0.08 |       0.41 #> 0.00        |     -0.06 |       0.34 #> 0.00        |      0.15 |       0.47 #> 0.00        |      0.28 |       0.47 #> 0.00        |     -0.18 |       0.27 #> 0.00        |      0.06 |       0.55 #> 0.00        |     -0.02 |       0.62 #> 0.00        |      0.07 |       0.42 #> 0.00        |      0.52 |       0.21 #> 0.00        |      0.46 |       0.21 #> 0.00        |      0.28 |       0.60 #> 0.00        |      0.03 |       0.18 #> 0.00        |      0.16 |       0.47 #> 0.00        |      0.27 |       0.22 #> 0.00        |     -0.11 |       0.58 #> 0.00        |      0.27 |       0.27 #> 0.00        |      0.18 |       0.38 #> 0.00        |      0.19 |       0.38 #> 0.00        |      0.16 |       0.68 #> 0.00        |     -0.13 |       0.12 #> 0.00        |     -0.07 |       0.21 #> 0.00        |      0.12 |       0.66 #> 0.00        |      0.03 |       0.08 #> 0.00        |      0.11 |       0.42 #> 0.00        |      0.11 |       0.44 #> 0.00        |     -0.10 |       0.46 #> 0.00        |     -0.04 |       0.69 #> 0.00        |      0.29 |       0.24 #> 0.00        |      0.34 |       0.19 #> 0.00        |     -0.08 |       0.67 #> 0.00        |     -0.23 |       0.61 #> 0.00        |     -0.19 |       0.51 #> 0.00        |     -0.04 |       0.69 #> 0.00        |     -0.06 |       0.52 #> 0.00        |      0.08 |       0.54 #> 0.00        |     -0.31 |       0.56 #> 0.00        |      0.28 |       0.25 #> 0.00        |      0.08 |       0.28 #> 0.00        |      0.22 |       0.28 #> 0.00        |      0.13 |       0.34 #> 0.00        |      0.17 |   9.50e-04 #> 0.00        |      0.26 |       0.71 #> 0.00        |      0.03 |       0.50 #> 0.00        |      0.25 |       0.57 #> 0.00        |      0.35 |       0.56 #> 0.00        |      0.02 |       0.83 #> 0.00        |      0.01 |       0.81 #> 0.00        |  6.17e-03 |       0.71 #> 0.00        |      0.13 |       0.09 #> 0.00        |      0.29 |       0.53 #> 0.00        |      0.22 |       0.10 #> 0.00        |     -0.12 |       0.75 #> 0.00        | -6.81e-03 |       0.35 #> 0.00        |      0.48 |       0.49 #> 0.00        |     -0.17 |       0.42 #> 0.00        |      0.02 |       0.47 #> 0.00        |      0.32 |       0.26 #> 0.00        |     -0.04 |       0.46 #> 0.00        |      0.02 |       0.48 #> 0.00        |      0.17 |       0.30 #> 0.00        |      0.11 |       0.35 #> 0.00        |      0.20 |       0.41 #> 0.00        |      0.06 |       0.47 #> 0.00        |      0.03 |       0.42 #> 0.00        |     -0.17 |       0.37 #> 0.00        |  6.32e-03 |       0.70 #> 0.00        |     -0.10 |       0.48 #> 0.00        |     -0.16 |       0.13 #> 0.00        |     -0.16 |       0.55 #> 0.00        |      0.21 |       0.25 #> 0.00        |      0.28 |       0.47 #> 0.00        |      0.34 |       0.40 #> 0.00        |      0.21 |       0.14 #> 0.00        |      0.29 |       0.45 #> 0.00        |     -0.08 |       0.46 #> 0.00        |      0.11 |       0.50 #> 0.00        |      0.04 |       0.23 #> 0.00        |      0.21 |       0.62 #> 0.00        |      0.29 |       0.53 #> 0.00        |     -0.10 |       0.20 #> 0.00        |      0.18 |       0.31 #> 0.00        |      0.24 |       0.55 #> 0.00        |     -0.05 |       0.33 #> 0.00        |      0.06 |       0.50 #> 0.00        |      0.03 |       0.55 #> 0.00        |      0.15 |       0.61 #> 0.00        |      0.11 |       0.27 #> 0.00        |      0.16 |       0.57 #> 0.00        |      0.11 |       0.23 #> 0.00        |      0.12 |       0.31 #> 0.00        |     -0.01 |       0.54 #> 0.00        |      0.27 |       0.27 #> 0.00        |     -0.06 |       0.55 #> 0.00        |     -0.07 |       0.42 #> 0.00        |      0.24 |       0.32 #> 0.00        |      0.09 |       0.61 #> 0.00        |      0.28 |       0.13 #> 0.00        |      0.05 |       0.31 #> 0.00        |      0.14 |       0.21 #> 0.00        |     -0.05 |       0.37 #> 0.00        |      0.26 |       0.55 #> 0.00        |      0.38 |       0.60 #> 0.00        |     -0.17 |       0.50 #> 0.00        |      0.04 |       0.52 #> 0.00        |      0.26 |       0.49 #> 0.00        |     -0.24 |       0.37 #> 0.00        |      0.60 |       0.28 #> 0.00        |     -0.32 |       0.55 #> 0.00        |     -0.25 |       0.40 #> 0.00        |     -0.18 |       0.40 #> 0.00        |      0.44 |       0.44 #> 0.00        |      0.12 |       0.38 #> 0.00        |      0.10 |       0.47 #> 0.00        |      0.03 |       0.66 #> 0.00        |      0.04 |       0.62 #> 0.00        |      0.14 |       0.23 #> 0.00        |     -0.08 |       0.69 #> 0.00        |     -0.14 |       0.67 #> 0.00        |     -0.13 |       0.70 #> 0.00        |      0.06 |       0.15 #> 0.00        |     -0.17 |       0.85 #> 0.00        |      0.07 |       0.68 #> 0.00        |      0.25 |       0.20 #> 0.00        |      0.21 |       0.23 #> 0.00        |     -0.04 |       0.42 #> 0.00        |      0.03 |       0.52 #> 0.00        |      0.12 |       0.37 #> 0.00        |     -0.06 |       0.43 #> 0.00        |      0.04 |       0.54 #> 0.00        |      0.07 |       0.33 #> 0.00        |      0.11 |       0.36 #> 0.00        |      0.10 |       0.52 #> 0.00        |      0.03 |       0.36 #> 0.00        |      0.09 |       0.59 #> 0.00        |     -0.39 |       0.59 #> 0.00        |      0.36 |       0.45 #> 0.00        |      0.17 |       0.32 #> 0.00        |      0.35 |       0.74 #> 0.00        |     -0.05 |       0.03 #> 0.00        |      0.15 |       0.26 #> 0.00        |      0.05 |       0.33 #> 0.00        |      0.37 |       0.43 #> 0.00        |     -0.24 |       0.57 #> 0.00        |      0.18 |       0.36 #> 0.00        |     -0.15 |       0.55 #> 0.00        |      0.37 |       0.22 #> 0.00        |      0.40 |       0.31 #> 0.00        |      0.36 |       0.30 #> 0.00        |     -0.08 |       0.50 #> 0.00        |      0.11 |       0.23 #> 0.00        |      0.06 |       0.45 #> 0.00        |      0.18 |       0.40 #> 0.00        |     -0.03 |       0.36 #> 0.00        |     -0.16 |       0.39 #> 0.00        |      0.20 |       0.27 #> 0.00        |     -0.13 |       0.31 #> 0.00        |      0.28 |       0.54 #> 0.00        |     -0.07 |       0.31 #> 0.00        |      0.27 |       0.52 #> 0.00        |      0.41 |       0.46 #> 0.00        |      0.13 |       0.19 #> 0.00        |      0.09 |       0.38 #> 0.00        |      0.19 |       0.58 #> 0.00        |      0.35 |      -0.08 #> 0.00        |      0.28 |       0.64 #> 0.00        | -9.05e-03 |       0.33 #> 0.00        |      0.07 |       0.40 #> 0.00        |      0.17 |       0.32 #> 0.00        |      0.13 |       0.52 #> 0.00        |     -0.14 |       0.50 #> 0.00        |      0.12 |       0.32 #> 0.00        |      0.12 |       0.32 #> 0.00        |      0.14 |       0.73 #> 0.00        |      0.15 |       0.48 #> 0.00        |      0.30 |       0.27 #> 0.00        |      0.11 |       0.44 #> 0.00        |      0.13 |       0.52 #> 0.00        |      0.21 |       0.22 #> 0.00        |      0.47 |       0.36 #> 0.00        |      0.61 |       0.53 #> 0.00        |      0.10 |       0.55 #> 0.00        |      0.38 |       0.17 #> 0.00        |     -0.19 |       0.57 #> 0.00        |      0.33 |       0.37 #> 0.00        |      0.30 |       0.28 #> 0.00        |      0.18 |       0.27 #> 0.00        |     -0.10 |       0.39 #> 0.00        |      0.22 |       0.38 #> 0.00        |      0.44 |       0.43 #> 0.00        |      0.17 |       0.52 #> 0.00        |      0.29 |       0.69 #> 0.00        |     -0.02 |       0.25 #> 0.00        |      0.20 |       0.51 #> 0.00        |      0.10 |       0.55 #> 0.00        |      0.05 |       0.35 #> 0.00        |     -0.10 |       0.81 #> 0.00        |     -0.07 |       0.41 #> 0.00        |      0.20 |       0.33 #> 0.00        |     -0.03 |       0.47 #> 0.00        |      0.14 |       0.31 #> 0.00        |      0.45 |       0.41 #> 0.00        |  3.28e-04 |       0.10 #> 0.00        |      0.16 |       0.58 #> 0.00        |      0.06 |       0.20 #> 0.00        |     -0.05 |       0.70 #> 0.00        |      0.26 |       0.35 #> 0.00        |      0.23 |       0.34 #> 0.00        |      0.06 |       0.42 #> 0.00        |     -0.12 |       0.69 #> 0.00        |      0.04 |       0.42 #> 0.00        |      0.25 |       0.38 head(standardize_posteriors(model, method = \"basic\", verbose = FALSE)) #> # Standardization method: basic #>  #> (Intercept) | critical | privileges #> ----------------------------------- #> 0.00        |     0.21 |       0.51 #> 0.00        |    -0.02 |       0.31 #> 0.00        |     0.07 |       0.33 #> 0.00        |    -0.03 |       0.13 #> 0.00        |    -0.03 |       0.23 #> 0.00        |    -0.08 |       0.34 # }"},{"path":[]},{"path":"https://easystats.github.io/parameters/news/index.html","id":"breaking-changes-0-24-0","dir":"Changelog","previous_headings":"","what":"Breaking Changes","title":"parameters 0.24.0","text":"robust argument, deprecated long time, now longer supported. Please use vcov vcov_args instead.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"changes-0-24-0","dir":"Changelog","previous_headings":"","what":"Changes","title":"parameters 0.24.0","text":"Added support coxph.panel models. Added support anova() models survey package. Documentation re-organized clarified, index reduced removing redundant class-documentation.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"bug-fixes-0-24-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"parameters 0.24.0","text":"Fixed bug extracting ‘pretty labels’ model parameters, fail predictors character vectors. Fixed bug inaccurate standard errors models package fixest used sunab() function formula.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"parameters-0230","dir":"Changelog","previous_headings":"","what":"parameters 0.23.0","title":"parameters 0.23.0","text":"CRAN release: 2024-10-18","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"breaking-changes-0-23-0","dir":"Changelog","previous_headings":"","what":"Breaking Changes","title":"parameters 0.23.0","text":"Argument summary model_parameters() now deprecated. Please use include_info instead. Changed output style included additional information model formula, sigma R2 printing model parameters. information now also includes RMSE.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"changes-0-23-0","dir":"Changelog","previous_headings":"","what":"Changes","title":"parameters 0.23.0","text":"Used accurate analytic approach calculate normal distributions SGPV equivalence_test() used p_significance(). Added p_direction() methods frequentist models. convenient way test direction effect, formerly already (still ) possible pd = TRUE model_parameters(). p_function(), p_significance() equivalence_test() get vcov vcov_args argument, results can based robust standard errors confidence intervals. equivalence_test() p_significance() work objects returned model_parameters(). pool_parameters() now better deals models multiple components (e.g. zero-inflation dispersion). Revision / enhancement documentation. Updated glmmTMB methods work latest version package. Improved printing simulate_parameters() models packages mclogit. print() compare_parameters() now also puts factor levels square brackets, like print() method model_parameters(). include_reference now adds reference category factors parameters table factors appropriate contrasts (treatment SAS contrasts).","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"bug-fixes-0-23-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"parameters 0.23.0","text":"Arguments like digits etc. ignored `model_parameters() objects marginaleffects package.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"parameters-0222","dir":"Changelog","previous_headings":"","what":"parameters 0.22.2","title":"parameters 0.22.2","text":"CRAN release: 2024-09-03","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"new-supported-models-0-22-2","dir":"Changelog","previous_headings":"","what":"New supported models","title":"parameters 0.22.2","text":"Support models glm_weightit, multinom_weightit ordinal_weightit package WeightIt.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"changes-0-22-2","dir":"Changelog","previous_headings":"","what":"Changes","title":"parameters 0.22.2","text":"Added p_significance() methods frequentist models. Methods degrees_of_freedom() removed. degrees_of_freedom() now calls insight::get_df(). model_parameters() data frames draws objects package posterior also gets exponentiate argument.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"bug-fixes-0-22-2","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"parameters 0.22.2","text":"Fixed issue warning spuriously high coefficients Stan-models (non-Gaussian).","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"parameters-0221","dir":"Changelog","previous_headings":"","what":"parameters 0.22.1","title":"parameters 0.22.1","text":"CRAN release: 2024-07-21","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"breaking-changes-0-22-1","dir":"Changelog","previous_headings":"","what":"Breaking changes","title":"parameters 0.22.1","text":"Revised calculation second generation p-value (SGPV) equivalence_test(), now accurate related proportion interval falls inside ROPE. Formerly, confidence interval simply treated uniformly distributed calculating SGPV, now interval assumed normally distributed.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"new-supported-models-0-22-1","dir":"Changelog","previous_headings":"","what":"New supported models","title":"parameters 0.22.1","text":"Support svy2lme models package svylme.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"changes-0-22-1","dir":"Changelog","previous_headings":"","what":"Changes","title":"parameters 0.22.1","text":"standardize_parameters() now also prettifies labels factors.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"bug-fixes-0-22-1","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"parameters 0.22.1","text":"Fixed issue equivalence_test() ROPE range symmetrically centered around zero (e.g., range = c(-99, 0.1)). model_parameters() anova() mixed models now also includes denominator degrees freedom output (df_error). print(..., pretty_names = \"labels\") tobit-models package AER now include value labels, available. Patch release, ensure performance runs older version datawizard Mac OS X R (old-release).","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"parameters-0220","dir":"Changelog","previous_headings":"","what":"parameters 0.22.0","title":"parameters 0.22.0","text":"CRAN release: 2024-06-20","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"breaking-changes-0-22-0","dir":"Changelog","previous_headings":"","what":"Breaking changes","title":"parameters 0.22.0","text":"Deprecated arguments model_parameters() htest, aov BFBayesFactor objects removed. Argument effectsize_type deprecated. Please use es_type now. change necessary avoid conflicts partial matching argument names (: effects).","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"new-supported-models-0-22-0","dir":"Changelog","previous_headings":"","what":"New supported models","title":"parameters 0.22.0","text":"Support objects stats::Box.test(). Support glmgee models package glmtoolbox.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"bug-fix-0-22-0","dir":"Changelog","previous_headings":"","what":"Bug fix","title":"parameters 0.22.0","text":"Fixed edge case predict() factor_analysis(). Fixed wrong ORCID DESCRIPTION.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"parameters-0217","dir":"Changelog","previous_headings":"","what":"parameters 0.21.7","title":"parameters 0.21.7","text":"CRAN release: 2024-05-14","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"changes-0-21-7","dir":"Changelog","previous_headings":"","what":"Changes","title":"parameters 0.21.7","text":"Fixed issues related latest release marginaleffects.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"bug-fixes-0-21-7","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"parameters 0.21.7","text":"Fixes issue compare_parameters() models package blme. Fixed conflict model_parameters() include_reference = TRUE pretty_names = \"labels\" used. Now, pretty labels correctly updated preserved.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"parameters-0216","dir":"Changelog","previous_headings":"","what":"parameters 0.21.6","title":"parameters 0.21.6","text":"CRAN release: 2024-03-18","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"new-supported-models-0-21-6","dir":"Changelog","previous_headings":"","what":"New supported models","title":"parameters 0.21.6","text":"Support models class serp (serp).","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"changes-0-21-6","dir":"Changelog","previous_headings":"","what":"Changes","title":"parameters 0.21.6","text":"include_reference can now directly set TRUE model_parameters() doesn’t require call print() anymore. compare_parameters() gains include_reference argument, add reference category categorical predictors parameters table. print_md() compare_parameters() now default uses tinytable package create markdown tables. allows better control column heading spanning multiple columns.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"bug-fixes-0-21-6","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"parameters 0.21.6","text":"Fixed issue parameter names model_parameters() objects package epiR. Fixed issue exponentiate = TRUE model_parameters() models class clmm (package ordinal), model component column (e.g., scale location parameters returned). include_reference now also works factor created “--fly” inside model formula (.e. y ~ .factor(x)).","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"parameters-0215","dir":"Changelog","previous_headings":"","what":"parameters 0.21.5","title":"parameters 0.21.5","text":"CRAN release: 2024-02-07","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"bug-fixes-0-21-5","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"parameters 0.21.5","text":"Fixes CRAN check errors related changes latest update marginaleffects.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"parameters-0214","dir":"Changelog","previous_headings":"","what":"parameters 0.21.4","title":"parameters 0.21.4","text":"CRAN release: 2024-02-03","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"breaking-changes-0-21-4","dir":"Changelog","previous_headings":"","what":"Breaking changes","title":"parameters 0.21.4","text":"exponentiate argument model_parameters() marginaleffects::predictions() now defaults FALSE, line model_parameters() methods.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"changes-0-21-4","dir":"Changelog","previous_headings":"","what":"Changes","title":"parameters 0.21.4","text":"model_parameters() models package survey now gives informative messages bootstrap = TRUE (currently supported). n_factors() now also returns explained variance number factors attributes. model_parameters() objects package metafor now warns unsupported arguments (like vcov) used. Improved documentation pool_parameters().","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"bug-fixes-0-21-4","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"parameters 0.21.4","text":"print(include_reference = TRUE) model_parameters() work run inside pipe-chain. Fixed issues format() objects returned compare_parameters() included mixed models.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"parameters-0213","dir":"Changelog","previous_headings":"","what":"parameters 0.21.3","title":"parameters 0.21.3","text":"CRAN release: 2023-11-02","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"changes-0-21-3","dir":"Changelog","previous_headings":"","what":"Changes","title":"parameters 0.21.3","text":"principal_components() factor_analysis() now also work argument n = 1. print_md() compare_parameters() now gains arguments, similar print() method. bootstrap_parameters() model_parameters() now accept bootstrapped samples returned bootstrap_model(). print() method model_parameters() now also yields warning models logit-links possible issues (quasi) complete separation occur.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"bug-fixes-0-21-3","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"parameters 0.21.3","text":"Fixed issue print_html() objects package ggeffects. Fixed issues nnet::multinom() wide-format response variables (using cbind()). Minor fixes print_html() method model_parameters(). Robust standard errors (argument vcov) now works plm models.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"parameters-0212","dir":"Changelog","previous_headings":"","what":"parameters 0.21.2","title":"parameters 0.21.2","text":"CRAN release: 2023-09-16","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"changes-0-21-2","dir":"Changelog","previous_headings":"","what":"Changes","title":"parameters 0.21.2","text":"Minor improvements factor analysis functions. ci_digits argument print() method model_parameters() now defaults value digits. model_parameters() objects package marginaleffects now also accepts exponentiate argument. print(), print_html(), print_md() format() methods model_parameters() get include_reference argument, add reference category categorical predictors parameters table.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"bug-fixes-0-21-2","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"parameters 0.21.2","text":"Fixed issue wrong calculation test-statistic p-values model_parameters() fixest models. Fixed issue wrong column header glm models family = binomial(\"identiy\"). Minor fixes dominance_analysis().","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"parameters-0211","dir":"Changelog","previous_headings":"","what":"parameters 0.21.1","title":"parameters 0.21.1","text":"CRAN release: 2023-05-26","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"general-0-21-1","dir":"Changelog","previous_headings":"","what":"General","title":"parameters 0.21.1","text":"Added support models class nestedLogit (nestedLogit).","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"changes-to-functions-0-21-1","dir":"Changelog","previous_headings":"","what":"Changes to functions","title":"parameters 0.21.1","text":"model_parameters() now also prints correct “pretty names” predictors converted ordered factors inside formulas, e.g. y ~ .ordered(x). model_parameters() now prints message vcov argument provided ci_method explicitly set \"profile\". Else, vcov NULL ci_method NULL, defaults \"wald\", return confidence intervals based robust standard errors.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"parameters-0210","dir":"Changelog","previous_headings":"","what":"parameters 0.21.0","title":"parameters 0.21.0","text":"CRAN release: 2023-04-19","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"breaking-changes-0-21-0","dir":"Changelog","previous_headings":"","what":"Breaking Changes","title":"parameters 0.21.0","text":"longer possible calculate Satterthwaite-approximated degrees freedom mixed models package nlme. based lavaSearch2 package, longer seems support models class lme.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"changes-to-functions-0-21-0","dir":"Changelog","previous_headings":"","what":"Changes to functions","title":"parameters 0.21.0","text":"Improved support objects class mipo models ordinal categorical outcome.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"parameters-0203","dir":"Changelog","previous_headings":"","what":"parameters 0.20.3","title":"parameters 0.20.3","text":"CRAN release: 2023-04-05","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"general-0-20-3","dir":"Changelog","previous_headings":"","what":"General","title":"parameters 0.20.3","text":"Added support models class hglm (hglm), mblogit (mclogit), fixest_multi (fixest), phylolm / phyloglm (phylolm). .data.frame methods extracting posterior draws via bootstrap_model() retired. Instead, directly using bootstrap_model() recommended.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"changes-to-functions-0-20-3","dir":"Changelog","previous_headings":"","what":"Changes to functions","title":"parameters 0.20.3","text":"equivalence_test() gets method ggeffects objects package ggeffects. equivalence_test() now prints SGPV column instead % ROPE. former % ROPE actually equivalent second generation p-value (SGPV) refers proportion range confidence interval covered ROPE. However, % ROPE refer probability mass underlying distribution confidence interval covered ROPE, hence old column name bit misleading. Fixed issue model_parameters.ggeffects() address forthcoming changes ggeffects package.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"bug-fixes-0-20-3","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"parameters 0.20.3","text":"invalid supported value p_adjust argument model_parameters() provided, valid options shown correct capital letters, appropriate. Fixed bug cluster_analysis() include_factors = TRUE. Fixed warning model_parameters() ci() models package glmmTMB ci_method either \"profile\" \"uniroot\".","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"parameters-0202","dir":"Changelog","previous_headings":"","what":"parameters 0.20.2","title":"parameters 0.20.2","text":"CRAN release: 2023-01-27","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"general-0-20-2","dir":"Changelog","previous_headings":"","what":"General","title":"parameters 0.20.2","text":"Reduce unnecessary warnings. deprecated argument df_method model_parameters()removed. Output model_parameters() objects returned manova() car::Manova() now consistent.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"bug-fix-0-20-2","dir":"Changelog","previous_headings":"","what":"Bug fix","title":"parameters 0.20.2","text":"Fixed issues tests mmrm models. Fixed issue bootstrap_model() models class glmmTMB dispersion parameters. Fixed failing examples.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"parameters-0201","dir":"Changelog","previous_headings":"","what":"parameters 0.20.1","title":"parameters 0.20.1","text":"CRAN release: 2023-01-11","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"general-0-20-1","dir":"Changelog","previous_headings":"","what":"General","title":"parameters 0.20.1","text":"Added support models class flic flac (logistf), mmrm (mmrm).","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"changes-0-20-1","dir":"Changelog","previous_headings":"","what":"Changes","title":"parameters 0.20.1","text":"model_parameters() now includes Group column stanreg brmsfit models random effects. print() method model_parameters() now uses pattern print random effect variances Bayesian models frequentist models.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"bug-fix-0-20-1","dir":"Changelog","previous_headings":"","what":"Bug fix","title":"parameters 0.20.1","text":"Fixed issue print() method compare_parameters(), duplicated random effects parameters rows edge cases. Fixed issue print() method compare_parameters(), didn’t work properly ci=NULL.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"parameters-0200","dir":"Changelog","previous_headings":"","what":"parameters 0.20.0","title":"parameters 0.20.0","text":"CRAN release: 2022-11-21","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"breaking-0-20-0","dir":"Changelog","previous_headings":"","what":"Breaking","title":"parameters 0.20.0","text":"deprecated argument df_method model_parameters() now defunct throws error used. deprecated functions ci_robust(), p_robust() standard_error_robust removed. superseded vcov argument ci(), p_value(), standard_error(), respectively. style argument compare_parameters() renamed select.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"new-functions-0-20-0","dir":"Changelog","previous_headings":"","what":"New functions","title":"parameters 0.20.0","text":"p_function(), print plot p-values compatibility (confidence) intervals statistical models, different levels. allows see estimates compatible model various compatibility levels. p_calibrate(), compute calibrated p-values.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"changes-0-20-0","dir":"Changelog","previous_headings":"","what":"Changes","title":"parameters 0.20.0","text":"model_parameters() compare_parameters() now use unicode character multiplication-sign interaction mark (.e. \\u00d7). Use options(parameters_interaction = <value>) argument interaction_mark use different character interaction mark. select argument compare_parameters(), used control table column elements, now supports experimental glue-like syntax. See vignette Printing Model Parameters. Furthermore, select argument can also used print() method model_parameters(). print_html() gets font_size line_padding argument tweak appearance HTML tables. Furthermore, arguments select column_labels new, customize column layout tables. See examples ?display. Consolidation vignettes standardization model parameters. Minor speed improvements.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"bug-fix-0-20-0","dir":"Changelog","previous_headings":"","what":"Bug fix","title":"parameters 0.20.0","text":"model_parameters().BFBayesFactor longer drops BF column Bayes factor NA. print() display() methods model_parameters() Bayesian models now pass ... insight::format_table(), allowing extra arguments recognized. Fixed footer message regarding approximation method CU p-values mixed models. Fixed issues print() method compare_parameters() mixed models, models contained within-components (see wb_component) others .","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"parameters-0190","dir":"Changelog","previous_headings":"","what":"parameters 0.19.0","title":"parameters 0.19.0","text":"CRAN release: 2022-10-05","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"breaking-0-19-0","dir":"Changelog","previous_headings":"","what":"Breaking","title":"parameters 0.19.0","text":"Arguments calculate effectsize model_parameters() htest, Anova objects objects class BFBayesFactor revised. Instead single arguments different effectsizes, now one argument, effectsize_type. reason behind change meanwhile many new type effectsizes added effectsize package, generic argument allows make use effect sizes. attribute name PCA / EFA changed data_set dataset. minimum needed R version bumped 3.6. Removed deprecated argument parameters model_parameters(). standard_error_robust(), ci_robust() p_value_robust() now deprecated superseded vcov vcov_args arguments related methods standard_error(), ci() p_value(), respectively. Following functions moved package parameters performance: check_sphericity_bartlett(), check_kmo(), check_factorstructure() check_clusterstructure().","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"changes-to-functions-0-19-0","dir":"Changelog","previous_headings":"","what":"Changes to functions","title":"parameters 0.19.0","text":"Added sparse option principal_components() sparse PCA. pretty_names argument print() method can now also \"labels\", use variable value labels (data labelled) pretty names. labels found, default pretty names used. bootstrap_model() models class glmmTMB merMod gains cluster argument specify optional clusters parallel option set \"snow\". P-value adjustment (argument p_adjust model_parameters()) now performed potential parameters removed (using keep drop), adjusted p-values applied parameters interest. Robust standard errors now supported fixest models vcov argument. print() model_parameters() gains footer argument, can used suppress footer output. , footer = \"\" footer = FALSE print_md(), footer printed. simulate_model() simulate_parameters() now pass ... insight::get_varcov(), allow simulated draws based heteroscedasticity consistent variance covariance matrices. print() method compare_parameters() improved models multiple components (e.g., mixed models fixed random effects, models count- zero-inflation parts). models, compare_parameters(effects = \"\", component = \"\") prints nicely.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"bug-fixes-0-19-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"parameters 0.19.0","text":"Fix erroneous warning p-value adjustments differences original adjusted p-values small.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"parameters-0182","dir":"Changelog","previous_headings":"","what":"parameters 0.18.2","title":"parameters 0.18.2","text":"CRAN release: 2022-08-10","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"new-functions-0-18-2","dir":"Changelog","previous_headings":"","what":"New functions","title":"parameters 0.18.2","text":"New function dominance_analysis(), compute dominance analysis statistics designations.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"changes-to-functions-0-18-2","dir":"Changelog","previous_headings":"","what":"Changes to functions","title":"parameters 0.18.2","text":"Argument ci_random model_parameters() defaults NULL. uses heuristic determine random effects confidence intervals likely take long time compute, automatically includes excludes confidence intervals. Set ci_random TRUE FALSE explicitly calculate omit confidence intervals random effects.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"bug-fixes-0-18-2","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"parameters 0.18.2","text":"Fix issues pool_parameters() certain models special components (like MASS::polr()), failed argument component set \"conditional\" (default). Fix issues model_parameters() multiple imputation models package Hmisc.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"parameters-0181","dir":"Changelog","previous_headings":"","what":"parameters 0.18.1","title":"parameters 0.18.1","text":"CRAN release: 2022-05-29","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"general-0-18-1","dir":"Changelog","previous_headings":"","what":"General","title":"parameters 0.18.1","text":"now possible hide messages CI method tables specifying options(\"parameters_cimethod\" = FALSE) (#722). default, messages displayed. model_parameters() now supports objects package marginaleffects objects returned car::linearHypothesis(). Added predict() method cluster_meta objects. Reorganization docs model_parameters().","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"changes-to-functions-0-18-1","dir":"Changelog","previous_headings":"","what":"Changes to functions","title":"parameters 0.18.1","text":"model_parameters() now also includes standard errors confidence intervals slope-slope-correlations random effects variances. model_parameters() mixed models gains ci_random argument, toggle whether confidence intervals random effects parameters also computed. Set FALSE calculation confidence intervals random effects parameters takes long. ci() glmmTMB models method = \"profile\" now robust.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"bug-fixes-0-18-1","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"parameters 0.18.1","text":"Fixed issue glmmTMB models calculating confidence intervals random effects failed due singular fits. display() now correctly includes custom text additional information footer (#722). Fixed issue argument column_names compare_parameters() strings contained characters needed escaped regular expressions. Fixed issues unknown arguments model_parameters() lavaan models standardize = TRUE.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"parameters-0180","dir":"Changelog","previous_headings":"","what":"parameters 0.18.0","title":"parameters 0.18.0","text":"CRAN release: 2022-05-24","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"breaking-changes-0-18-0","dir":"Changelog","previous_headings":"","what":"Breaking Changes","title":"parameters 0.18.0","text":"model_parameters() now longer treats data frame inputs posterior samples. Rather, data frames, now NULL returned. want treat data frame posterior samples, set new argument as_draws = TRUE.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"new-functions-0-18-0","dir":"Changelog","previous_headings":"","what":"New functions","title":"parameters 0.18.0","text":"sort_parameters() sort model parameters coefficient values. standardize_parameters(), standardize_info() standardise_posteriors() standardize model parameters.","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/news/index.html","id":"model_parameters-0-18-0","dir":"Changelog","previous_headings":"Changes to functions","what":"model_parameters()","title":"parameters 0.18.0","text":"model_parameters() mixed models package lme4 now also reports confidence intervals random effect variances default. Formerly, CIs included ci_method \"profile\" \"boot\". merDeriv package required feature. model_parameters() htest objects now also supports models var.test(). Improved support anova.rms models model_parameters(). model_parameters() now supports draws objects package posterior deltaMethods objects package car. model_parameters() now checks arguments informs user specific given arguments supported model class (e.g., \"vcov\" currently supported models class glmmTMB).","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"bug-fixes-0-18-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"parameters 0.18.0","text":"vcov argument, used computing robust standard errors, calculate correct p-values confidence intervals models class lme. pool_parameters() save relevant model information attributes. model_parameters() models package glmmTMB work exponentiate = TRUE model contained dispersion parameter different sigma. Furthermore, exponentiating falsely exponentiated dispersion parameter.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"parameters-0170","dir":"Changelog","previous_headings":"","what":"parameters 0.17.0","title":"parameters 0.17.0","text":"CRAN release: 2022-03-10","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"general-0-17-0","dir":"Changelog","previous_headings":"","what":"General","title":"parameters 0.17.0","text":"Added options set defaults different arguments. Currently supported: options(\"parameters_summary\" = TRUE/FALSE), sets default value summary argument model_parameters() non-mixed models. options(\"parameters_mixed_summary\" = TRUE/FALSE), sets default value summary argument model_parameters() mixed models. Minor improvements print() methods. Robust uncertainty estimates: vcov_estimation, vcov_type, robust arguments deprecated functions: model_parameters(), parameters(), standard_error(), p_value(), ci(). replaced vcov vcov_args arguments. standard_error_robust() p_value_robust() functions superseded vcov vcov_args arguments standard_error() p_value() functions. Vignette: https://easystats.github.io/parameters/articles/model_parameters_robust.html","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"bug-fixes-0-17-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"parameters 0.17.0","text":"Fixed minor issues edge cases n_clusters() related cluster functions. Fixed issue p_value() returned wrong p-values fixest::feols().","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"parameters-0160","dir":"Changelog","previous_headings":"","what":"parameters 0.16.0","title":"parameters 0.16.0","text":"CRAN release: 2022-01-12","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"general-0-16-0","dir":"Changelog","previous_headings":"","what":"General","title":"parameters 0.16.0","text":"Improved speed performance model_parameters(), particular glm’s mixed models random effect variances calculated. Added options printing model_parameters(). See also revised vignette: https://easystats.github.io/parameters/articles/model_parameters_print.html","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/news/index.html","id":"model_parameters-0-16-0","dir":"Changelog","previous_headings":"Changes to functions","what":"model_parameters()","title":"parameters 0.16.0","text":"model_parameters() mixed models gains include_sigma argument. TRUE, adds residual variance, computed random effects variances, attribute returned data frame. Including sigma default behaviour, now defaults FALSE included include_sigma = TRUE, calculation time consuming. model_parameters() merMod models now also computes CIs random SD parameters ci_method=\"boot\" (previously, possible ci_method \"profile\"). model_parameters() glmmTMB models now computes CIs random SD parameters. Note based Wald-z-distribution. Similar model_parameters.htest(), model_parameters.BFBayesFactor() method gains cohens_d cramers_v arguments control need add frequentist effect size estimates returned summary data frame. Previously, done default. Column name coefficients emmeans objects now specific. model_prameters() MixMod objects (package GLMMadaptive) gains robust argument, compute robust standard errors.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"bug-fixes-0-16-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"parameters 0.16.0","text":"Fixed bug ci() class merMod method=\"boot\". Fixed issue correct association components ordinal models classes clm clm2. Fixed issues random_parameters() model_parameters() mixed models without random intercept. Confidence intervals random parameters model_parameters() failed (?) glmer models. Fix issue default ci_type compare_parameters() Bayesian models.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"parameters-0150","dir":"Changelog","previous_headings":"","what":"parameters 0.15.0","title":"parameters 0.15.0","text":"CRAN release: 2021-10-18","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"breaking-changes-0-15-0","dir":"Changelog","previous_headings":"","what":"Breaking changes","title":"parameters 0.15.0","text":"Following functions moved new datawizard package now re-exported parameters package: center() convert_data_to_numeric() data_partition() demean() (aliases degroup() detrend()) kurtosis() rescale_weights() skewness() smoothness() Note functions removed next release parameters package currently re-exported convenience package developers. release provide time make necessary changes breaking change implemented. Following functions moved performance package: check_heterogeneity() check_multimodal()","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"general-0-15-0","dir":"Changelog","previous_headings":"","what":"General","title":"parameters 0.15.0","text":"handling approximate degrees freedom model_parameters(), ci() p_value() revised now consistent. bugs related previous computation confidence intervals p-values fixed. Now possible change method approximate degrees freedom CIs p-values using ci_method, resp. method argument. change documented detail ?model_parameters, online : https://easystats.github.io/parameters/reference/model_parameters.html Minor changes print() glmmTMB dispersion parameter. Added vignette printing options model parameters.","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/news/index.html","id":"model_parameters-0-15-0","dir":"Changelog","previous_headings":"Changes to functions","what":"model_parameters()","title":"parameters 0.15.0","text":"df_method argument model_parameters() deprecated. Please use ci_method now. model_parameters() standardize = \"refit\" now returns random effects standardized model. model_parameters() ci() lmerMod models gain \"residuals\" option ci_method (resp. method) argument, explicitly calculate confidence intervals based residual degrees freedom, present. model_parameters() supports following new objects: trimcibt, wmcpAKP, dep.effect (WRS2 package), systemfit model_parameters() gains new argument table_wide ANOVA tables. can helpful users may wish report ANOVA table wide format (.e., numerator denominator degrees freedom row). model_parameters() gains two new arguments, keep drop. keep new names former parameters argument can used filter parameters. keep selects parameters whose names match regular expression pattern defined keep, drop counterpart excludes matching parameter names. model_parameters() called verbose = TRUE, ci_method default value, printed output includes message indicating approximation-method degrees freedom used. model_parameters() mixed models ci_method = \"profile computes (profiled) confidence intervals fixed random effects. Thus, ci_method = \"profile allows add confidence intervals random effect variances. model_parameters() longer fail supported model classes robust standard errors available.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"other-functions-0-15-0","dir":"Changelog","previous_headings":"Changes to functions","what":"Other functions","title":"parameters 0.15.0","text":"n_factors() methods based fit indices fixed can included separately (package = \"fit\"). Also added n_max argument crop output. compare_parameters() now also accepts list model objects. describe_distribution() gets verbose argument toggle warnings messages. format_parameters() removes dots underscores parameter names, make “human readable”. experimental calculation p-values equivalence_test() replaced proper calculation p-values. argument p_value removed p-values now always included. Minor improvements print(), print_html() print_md().","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"bug-fixes-0-15-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"parameters 0.15.0","text":"random effects returned model_parameters() mistakenly displayed residuals standard deviation square-root residual SD. Fixed issue model_parameters() brmsfit objects model standard errors (.e. meta-analysis). Fixed issue model_parameters lmerMod models , default, returned residual degrees freedom statistic column, confidence intervals based Inf degrees freedom instead. Fixed issue ci_satterthwaite(), used Inf degrees freedom instead Satterthwaite approximation. Fixed issue model_parameters.mlm() model contained interaction terms. Fixed issue model_parameters.rma() model contained interaction terms. Fixed sign error model_parameters.htest() objects created t.test.formula() (issue #552) Fixed issue computing random effect variances model_parameters() mixed models categorical random slopes.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"parameters-0140","dir":"Changelog","previous_headings":"","what":"parameters 0.14.0","title":"parameters 0.14.0","text":"CRAN release: 2021-05-29","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"breaking-changes-0-14-0","dir":"Changelog","previous_headings":"","what":"Breaking changes","title":"parameters 0.14.0","text":"check_sphericity() renamed check_sphericity_bartlett(). Removed deprecated arguments. model_parameters() bootstrapped samples used emmeans now treats bootstrap samples samples posterior distributions (Bayesian models).","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"new-supported-model-classes-0-14-0","dir":"Changelog","previous_headings":"","what":"New supported model classes","title":"parameters 0.14.0","text":"SemiParBIV (GJRM), selection (sampleSelection), htest survey package, pgmm (plm).","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"general-0-14-0","dir":"Changelog","previous_headings":"","what":"General","title":"parameters 0.14.0","text":"Performance improvements models package survey.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"new-functions-0-14-0","dir":"Changelog","previous_headings":"","what":"New functions","title":"parameters 0.14.0","text":"Added summary() method model_parameters(), convenient shortcut print(..., select = \"minimal\").","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/news/index.html","id":"model_parameters-0-14-0","dir":"Changelog","previous_headings":"Changes to functions","what":"model_parameters()","title":"parameters 0.14.0","text":"model_parameters() gains parameters argument, takes regular expression string, select specific parameters returned data frame. print() model_parameters() compare_parameters() gains groups argument, group parameters output. Furthermore, groups can used directly argument model_parameters() compare_parameters() passed print() method. model_parameters() ANOVAs now saves type attribute prints information footer output well. model_parameters() htest-objects now saves alternative hypothesis attribute prints information footer output well. model_parameters() passes arguments type, parallel n_cpus bootstrap_model() bootstrap = TRUE.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"other-0-14-0","dir":"Changelog","previous_headings":"Changes to functions","what":"other","title":"parameters 0.14.0","text":"bootstrap_models() merMod glmmTMB objects gains arguments set type bootstrapping allow parallel computing. bootstrap_parameters() gains ci_method type \"bci\", compute bias-corrected accelerated bootstrapped intervals. ci() svyglm gains method argument.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"bug-fixes-0-14-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"parameters 0.14.0","text":"Fixed issue model_parameters() emmGrid objects Bayesian models. Arguments digits, ci_digits p_digits ignored print() worked used call model_parameters() directly.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"parameters-0130","dir":"Changelog","previous_headings":"","what":"parameters 0.13.0","title":"parameters 0.13.0","text":"CRAN release: 2021-04-08","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"general-0-13-0","dir":"Changelog","previous_headings":"","what":"General","title":"parameters 0.13.0","text":"Revised improved print() method model_parameters().","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"new-supported-model-classes-0-13-0","dir":"Changelog","previous_headings":"","what":"New supported model classes","title":"parameters 0.13.0","text":"blrm (rmsb), AKP, med1way, robtab (WRS2), epi.2by2 (epiR), mjoint (joineRML), mhurdle (mhurdle), sarlm (spatialreg), model_fit (tidymodels), BGGM (BGGM), mvord (mvord)","code":""},{"path":[]},{"path":"https://easystats.github.io/parameters/news/index.html","id":"model_parameters-0-13-0","dir":"Changelog","previous_headings":"Changes to functions","what":"model_parameters()","title":"parameters 0.13.0","text":"model_parameters() blavaan models now fully treated Bayesian model thus relies functions bayestestR (.e. ROPE, Rhat ESS reported) . effects-argument model_parameters() mixed models revised now shows random effects variances default (functionality random_parameters(), mimicking behaviour broom.mixed::tidy()). group_level argument set TRUE, conditional modes (BLUPs) random effects shown. model_parameters() mixed models now returns Effects column even just one type “effects”, mimic behaviour broom.mixed::tidy(). conjunction standardize_names() users can get column names tidy() model_parameters() objects. model_parameters() t-tests now uses group values column names. print() model_parameters() gains zap_small argument, avoid scientific notation small numbers. Instead, zap_small forces round specified number digits. internally consistent, degrees freedom column lqm(m) cgam(m) objects (t-statistic) called df_error. model_parameters() gains summary argument add summary information model printed outputs. Minor improvements models quantreg. model_parameters supports rank-biserial, rank epsilon-squared, Kendall’s W effect size measures wilcox.test(), kruskal.test, friedman.test, respectively.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"other-functions-0-13-0","dir":"Changelog","previous_headings":"Changes to functions","what":"Other functions","title":"parameters 0.13.0","text":"describe_distribution() gets quartiles argument include 25th 75th quartiles variable.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"bug-fixes-0-13-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"parameters 0.13.0","text":"Fixed issue non-initialized argument style display() compare_parameters(). Make print() compare_parameters() work objects “simple” column names confidence intervals missing CI-level (.e. column named \"CI\" instead , say, \"95% CI\"). Fixed issue p_adjust model_parameters(), work adjustment-methods \"\" \"BH\". Fixed issue show_sigma print() model_parameters(). Fixed issue model_parameters() incorrect order degrees freedom.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"parameters-0120","dir":"Changelog","previous_headings":"","what":"parameters 0.12.0","title":"parameters 0.12.0","text":"CRAN release: 2021-02-21","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"general-0-12-0","dir":"Changelog","previous_headings":"","what":"General","title":"parameters 0.12.0","text":"Roll-back R dependency R >= 3.4. Bootstrapped estimates (bootstrap_model() bootstrap_parameters()) can passed emmeans obtain bootstrapped estimates, contrasts, simple slopes (etc) CIs. can passed model_parameters() related functions obtain standard errors, p-values, etc.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"breaking-changes-0-12-0","dir":"Changelog","previous_headings":"","what":"Breaking changes","title":"parameters 0.12.0","text":"model_parameters() now always returns confidence level additional CI column. rule argument equivalenct_test() defaults \"classic\".","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"new-supported-model-classes-0-12-0","dir":"Changelog","previous_headings":"","what":"New supported model classes","title":"parameters 0.12.0","text":"crr (cmprsk), leveneTest() (car), varest (vars), ergm (ergm), btergm (btergm), Rchoice (Rchoice), garch (tseries)","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"new-functions-0-12-0","dir":"Changelog","previous_headings":"","what":"New functions","title":"parameters 0.12.0","text":"compare_parameters() (alias compare_models()) show / print parameters multiple models one table.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"changes-to-functions-0-12-0","dir":"Changelog","previous_headings":"","what":"Changes to functions","title":"parameters 0.12.0","text":"Estimation bootstrapped p-values re-written accurate. model_parameters() mixed models gains effects-argument, return fixed, random fixed random effects parameters. Revised printing model_parameters() metafor models. model_parameters() metafor models now recognized confidence levels specified function call (via argument level). Improved support effect sizes model_parameters() anova objects.","code":""},{"path":"https://easystats.github.io/parameters/news/index.html","id":"bug-fixes-0-12-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"parameters 0.12.0","text":"Fixed edge case formatting parameters polynomial terms many degrees. Fixed issue random sampling dropped factor levels bootstrap_model().","code":""}]
